; ModuleID = 'crypto/ec/curve25519.c'
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.11.0"

; Function Attrs: nounwind ssp uwtable
define void @fe51_invert(i64* nocapture %out, i64* nocapture readonly %z) #0 {
entry:
  %t0 = alloca [5 x i64], align 16
  %t1 = alloca [5 x i64], align 16
  %t2 = alloca [5 x i64], align 16
  %t3 = alloca [5 x i64], align 16
  %0 = bitcast [5 x i64]* %t0 to i8*
  call void @llvm.lifetime.start(i64 40, i8* %0) #1
  %1 = bitcast [5 x i64]* %t1 to i8*
  call void @llvm.lifetime.start(i64 40, i8* %1) #1
  %2 = bitcast [5 x i64]* %t2 to i8*
  call void @llvm.lifetime.start(i64 40, i8* %2) #1
  %3 = bitcast [5 x i64]* %t3 to i8*
  call void @llvm.lifetime.start(i64 40, i8* %3) #1
  %arraydecay = getelementptr inbounds [5 x i64], [5 x i64]* %t0, i64 0, i64 0
  %4 = load i64, i64* %z, align 8, !tbaa !5
  %arrayidx1.i = getelementptr inbounds i64, i64* %z, i64 1
  %5 = load i64, i64* %arrayidx1.i, align 8, !tbaa !5
  %arrayidx2.i = getelementptr inbounds i64, i64* %z, i64 2
  %6 = load i64, i64* %arrayidx2.i, align 8, !tbaa !5
  %arrayidx3.i = getelementptr inbounds i64, i64* %z, i64 3
  %7 = load i64, i64* %arrayidx3.i, align 8, !tbaa !5
  %arrayidx4.i = getelementptr inbounds i64, i64* %z, i64 4
  %8 = load i64, i64* %arrayidx4.i, align 8, !tbaa !5
  %conv.i = zext i64 %4 to i128
  %mul.i = mul nuw i128 %conv.i, %conv.i
  %mul6.i = shl i64 %4, 1
  %conv7.i = zext i64 %mul6.i to i128
  %conv8.i = zext i64 %5 to i128
  %mul9.i = mul nuw i128 %conv7.i, %conv8.i
  %conv11.i = zext i64 %6 to i128
  %mul12.i = mul nuw i128 %conv11.i, %conv7.i
  %conv14.i = zext i64 %7 to i128
  %mul15.i = mul nuw i128 %conv14.i, %conv7.i
  %conv17.i = zext i64 %8 to i128
  %mul18.i = mul nuw i128 %conv17.i, %conv7.i
  %mul20.i = mul i64 %8, 19
  %conv21.i = zext i64 %mul20.i to i128
  %mul22.i = mul nuw i128 %conv21.i, %conv17.i
  %mul25.i = mul nuw i128 %conv8.i, %conv8.i
  %add26.i = add i128 %mul12.i, %mul25.i
  %mul27.i = shl i64 %5, 1
  %conv28.i = zext i64 %mul27.i to i128
  %mul30.i = mul nuw i128 %conv28.i, %conv11.i
  %mul34.i = mul nuw i128 %conv14.i, %conv28.i
  %mul38.i = mul nuw i128 %conv21.i, %conv28.i
  %mul41.i = mul i64 %7, 19
  %conv42.i = zext i64 %mul41.i to i128
  %mul43.i = mul nuw i128 %conv42.i, %conv14.i
  %add44.i = add i128 %mul43.i, %mul9.i
  %mul45.i = shl i64 %7, 1
  %conv46.i = zext i64 %mul45.i to i128
  %mul48.i = mul nuw i128 %conv21.i, %conv46.i
  %add49.i = add i128 %add26.i, %mul48.i
  %mul52.i = mul nuw i128 %conv11.i, %conv11.i
  %mul54.i = shl i64 %6, 1
  %conv55.i = zext i64 %mul54.i to i128
  %mul57.i = mul nuw i128 %conv42.i, %conv55.i
  %add39.i = add i128 %mul57.i, %mul.i
  %add58.i = add i128 %add39.i, %mul38.i
  %mul61.i = mul nuw i128 %conv21.i, %conv55.i
  %add62.i = add i128 %add44.i, %mul61.i
  %shr.i = lshr i128 %add49.i, 51
  %conv64.i = and i128 %shr.i, 18446744073709551615
  %add.i = add i128 %mul15.i, %mul30.i
  %add31.i = add i128 %add.i, %mul22.i
  %add65.i = add i128 %add31.i, %conv64.i
  %conv66.i = trunc i128 %add49.i to i64
  %and.i = and i64 %conv66.i, 2251799813685247
  %shr67.i = lshr i128 %add58.i, 51
  %conv69.i = and i128 %shr67.i, 18446744073709551615
  %add70.i = add i128 %add62.i, %conv69.i
  %conv71.i = trunc i128 %add58.i to i64
  %and72.i = and i64 %conv71.i, 2251799813685247
  %shr73.i = lshr i128 %add65.i, 51
  %conv75.i = and i128 %shr73.i, 18446744073709551615
  %add35.i = add i128 %mul34.i, %mul52.i
  %add53.i = add i128 %add35.i, %mul18.i
  %add76.i = add i128 %add53.i, %conv75.i
  %conv77.i = trunc i128 %add65.i to i64
  %and78.i = and i64 %conv77.i, 2251799813685247
  %shr79.i = lshr i128 %add70.i, 51
  %conv80.i = trunc i128 %shr79.i to i64
  %add81.i = add i64 %conv80.i, %and.i
  %conv82.i = trunc i128 %add70.i to i64
  %and83.i = and i64 %conv82.i, 2251799813685247
  %shr84.i = lshr i128 %add76.i, 51
  %conv85.i = trunc i128 %shr84.i to i64
  %mul86.i = mul i64 %conv85.i, 19
  %add87.i = add i64 %mul86.i, %and72.i
  %conv88.i = trunc i128 %add76.i to i64
  %and89.i = and i64 %conv88.i, 2251799813685247
  %shr90.i = lshr i64 %add81.i, 51
  %add91.i = add nuw nsw i64 %shr90.i, %and78.i
  %fold.i = add i64 %conv80.i, %conv66.i
  %and92.i = and i64 %fold.i, 2251799813685247
  %shr93.i = lshr i64 %add87.i, 51
  %add94.i = add nuw nsw i64 %shr93.i, %and83.i
  %fold180.i = add i64 %mul86.i, %conv71.i
  %and95.i = and i64 %fold180.i, 2251799813685247
  store i64 %and95.i, i64* %arraydecay, align 16, !tbaa !5
  %arrayidx97.i = getelementptr inbounds [5 x i64], [5 x i64]* %t0, i64 0, i64 1
  store i64 %add94.i, i64* %arrayidx97.i, align 8, !tbaa !5
  %arrayidx98.i = getelementptr inbounds [5 x i64], [5 x i64]* %t0, i64 0, i64 2
  store i64 %and92.i, i64* %arrayidx98.i, align 16, !tbaa !5
  %arrayidx99.i = getelementptr inbounds [5 x i64], [5 x i64]* %t0, i64 0, i64 3
  store i64 %add91.i, i64* %arrayidx99.i, align 8, !tbaa !5
  %arrayidx100.i = getelementptr inbounds [5 x i64], [5 x i64]* %t0, i64 0, i64 4
  store i64 %and89.i, i64* %arrayidx100.i, align 16, !tbaa !5
  %arraydecay1 = getelementptr inbounds [5 x i64], [5 x i64]* %t1, i64 0, i64 0
  %conv.i.127 = zext i64 %and95.i to i128
  %mul.i.128 = mul nuw nsw i128 %conv.i.127, %conv.i.127
  %mul6.i.129 = shl nuw nsw i64 %and95.i, 1
  %conv7.i.130 = zext i64 %mul6.i.129 to i128
  %conv8.i.131 = zext i64 %add94.i to i128
  %mul9.i.132 = mul nuw nsw i128 %conv7.i.130, %conv8.i.131
  %conv11.i.133 = zext i64 %and92.i to i128
  %mul12.i.134 = mul nuw nsw i128 %conv11.i.133, %conv7.i.130
  %conv14.i.135 = zext i64 %add91.i to i128
  %mul15.i.136 = mul nuw nsw i128 %conv14.i.135, %conv7.i.130
  %conv17.i.137 = zext i64 %and89.i to i128
  %mul18.i.138 = mul nuw nsw i128 %conv17.i.137, %conv7.i.130
  %mul20.i.139 = mul nuw nsw i64 %and89.i, 19
  %conv21.i.140 = zext i64 %mul20.i.139 to i128
  %mul22.i.141 = mul nuw nsw i128 %conv21.i.140, %conv17.i.137
  %mul25.i.142 = mul nuw nsw i128 %conv8.i.131, %conv8.i.131
  %add26.i.143 = add nuw nsw i128 %mul12.i.134, %mul25.i.142
  %mul27.i.144 = shl nuw nsw i64 %add94.i, 1
  %conv28.i.145 = zext i64 %mul27.i.144 to i128
  %mul30.i.146 = mul nuw nsw i128 %conv28.i.145, %conv11.i.133
  %mul34.i.147 = mul nuw nsw i128 %conv14.i.135, %conv28.i.145
  %mul38.i.148 = mul nuw nsw i128 %conv21.i.140, %conv28.i.145
  %mul41.i.149 = mul nuw nsw i64 %add91.i, 19
  %conv42.i.150 = zext i64 %mul41.i.149 to i128
  %mul43.i.151 = mul nuw nsw i128 %conv42.i.150, %conv14.i.135
  %add44.i.152 = add nuw nsw i128 %mul43.i.151, %mul9.i.132
  %mul45.i.153 = shl nuw nsw i64 %add91.i, 1
  %conv46.i.154 = zext i64 %mul45.i.153 to i128
  %mul48.i.155 = mul nuw nsw i128 %conv21.i.140, %conv46.i.154
  %add49.i.156 = add nuw nsw i128 %add26.i.143, %mul48.i.155
  %mul52.i.157 = mul nuw nsw i128 %conv11.i.133, %conv11.i.133
  %mul54.i.158 = shl nuw nsw i64 %and92.i, 1
  %conv55.i.159 = zext i64 %mul54.i.158 to i128
  %mul57.i.160 = mul nuw nsw i128 %conv42.i.150, %conv55.i.159
  %add39.i.161 = add nuw nsw i128 %mul57.i.160, %mul.i.128
  %add58.i.162 = add nuw nsw i128 %add39.i.161, %mul38.i.148
  %mul61.i.163 = mul nuw nsw i128 %conv21.i.140, %conv55.i.159
  %add62.i.164 = add nuw nsw i128 %add44.i.152, %mul61.i.163
  %shr.i.165 = lshr i128 %add49.i.156, 51
  %conv64.i.166 = and i128 %shr.i.165, 18446744073709551615
  %add.i.167 = add nuw nsw i128 %mul15.i.136, %mul30.i.146
  %add31.i.168 = add nuw nsw i128 %add.i.167, %mul22.i.141
  %add65.i.169 = add nuw nsw i128 %add31.i.168, %conv64.i.166
  %conv66.i.170 = trunc i128 %add49.i.156 to i64
  %and.i.171 = and i64 %conv66.i.170, 2251799813685247
  %shr67.i.172 = lshr i128 %add58.i.162, 51
  %conv69.i.173 = and i128 %shr67.i.172, 18446744073709551615
  %add70.i.174 = add nuw nsw i128 %add62.i.164, %conv69.i.173
  %conv71.i.175 = trunc i128 %add58.i.162 to i64
  %and72.i.176 = and i64 %conv71.i.175, 2251799813685247
  %shr73.i.177 = lshr i128 %add65.i.169, 51
  %conv75.i.178 = and i128 %shr73.i.177, 18446744073709551615
  %add35.i.179 = add nuw nsw i128 %mul34.i.147, %mul52.i.157
  %add53.i.180 = add nuw nsw i128 %add35.i.179, %mul18.i.138
  %add76.i.181 = add nuw nsw i128 %add53.i.180, %conv75.i.178
  %conv77.i.182 = trunc i128 %add65.i.169 to i64
  %and78.i.183 = and i64 %conv77.i.182, 2251799813685247
  %shr79.i.184 = lshr i128 %add70.i.174, 51
  %conv80.i.185 = trunc i128 %shr79.i.184 to i64
  %add81.i.186 = add i64 %conv80.i.185, %and.i.171
  %conv82.i.187 = trunc i128 %add70.i.174 to i64
  %and83.i.188 = and i64 %conv82.i.187, 2251799813685247
  %shr84.i.189 = lshr i128 %add76.i.181, 51
  %conv85.i.190 = trunc i128 %shr84.i.189 to i64
  %mul86.i.191 = mul i64 %conv85.i.190, 19
  %add87.i.192 = add i64 %mul86.i.191, %and72.i.176
  %conv88.i.193 = trunc i128 %add76.i.181 to i64
  %and89.i.194 = and i64 %conv88.i.193, 2251799813685247
  %shr90.i.195 = lshr i64 %add81.i.186, 51
  %add91.i.196 = add nuw nsw i64 %shr90.i.195, %and78.i.183
  %fold.i.197 = add i64 %conv80.i.185, %conv66.i.170
  %and92.i.198 = and i64 %fold.i.197, 2251799813685247
  %shr93.i.199 = lshr i64 %add87.i.192, 51
  %add94.i.200 = add nuw nsw i64 %shr93.i.199, %and83.i.188
  %fold180.i.201 = add i64 %mul86.i.191, %conv71.i.175
  %and95.i.202 = and i64 %fold180.i.201, 2251799813685247
  %arrayidx97.i.203 = getelementptr inbounds [5 x i64], [5 x i64]* %t1, i64 0, i64 1
  %arrayidx98.i.204 = getelementptr inbounds [5 x i64], [5 x i64]* %t1, i64 0, i64 2
  %arrayidx99.i.205 = getelementptr inbounds [5 x i64], [5 x i64]* %t1, i64 0, i64 3
  %arrayidx100.i.206 = getelementptr inbounds [5 x i64], [5 x i64]* %t1, i64 0, i64 4
  %conv.i.295 = zext i64 %and95.i.202 to i128
  %mul.i.296 = mul nuw nsw i128 %conv.i.295, %conv.i.295
  %mul6.i.297 = shl nuw nsw i64 %and95.i.202, 1
  %conv7.i.298 = zext i64 %mul6.i.297 to i128
  %conv8.i.299 = zext i64 %add94.i.200 to i128
  %mul9.i.300 = mul nuw nsw i128 %conv7.i.298, %conv8.i.299
  %conv11.i.301 = zext i64 %and92.i.198 to i128
  %mul12.i.302 = mul nuw nsw i128 %conv11.i.301, %conv7.i.298
  %conv14.i.303 = zext i64 %add91.i.196 to i128
  %mul15.i.304 = mul nuw nsw i128 %conv14.i.303, %conv7.i.298
  %conv17.i.305 = zext i64 %and89.i.194 to i128
  %mul18.i.306 = mul nuw nsw i128 %conv17.i.305, %conv7.i.298
  %mul20.i.307 = mul nuw nsw i64 %and89.i.194, 19
  %conv21.i.308 = zext i64 %mul20.i.307 to i128
  %mul22.i.309 = mul nuw nsw i128 %conv21.i.308, %conv17.i.305
  %mul25.i.310 = mul nuw nsw i128 %conv8.i.299, %conv8.i.299
  %add26.i.311 = add nuw nsw i128 %mul12.i.302, %mul25.i.310
  %mul27.i.312 = shl nuw nsw i64 %add94.i.200, 1
  %conv28.i.313 = zext i64 %mul27.i.312 to i128
  %mul30.i.314 = mul nuw nsw i128 %conv28.i.313, %conv11.i.301
  %mul34.i.315 = mul nuw nsw i128 %conv14.i.303, %conv28.i.313
  %mul38.i.316 = mul nuw nsw i128 %conv21.i.308, %conv28.i.313
  %mul41.i.317 = mul nuw nsw i64 %add91.i.196, 19
  %conv42.i.318 = zext i64 %mul41.i.317 to i128
  %mul43.i.319 = mul nuw nsw i128 %conv42.i.318, %conv14.i.303
  %add44.i.320 = add nuw nsw i128 %mul43.i.319, %mul9.i.300
  %mul45.i.321 = shl nuw nsw i64 %add91.i.196, 1
  %conv46.i.322 = zext i64 %mul45.i.321 to i128
  %mul48.i.323 = mul nuw nsw i128 %conv21.i.308, %conv46.i.322
  %add49.i.324 = add nuw nsw i128 %add26.i.311, %mul48.i.323
  %mul52.i.325 = mul nuw nsw i128 %conv11.i.301, %conv11.i.301
  %mul54.i.326 = shl nuw nsw i64 %and92.i.198, 1
  %conv55.i.327 = zext i64 %mul54.i.326 to i128
  %mul57.i.328 = mul nuw nsw i128 %conv42.i.318, %conv55.i.327
  %add39.i.329 = add nuw nsw i128 %mul57.i.328, %mul.i.296
  %add58.i.330 = add nuw nsw i128 %add39.i.329, %mul38.i.316
  %mul61.i.331 = mul nuw nsw i128 %conv21.i.308, %conv55.i.327
  %add62.i.332 = add nuw nsw i128 %add44.i.320, %mul61.i.331
  %shr.i.333 = lshr i128 %add49.i.324, 51
  %conv64.i.334 = and i128 %shr.i.333, 18446744073709551615
  %add.i.335 = add nuw nsw i128 %mul15.i.304, %mul30.i.314
  %add31.i.336 = add nuw nsw i128 %add.i.335, %mul22.i.309
  %add65.i.337 = add nuw nsw i128 %add31.i.336, %conv64.i.334
  %conv66.i.338 = trunc i128 %add49.i.324 to i64
  %and.i.339 = and i64 %conv66.i.338, 2251799813685247
  %shr67.i.340 = lshr i128 %add58.i.330, 51
  %conv69.i.341 = and i128 %shr67.i.340, 18446744073709551615
  %add70.i.342 = add nuw nsw i128 %add62.i.332, %conv69.i.341
  %conv71.i.343 = trunc i128 %add58.i.330 to i64
  %and72.i.344 = and i64 %conv71.i.343, 2251799813685247
  %shr73.i.345 = lshr i128 %add65.i.337, 51
  %conv75.i.346 = and i128 %shr73.i.345, 18446744073709551615
  %add35.i.347 = add nuw nsw i128 %mul34.i.315, %mul52.i.325
  %add53.i.348 = add nuw nsw i128 %add35.i.347, %mul18.i.306
  %add76.i.349 = add nuw nsw i128 %add53.i.348, %conv75.i.346
  %conv77.i.350 = trunc i128 %add65.i.337 to i64
  %and78.i.351 = and i64 %conv77.i.350, 2251799813685247
  %shr79.i.352 = lshr i128 %add70.i.342, 51
  %conv80.i.353 = trunc i128 %shr79.i.352 to i64
  %add81.i.354 = add i64 %conv80.i.353, %and.i.339
  %conv82.i.355 = trunc i128 %add70.i.342 to i64
  %and83.i.356 = and i64 %conv82.i.355, 2251799813685247
  %shr84.i.357 = lshr i128 %add76.i.349, 51
  %conv85.i.358 = trunc i128 %shr84.i.357 to i64
  %mul86.i.359 = mul i64 %conv85.i.358, 19
  %add87.i.360 = add i64 %mul86.i.359, %and72.i.344
  %conv88.i.361 = trunc i128 %add76.i.349 to i64
  %and89.i.362 = and i64 %conv88.i.361, 2251799813685247
  %shr90.i.363 = lshr i64 %add81.i.354, 51
  %add91.i.364 = add nuw nsw i64 %shr90.i.363, %and78.i.351
  %fold.i.365 = add i64 %conv80.i.353, %conv66.i.338
  %and92.i.366 = and i64 %fold.i.365, 2251799813685247
  %shr93.i.367 = lshr i64 %add87.i.360, 51
  %add94.i.368 = add nuw nsw i64 %shr93.i.367, %and83.i.356
  %fold180.i.369 = add i64 %mul86.i.359, %conv71.i.343
  %and95.i.370 = and i64 %fold180.i.369, 2251799813685247
  store i64 %and95.i.370, i64* %arraydecay1, align 16, !tbaa !5
  store i64 %add94.i.368, i64* %arrayidx97.i.203, align 8, !tbaa !5
  store i64 %and92.i.366, i64* %arrayidx98.i.204, align 16, !tbaa !5
  store i64 %add91.i.364, i64* %arrayidx99.i.205, align 8, !tbaa !5
  store i64 %and89.i.362, i64* %arrayidx100.i.206, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay1, i64* %z, i64* %arraydecay1)
  call void @fe51_mul(i64* %arraydecay, i64* %arraydecay, i64* %arraydecay1)
  %arraydecay10 = getelementptr inbounds [5 x i64], [5 x i64]* %t2, i64 0, i64 0
  %9 = load i64, i64* %arraydecay, align 16, !tbaa !5
  %10 = load i64, i64* %arrayidx97.i, align 8, !tbaa !5
  %11 = load i64, i64* %arrayidx98.i, align 16, !tbaa !5
  %12 = load i64, i64* %arrayidx99.i, align 8, !tbaa !5
  %13 = load i64, i64* %arrayidx100.i, align 16, !tbaa !5
  %conv.i.463 = zext i64 %9 to i128
  %mul.i.464 = mul nuw i128 %conv.i.463, %conv.i.463
  %mul6.i.465 = shl i64 %9, 1
  %conv7.i.466 = zext i64 %mul6.i.465 to i128
  %conv8.i.467 = zext i64 %10 to i128
  %mul9.i.468 = mul nuw i128 %conv7.i.466, %conv8.i.467
  %conv11.i.469 = zext i64 %11 to i128
  %mul12.i.470 = mul nuw i128 %conv11.i.469, %conv7.i.466
  %conv14.i.471 = zext i64 %12 to i128
  %mul15.i.472 = mul nuw i128 %conv14.i.471, %conv7.i.466
  %conv17.i.473 = zext i64 %13 to i128
  %mul18.i.474 = mul nuw i128 %conv17.i.473, %conv7.i.466
  %mul20.i.475 = mul i64 %13, 19
  %conv21.i.476 = zext i64 %mul20.i.475 to i128
  %mul22.i.477 = mul nuw i128 %conv21.i.476, %conv17.i.473
  %mul25.i.478 = mul nuw i128 %conv8.i.467, %conv8.i.467
  %add26.i.479 = add i128 %mul12.i.470, %mul25.i.478
  %mul27.i.480 = shl i64 %10, 1
  %conv28.i.481 = zext i64 %mul27.i.480 to i128
  %mul30.i.482 = mul nuw i128 %conv28.i.481, %conv11.i.469
  %mul34.i.483 = mul nuw i128 %conv14.i.471, %conv28.i.481
  %mul38.i.484 = mul nuw i128 %conv21.i.476, %conv28.i.481
  %mul41.i.485 = mul i64 %12, 19
  %conv42.i.486 = zext i64 %mul41.i.485 to i128
  %mul43.i.487 = mul nuw i128 %conv42.i.486, %conv14.i.471
  %add44.i.488 = add i128 %mul43.i.487, %mul9.i.468
  %mul45.i.489 = shl i64 %12, 1
  %conv46.i.490 = zext i64 %mul45.i.489 to i128
  %mul48.i.491 = mul nuw i128 %conv21.i.476, %conv46.i.490
  %add49.i.492 = add i128 %add26.i.479, %mul48.i.491
  %mul52.i.493 = mul nuw i128 %conv11.i.469, %conv11.i.469
  %mul54.i.494 = shl i64 %11, 1
  %conv55.i.495 = zext i64 %mul54.i.494 to i128
  %mul57.i.496 = mul nuw i128 %conv42.i.486, %conv55.i.495
  %add39.i.497 = add i128 %mul57.i.496, %mul.i.464
  %add58.i.498 = add i128 %add39.i.497, %mul38.i.484
  %mul61.i.499 = mul nuw i128 %conv21.i.476, %conv55.i.495
  %add62.i.500 = add i128 %add44.i.488, %mul61.i.499
  %shr.i.501 = lshr i128 %add49.i.492, 51
  %conv64.i.502 = and i128 %shr.i.501, 18446744073709551615
  %add.i.503 = add i128 %mul15.i.472, %mul30.i.482
  %add31.i.504 = add i128 %add.i.503, %mul22.i.477
  %add65.i.505 = add i128 %add31.i.504, %conv64.i.502
  %conv66.i.506 = trunc i128 %add49.i.492 to i64
  %and.i.507 = and i64 %conv66.i.506, 2251799813685247
  %shr67.i.508 = lshr i128 %add58.i.498, 51
  %conv69.i.509 = and i128 %shr67.i.508, 18446744073709551615
  %add70.i.510 = add i128 %add62.i.500, %conv69.i.509
  %conv71.i.511 = trunc i128 %add58.i.498 to i64
  %and72.i.512 = and i64 %conv71.i.511, 2251799813685247
  %shr73.i.513 = lshr i128 %add65.i.505, 51
  %conv75.i.514 = and i128 %shr73.i.513, 18446744073709551615
  %add35.i.515 = add i128 %mul34.i.483, %mul52.i.493
  %add53.i.516 = add i128 %add35.i.515, %mul18.i.474
  %add76.i.517 = add i128 %add53.i.516, %conv75.i.514
  %conv77.i.518 = trunc i128 %add65.i.505 to i64
  %and78.i.519 = and i64 %conv77.i.518, 2251799813685247
  %shr79.i.520 = lshr i128 %add70.i.510, 51
  %conv80.i.521 = trunc i128 %shr79.i.520 to i64
  %add81.i.522 = add i64 %conv80.i.521, %and.i.507
  %conv82.i.523 = trunc i128 %add70.i.510 to i64
  %and83.i.524 = and i64 %conv82.i.523, 2251799813685247
  %shr84.i.525 = lshr i128 %add76.i.517, 51
  %conv85.i.526 = trunc i128 %shr84.i.525 to i64
  %mul86.i.527 = mul i64 %conv85.i.526, 19
  %add87.i.528 = add i64 %mul86.i.527, %and72.i.512
  %conv88.i.529 = trunc i128 %add76.i.517 to i64
  %and89.i.530 = and i64 %conv88.i.529, 2251799813685247
  %shr90.i.531 = lshr i64 %add81.i.522, 51
  %add91.i.532 = add nuw nsw i64 %shr90.i.531, %and78.i.519
  %fold.i.533 = add i64 %conv80.i.521, %conv66.i.506
  %and92.i.534 = and i64 %fold.i.533, 2251799813685247
  %shr93.i.535 = lshr i64 %add87.i.528, 51
  %add94.i.536 = add nuw nsw i64 %shr93.i.535, %and83.i.524
  %fold180.i.537 = add i64 %mul86.i.527, %conv71.i.511
  %and95.i.538 = and i64 %fold180.i.537, 2251799813685247
  store i64 %and95.i.538, i64* %arraydecay10, align 16, !tbaa !5
  %arrayidx97.i.539 = getelementptr inbounds [5 x i64], [5 x i64]* %t2, i64 0, i64 1
  store i64 %add94.i.536, i64* %arrayidx97.i.539, align 8, !tbaa !5
  %arrayidx98.i.540 = getelementptr inbounds [5 x i64], [5 x i64]* %t2, i64 0, i64 2
  store i64 %and92.i.534, i64* %arrayidx98.i.540, align 16, !tbaa !5
  %arrayidx99.i.541 = getelementptr inbounds [5 x i64], [5 x i64]* %t2, i64 0, i64 3
  store i64 %add91.i.532, i64* %arrayidx99.i.541, align 8, !tbaa !5
  %arrayidx100.i.542 = getelementptr inbounds [5 x i64], [5 x i64]* %t2, i64 0, i64 4
  store i64 %and89.i.530, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay1, i64* %arraydecay1, i64* %arraydecay10)
  %14 = load i64, i64* %arraydecay1, align 16, !tbaa !5
  %15 = load i64, i64* %arrayidx97.i.203, align 8, !tbaa !5
  %16 = load i64, i64* %arrayidx98.i.204, align 16, !tbaa !5
  %17 = load i64, i64* %arrayidx99.i.205, align 8, !tbaa !5
  %18 = load i64, i64* %arrayidx100.i.206, align 16, !tbaa !5
  %conv.i.715 = zext i64 %14 to i128
  %mul.i.716 = mul nuw i128 %conv.i.715, %conv.i.715
  %mul6.i.717 = shl i64 %14, 1
  %conv7.i.718 = zext i64 %mul6.i.717 to i128
  %conv8.i.719 = zext i64 %15 to i128
  %mul9.i.720 = mul nuw i128 %conv7.i.718, %conv8.i.719
  %conv11.i.721 = zext i64 %16 to i128
  %mul12.i.722 = mul nuw i128 %conv11.i.721, %conv7.i.718
  %conv14.i.723 = zext i64 %17 to i128
  %mul15.i.724 = mul nuw i128 %conv14.i.723, %conv7.i.718
  %conv17.i.725 = zext i64 %18 to i128
  %mul18.i.726 = mul nuw i128 %conv17.i.725, %conv7.i.718
  %mul20.i.727 = mul i64 %18, 19
  %conv21.i.728 = zext i64 %mul20.i.727 to i128
  %mul22.i.729 = mul nuw i128 %conv21.i.728, %conv17.i.725
  %mul25.i.730 = mul nuw i128 %conv8.i.719, %conv8.i.719
  %add26.i.731 = add i128 %mul12.i.722, %mul25.i.730
  %mul27.i.732 = shl i64 %15, 1
  %conv28.i.733 = zext i64 %mul27.i.732 to i128
  %mul30.i.734 = mul nuw i128 %conv28.i.733, %conv11.i.721
  %mul34.i.735 = mul nuw i128 %conv14.i.723, %conv28.i.733
  %mul38.i.736 = mul nuw i128 %conv21.i.728, %conv28.i.733
  %mul41.i.737 = mul i64 %17, 19
  %conv42.i.738 = zext i64 %mul41.i.737 to i128
  %mul43.i.739 = mul nuw i128 %conv42.i.738, %conv14.i.723
  %add44.i.740 = add i128 %mul43.i.739, %mul9.i.720
  %mul45.i.741 = shl i64 %17, 1
  %conv46.i.742 = zext i64 %mul45.i.741 to i128
  %mul48.i.743 = mul nuw i128 %conv21.i.728, %conv46.i.742
  %add49.i.744 = add i128 %add26.i.731, %mul48.i.743
  %mul52.i.745 = mul nuw i128 %conv11.i.721, %conv11.i.721
  %mul54.i.746 = shl i64 %16, 1
  %conv55.i.747 = zext i64 %mul54.i.746 to i128
  %mul57.i.748 = mul nuw i128 %conv42.i.738, %conv55.i.747
  %add39.i.749 = add i128 %mul57.i.748, %mul.i.716
  %add58.i.750 = add i128 %add39.i.749, %mul38.i.736
  %mul61.i.751 = mul nuw i128 %conv21.i.728, %conv55.i.747
  %add62.i.752 = add i128 %add44.i.740, %mul61.i.751
  %shr.i.753 = lshr i128 %add49.i.744, 51
  %conv64.i.754 = and i128 %shr.i.753, 18446744073709551615
  %add.i.755 = add i128 %mul15.i.724, %mul30.i.734
  %add31.i.756 = add i128 %add.i.755, %mul22.i.729
  %add65.i.757 = add i128 %add31.i.756, %conv64.i.754
  %conv66.i.758 = trunc i128 %add49.i.744 to i64
  %and.i.759 = and i64 %conv66.i.758, 2251799813685247
  %shr67.i.760 = lshr i128 %add58.i.750, 51
  %conv69.i.761 = and i128 %shr67.i.760, 18446744073709551615
  %add70.i.762 = add i128 %add62.i.752, %conv69.i.761
  %conv71.i.763 = trunc i128 %add58.i.750 to i64
  %and72.i.764 = and i64 %conv71.i.763, 2251799813685247
  %shr73.i.765 = lshr i128 %add65.i.757, 51
  %conv75.i.766 = and i128 %shr73.i.765, 18446744073709551615
  %add35.i.767 = add i128 %mul34.i.735, %mul52.i.745
  %add53.i.768 = add i128 %add35.i.767, %mul18.i.726
  %add76.i.769 = add i128 %add53.i.768, %conv75.i.766
  %conv77.i.770 = trunc i128 %add65.i.757 to i64
  %and78.i.771 = and i64 %conv77.i.770, 2251799813685247
  %shr79.i.772 = lshr i128 %add70.i.762, 51
  %conv80.i.773 = trunc i128 %shr79.i.772 to i64
  %add81.i.774 = add i64 %conv80.i.773, %and.i.759
  %conv82.i.775 = trunc i128 %add70.i.762 to i64
  %and83.i.776 = and i64 %conv82.i.775, 2251799813685247
  %shr84.i.777 = lshr i128 %add76.i.769, 51
  %conv85.i.778 = trunc i128 %shr84.i.777 to i64
  %mul86.i.779 = mul i64 %conv85.i.778, 19
  %add87.i.780 = add i64 %mul86.i.779, %and72.i.764
  %conv88.i.781 = trunc i128 %add76.i.769 to i64
  %and89.i.782 = and i64 %conv88.i.781, 2251799813685247
  %shr90.i.783 = lshr i64 %add81.i.774, 51
  %add91.i.784 = add nuw nsw i64 %shr90.i.783, %and78.i.771
  %fold.i.785 = add i64 %conv80.i.773, %conv66.i.758
  %and92.i.786 = and i64 %fold.i.785, 2251799813685247
  %shr93.i.787 = lshr i64 %add87.i.780, 51
  %add94.i.788 = add nuw nsw i64 %shr93.i.787, %and83.i.776
  %fold180.i.789 = add i64 %mul86.i.779, %conv71.i.763
  %and95.i.790 = and i64 %fold180.i.789, 2251799813685247
  store i64 %and95.i.790, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.788, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.786, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.784, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.782, i64* %arrayidx100.i.542, align 16, !tbaa !5
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %19 = phi i64 [ %and89.i.782, %entry ], [ %and89.i.1034, %for.body ]
  %20 = phi i64 [ %add91.i.784, %entry ], [ %add91.i.1036, %for.body ]
  %21 = phi i64 [ %and92.i.786, %entry ], [ %and92.i.1038, %for.body ]
  %22 = phi i64 [ %add94.i.788, %entry ], [ %add94.i.1040, %for.body ]
  %and95.i.10421503 = phi i64 [ %and95.i.790, %entry ], [ %and95.i.1042, %for.body ]
  %i.01501 = phi i32 [ 1, %entry ], [ %inc, %for.body ]
  %conv.i.967 = zext i64 %and95.i.10421503 to i128
  %mul.i.968 = mul nuw nsw i128 %conv.i.967, %conv.i.967
  %mul6.i.969 = shl nuw nsw i64 %and95.i.10421503, 1
  %conv7.i.970 = zext i64 %mul6.i.969 to i128
  %conv8.i.971 = zext i64 %22 to i128
  %mul9.i.972 = mul nuw nsw i128 %conv7.i.970, %conv8.i.971
  %conv11.i.973 = zext i64 %21 to i128
  %mul12.i.974 = mul nuw nsw i128 %conv11.i.973, %conv7.i.970
  %conv14.i.975 = zext i64 %20 to i128
  %mul15.i.976 = mul nuw nsw i128 %conv14.i.975, %conv7.i.970
  %conv17.i.977 = zext i64 %19 to i128
  %mul18.i.978 = mul nuw nsw i128 %conv17.i.977, %conv7.i.970
  %mul20.i.979 = mul nuw nsw i64 %19, 19
  %conv21.i.980 = zext i64 %mul20.i.979 to i128
  %mul22.i.981 = mul nuw nsw i128 %conv21.i.980, %conv17.i.977
  %mul25.i.982 = mul nuw i128 %conv8.i.971, %conv8.i.971
  %add26.i.983 = add i128 %mul12.i.974, %mul25.i.982
  %mul27.i.984 = shl nsw i64 %22, 1
  %conv28.i.985 = zext i64 %mul27.i.984 to i128
  %mul30.i.986 = mul nuw nsw i128 %conv28.i.985, %conv11.i.973
  %mul34.i.987 = mul nuw i128 %conv14.i.975, %conv28.i.985
  %mul38.i.988 = mul nuw nsw i128 %conv21.i.980, %conv28.i.985
  %mul41.i.989 = mul nsw i64 %20, 19
  %conv42.i.990 = zext i64 %mul41.i.989 to i128
  %mul43.i.991 = mul nuw i128 %conv42.i.990, %conv14.i.975
  %add44.i.992 = add i128 %mul43.i.991, %mul9.i.972
  %mul45.i.993 = shl nsw i64 %20, 1
  %conv46.i.994 = zext i64 %mul45.i.993 to i128
  %mul48.i.995 = mul nuw nsw i128 %conv21.i.980, %conv46.i.994
  %add49.i.996 = add i128 %add26.i.983, %mul48.i.995
  %mul52.i.997 = mul nuw nsw i128 %conv11.i.973, %conv11.i.973
  %mul54.i.998 = shl nuw nsw i64 %21, 1
  %conv55.i.999 = zext i64 %mul54.i.998 to i128
  %mul57.i.1000 = mul nuw nsw i128 %conv42.i.990, %conv55.i.999
  %add39.i.1001 = add nuw nsw i128 %mul57.i.1000, %mul.i.968
  %add58.i.1002 = add nuw nsw i128 %add39.i.1001, %mul38.i.988
  %mul61.i.1003 = mul nuw nsw i128 %conv21.i.980, %conv55.i.999
  %add62.i.1004 = add i128 %add44.i.992, %mul61.i.1003
  %shr.i.1005 = lshr i128 %add49.i.996, 51
  %conv64.i.1006 = and i128 %shr.i.1005, 18446744073709551615
  %add.i.1007 = add nuw nsw i128 %mul15.i.976, %mul30.i.986
  %add31.i.1008 = add nuw nsw i128 %add.i.1007, %mul22.i.981
  %add65.i.1009 = add nuw i128 %add31.i.1008, %conv64.i.1006
  %conv66.i.1010 = trunc i128 %add49.i.996 to i64
  %and.i.1011 = and i64 %conv66.i.1010, 2251799813685247
  %shr67.i.1012 = lshr i128 %add58.i.1002, 51
  %conv69.i.1013 = and i128 %shr67.i.1012, 18446744073709551615
  %add70.i.1014 = add i128 %add62.i.1004, %conv69.i.1013
  %conv71.i.1015 = trunc i128 %add58.i.1002 to i64
  %and72.i.1016 = and i64 %conv71.i.1015, 2251799813685247
  %shr73.i.1017 = lshr i128 %add65.i.1009, 51
  %conv75.i.1018 = and i128 %shr73.i.1017, 18446744073709551615
  %add35.i.1019 = add i128 %mul34.i.987, %mul52.i.997
  %add53.i.1020 = add i128 %add35.i.1019, %mul18.i.978
  %add76.i.1021 = add i128 %add53.i.1020, %conv75.i.1018
  %conv77.i.1022 = trunc i128 %add65.i.1009 to i64
  %and78.i.1023 = and i64 %conv77.i.1022, 2251799813685247
  %shr79.i.1024 = lshr i128 %add70.i.1014, 51
  %conv80.i.1025 = trunc i128 %shr79.i.1024 to i64
  %add81.i.1026 = add i64 %conv80.i.1025, %and.i.1011
  %conv82.i.1027 = trunc i128 %add70.i.1014 to i64
  %and83.i.1028 = and i64 %conv82.i.1027, 2251799813685247
  %shr84.i.1029 = lshr i128 %add76.i.1021, 51
  %conv85.i.1030 = trunc i128 %shr84.i.1029 to i64
  %mul86.i.1031 = mul i64 %conv85.i.1030, 19
  %add87.i.1032 = add i64 %mul86.i.1031, %and72.i.1016
  %conv88.i.1033 = trunc i128 %add76.i.1021 to i64
  %and89.i.1034 = and i64 %conv88.i.1033, 2251799813685247
  %shr90.i.1035 = lshr i64 %add81.i.1026, 51
  %add91.i.1036 = add nuw nsw i64 %shr90.i.1035, %and78.i.1023
  %fold.i.1037 = add i64 %conv80.i.1025, %conv66.i.1010
  %and92.i.1038 = and i64 %fold.i.1037, 2251799813685247
  %shr93.i.1039 = lshr i64 %add87.i.1032, 51
  %add94.i.1040 = add nuw nsw i64 %shr93.i.1039, %and83.i.1028
  %fold180.i.1041 = add i64 %mul86.i.1031, %conv71.i.1015
  %and95.i.1042 = and i64 %fold180.i.1041, 2251799813685247
  %inc = add nuw nsw i32 %i.01501, 1
  %exitcond1514 = icmp eq i32 %inc, 5
  br i1 %exitcond1514, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %and95.i.1042.lcssa = phi i64 [ %and95.i.1042, %for.body ]
  %add94.i.1040.lcssa = phi i64 [ %add94.i.1040, %for.body ]
  %and92.i.1038.lcssa = phi i64 [ %and92.i.1038, %for.body ]
  %add91.i.1036.lcssa = phi i64 [ %add91.i.1036, %for.body ]
  %and89.i.1034.lcssa = phi i64 [ %and89.i.1034, %for.body ]
  store i64 %and95.i.1042.lcssa, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.1040.lcssa, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.1038.lcssa, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.1036.lcssa, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.1034.lcssa, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay1, i64* %arraydecay10, i64* %arraydecay1)
  %23 = load i64, i64* %arraydecay1, align 16, !tbaa !5
  %24 = load i64, i64* %arrayidx97.i.203, align 8, !tbaa !5
  %25 = load i64, i64* %arrayidx98.i.204, align 16, !tbaa !5
  %26 = load i64, i64* %arrayidx99.i.205, align 8, !tbaa !5
  %27 = load i64, i64* %arrayidx100.i.206, align 16, !tbaa !5
  %conv.i.1135 = zext i64 %23 to i128
  %mul.i.1136 = mul nuw i128 %conv.i.1135, %conv.i.1135
  %mul6.i.1137 = shl i64 %23, 1
  %conv7.i.1138 = zext i64 %mul6.i.1137 to i128
  %conv8.i.1139 = zext i64 %24 to i128
  %mul9.i.1140 = mul nuw i128 %conv7.i.1138, %conv8.i.1139
  %conv11.i.1141 = zext i64 %25 to i128
  %mul12.i.1142 = mul nuw i128 %conv11.i.1141, %conv7.i.1138
  %conv14.i.1143 = zext i64 %26 to i128
  %mul15.i.1144 = mul nuw i128 %conv14.i.1143, %conv7.i.1138
  %conv17.i.1145 = zext i64 %27 to i128
  %mul18.i.1146 = mul nuw i128 %conv17.i.1145, %conv7.i.1138
  %mul20.i.1147 = mul i64 %27, 19
  %conv21.i.1148 = zext i64 %mul20.i.1147 to i128
  %mul22.i.1149 = mul nuw i128 %conv21.i.1148, %conv17.i.1145
  %mul25.i.1150 = mul nuw i128 %conv8.i.1139, %conv8.i.1139
  %add26.i.1151 = add i128 %mul12.i.1142, %mul25.i.1150
  %mul27.i.1152 = shl i64 %24, 1
  %conv28.i.1153 = zext i64 %mul27.i.1152 to i128
  %mul30.i.1154 = mul nuw i128 %conv28.i.1153, %conv11.i.1141
  %mul34.i.1155 = mul nuw i128 %conv14.i.1143, %conv28.i.1153
  %mul38.i.1156 = mul nuw i128 %conv21.i.1148, %conv28.i.1153
  %mul41.i.1157 = mul i64 %26, 19
  %conv42.i.1158 = zext i64 %mul41.i.1157 to i128
  %mul43.i.1159 = mul nuw i128 %conv42.i.1158, %conv14.i.1143
  %add44.i.1160 = add i128 %mul43.i.1159, %mul9.i.1140
  %mul45.i.1161 = shl i64 %26, 1
  %conv46.i.1162 = zext i64 %mul45.i.1161 to i128
  %mul48.i.1163 = mul nuw i128 %conv21.i.1148, %conv46.i.1162
  %add49.i.1164 = add i128 %add26.i.1151, %mul48.i.1163
  %mul52.i.1165 = mul nuw i128 %conv11.i.1141, %conv11.i.1141
  %mul54.i.1166 = shl i64 %25, 1
  %conv55.i.1167 = zext i64 %mul54.i.1166 to i128
  %mul57.i.1168 = mul nuw i128 %conv42.i.1158, %conv55.i.1167
  %add39.i.1169 = add i128 %mul57.i.1168, %mul.i.1136
  %add58.i.1170 = add i128 %add39.i.1169, %mul38.i.1156
  %mul61.i.1171 = mul nuw i128 %conv21.i.1148, %conv55.i.1167
  %add62.i.1172 = add i128 %add44.i.1160, %mul61.i.1171
  %shr.i.1173 = lshr i128 %add49.i.1164, 51
  %conv64.i.1174 = and i128 %shr.i.1173, 18446744073709551615
  %add.i.1175 = add i128 %mul15.i.1144, %mul30.i.1154
  %add31.i.1176 = add i128 %add.i.1175, %mul22.i.1149
  %add65.i.1177 = add i128 %add31.i.1176, %conv64.i.1174
  %conv66.i.1178 = trunc i128 %add49.i.1164 to i64
  %and.i.1179 = and i64 %conv66.i.1178, 2251799813685247
  %shr67.i.1180 = lshr i128 %add58.i.1170, 51
  %conv69.i.1181 = and i128 %shr67.i.1180, 18446744073709551615
  %add70.i.1182 = add i128 %add62.i.1172, %conv69.i.1181
  %conv71.i.1183 = trunc i128 %add58.i.1170 to i64
  %and72.i.1184 = and i64 %conv71.i.1183, 2251799813685247
  %shr73.i.1185 = lshr i128 %add65.i.1177, 51
  %conv75.i.1186 = and i128 %shr73.i.1185, 18446744073709551615
  %add35.i.1187 = add i128 %mul34.i.1155, %mul52.i.1165
  %add53.i.1188 = add i128 %add35.i.1187, %mul18.i.1146
  %add76.i.1189 = add i128 %add53.i.1188, %conv75.i.1186
  %conv77.i.1190 = trunc i128 %add65.i.1177 to i64
  %and78.i.1191 = and i64 %conv77.i.1190, 2251799813685247
  %shr79.i.1192 = lshr i128 %add70.i.1182, 51
  %conv80.i.1193 = trunc i128 %shr79.i.1192 to i64
  %add81.i.1194 = add i64 %conv80.i.1193, %and.i.1179
  %conv82.i.1195 = trunc i128 %add70.i.1182 to i64
  %and83.i.1196 = and i64 %conv82.i.1195, 2251799813685247
  %shr84.i.1197 = lshr i128 %add76.i.1189, 51
  %conv85.i.1198 = trunc i128 %shr84.i.1197 to i64
  %mul86.i.1199 = mul i64 %conv85.i.1198, 19
  %add87.i.1200 = add i64 %mul86.i.1199, %and72.i.1184
  %conv88.i.1201 = trunc i128 %add76.i.1189 to i64
  %and89.i.1202 = and i64 %conv88.i.1201, 2251799813685247
  %shr90.i.1203 = lshr i64 %add81.i.1194, 51
  %add91.i.1204 = add nuw nsw i64 %shr90.i.1203, %and78.i.1191
  %fold.i.1205 = add i64 %conv80.i.1193, %conv66.i.1178
  %and92.i.1206 = and i64 %fold.i.1205, 2251799813685247
  %shr93.i.1207 = lshr i64 %add87.i.1200, 51
  %add94.i.1208 = add nuw nsw i64 %shr93.i.1207, %and83.i.1196
  %fold180.i.1209 = add i64 %mul86.i.1199, %conv71.i.1183
  %and95.i.1210 = and i64 %fold180.i.1209, 2251799813685247
  store i64 %and95.i.1210, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.1208, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.1206, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.1204, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.1202, i64* %arrayidx100.i.542, align 16, !tbaa !5
  br label %for.body.26

for.body.26:                                      ; preds = %for.body.26, %for.end
  %28 = phi i64 [ %and89.i.1202, %for.end ], [ %and89.i.1454, %for.body.26 ]
  %29 = phi i64 [ %add91.i.1204, %for.end ], [ %add91.i.1456, %for.body.26 ]
  %30 = phi i64 [ %and92.i.1206, %for.end ], [ %and92.i.1458, %for.body.26 ]
  %31 = phi i64 [ %add94.i.1208, %for.end ], [ %add94.i.1460, %for.body.26 ]
  %and95.i.14621496 = phi i64 [ %and95.i.1210, %for.end ], [ %and95.i.1462, %for.body.26 ]
  %i.11494 = phi i32 [ 1, %for.end ], [ %inc30, %for.body.26 ]
  %conv.i.1387 = zext i64 %and95.i.14621496 to i128
  %mul.i.1388 = mul nuw nsw i128 %conv.i.1387, %conv.i.1387
  %mul6.i.1389 = shl nuw nsw i64 %and95.i.14621496, 1
  %conv7.i.1390 = zext i64 %mul6.i.1389 to i128
  %conv8.i.1391 = zext i64 %31 to i128
  %mul9.i.1392 = mul nuw nsw i128 %conv7.i.1390, %conv8.i.1391
  %conv11.i.1393 = zext i64 %30 to i128
  %mul12.i.1394 = mul nuw nsw i128 %conv11.i.1393, %conv7.i.1390
  %conv14.i.1395 = zext i64 %29 to i128
  %mul15.i.1396 = mul nuw nsw i128 %conv14.i.1395, %conv7.i.1390
  %conv17.i.1397 = zext i64 %28 to i128
  %mul18.i.1398 = mul nuw nsw i128 %conv17.i.1397, %conv7.i.1390
  %mul20.i.1399 = mul nuw nsw i64 %28, 19
  %conv21.i.1400 = zext i64 %mul20.i.1399 to i128
  %mul22.i.1401 = mul nuw nsw i128 %conv21.i.1400, %conv17.i.1397
  %mul25.i.1402 = mul nuw i128 %conv8.i.1391, %conv8.i.1391
  %add26.i.1403 = add i128 %mul12.i.1394, %mul25.i.1402
  %mul27.i.1404 = shl nsw i64 %31, 1
  %conv28.i.1405 = zext i64 %mul27.i.1404 to i128
  %mul30.i.1406 = mul nuw nsw i128 %conv28.i.1405, %conv11.i.1393
  %mul34.i.1407 = mul nuw i128 %conv14.i.1395, %conv28.i.1405
  %mul38.i.1408 = mul nuw nsw i128 %conv21.i.1400, %conv28.i.1405
  %mul41.i.1409 = mul nsw i64 %29, 19
  %conv42.i.1410 = zext i64 %mul41.i.1409 to i128
  %mul43.i.1411 = mul nuw i128 %conv42.i.1410, %conv14.i.1395
  %add44.i.1412 = add i128 %mul43.i.1411, %mul9.i.1392
  %mul45.i.1413 = shl nsw i64 %29, 1
  %conv46.i.1414 = zext i64 %mul45.i.1413 to i128
  %mul48.i.1415 = mul nuw nsw i128 %conv21.i.1400, %conv46.i.1414
  %add49.i.1416 = add i128 %add26.i.1403, %mul48.i.1415
  %mul52.i.1417 = mul nuw nsw i128 %conv11.i.1393, %conv11.i.1393
  %mul54.i.1418 = shl nuw nsw i64 %30, 1
  %conv55.i.1419 = zext i64 %mul54.i.1418 to i128
  %mul57.i.1420 = mul nuw nsw i128 %conv42.i.1410, %conv55.i.1419
  %add39.i.1421 = add nuw nsw i128 %mul57.i.1420, %mul.i.1388
  %add58.i.1422 = add nuw nsw i128 %add39.i.1421, %mul38.i.1408
  %mul61.i.1423 = mul nuw nsw i128 %conv21.i.1400, %conv55.i.1419
  %add62.i.1424 = add i128 %add44.i.1412, %mul61.i.1423
  %shr.i.1425 = lshr i128 %add49.i.1416, 51
  %conv64.i.1426 = and i128 %shr.i.1425, 18446744073709551615
  %add.i.1427 = add nuw nsw i128 %mul15.i.1396, %mul30.i.1406
  %add31.i.1428 = add nuw nsw i128 %add.i.1427, %mul22.i.1401
  %add65.i.1429 = add nuw i128 %add31.i.1428, %conv64.i.1426
  %conv66.i.1430 = trunc i128 %add49.i.1416 to i64
  %and.i.1431 = and i64 %conv66.i.1430, 2251799813685247
  %shr67.i.1432 = lshr i128 %add58.i.1422, 51
  %conv69.i.1433 = and i128 %shr67.i.1432, 18446744073709551615
  %add70.i.1434 = add i128 %add62.i.1424, %conv69.i.1433
  %conv71.i.1435 = trunc i128 %add58.i.1422 to i64
  %and72.i.1436 = and i64 %conv71.i.1435, 2251799813685247
  %shr73.i.1437 = lshr i128 %add65.i.1429, 51
  %conv75.i.1438 = and i128 %shr73.i.1437, 18446744073709551615
  %add35.i.1439 = add i128 %mul34.i.1407, %mul52.i.1417
  %add53.i.1440 = add i128 %add35.i.1439, %mul18.i.1398
  %add76.i.1441 = add i128 %add53.i.1440, %conv75.i.1438
  %conv77.i.1442 = trunc i128 %add65.i.1429 to i64
  %and78.i.1443 = and i64 %conv77.i.1442, 2251799813685247
  %shr79.i.1444 = lshr i128 %add70.i.1434, 51
  %conv80.i.1445 = trunc i128 %shr79.i.1444 to i64
  %add81.i.1446 = add i64 %conv80.i.1445, %and.i.1431
  %conv82.i.1447 = trunc i128 %add70.i.1434 to i64
  %and83.i.1448 = and i64 %conv82.i.1447, 2251799813685247
  %shr84.i.1449 = lshr i128 %add76.i.1441, 51
  %conv85.i.1450 = trunc i128 %shr84.i.1449 to i64
  %mul86.i.1451 = mul i64 %conv85.i.1450, 19
  %add87.i.1452 = add i64 %mul86.i.1451, %and72.i.1436
  %conv88.i.1453 = trunc i128 %add76.i.1441 to i64
  %and89.i.1454 = and i64 %conv88.i.1453, 2251799813685247
  %shr90.i.1455 = lshr i64 %add81.i.1446, 51
  %add91.i.1456 = add nuw nsw i64 %shr90.i.1455, %and78.i.1443
  %fold.i.1457 = add i64 %conv80.i.1445, %conv66.i.1430
  %and92.i.1458 = and i64 %fold.i.1457, 2251799813685247
  %shr93.i.1459 = lshr i64 %add87.i.1452, 51
  %add94.i.1460 = add nuw nsw i64 %shr93.i.1459, %and83.i.1448
  %fold180.i.1461 = add i64 %mul86.i.1451, %conv71.i.1435
  %and95.i.1462 = and i64 %fold180.i.1461, 2251799813685247
  %inc30 = add nuw nsw i32 %i.11494, 1
  %exitcond1513 = icmp eq i32 %inc30, 10
  br i1 %exitcond1513, label %for.end.31, label %for.body.26

for.end.31:                                       ; preds = %for.body.26
  %and95.i.1462.lcssa = phi i64 [ %and95.i.1462, %for.body.26 ]
  %add94.i.1460.lcssa = phi i64 [ %add94.i.1460, %for.body.26 ]
  %and92.i.1458.lcssa = phi i64 [ %and92.i.1458, %for.body.26 ]
  %add91.i.1456.lcssa = phi i64 [ %add91.i.1456, %for.body.26 ]
  %and89.i.1454.lcssa = phi i64 [ %and89.i.1454, %for.body.26 ]
  store i64 %and95.i.1462.lcssa, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.1460.lcssa, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.1458.lcssa, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.1456.lcssa, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.1454.lcssa, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay10, i64* %arraydecay10, i64* %arraydecay1)
  %arraydecay35 = getelementptr inbounds [5 x i64], [5 x i64]* %t3, i64 0, i64 0
  %32 = load i64, i64* %arraydecay10, align 16, !tbaa !5
  %33 = load i64, i64* %arrayidx97.i.539, align 8, !tbaa !5
  %34 = load i64, i64* %arrayidx98.i.540, align 16, !tbaa !5
  %35 = load i64, i64* %arrayidx99.i.541, align 8, !tbaa !5
  %36 = load i64, i64* %arrayidx100.i.542, align 16, !tbaa !5
  %conv.i.1303 = zext i64 %32 to i128
  %mul.i.1304 = mul nuw i128 %conv.i.1303, %conv.i.1303
  %mul6.i.1305 = shl i64 %32, 1
  %conv7.i.1306 = zext i64 %mul6.i.1305 to i128
  %conv8.i.1307 = zext i64 %33 to i128
  %mul9.i.1308 = mul nuw i128 %conv7.i.1306, %conv8.i.1307
  %conv11.i.1309 = zext i64 %34 to i128
  %mul12.i.1310 = mul nuw i128 %conv11.i.1309, %conv7.i.1306
  %conv14.i.1311 = zext i64 %35 to i128
  %mul15.i.1312 = mul nuw i128 %conv14.i.1311, %conv7.i.1306
  %conv17.i.1313 = zext i64 %36 to i128
  %mul18.i.1314 = mul nuw i128 %conv17.i.1313, %conv7.i.1306
  %mul20.i.1315 = mul i64 %36, 19
  %conv21.i.1316 = zext i64 %mul20.i.1315 to i128
  %mul22.i.1317 = mul nuw i128 %conv21.i.1316, %conv17.i.1313
  %mul25.i.1318 = mul nuw i128 %conv8.i.1307, %conv8.i.1307
  %add26.i.1319 = add i128 %mul12.i.1310, %mul25.i.1318
  %mul27.i.1320 = shl i64 %33, 1
  %conv28.i.1321 = zext i64 %mul27.i.1320 to i128
  %mul30.i.1322 = mul nuw i128 %conv28.i.1321, %conv11.i.1309
  %mul34.i.1323 = mul nuw i128 %conv14.i.1311, %conv28.i.1321
  %mul38.i.1324 = mul nuw i128 %conv21.i.1316, %conv28.i.1321
  %mul41.i.1325 = mul i64 %35, 19
  %conv42.i.1326 = zext i64 %mul41.i.1325 to i128
  %mul43.i.1327 = mul nuw i128 %conv42.i.1326, %conv14.i.1311
  %add44.i.1328 = add i128 %mul43.i.1327, %mul9.i.1308
  %mul45.i.1329 = shl i64 %35, 1
  %conv46.i.1330 = zext i64 %mul45.i.1329 to i128
  %mul48.i.1331 = mul nuw i128 %conv21.i.1316, %conv46.i.1330
  %add49.i.1332 = add i128 %add26.i.1319, %mul48.i.1331
  %mul52.i.1333 = mul nuw i128 %conv11.i.1309, %conv11.i.1309
  %mul54.i.1334 = shl i64 %34, 1
  %conv55.i.1335 = zext i64 %mul54.i.1334 to i128
  %mul57.i.1336 = mul nuw i128 %conv42.i.1326, %conv55.i.1335
  %add39.i.1337 = add i128 %mul57.i.1336, %mul.i.1304
  %add58.i.1338 = add i128 %add39.i.1337, %mul38.i.1324
  %mul61.i.1339 = mul nuw i128 %conv21.i.1316, %conv55.i.1335
  %add62.i.1340 = add i128 %add44.i.1328, %mul61.i.1339
  %shr.i.1341 = lshr i128 %add49.i.1332, 51
  %conv64.i.1342 = and i128 %shr.i.1341, 18446744073709551615
  %add.i.1343 = add i128 %mul15.i.1312, %mul30.i.1322
  %add31.i.1344 = add i128 %add.i.1343, %mul22.i.1317
  %add65.i.1345 = add i128 %add31.i.1344, %conv64.i.1342
  %conv66.i.1346 = trunc i128 %add49.i.1332 to i64
  %and.i.1347 = and i64 %conv66.i.1346, 2251799813685247
  %shr67.i.1348 = lshr i128 %add58.i.1338, 51
  %conv69.i.1349 = and i128 %shr67.i.1348, 18446744073709551615
  %add70.i.1350 = add i128 %add62.i.1340, %conv69.i.1349
  %conv71.i.1351 = trunc i128 %add58.i.1338 to i64
  %and72.i.1352 = and i64 %conv71.i.1351, 2251799813685247
  %shr73.i.1353 = lshr i128 %add65.i.1345, 51
  %conv75.i.1354 = and i128 %shr73.i.1353, 18446744073709551615
  %add35.i.1355 = add i128 %mul34.i.1323, %mul52.i.1333
  %add53.i.1356 = add i128 %add35.i.1355, %mul18.i.1314
  %add76.i.1357 = add i128 %add53.i.1356, %conv75.i.1354
  %conv77.i.1358 = trunc i128 %add65.i.1345 to i64
  %and78.i.1359 = and i64 %conv77.i.1358, 2251799813685247
  %shr79.i.1360 = lshr i128 %add70.i.1350, 51
  %conv80.i.1361 = trunc i128 %shr79.i.1360 to i64
  %add81.i.1362 = add i64 %conv80.i.1361, %and.i.1347
  %conv82.i.1363 = trunc i128 %add70.i.1350 to i64
  %and83.i.1364 = and i64 %conv82.i.1363, 2251799813685247
  %shr84.i.1365 = lshr i128 %add76.i.1357, 51
  %conv85.i.1366 = trunc i128 %shr84.i.1365 to i64
  %mul86.i.1367 = mul i64 %conv85.i.1366, 19
  %add87.i.1368 = add i64 %mul86.i.1367, %and72.i.1352
  %conv88.i.1369 = trunc i128 %add76.i.1357 to i64
  %and89.i.1370 = and i64 %conv88.i.1369, 2251799813685247
  %shr90.i.1371 = lshr i64 %add81.i.1362, 51
  %add91.i.1372 = add nuw nsw i64 %shr90.i.1371, %and78.i.1359
  %fold.i.1373 = add i64 %conv80.i.1361, %conv66.i.1346
  %and92.i.1374 = and i64 %fold.i.1373, 2251799813685247
  %shr93.i.1375 = lshr i64 %add87.i.1368, 51
  %add94.i.1376 = add nuw nsw i64 %shr93.i.1375, %and83.i.1364
  %fold180.i.1377 = add i64 %mul86.i.1367, %conv71.i.1351
  %and95.i.1378 = and i64 %fold180.i.1377, 2251799813685247
  store i64 %and95.i.1378, i64* %arraydecay35, align 16, !tbaa !5
  %arrayidx97.i.1379 = getelementptr inbounds [5 x i64], [5 x i64]* %t3, i64 0, i64 1
  store i64 %add94.i.1376, i64* %arrayidx97.i.1379, align 8, !tbaa !5
  %arrayidx98.i.1380 = getelementptr inbounds [5 x i64], [5 x i64]* %t3, i64 0, i64 2
  store i64 %and92.i.1374, i64* %arrayidx98.i.1380, align 16, !tbaa !5
  %arrayidx99.i.1381 = getelementptr inbounds [5 x i64], [5 x i64]* %t3, i64 0, i64 3
  store i64 %add91.i.1372, i64* %arrayidx99.i.1381, align 8, !tbaa !5
  %arrayidx100.i.1382 = getelementptr inbounds [5 x i64], [5 x i64]* %t3, i64 0, i64 4
  store i64 %and89.i.1370, i64* %arrayidx100.i.1382, align 16, !tbaa !5
  br label %for.body.39

for.body.39:                                      ; preds = %for.body.39, %for.end.31
  %37 = phi i64 [ %and89.i.1370, %for.end.31 ], [ %and89.i.1286, %for.body.39 ]
  %38 = phi i64 [ %add91.i.1372, %for.end.31 ], [ %add91.i.1288, %for.body.39 ]
  %39 = phi i64 [ %and92.i.1374, %for.end.31 ], [ %and92.i.1290, %for.body.39 ]
  %40 = phi i64 [ %add94.i.1376, %for.end.31 ], [ %add94.i.1292, %for.body.39 ]
  %and95.i.12941489 = phi i64 [ %and95.i.1378, %for.end.31 ], [ %and95.i.1294, %for.body.39 ]
  %i.21487 = phi i32 [ 1, %for.end.31 ], [ %inc43, %for.body.39 ]
  %conv.i.1219 = zext i64 %and95.i.12941489 to i128
  %mul.i.1220 = mul nuw nsw i128 %conv.i.1219, %conv.i.1219
  %mul6.i.1221 = shl nuw nsw i64 %and95.i.12941489, 1
  %conv7.i.1222 = zext i64 %mul6.i.1221 to i128
  %conv8.i.1223 = zext i64 %40 to i128
  %mul9.i.1224 = mul nuw nsw i128 %conv7.i.1222, %conv8.i.1223
  %conv11.i.1225 = zext i64 %39 to i128
  %mul12.i.1226 = mul nuw nsw i128 %conv11.i.1225, %conv7.i.1222
  %conv14.i.1227 = zext i64 %38 to i128
  %mul15.i.1228 = mul nuw nsw i128 %conv14.i.1227, %conv7.i.1222
  %conv17.i.1229 = zext i64 %37 to i128
  %mul18.i.1230 = mul nuw nsw i128 %conv17.i.1229, %conv7.i.1222
  %mul20.i.1231 = mul nuw nsw i64 %37, 19
  %conv21.i.1232 = zext i64 %mul20.i.1231 to i128
  %mul22.i.1233 = mul nuw nsw i128 %conv21.i.1232, %conv17.i.1229
  %mul25.i.1234 = mul nuw i128 %conv8.i.1223, %conv8.i.1223
  %add26.i.1235 = add i128 %mul12.i.1226, %mul25.i.1234
  %mul27.i.1236 = shl nsw i64 %40, 1
  %conv28.i.1237 = zext i64 %mul27.i.1236 to i128
  %mul30.i.1238 = mul nuw nsw i128 %conv28.i.1237, %conv11.i.1225
  %mul34.i.1239 = mul nuw i128 %conv14.i.1227, %conv28.i.1237
  %mul38.i.1240 = mul nuw nsw i128 %conv21.i.1232, %conv28.i.1237
  %mul41.i.1241 = mul nsw i64 %38, 19
  %conv42.i.1242 = zext i64 %mul41.i.1241 to i128
  %mul43.i.1243 = mul nuw i128 %conv42.i.1242, %conv14.i.1227
  %add44.i.1244 = add i128 %mul43.i.1243, %mul9.i.1224
  %mul45.i.1245 = shl nsw i64 %38, 1
  %conv46.i.1246 = zext i64 %mul45.i.1245 to i128
  %mul48.i.1247 = mul nuw nsw i128 %conv21.i.1232, %conv46.i.1246
  %add49.i.1248 = add i128 %add26.i.1235, %mul48.i.1247
  %mul52.i.1249 = mul nuw nsw i128 %conv11.i.1225, %conv11.i.1225
  %mul54.i.1250 = shl nuw nsw i64 %39, 1
  %conv55.i.1251 = zext i64 %mul54.i.1250 to i128
  %mul57.i.1252 = mul nuw nsw i128 %conv42.i.1242, %conv55.i.1251
  %add39.i.1253 = add nuw nsw i128 %mul57.i.1252, %mul.i.1220
  %add58.i.1254 = add nuw nsw i128 %add39.i.1253, %mul38.i.1240
  %mul61.i.1255 = mul nuw nsw i128 %conv21.i.1232, %conv55.i.1251
  %add62.i.1256 = add i128 %add44.i.1244, %mul61.i.1255
  %shr.i.1257 = lshr i128 %add49.i.1248, 51
  %conv64.i.1258 = and i128 %shr.i.1257, 18446744073709551615
  %add.i.1259 = add nuw nsw i128 %mul15.i.1228, %mul30.i.1238
  %add31.i.1260 = add nuw nsw i128 %add.i.1259, %mul22.i.1233
  %add65.i.1261 = add nuw i128 %add31.i.1260, %conv64.i.1258
  %conv66.i.1262 = trunc i128 %add49.i.1248 to i64
  %and.i.1263 = and i64 %conv66.i.1262, 2251799813685247
  %shr67.i.1264 = lshr i128 %add58.i.1254, 51
  %conv69.i.1265 = and i128 %shr67.i.1264, 18446744073709551615
  %add70.i.1266 = add i128 %add62.i.1256, %conv69.i.1265
  %conv71.i.1267 = trunc i128 %add58.i.1254 to i64
  %and72.i.1268 = and i64 %conv71.i.1267, 2251799813685247
  %shr73.i.1269 = lshr i128 %add65.i.1261, 51
  %conv75.i.1270 = and i128 %shr73.i.1269, 18446744073709551615
  %add35.i.1271 = add i128 %mul34.i.1239, %mul52.i.1249
  %add53.i.1272 = add i128 %add35.i.1271, %mul18.i.1230
  %add76.i.1273 = add i128 %add53.i.1272, %conv75.i.1270
  %conv77.i.1274 = trunc i128 %add65.i.1261 to i64
  %and78.i.1275 = and i64 %conv77.i.1274, 2251799813685247
  %shr79.i.1276 = lshr i128 %add70.i.1266, 51
  %conv80.i.1277 = trunc i128 %shr79.i.1276 to i64
  %add81.i.1278 = add i64 %conv80.i.1277, %and.i.1263
  %conv82.i.1279 = trunc i128 %add70.i.1266 to i64
  %and83.i.1280 = and i64 %conv82.i.1279, 2251799813685247
  %shr84.i.1281 = lshr i128 %add76.i.1273, 51
  %conv85.i.1282 = trunc i128 %shr84.i.1281 to i64
  %mul86.i.1283 = mul i64 %conv85.i.1282, 19
  %add87.i.1284 = add i64 %mul86.i.1283, %and72.i.1268
  %conv88.i.1285 = trunc i128 %add76.i.1273 to i64
  %and89.i.1286 = and i64 %conv88.i.1285, 2251799813685247
  %shr90.i.1287 = lshr i64 %add81.i.1278, 51
  %add91.i.1288 = add nuw nsw i64 %shr90.i.1287, %and78.i.1275
  %fold.i.1289 = add i64 %conv80.i.1277, %conv66.i.1262
  %and92.i.1290 = and i64 %fold.i.1289, 2251799813685247
  %shr93.i.1291 = lshr i64 %add87.i.1284, 51
  %add94.i.1292 = add nuw nsw i64 %shr93.i.1291, %and83.i.1280
  %fold180.i.1293 = add i64 %mul86.i.1283, %conv71.i.1267
  %and95.i.1294 = and i64 %fold180.i.1293, 2251799813685247
  %inc43 = add nuw nsw i32 %i.21487, 1
  %exitcond1512 = icmp eq i32 %inc43, 20
  br i1 %exitcond1512, label %for.end.44, label %for.body.39

for.end.44:                                       ; preds = %for.body.39
  %and95.i.1294.lcssa = phi i64 [ %and95.i.1294, %for.body.39 ]
  %add94.i.1292.lcssa = phi i64 [ %add94.i.1292, %for.body.39 ]
  %and92.i.1290.lcssa = phi i64 [ %and92.i.1290, %for.body.39 ]
  %add91.i.1288.lcssa = phi i64 [ %add91.i.1288, %for.body.39 ]
  %and89.i.1286.lcssa = phi i64 [ %and89.i.1286, %for.body.39 ]
  store i64 %and95.i.1294.lcssa, i64* %arraydecay35, align 16, !tbaa !5
  store i64 %add94.i.1292.lcssa, i64* %arrayidx97.i.1379, align 8, !tbaa !5
  store i64 %and92.i.1290.lcssa, i64* %arrayidx98.i.1380, align 16, !tbaa !5
  store i64 %add91.i.1288.lcssa, i64* %arrayidx99.i.1381, align 8, !tbaa !5
  store i64 %and89.i.1286.lcssa, i64* %arrayidx100.i.1382, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay10, i64* %arraydecay35, i64* %arraydecay10)
  %arraydecay10.promoted1481 = load i64, i64* %arraydecay10, align 16, !tbaa !5
  %arrayidx97.i.539.promoted1483 = load i64, i64* %arrayidx97.i.539, align 8, !tbaa !5
  %arrayidx98.i.540.promoted1484 = load i64, i64* %arrayidx98.i.540, align 16, !tbaa !5
  %arrayidx99.i.541.promoted1485 = load i64, i64* %arrayidx99.i.541, align 8, !tbaa !5
  %arrayidx100.i.542.promoted1486 = load i64, i64* %arrayidx100.i.542, align 16, !tbaa !5
  br label %for.body.50

for.body.50:                                      ; preds = %for.body.50, %for.end.44
  %41 = phi i64 [ %arrayidx100.i.542.promoted1486, %for.end.44 ], [ %and89.i.1118, %for.body.50 ]
  %42 = phi i64 [ %arrayidx99.i.541.promoted1485, %for.end.44 ], [ %add91.i.1120, %for.body.50 ]
  %43 = phi i64 [ %arrayidx98.i.540.promoted1484, %for.end.44 ], [ %and92.i.1122, %for.body.50 ]
  %44 = phi i64 [ %arrayidx97.i.539.promoted1483, %for.end.44 ], [ %add94.i.1124, %for.body.50 ]
  %and95.i.11261482 = phi i64 [ %arraydecay10.promoted1481, %for.end.44 ], [ %and95.i.1126, %for.body.50 ]
  %i.31480 = phi i32 [ 0, %for.end.44 ], [ %inc54, %for.body.50 ]
  %conv.i.1051 = zext i64 %and95.i.11261482 to i128
  %mul.i.1052 = mul nuw i128 %conv.i.1051, %conv.i.1051
  %mul6.i.1053 = shl i64 %and95.i.11261482, 1
  %conv7.i.1054 = zext i64 %mul6.i.1053 to i128
  %conv8.i.1055 = zext i64 %44 to i128
  %mul9.i.1056 = mul nuw i128 %conv7.i.1054, %conv8.i.1055
  %conv11.i.1057 = zext i64 %43 to i128
  %mul12.i.1058 = mul nuw i128 %conv11.i.1057, %conv7.i.1054
  %conv14.i.1059 = zext i64 %42 to i128
  %mul15.i.1060 = mul nuw i128 %conv14.i.1059, %conv7.i.1054
  %conv17.i.1061 = zext i64 %41 to i128
  %mul18.i.1062 = mul nuw i128 %conv17.i.1061, %conv7.i.1054
  %mul20.i.1063 = mul i64 %41, 19
  %conv21.i.1064 = zext i64 %mul20.i.1063 to i128
  %mul22.i.1065 = mul nuw i128 %conv21.i.1064, %conv17.i.1061
  %mul25.i.1066 = mul nuw i128 %conv8.i.1055, %conv8.i.1055
  %add26.i.1067 = add i128 %mul12.i.1058, %mul25.i.1066
  %mul27.i.1068 = shl i64 %44, 1
  %conv28.i.1069 = zext i64 %mul27.i.1068 to i128
  %mul30.i.1070 = mul nuw i128 %conv28.i.1069, %conv11.i.1057
  %mul34.i.1071 = mul nuw i128 %conv14.i.1059, %conv28.i.1069
  %mul38.i.1072 = mul nuw i128 %conv21.i.1064, %conv28.i.1069
  %mul41.i.1073 = mul i64 %42, 19
  %conv42.i.1074 = zext i64 %mul41.i.1073 to i128
  %mul43.i.1075 = mul nuw i128 %conv42.i.1074, %conv14.i.1059
  %add44.i.1076 = add i128 %mul43.i.1075, %mul9.i.1056
  %mul45.i.1077 = shl i64 %42, 1
  %conv46.i.1078 = zext i64 %mul45.i.1077 to i128
  %mul48.i.1079 = mul nuw i128 %conv21.i.1064, %conv46.i.1078
  %add49.i.1080 = add i128 %add26.i.1067, %mul48.i.1079
  %mul52.i.1081 = mul nuw i128 %conv11.i.1057, %conv11.i.1057
  %mul54.i.1082 = shl i64 %43, 1
  %conv55.i.1083 = zext i64 %mul54.i.1082 to i128
  %mul57.i.1084 = mul nuw i128 %conv42.i.1074, %conv55.i.1083
  %add39.i.1085 = add i128 %mul57.i.1084, %mul.i.1052
  %add58.i.1086 = add i128 %add39.i.1085, %mul38.i.1072
  %mul61.i.1087 = mul nuw i128 %conv21.i.1064, %conv55.i.1083
  %add62.i.1088 = add i128 %add44.i.1076, %mul61.i.1087
  %shr.i.1089 = lshr i128 %add49.i.1080, 51
  %conv64.i.1090 = and i128 %shr.i.1089, 18446744073709551615
  %add.i.1091 = add i128 %mul15.i.1060, %mul30.i.1070
  %add31.i.1092 = add i128 %add.i.1091, %mul22.i.1065
  %add65.i.1093 = add i128 %add31.i.1092, %conv64.i.1090
  %conv66.i.1094 = trunc i128 %add49.i.1080 to i64
  %and.i.1095 = and i64 %conv66.i.1094, 2251799813685247
  %shr67.i.1096 = lshr i128 %add58.i.1086, 51
  %conv69.i.1097 = and i128 %shr67.i.1096, 18446744073709551615
  %add70.i.1098 = add i128 %add62.i.1088, %conv69.i.1097
  %conv71.i.1099 = trunc i128 %add58.i.1086 to i64
  %and72.i.1100 = and i64 %conv71.i.1099, 2251799813685247
  %shr73.i.1101 = lshr i128 %add65.i.1093, 51
  %conv75.i.1102 = and i128 %shr73.i.1101, 18446744073709551615
  %add35.i.1103 = add i128 %mul34.i.1071, %mul52.i.1081
  %add53.i.1104 = add i128 %add35.i.1103, %mul18.i.1062
  %add76.i.1105 = add i128 %add53.i.1104, %conv75.i.1102
  %conv77.i.1106 = trunc i128 %add65.i.1093 to i64
  %and78.i.1107 = and i64 %conv77.i.1106, 2251799813685247
  %shr79.i.1108 = lshr i128 %add70.i.1098, 51
  %conv80.i.1109 = trunc i128 %shr79.i.1108 to i64
  %add81.i.1110 = add i64 %conv80.i.1109, %and.i.1095
  %conv82.i.1111 = trunc i128 %add70.i.1098 to i64
  %and83.i.1112 = and i64 %conv82.i.1111, 2251799813685247
  %shr84.i.1113 = lshr i128 %add76.i.1105, 51
  %conv85.i.1114 = trunc i128 %shr84.i.1113 to i64
  %mul86.i.1115 = mul i64 %conv85.i.1114, 19
  %add87.i.1116 = add i64 %mul86.i.1115, %and72.i.1100
  %conv88.i.1117 = trunc i128 %add76.i.1105 to i64
  %and89.i.1118 = and i64 %conv88.i.1117, 2251799813685247
  %shr90.i.1119 = lshr i64 %add81.i.1110, 51
  %add91.i.1120 = add nuw nsw i64 %shr90.i.1119, %and78.i.1107
  %fold.i.1121 = add i64 %conv80.i.1109, %conv66.i.1094
  %and92.i.1122 = and i64 %fold.i.1121, 2251799813685247
  %shr93.i.1123 = lshr i64 %add87.i.1116, 51
  %add94.i.1124 = add nuw nsw i64 %shr93.i.1123, %and83.i.1112
  %fold180.i.1125 = add i64 %mul86.i.1115, %conv71.i.1099
  %and95.i.1126 = and i64 %fold180.i.1125, 2251799813685247
  %inc54 = add nuw nsw i32 %i.31480, 1
  %exitcond1511 = icmp eq i32 %inc54, 10
  br i1 %exitcond1511, label %for.end.55, label %for.body.50

for.end.55:                                       ; preds = %for.body.50
  %and95.i.1126.lcssa = phi i64 [ %and95.i.1126, %for.body.50 ]
  %add94.i.1124.lcssa = phi i64 [ %add94.i.1124, %for.body.50 ]
  %and92.i.1122.lcssa = phi i64 [ %and92.i.1122, %for.body.50 ]
  %add91.i.1120.lcssa = phi i64 [ %add91.i.1120, %for.body.50 ]
  %and89.i.1118.lcssa = phi i64 [ %and89.i.1118, %for.body.50 ]
  store i64 %and95.i.1126.lcssa, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.1124.lcssa, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.1122.lcssa, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.1120.lcssa, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.1118.lcssa, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay1, i64* %arraydecay10, i64* %arraydecay1)
  %45 = load i64, i64* %arraydecay1, align 16, !tbaa !5
  %46 = load i64, i64* %arrayidx97.i.203, align 8, !tbaa !5
  %47 = load i64, i64* %arrayidx98.i.204, align 16, !tbaa !5
  %48 = load i64, i64* %arrayidx99.i.205, align 8, !tbaa !5
  %49 = load i64, i64* %arrayidx100.i.206, align 16, !tbaa !5
  %conv.i.883 = zext i64 %45 to i128
  %mul.i.884 = mul nuw i128 %conv.i.883, %conv.i.883
  %mul6.i.885 = shl i64 %45, 1
  %conv7.i.886 = zext i64 %mul6.i.885 to i128
  %conv8.i.887 = zext i64 %46 to i128
  %mul9.i.888 = mul nuw i128 %conv7.i.886, %conv8.i.887
  %conv11.i.889 = zext i64 %47 to i128
  %mul12.i.890 = mul nuw i128 %conv11.i.889, %conv7.i.886
  %conv14.i.891 = zext i64 %48 to i128
  %mul15.i.892 = mul nuw i128 %conv14.i.891, %conv7.i.886
  %conv17.i.893 = zext i64 %49 to i128
  %mul18.i.894 = mul nuw i128 %conv17.i.893, %conv7.i.886
  %mul20.i.895 = mul i64 %49, 19
  %conv21.i.896 = zext i64 %mul20.i.895 to i128
  %mul22.i.897 = mul nuw i128 %conv21.i.896, %conv17.i.893
  %mul25.i.898 = mul nuw i128 %conv8.i.887, %conv8.i.887
  %add26.i.899 = add i128 %mul12.i.890, %mul25.i.898
  %mul27.i.900 = shl i64 %46, 1
  %conv28.i.901 = zext i64 %mul27.i.900 to i128
  %mul30.i.902 = mul nuw i128 %conv28.i.901, %conv11.i.889
  %mul34.i.903 = mul nuw i128 %conv14.i.891, %conv28.i.901
  %mul38.i.904 = mul nuw i128 %conv21.i.896, %conv28.i.901
  %mul41.i.905 = mul i64 %48, 19
  %conv42.i.906 = zext i64 %mul41.i.905 to i128
  %mul43.i.907 = mul nuw i128 %conv42.i.906, %conv14.i.891
  %add44.i.908 = add i128 %mul43.i.907, %mul9.i.888
  %mul45.i.909 = shl i64 %48, 1
  %conv46.i.910 = zext i64 %mul45.i.909 to i128
  %mul48.i.911 = mul nuw i128 %conv21.i.896, %conv46.i.910
  %add49.i.912 = add i128 %add26.i.899, %mul48.i.911
  %mul52.i.913 = mul nuw i128 %conv11.i.889, %conv11.i.889
  %mul54.i.914 = shl i64 %47, 1
  %conv55.i.915 = zext i64 %mul54.i.914 to i128
  %mul57.i.916 = mul nuw i128 %conv42.i.906, %conv55.i.915
  %add39.i.917 = add i128 %mul57.i.916, %mul.i.884
  %add58.i.918 = add i128 %add39.i.917, %mul38.i.904
  %mul61.i.919 = mul nuw i128 %conv21.i.896, %conv55.i.915
  %add62.i.920 = add i128 %add44.i.908, %mul61.i.919
  %shr.i.921 = lshr i128 %add49.i.912, 51
  %conv64.i.922 = and i128 %shr.i.921, 18446744073709551615
  %add.i.923 = add i128 %mul15.i.892, %mul30.i.902
  %add31.i.924 = add i128 %add.i.923, %mul22.i.897
  %add65.i.925 = add i128 %add31.i.924, %conv64.i.922
  %conv66.i.926 = trunc i128 %add49.i.912 to i64
  %and.i.927 = and i64 %conv66.i.926, 2251799813685247
  %shr67.i.928 = lshr i128 %add58.i.918, 51
  %conv69.i.929 = and i128 %shr67.i.928, 18446744073709551615
  %add70.i.930 = add i128 %add62.i.920, %conv69.i.929
  %conv71.i.931 = trunc i128 %add58.i.918 to i64
  %and72.i.932 = and i64 %conv71.i.931, 2251799813685247
  %shr73.i.933 = lshr i128 %add65.i.925, 51
  %conv75.i.934 = and i128 %shr73.i.933, 18446744073709551615
  %add35.i.935 = add i128 %mul34.i.903, %mul52.i.913
  %add53.i.936 = add i128 %add35.i.935, %mul18.i.894
  %add76.i.937 = add i128 %add53.i.936, %conv75.i.934
  %conv77.i.938 = trunc i128 %add65.i.925 to i64
  %and78.i.939 = and i64 %conv77.i.938, 2251799813685247
  %shr79.i.940 = lshr i128 %add70.i.930, 51
  %conv80.i.941 = trunc i128 %shr79.i.940 to i64
  %add81.i.942 = add i64 %conv80.i.941, %and.i.927
  %conv82.i.943 = trunc i128 %add70.i.930 to i64
  %and83.i.944 = and i64 %conv82.i.943, 2251799813685247
  %shr84.i.945 = lshr i128 %add76.i.937, 51
  %conv85.i.946 = trunc i128 %shr84.i.945 to i64
  %mul86.i.947 = mul i64 %conv85.i.946, 19
  %add87.i.948 = add i64 %mul86.i.947, %and72.i.932
  %conv88.i.949 = trunc i128 %add76.i.937 to i64
  %and89.i.950 = and i64 %conv88.i.949, 2251799813685247
  %shr90.i.951 = lshr i64 %add81.i.942, 51
  %add91.i.952 = add nuw nsw i64 %shr90.i.951, %and78.i.939
  %fold.i.953 = add i64 %conv80.i.941, %conv66.i.926
  %and92.i.954 = and i64 %fold.i.953, 2251799813685247
  %shr93.i.955 = lshr i64 %add87.i.948, 51
  %add94.i.956 = add nuw nsw i64 %shr93.i.955, %and83.i.944
  %fold180.i.957 = add i64 %mul86.i.947, %conv71.i.931
  %and95.i.958 = and i64 %fold180.i.957, 2251799813685247
  store i64 %and95.i.958, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.956, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.954, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.952, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.950, i64* %arrayidx100.i.542, align 16, !tbaa !5
  br label %for.body.63

for.body.63:                                      ; preds = %for.body.63, %for.end.55
  %50 = phi i64 [ %and89.i.950, %for.end.55 ], [ %and89.i.866, %for.body.63 ]
  %51 = phi i64 [ %add91.i.952, %for.end.55 ], [ %add91.i.868, %for.body.63 ]
  %52 = phi i64 [ %and92.i.954, %for.end.55 ], [ %and92.i.870, %for.body.63 ]
  %53 = phi i64 [ %add94.i.956, %for.end.55 ], [ %add94.i.872, %for.body.63 ]
  %and95.i.8741475 = phi i64 [ %and95.i.958, %for.end.55 ], [ %and95.i.874, %for.body.63 ]
  %i.41473 = phi i32 [ 1, %for.end.55 ], [ %inc67, %for.body.63 ]
  %conv.i.799 = zext i64 %and95.i.8741475 to i128
  %mul.i.800 = mul nuw nsw i128 %conv.i.799, %conv.i.799
  %mul6.i.801 = shl nuw nsw i64 %and95.i.8741475, 1
  %conv7.i.802 = zext i64 %mul6.i.801 to i128
  %conv8.i.803 = zext i64 %53 to i128
  %mul9.i.804 = mul nuw nsw i128 %conv7.i.802, %conv8.i.803
  %conv11.i.805 = zext i64 %52 to i128
  %mul12.i.806 = mul nuw nsw i128 %conv11.i.805, %conv7.i.802
  %conv14.i.807 = zext i64 %51 to i128
  %mul15.i.808 = mul nuw nsw i128 %conv14.i.807, %conv7.i.802
  %conv17.i.809 = zext i64 %50 to i128
  %mul18.i.810 = mul nuw nsw i128 %conv17.i.809, %conv7.i.802
  %mul20.i.811 = mul nuw nsw i64 %50, 19
  %conv21.i.812 = zext i64 %mul20.i.811 to i128
  %mul22.i.813 = mul nuw nsw i128 %conv21.i.812, %conv17.i.809
  %mul25.i.814 = mul nuw i128 %conv8.i.803, %conv8.i.803
  %add26.i.815 = add i128 %mul12.i.806, %mul25.i.814
  %mul27.i.816 = shl nsw i64 %53, 1
  %conv28.i.817 = zext i64 %mul27.i.816 to i128
  %mul30.i.818 = mul nuw nsw i128 %conv28.i.817, %conv11.i.805
  %mul34.i.819 = mul nuw i128 %conv14.i.807, %conv28.i.817
  %mul38.i.820 = mul nuw nsw i128 %conv21.i.812, %conv28.i.817
  %mul41.i.821 = mul nsw i64 %51, 19
  %conv42.i.822 = zext i64 %mul41.i.821 to i128
  %mul43.i.823 = mul nuw i128 %conv42.i.822, %conv14.i.807
  %add44.i.824 = add i128 %mul43.i.823, %mul9.i.804
  %mul45.i.825 = shl nsw i64 %51, 1
  %conv46.i.826 = zext i64 %mul45.i.825 to i128
  %mul48.i.827 = mul nuw nsw i128 %conv21.i.812, %conv46.i.826
  %add49.i.828 = add i128 %add26.i.815, %mul48.i.827
  %mul52.i.829 = mul nuw nsw i128 %conv11.i.805, %conv11.i.805
  %mul54.i.830 = shl nuw nsw i64 %52, 1
  %conv55.i.831 = zext i64 %mul54.i.830 to i128
  %mul57.i.832 = mul nuw nsw i128 %conv42.i.822, %conv55.i.831
  %add39.i.833 = add nuw nsw i128 %mul57.i.832, %mul.i.800
  %add58.i.834 = add nuw nsw i128 %add39.i.833, %mul38.i.820
  %mul61.i.835 = mul nuw nsw i128 %conv21.i.812, %conv55.i.831
  %add62.i.836 = add i128 %add44.i.824, %mul61.i.835
  %shr.i.837 = lshr i128 %add49.i.828, 51
  %conv64.i.838 = and i128 %shr.i.837, 18446744073709551615
  %add.i.839 = add nuw nsw i128 %mul15.i.808, %mul30.i.818
  %add31.i.840 = add nuw nsw i128 %add.i.839, %mul22.i.813
  %add65.i.841 = add nuw i128 %add31.i.840, %conv64.i.838
  %conv66.i.842 = trunc i128 %add49.i.828 to i64
  %and.i.843 = and i64 %conv66.i.842, 2251799813685247
  %shr67.i.844 = lshr i128 %add58.i.834, 51
  %conv69.i.845 = and i128 %shr67.i.844, 18446744073709551615
  %add70.i.846 = add i128 %add62.i.836, %conv69.i.845
  %conv71.i.847 = trunc i128 %add58.i.834 to i64
  %and72.i.848 = and i64 %conv71.i.847, 2251799813685247
  %shr73.i.849 = lshr i128 %add65.i.841, 51
  %conv75.i.850 = and i128 %shr73.i.849, 18446744073709551615
  %add35.i.851 = add i128 %mul34.i.819, %mul52.i.829
  %add53.i.852 = add i128 %add35.i.851, %mul18.i.810
  %add76.i.853 = add i128 %add53.i.852, %conv75.i.850
  %conv77.i.854 = trunc i128 %add65.i.841 to i64
  %and78.i.855 = and i64 %conv77.i.854, 2251799813685247
  %shr79.i.856 = lshr i128 %add70.i.846, 51
  %conv80.i.857 = trunc i128 %shr79.i.856 to i64
  %add81.i.858 = add i64 %conv80.i.857, %and.i.843
  %conv82.i.859 = trunc i128 %add70.i.846 to i64
  %and83.i.860 = and i64 %conv82.i.859, 2251799813685247
  %shr84.i.861 = lshr i128 %add76.i.853, 51
  %conv85.i.862 = trunc i128 %shr84.i.861 to i64
  %mul86.i.863 = mul i64 %conv85.i.862, 19
  %add87.i.864 = add i64 %mul86.i.863, %and72.i.848
  %conv88.i.865 = trunc i128 %add76.i.853 to i64
  %and89.i.866 = and i64 %conv88.i.865, 2251799813685247
  %shr90.i.867 = lshr i64 %add81.i.858, 51
  %add91.i.868 = add nuw nsw i64 %shr90.i.867, %and78.i.855
  %fold.i.869 = add i64 %conv80.i.857, %conv66.i.842
  %and92.i.870 = and i64 %fold.i.869, 2251799813685247
  %shr93.i.871 = lshr i64 %add87.i.864, 51
  %add94.i.872 = add nuw nsw i64 %shr93.i.871, %and83.i.860
  %fold180.i.873 = add i64 %mul86.i.863, %conv71.i.847
  %and95.i.874 = and i64 %fold180.i.873, 2251799813685247
  %inc67 = add nuw nsw i32 %i.41473, 1
  %exitcond1510 = icmp eq i32 %inc67, 50
  br i1 %exitcond1510, label %for.end.68, label %for.body.63

for.end.68:                                       ; preds = %for.body.63
  %and95.i.874.lcssa = phi i64 [ %and95.i.874, %for.body.63 ]
  %add94.i.872.lcssa = phi i64 [ %add94.i.872, %for.body.63 ]
  %and92.i.870.lcssa = phi i64 [ %and92.i.870, %for.body.63 ]
  %add91.i.868.lcssa = phi i64 [ %add91.i.868, %for.body.63 ]
  %and89.i.866.lcssa = phi i64 [ %and89.i.866, %for.body.63 ]
  store i64 %and95.i.874.lcssa, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.872.lcssa, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.870.lcssa, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.868.lcssa, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.866.lcssa, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay10, i64* %arraydecay10, i64* %arraydecay1)
  %54 = load i64, i64* %arraydecay10, align 16, !tbaa !5
  %55 = load i64, i64* %arrayidx97.i.539, align 8, !tbaa !5
  %56 = load i64, i64* %arrayidx98.i.540, align 16, !tbaa !5
  %57 = load i64, i64* %arrayidx99.i.541, align 8, !tbaa !5
  %58 = load i64, i64* %arrayidx100.i.542, align 16, !tbaa !5
  %conv.i.631 = zext i64 %54 to i128
  %mul.i.632 = mul nuw i128 %conv.i.631, %conv.i.631
  %mul6.i.633 = shl i64 %54, 1
  %conv7.i.634 = zext i64 %mul6.i.633 to i128
  %conv8.i.635 = zext i64 %55 to i128
  %mul9.i.636 = mul nuw i128 %conv7.i.634, %conv8.i.635
  %conv11.i.637 = zext i64 %56 to i128
  %mul12.i.638 = mul nuw i128 %conv11.i.637, %conv7.i.634
  %conv14.i.639 = zext i64 %57 to i128
  %mul15.i.640 = mul nuw i128 %conv14.i.639, %conv7.i.634
  %conv17.i.641 = zext i64 %58 to i128
  %mul18.i.642 = mul nuw i128 %conv17.i.641, %conv7.i.634
  %mul20.i.643 = mul i64 %58, 19
  %conv21.i.644 = zext i64 %mul20.i.643 to i128
  %mul22.i.645 = mul nuw i128 %conv21.i.644, %conv17.i.641
  %mul25.i.646 = mul nuw i128 %conv8.i.635, %conv8.i.635
  %add26.i.647 = add i128 %mul12.i.638, %mul25.i.646
  %mul27.i.648 = shl i64 %55, 1
  %conv28.i.649 = zext i64 %mul27.i.648 to i128
  %mul30.i.650 = mul nuw i128 %conv28.i.649, %conv11.i.637
  %mul34.i.651 = mul nuw i128 %conv14.i.639, %conv28.i.649
  %mul38.i.652 = mul nuw i128 %conv21.i.644, %conv28.i.649
  %mul41.i.653 = mul i64 %57, 19
  %conv42.i.654 = zext i64 %mul41.i.653 to i128
  %mul43.i.655 = mul nuw i128 %conv42.i.654, %conv14.i.639
  %add44.i.656 = add i128 %mul43.i.655, %mul9.i.636
  %mul45.i.657 = shl i64 %57, 1
  %conv46.i.658 = zext i64 %mul45.i.657 to i128
  %mul48.i.659 = mul nuw i128 %conv21.i.644, %conv46.i.658
  %add49.i.660 = add i128 %add26.i.647, %mul48.i.659
  %mul52.i.661 = mul nuw i128 %conv11.i.637, %conv11.i.637
  %mul54.i.662 = shl i64 %56, 1
  %conv55.i.663 = zext i64 %mul54.i.662 to i128
  %mul57.i.664 = mul nuw i128 %conv42.i.654, %conv55.i.663
  %add39.i.665 = add i128 %mul57.i.664, %mul.i.632
  %add58.i.666 = add i128 %add39.i.665, %mul38.i.652
  %mul61.i.667 = mul nuw i128 %conv21.i.644, %conv55.i.663
  %add62.i.668 = add i128 %add44.i.656, %mul61.i.667
  %shr.i.669 = lshr i128 %add49.i.660, 51
  %conv64.i.670 = and i128 %shr.i.669, 18446744073709551615
  %add.i.671 = add i128 %mul15.i.640, %mul30.i.650
  %add31.i.672 = add i128 %add.i.671, %mul22.i.645
  %add65.i.673 = add i128 %add31.i.672, %conv64.i.670
  %conv66.i.674 = trunc i128 %add49.i.660 to i64
  %and.i.675 = and i64 %conv66.i.674, 2251799813685247
  %shr67.i.676 = lshr i128 %add58.i.666, 51
  %conv69.i.677 = and i128 %shr67.i.676, 18446744073709551615
  %add70.i.678 = add i128 %add62.i.668, %conv69.i.677
  %conv71.i.679 = trunc i128 %add58.i.666 to i64
  %and72.i.680 = and i64 %conv71.i.679, 2251799813685247
  %shr73.i.681 = lshr i128 %add65.i.673, 51
  %conv75.i.682 = and i128 %shr73.i.681, 18446744073709551615
  %add35.i.683 = add i128 %mul34.i.651, %mul52.i.661
  %add53.i.684 = add i128 %add35.i.683, %mul18.i.642
  %add76.i.685 = add i128 %add53.i.684, %conv75.i.682
  %conv77.i.686 = trunc i128 %add65.i.673 to i64
  %and78.i.687 = and i64 %conv77.i.686, 2251799813685247
  %shr79.i.688 = lshr i128 %add70.i.678, 51
  %conv80.i.689 = trunc i128 %shr79.i.688 to i64
  %add81.i.690 = add i64 %conv80.i.689, %and.i.675
  %conv82.i.691 = trunc i128 %add70.i.678 to i64
  %and83.i.692 = and i64 %conv82.i.691, 2251799813685247
  %shr84.i.693 = lshr i128 %add76.i.685, 51
  %conv85.i.694 = trunc i128 %shr84.i.693 to i64
  %mul86.i.695 = mul i64 %conv85.i.694, 19
  %add87.i.696 = add i64 %mul86.i.695, %and72.i.680
  %conv88.i.697 = trunc i128 %add76.i.685 to i64
  %and89.i.698 = and i64 %conv88.i.697, 2251799813685247
  %shr90.i.699 = lshr i64 %add81.i.690, 51
  %add91.i.700 = add nuw nsw i64 %shr90.i.699, %and78.i.687
  %fold.i.701 = add i64 %conv80.i.689, %conv66.i.674
  %and92.i.702 = and i64 %fold.i.701, 2251799813685247
  %shr93.i.703 = lshr i64 %add87.i.696, 51
  %add94.i.704 = add nuw nsw i64 %shr93.i.703, %and83.i.692
  %fold180.i.705 = add i64 %mul86.i.695, %conv71.i.679
  %and95.i.706 = and i64 %fold180.i.705, 2251799813685247
  store i64 %and95.i.706, i64* %arraydecay35, align 16, !tbaa !5
  store i64 %add94.i.704, i64* %arrayidx97.i.1379, align 8, !tbaa !5
  store i64 %and92.i.702, i64* %arrayidx98.i.1380, align 16, !tbaa !5
  store i64 %add91.i.700, i64* %arrayidx99.i.1381, align 8, !tbaa !5
  store i64 %and89.i.698, i64* %arrayidx100.i.1382, align 16, !tbaa !5
  br label %for.body.76

for.body.76:                                      ; preds = %for.body.76, %for.end.68
  %59 = phi i64 [ %and89.i.698, %for.end.68 ], [ %and89.i.614, %for.body.76 ]
  %60 = phi i64 [ %add91.i.700, %for.end.68 ], [ %add91.i.616, %for.body.76 ]
  %61 = phi i64 [ %and92.i.702, %for.end.68 ], [ %and92.i.618, %for.body.76 ]
  %62 = phi i64 [ %add94.i.704, %for.end.68 ], [ %add94.i.620, %for.body.76 ]
  %and95.i.6221472 = phi i64 [ %and95.i.706, %for.end.68 ], [ %and95.i.622, %for.body.76 ]
  %i.51471 = phi i32 [ 1, %for.end.68 ], [ %inc80, %for.body.76 ]
  %conv.i.547 = zext i64 %and95.i.6221472 to i128
  %mul.i.548 = mul nuw nsw i128 %conv.i.547, %conv.i.547
  %mul6.i.549 = shl nuw nsw i64 %and95.i.6221472, 1
  %conv7.i.550 = zext i64 %mul6.i.549 to i128
  %conv8.i.551 = zext i64 %62 to i128
  %mul9.i.552 = mul nuw nsw i128 %conv7.i.550, %conv8.i.551
  %conv11.i.553 = zext i64 %61 to i128
  %mul12.i.554 = mul nuw nsw i128 %conv11.i.553, %conv7.i.550
  %conv14.i.555 = zext i64 %60 to i128
  %mul15.i.556 = mul nuw nsw i128 %conv14.i.555, %conv7.i.550
  %conv17.i.557 = zext i64 %59 to i128
  %mul18.i.558 = mul nuw nsw i128 %conv17.i.557, %conv7.i.550
  %mul20.i.559 = mul nuw nsw i64 %59, 19
  %conv21.i.560 = zext i64 %mul20.i.559 to i128
  %mul22.i.561 = mul nuw nsw i128 %conv21.i.560, %conv17.i.557
  %mul25.i.562 = mul nuw i128 %conv8.i.551, %conv8.i.551
  %add26.i.563 = add i128 %mul12.i.554, %mul25.i.562
  %mul27.i.564 = shl nsw i64 %62, 1
  %conv28.i.565 = zext i64 %mul27.i.564 to i128
  %mul30.i.566 = mul nuw nsw i128 %conv28.i.565, %conv11.i.553
  %mul34.i.567 = mul nuw i128 %conv14.i.555, %conv28.i.565
  %mul38.i.568 = mul nuw nsw i128 %conv21.i.560, %conv28.i.565
  %mul41.i.569 = mul nsw i64 %60, 19
  %conv42.i.570 = zext i64 %mul41.i.569 to i128
  %mul43.i.571 = mul nuw i128 %conv42.i.570, %conv14.i.555
  %add44.i.572 = add i128 %mul43.i.571, %mul9.i.552
  %mul45.i.573 = shl nsw i64 %60, 1
  %conv46.i.574 = zext i64 %mul45.i.573 to i128
  %mul48.i.575 = mul nuw nsw i128 %conv21.i.560, %conv46.i.574
  %add49.i.576 = add i128 %add26.i.563, %mul48.i.575
  %mul52.i.577 = mul nuw nsw i128 %conv11.i.553, %conv11.i.553
  %mul54.i.578 = shl nuw nsw i64 %61, 1
  %conv55.i.579 = zext i64 %mul54.i.578 to i128
  %mul57.i.580 = mul nuw nsw i128 %conv42.i.570, %conv55.i.579
  %add39.i.581 = add nuw nsw i128 %mul57.i.580, %mul.i.548
  %add58.i.582 = add nuw nsw i128 %add39.i.581, %mul38.i.568
  %mul61.i.583 = mul nuw nsw i128 %conv21.i.560, %conv55.i.579
  %add62.i.584 = add i128 %add44.i.572, %mul61.i.583
  %shr.i.585 = lshr i128 %add49.i.576, 51
  %conv64.i.586 = and i128 %shr.i.585, 18446744073709551615
  %add.i.587 = add nuw nsw i128 %mul15.i.556, %mul30.i.566
  %add31.i.588 = add nuw nsw i128 %add.i.587, %mul22.i.561
  %add65.i.589 = add nuw i128 %add31.i.588, %conv64.i.586
  %conv66.i.590 = trunc i128 %add49.i.576 to i64
  %and.i.591 = and i64 %conv66.i.590, 2251799813685247
  %shr67.i.592 = lshr i128 %add58.i.582, 51
  %conv69.i.593 = and i128 %shr67.i.592, 18446744073709551615
  %add70.i.594 = add i128 %add62.i.584, %conv69.i.593
  %conv71.i.595 = trunc i128 %add58.i.582 to i64
  %and72.i.596 = and i64 %conv71.i.595, 2251799813685247
  %shr73.i.597 = lshr i128 %add65.i.589, 51
  %conv75.i.598 = and i128 %shr73.i.597, 18446744073709551615
  %add35.i.599 = add i128 %mul34.i.567, %mul52.i.577
  %add53.i.600 = add i128 %add35.i.599, %mul18.i.558
  %add76.i.601 = add i128 %add53.i.600, %conv75.i.598
  %conv77.i.602 = trunc i128 %add65.i.589 to i64
  %and78.i.603 = and i64 %conv77.i.602, 2251799813685247
  %shr79.i.604 = lshr i128 %add70.i.594, 51
  %conv80.i.605 = trunc i128 %shr79.i.604 to i64
  %add81.i.606 = add i64 %conv80.i.605, %and.i.591
  %conv82.i.607 = trunc i128 %add70.i.594 to i64
  %and83.i.608 = and i64 %conv82.i.607, 2251799813685247
  %shr84.i.609 = lshr i128 %add76.i.601, 51
  %conv85.i.610 = trunc i128 %shr84.i.609 to i64
  %mul86.i.611 = mul i64 %conv85.i.610, 19
  %add87.i.612 = add i64 %mul86.i.611, %and72.i.596
  %conv88.i.613 = trunc i128 %add76.i.601 to i64
  %and89.i.614 = and i64 %conv88.i.613, 2251799813685247
  %shr90.i.615 = lshr i64 %add81.i.606, 51
  %add91.i.616 = add nuw nsw i64 %shr90.i.615, %and78.i.603
  %fold.i.617 = add i64 %conv80.i.605, %conv66.i.590
  %and92.i.618 = and i64 %fold.i.617, 2251799813685247
  %shr93.i.619 = lshr i64 %add87.i.612, 51
  %add94.i.620 = add nuw nsw i64 %shr93.i.619, %and83.i.608
  %fold180.i.621 = add i64 %mul86.i.611, %conv71.i.595
  %and95.i.622 = and i64 %fold180.i.621, 2251799813685247
  %inc80 = add nuw nsw i32 %i.51471, 1
  %exitcond1509 = icmp eq i32 %inc80, 100
  br i1 %exitcond1509, label %for.end.81, label %for.body.76

for.end.81:                                       ; preds = %for.body.76
  %and95.i.622.lcssa = phi i64 [ %and95.i.622, %for.body.76 ]
  %add94.i.620.lcssa = phi i64 [ %add94.i.620, %for.body.76 ]
  %and92.i.618.lcssa = phi i64 [ %and92.i.618, %for.body.76 ]
  %add91.i.616.lcssa = phi i64 [ %add91.i.616, %for.body.76 ]
  %and89.i.614.lcssa = phi i64 [ %and89.i.614, %for.body.76 ]
  store i64 %and95.i.622.lcssa, i64* %arraydecay35, align 16, !tbaa !5
  store i64 %add94.i.620.lcssa, i64* %arrayidx97.i.1379, align 8, !tbaa !5
  store i64 %and92.i.618.lcssa, i64* %arrayidx98.i.1380, align 16, !tbaa !5
  store i64 %add91.i.616.lcssa, i64* %arrayidx99.i.1381, align 8, !tbaa !5
  store i64 %and89.i.614.lcssa, i64* %arrayidx100.i.1382, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay10, i64* %arraydecay35, i64* %arraydecay10)
  %arraydecay10.promoted = load i64, i64* %arraydecay10, align 16, !tbaa !5
  %arrayidx97.i.539.promoted = load i64, i64* %arrayidx97.i.539, align 8, !tbaa !5
  %arrayidx98.i.540.promoted = load i64, i64* %arrayidx98.i.540, align 16, !tbaa !5
  %arrayidx99.i.541.promoted = load i64, i64* %arrayidx99.i.541, align 8, !tbaa !5
  %arrayidx100.i.542.promoted = load i64, i64* %arrayidx100.i.542, align 16, !tbaa !5
  br label %for.body.87

for.body.87:                                      ; preds = %for.body.87, %for.end.81
  %63 = phi i64 [ %arrayidx100.i.542.promoted, %for.end.81 ], [ %and89.i.446, %for.body.87 ]
  %64 = phi i64 [ %arrayidx99.i.541.promoted, %for.end.81 ], [ %add91.i.448, %for.body.87 ]
  %65 = phi i64 [ %arrayidx98.i.540.promoted, %for.end.81 ], [ %and92.i.450, %for.body.87 ]
  %66 = phi i64 [ %arrayidx97.i.539.promoted, %for.end.81 ], [ %add94.i.452, %for.body.87 ]
  %and95.i.4541470 = phi i64 [ %arraydecay10.promoted, %for.end.81 ], [ %and95.i.454, %for.body.87 ]
  %i.61469 = phi i32 [ 0, %for.end.81 ], [ %inc91, %for.body.87 ]
  %conv.i.379 = zext i64 %and95.i.4541470 to i128
  %mul.i.380 = mul nuw i128 %conv.i.379, %conv.i.379
  %mul6.i.381 = shl i64 %and95.i.4541470, 1
  %conv7.i.382 = zext i64 %mul6.i.381 to i128
  %conv8.i.383 = zext i64 %66 to i128
  %mul9.i.384 = mul nuw i128 %conv7.i.382, %conv8.i.383
  %conv11.i.385 = zext i64 %65 to i128
  %mul12.i.386 = mul nuw i128 %conv11.i.385, %conv7.i.382
  %conv14.i.387 = zext i64 %64 to i128
  %mul15.i.388 = mul nuw i128 %conv14.i.387, %conv7.i.382
  %conv17.i.389 = zext i64 %63 to i128
  %mul18.i.390 = mul nuw i128 %conv17.i.389, %conv7.i.382
  %mul20.i.391 = mul i64 %63, 19
  %conv21.i.392 = zext i64 %mul20.i.391 to i128
  %mul22.i.393 = mul nuw i128 %conv21.i.392, %conv17.i.389
  %mul25.i.394 = mul nuw i128 %conv8.i.383, %conv8.i.383
  %add26.i.395 = add i128 %mul12.i.386, %mul25.i.394
  %mul27.i.396 = shl i64 %66, 1
  %conv28.i.397 = zext i64 %mul27.i.396 to i128
  %mul30.i.398 = mul nuw i128 %conv28.i.397, %conv11.i.385
  %mul34.i.399 = mul nuw i128 %conv14.i.387, %conv28.i.397
  %mul38.i.400 = mul nuw i128 %conv21.i.392, %conv28.i.397
  %mul41.i.401 = mul i64 %64, 19
  %conv42.i.402 = zext i64 %mul41.i.401 to i128
  %mul43.i.403 = mul nuw i128 %conv42.i.402, %conv14.i.387
  %add44.i.404 = add i128 %mul43.i.403, %mul9.i.384
  %mul45.i.405 = shl i64 %64, 1
  %conv46.i.406 = zext i64 %mul45.i.405 to i128
  %mul48.i.407 = mul nuw i128 %conv21.i.392, %conv46.i.406
  %add49.i.408 = add i128 %add26.i.395, %mul48.i.407
  %mul52.i.409 = mul nuw i128 %conv11.i.385, %conv11.i.385
  %mul54.i.410 = shl i64 %65, 1
  %conv55.i.411 = zext i64 %mul54.i.410 to i128
  %mul57.i.412 = mul nuw i128 %conv42.i.402, %conv55.i.411
  %add39.i.413 = add i128 %mul57.i.412, %mul.i.380
  %add58.i.414 = add i128 %add39.i.413, %mul38.i.400
  %mul61.i.415 = mul nuw i128 %conv21.i.392, %conv55.i.411
  %add62.i.416 = add i128 %add44.i.404, %mul61.i.415
  %shr.i.417 = lshr i128 %add49.i.408, 51
  %conv64.i.418 = and i128 %shr.i.417, 18446744073709551615
  %add.i.419 = add i128 %mul15.i.388, %mul30.i.398
  %add31.i.420 = add i128 %add.i.419, %mul22.i.393
  %add65.i.421 = add i128 %add31.i.420, %conv64.i.418
  %conv66.i.422 = trunc i128 %add49.i.408 to i64
  %and.i.423 = and i64 %conv66.i.422, 2251799813685247
  %shr67.i.424 = lshr i128 %add58.i.414, 51
  %conv69.i.425 = and i128 %shr67.i.424, 18446744073709551615
  %add70.i.426 = add i128 %add62.i.416, %conv69.i.425
  %conv71.i.427 = trunc i128 %add58.i.414 to i64
  %and72.i.428 = and i64 %conv71.i.427, 2251799813685247
  %shr73.i.429 = lshr i128 %add65.i.421, 51
  %conv75.i.430 = and i128 %shr73.i.429, 18446744073709551615
  %add35.i.431 = add i128 %mul34.i.399, %mul52.i.409
  %add53.i.432 = add i128 %add35.i.431, %mul18.i.390
  %add76.i.433 = add i128 %add53.i.432, %conv75.i.430
  %conv77.i.434 = trunc i128 %add65.i.421 to i64
  %and78.i.435 = and i64 %conv77.i.434, 2251799813685247
  %shr79.i.436 = lshr i128 %add70.i.426, 51
  %conv80.i.437 = trunc i128 %shr79.i.436 to i64
  %add81.i.438 = add i64 %conv80.i.437, %and.i.423
  %conv82.i.439 = trunc i128 %add70.i.426 to i64
  %and83.i.440 = and i64 %conv82.i.439, 2251799813685247
  %shr84.i.441 = lshr i128 %add76.i.433, 51
  %conv85.i.442 = trunc i128 %shr84.i.441 to i64
  %mul86.i.443 = mul i64 %conv85.i.442, 19
  %add87.i.444 = add i64 %mul86.i.443, %and72.i.428
  %conv88.i.445 = trunc i128 %add76.i.433 to i64
  %and89.i.446 = and i64 %conv88.i.445, 2251799813685247
  %shr90.i.447 = lshr i64 %add81.i.438, 51
  %add91.i.448 = add nuw nsw i64 %shr90.i.447, %and78.i.435
  %fold.i.449 = add i64 %conv80.i.437, %conv66.i.422
  %and92.i.450 = and i64 %fold.i.449, 2251799813685247
  %shr93.i.451 = lshr i64 %add87.i.444, 51
  %add94.i.452 = add nuw nsw i64 %shr93.i.451, %and83.i.440
  %fold180.i.453 = add i64 %mul86.i.443, %conv71.i.427
  %and95.i.454 = and i64 %fold180.i.453, 2251799813685247
  %inc91 = add nuw nsw i32 %i.61469, 1
  %exitcond1508 = icmp eq i32 %inc91, 50
  br i1 %exitcond1508, label %for.end.92, label %for.body.87

for.end.92:                                       ; preds = %for.body.87
  %and95.i.454.lcssa = phi i64 [ %and95.i.454, %for.body.87 ]
  %add94.i.452.lcssa = phi i64 [ %add94.i.452, %for.body.87 ]
  %and92.i.450.lcssa = phi i64 [ %and92.i.450, %for.body.87 ]
  %add91.i.448.lcssa = phi i64 [ %add91.i.448, %for.body.87 ]
  %and89.i.446.lcssa = phi i64 [ %and89.i.446, %for.body.87 ]
  store i64 %and95.i.454.lcssa, i64* %arraydecay10, align 16, !tbaa !5
  store i64 %add94.i.452.lcssa, i64* %arrayidx97.i.539, align 8, !tbaa !5
  store i64 %and92.i.450.lcssa, i64* %arrayidx98.i.540, align 16, !tbaa !5
  store i64 %add91.i.448.lcssa, i64* %arrayidx99.i.541, align 8, !tbaa !5
  store i64 %and89.i.446.lcssa, i64* %arrayidx100.i.542, align 16, !tbaa !5
  call void @fe51_mul(i64* %arraydecay1, i64* %arraydecay10, i64* %arraydecay1)
  %arraydecay1.promoted = load i64, i64* %arraydecay1, align 16, !tbaa !5
  %arrayidx97.i.203.promoted = load i64, i64* %arrayidx97.i.203, align 8, !tbaa !5
  %arrayidx98.i.204.promoted = load i64, i64* %arrayidx98.i.204, align 16, !tbaa !5
  %arrayidx99.i.205.promoted = load i64, i64* %arrayidx99.i.205, align 8, !tbaa !5
  %arrayidx100.i.206.promoted = load i64, i64* %arrayidx100.i.206, align 16, !tbaa !5
  br label %for.body.98

for.body.98:                                      ; preds = %for.body.98, %for.end.92
  %67 = phi i64 [ %arrayidx100.i.206.promoted, %for.end.92 ], [ %and89.i.278, %for.body.98 ]
  %68 = phi i64 [ %arrayidx99.i.205.promoted, %for.end.92 ], [ %add91.i.280, %for.body.98 ]
  %69 = phi i64 [ %arrayidx98.i.204.promoted, %for.end.92 ], [ %and92.i.282, %for.body.98 ]
  %70 = phi i64 [ %arrayidx97.i.203.promoted, %for.end.92 ], [ %add94.i.284, %for.body.98 ]
  %and95.i.2861468 = phi i64 [ %arraydecay1.promoted, %for.end.92 ], [ %and95.i.286, %for.body.98 ]
  %i.71467 = phi i32 [ 0, %for.end.92 ], [ %inc102, %for.body.98 ]
  %conv.i.211 = zext i64 %and95.i.2861468 to i128
  %mul.i.212 = mul nuw i128 %conv.i.211, %conv.i.211
  %mul6.i.213 = shl i64 %and95.i.2861468, 1
  %conv7.i.214 = zext i64 %mul6.i.213 to i128
  %conv8.i.215 = zext i64 %70 to i128
  %mul9.i.216 = mul nuw i128 %conv7.i.214, %conv8.i.215
  %conv11.i.217 = zext i64 %69 to i128
  %mul12.i.218 = mul nuw i128 %conv11.i.217, %conv7.i.214
  %conv14.i.219 = zext i64 %68 to i128
  %mul15.i.220 = mul nuw i128 %conv14.i.219, %conv7.i.214
  %conv17.i.221 = zext i64 %67 to i128
  %mul18.i.222 = mul nuw i128 %conv17.i.221, %conv7.i.214
  %mul20.i.223 = mul i64 %67, 19
  %conv21.i.224 = zext i64 %mul20.i.223 to i128
  %mul22.i.225 = mul nuw i128 %conv21.i.224, %conv17.i.221
  %mul25.i.226 = mul nuw i128 %conv8.i.215, %conv8.i.215
  %add26.i.227 = add i128 %mul12.i.218, %mul25.i.226
  %mul27.i.228 = shl i64 %70, 1
  %conv28.i.229 = zext i64 %mul27.i.228 to i128
  %mul30.i.230 = mul nuw i128 %conv28.i.229, %conv11.i.217
  %mul34.i.231 = mul nuw i128 %conv14.i.219, %conv28.i.229
  %mul38.i.232 = mul nuw i128 %conv21.i.224, %conv28.i.229
  %mul41.i.233 = mul i64 %68, 19
  %conv42.i.234 = zext i64 %mul41.i.233 to i128
  %mul43.i.235 = mul nuw i128 %conv42.i.234, %conv14.i.219
  %add44.i.236 = add i128 %mul43.i.235, %mul9.i.216
  %mul45.i.237 = shl i64 %68, 1
  %conv46.i.238 = zext i64 %mul45.i.237 to i128
  %mul48.i.239 = mul nuw i128 %conv21.i.224, %conv46.i.238
  %add49.i.240 = add i128 %add26.i.227, %mul48.i.239
  %mul52.i.241 = mul nuw i128 %conv11.i.217, %conv11.i.217
  %mul54.i.242 = shl i64 %69, 1
  %conv55.i.243 = zext i64 %mul54.i.242 to i128
  %mul57.i.244 = mul nuw i128 %conv42.i.234, %conv55.i.243
  %add39.i.245 = add i128 %mul57.i.244, %mul.i.212
  %add58.i.246 = add i128 %add39.i.245, %mul38.i.232
  %mul61.i.247 = mul nuw i128 %conv21.i.224, %conv55.i.243
  %add62.i.248 = add i128 %add44.i.236, %mul61.i.247
  %shr.i.249 = lshr i128 %add49.i.240, 51
  %conv64.i.250 = and i128 %shr.i.249, 18446744073709551615
  %add.i.251 = add i128 %mul15.i.220, %mul30.i.230
  %add31.i.252 = add i128 %add.i.251, %mul22.i.225
  %add65.i.253 = add i128 %add31.i.252, %conv64.i.250
  %conv66.i.254 = trunc i128 %add49.i.240 to i64
  %and.i.255 = and i64 %conv66.i.254, 2251799813685247
  %shr67.i.256 = lshr i128 %add58.i.246, 51
  %conv69.i.257 = and i128 %shr67.i.256, 18446744073709551615
  %add70.i.258 = add i128 %add62.i.248, %conv69.i.257
  %conv71.i.259 = trunc i128 %add58.i.246 to i64
  %and72.i.260 = and i64 %conv71.i.259, 2251799813685247
  %shr73.i.261 = lshr i128 %add65.i.253, 51
  %conv75.i.262 = and i128 %shr73.i.261, 18446744073709551615
  %add35.i.263 = add i128 %mul34.i.231, %mul52.i.241
  %add53.i.264 = add i128 %add35.i.263, %mul18.i.222
  %add76.i.265 = add i128 %add53.i.264, %conv75.i.262
  %conv77.i.266 = trunc i128 %add65.i.253 to i64
  %and78.i.267 = and i64 %conv77.i.266, 2251799813685247
  %shr79.i.268 = lshr i128 %add70.i.258, 51
  %conv80.i.269 = trunc i128 %shr79.i.268 to i64
  %add81.i.270 = add i64 %conv80.i.269, %and.i.255
  %conv82.i.271 = trunc i128 %add70.i.258 to i64
  %and83.i.272 = and i64 %conv82.i.271, 2251799813685247
  %shr84.i.273 = lshr i128 %add76.i.265, 51
  %conv85.i.274 = trunc i128 %shr84.i.273 to i64
  %mul86.i.275 = mul i64 %conv85.i.274, 19
  %add87.i.276 = add i64 %mul86.i.275, %and72.i.260
  %conv88.i.277 = trunc i128 %add76.i.265 to i64
  %and89.i.278 = and i64 %conv88.i.277, 2251799813685247
  %shr90.i.279 = lshr i64 %add81.i.270, 51
  %add91.i.280 = add nuw nsw i64 %shr90.i.279, %and78.i.267
  %fold.i.281 = add i64 %conv80.i.269, %conv66.i.254
  %and92.i.282 = and i64 %fold.i.281, 2251799813685247
  %shr93.i.283 = lshr i64 %add87.i.276, 51
  %add94.i.284 = add nuw nsw i64 %shr93.i.283, %and83.i.272
  %fold180.i.285 = add i64 %mul86.i.275, %conv71.i.259
  %and95.i.286 = and i64 %fold180.i.285, 2251799813685247
  %inc102 = add nuw nsw i32 %i.71467, 1
  %exitcond = icmp eq i32 %inc102, 5
  br i1 %exitcond, label %for.end.103, label %for.body.98

for.end.103:                                      ; preds = %for.body.98
  %and95.i.286.lcssa = phi i64 [ %and95.i.286, %for.body.98 ]
  %add94.i.284.lcssa = phi i64 [ %add94.i.284, %for.body.98 ]
  %and92.i.282.lcssa = phi i64 [ %and92.i.282, %for.body.98 ]
  %add91.i.280.lcssa = phi i64 [ %add91.i.280, %for.body.98 ]
  %and89.i.278.lcssa = phi i64 [ %and89.i.278, %for.body.98 ]
  store i64 %and95.i.286.lcssa, i64* %arraydecay1, align 16, !tbaa !5
  store i64 %add94.i.284.lcssa, i64* %arrayidx97.i.203, align 8, !tbaa !5
  store i64 %and92.i.282.lcssa, i64* %arrayidx98.i.204, align 16, !tbaa !5
  store i64 %add91.i.280.lcssa, i64* %arrayidx99.i.205, align 8, !tbaa !5
  store i64 %and89.i.278.lcssa, i64* %arrayidx100.i.206, align 16, !tbaa !5
  call void @fe51_mul(i64* %out, i64* %arraydecay1, i64* %arraydecay)
  call void @llvm.lifetime.end(i64 40, i8* %3) #1
  call void @llvm.lifetime.end(i64 40, i8* %2) #1
  call void @llvm.lifetime.end(i64 40, i8* %1) #1
  call void @llvm.lifetime.end(i64 40, i8* %0) #1
  ret void
}

attributes #0 = { nounwind ssp uwtable "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="core2" "target-features"="+cx16,+sse,+sse2,+sse3,+ssse3" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind }
attributes #2 = { "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="core2" "target-features"="+cx16,+sse,+sse2,+sse3,+ssse3" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="core2" "target-features"="+cx16,+sse,+sse2,+sse3,+ssse3" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"PIC Level", i32 2}
!1 = !{!"clang version 3.7.0 (tags/RELEASE_370/final)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!6, !6, i64 0}
!6 = !{!"long long", !3, i64 0}
!7 = !{!8, !8, i64 0}
!8 = !{!"int", !3, i64 0}
