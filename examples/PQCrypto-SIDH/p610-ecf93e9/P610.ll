; ModuleID = 'src/P610/P610.c'
source_filename = "src/P610/P610.c"
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.13.0"

%struct.point_proj = type { [2 x [10 x i64]], [2 x [10 x i64]] }

@p610 = local_unnamed_addr constant [10 x i64] [i64 -1, i64 -1, i64 -1, i64 -1, i64 7926898294125494271, i64 -5658687270105206738, i64 -7284643569098294869, i64 -5596370174845115094, i64 -9110763619386664820, i64 10669696872], align 16
@p610x2 = local_unnamed_addr constant [10 x i64] [i64 -2, i64 -1, i64 -1, i64 -1, i64 -2592947485458563073, i64 7129369533499138140, i64 3877456935512961879, i64 7254003724019321429, i64 225216834936221977, i64 21339393745], align 16
@p610x4 = local_unnamed_addr constant [10 x i64] [i64 -4, i64 -1, i64 -1, i64 -1, i64 -5185894970917126145, i64 -4188005006711275335, i64 7754913871025923758, i64 -3938736625670908758, i64 450433669872443954, i64 42678787490], align 16
@p610x8 = local_unnamed_addr constant [10 x i64] [i64 -8, i64 -1, i64 -1, i64 -1, i64 8074954131875299327, i64 -8376010013422550669, i64 -2936916331657704099, i64 -7877473251341817516, i64 900867339744887909, i64 85357574980], align 16
@p610p1 = local_unnamed_addr constant [10 x i64] [i64 0, i64 0, i64 0, i64 0, i64 7926898294125494272, i64 -5658687270105206738, i64 -7284643569098294869, i64 -5596370174845115094, i64 -9110763619386664820, i64 10669696872], align 16
@Alice_order = local_unnamed_addr constant [5 x i64] [i64 0, i64 0, i64 0, i64 0, i64 562949953421312], align 16
@Bob_order = local_unnamed_addr constant [5 x i64] [i64 2806962120998467329, i64 -2332158411328333636, i64 -2775052578078765709, i64 603808853150554410, i64 349624627118280], align 16
@A_gen = local_unnamed_addr constant [60 x i64] [i64 5771904529248994682, i64 -8436915071433390351, i64 270330086766583390, i64 6481898407746275289, i64 7865854910092666580, i64 -2826674533944143030, i64 -7553167192889215565, i64 -9032646596491157233, i64 5194719131280954495, i64 1729770898, i64 -1965085922052779020, i64 -4812970318505102637, i64 1977403254395278860, i64 2726390535525409621, i64 -248047565090072982, i64 -5454070453411567460, i64 -2860923682387992558, i64 4095961562244124488, i64 -4917308312211097814, i64 5102423139, i64 2124736252400681868, i64 -7322998048931732039, i64 2202127831239085027, i64 -3257580811259719115, i64 4313963896834226850, i64 -5076443579667205976, i64 4921946642166740880, i64 -3805954528561435943, i64 -2637702132890644254, i64 7907518294, i64 2200917311302176889, i64 2939498022256786432, i64 -2284167071920397343, i64 -8889311404158421409, i64 -3057031954716630490, i64 -4860527247048815703, i64 -7932579696214058839, i64 334500554730375393, i64 6399318707077975086, i64 8976719684, i64 2746580562334225805, i64 -4441891846683360495, i64 -6980094913201629698, i64 -6647113845825354661, i64 6714415832701611114, i64 -8334607330680099106, i64 7010145936394111770, i64 -403948467988784721, i64 -7139691166611819809, i64 3478841981, i64 -5079986323839184192, i64 3119472779256121459, i64 4709779656408495164, i64 -1878325030037470211, i64 -3755564803635956908, i64 5893360609436446022, i64 6635037533545129430, i64 5031143778661013925, i64 2711723078310815363, i64 10114015515], align 16
@B_gen = local_unnamed_addr constant [60 x i64] [i64 -4122797515158813510, i64 2405435625630280597, i64 -3749193287274905454, i64 -2935559660200231368, i64 7035179512456608727, i64 -1088186176647096380, i64 2237320506219039519, i64 -4139295546001939262, i64 -2033832934895166963, i64 5379123413, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 -754674776282359680, i64 8155755975969367465, i64 -7108179690244256889, i64 5678382275401384545, i64 -5945512278495342032, i64 4726463275275376934, i64 -1362977618025674515, i64 4479281637794437063, i64 -906589179791040647, i64 9074793307, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 8829176751768485847, i64 4330345099806588278, i64 6439066249656508832, i64 -774629675044450053, i64 -5503580640218556678, i64 -9083173236816041803, i64 -1462621330690897264, i64 -8763703354377076720, i64 -2191538623876663267, i64 9017845420, i64 6790521807624498538, i64 -2290772438416721629, i64 4283588130542979409, i64 514645655039295889, i64 8912678322428419353, i64 6038404330050892853, i64 -1270586841300829686, i64 -8530139311933844284, i64 910728456329037494, i64 5513273805], align 16
@Montgomery_R2 = constant [10 x i64] [i64 -1774597335702472921, i64 -2253953328706275026, i64 7764610893679053117, i64 -2558253936849870651, i64 8311396451547473226, i64 -8866252043420476836, i64 9136860735727631175, i64 -4198676031223070541, i64 8077651299688882586, i64 2385055731], align 16
@Montgomery_one = local_unnamed_addr constant [10 x i64] [i64 1728891110, i64 0, i64 0, i64 0, i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590, i64 1398651832995983165, i64 4438944100], align 16
@strat_Alice = local_unnamed_addr constant [151 x i32] [i32 67, i32 37, i32 21, i32 12, i32 7, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 9, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 16, i32 9, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 8, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 33, i32 16, i32 8, i32 5, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 8, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 16, i32 8, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 8, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1], align 16
@strat_Bob = local_unnamed_addr constant [191 x i32] [i32 86, i32 48, i32 27, i32 15, i32 8, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 7, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 12, i32 7, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 21, i32 12, i32 7, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 9, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 38, i32 21, i32 12, i32 7, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 9, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 17, i32 9, i32 5, i32 3, i32 2, i32 1, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 8, i32 4, i32 2, i32 1, i32 1, i32 1, i32 2, i32 1, i32 1, i32 4, i32 2, i32 1, i32 1, i32 2, i32 1, i32 1], align 16

; Function Attrs: norecurse nounwind ssp uwtable
define void @clear_words(i8* %mem, i64 %nwords) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %mem to i64*
  %cmp6 = icmp eq i64 %nwords, 0
  br i1 %cmp6, label %for.cond.cleanup, label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  ret void

for.body:                                         ; preds = %entry, %for.body
  %conv8 = phi i64 [ %conv, %for.body ], [ 0, %entry ]
  %i.07 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  %arrayidx = getelementptr inbounds i64, i64* %0, i64 %conv8
  store volatile i64 0, i64* %arrayidx, align 8, !tbaa !3
  %inc = add i32 %i.07, 1
  %conv = zext i32 %inc to i64
  %cmp = icmp ult i64 %conv, %nwords
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture) #1

; Function Attrs: norecurse nounwind readonly ssp uwtable
define signext i8 @ct_compare(i8* nocapture readonly %a, i8* nocapture readonly %b, i32 %len) local_unnamed_addr #2 {
entry:
  %cmp14 = icmp eq i32 %len, 0
  br i1 %cmp14, label %for.cond.cleanup, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %len to i64
  %min.iters.check = icmp ult i32 %len, 32
  br i1 %min.iters.check, label %for.body.preheader39, label %vector.ph

for.body.preheader39:                             ; preds = %middle.block, %for.body.preheader
  %indvars.iv.ph = phi i64 [ 0, %for.body.preheader ], [ %n.vec, %middle.block ]
  %r.015.ph = phi i32 [ 0, %for.body.preheader ], [ %88, %middle.block ]
  br label %for.body

vector.ph:                                        ; preds = %for.body.preheader
  %n.vec = and i64 %wide.trip.count, 4294967264
  %0 = add nsw i64 %n.vec, -32
  %1 = lshr exact i64 %0, 5
  %2 = add nuw nsw i64 %1, 1
  %xtraiter = and i64 %2, 1
  %3 = icmp eq i64 %0, 0
  br i1 %3, label %middle.block.unr-lcssa, label %vector.ph.new

vector.ph.new:                                    ; preds = %vector.ph
  %unroll_iter = sub nsw i64 %2, %xtraiter
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph.new
  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]
  %vec.phi = phi <8 x i32> [ zeroinitializer, %vector.ph.new ], [ %56, %vector.body ]
  %vec.phi22 = phi <8 x i32> [ zeroinitializer, %vector.ph.new ], [ %57, %vector.body ]
  %vec.phi23 = phi <8 x i32> [ zeroinitializer, %vector.ph.new ], [ %58, %vector.body ]
  %vec.phi24 = phi <8 x i32> [ zeroinitializer, %vector.ph.new ], [ %59, %vector.body ]
  %niter = phi i64 [ %unroll_iter, %vector.ph.new ], [ %niter.nsub.1, %vector.body ]
  %4 = getelementptr inbounds i8, i8* %a, i64 %index
  %5 = bitcast i8* %4 to <8 x i8>*
  %wide.load = load <8 x i8>, <8 x i8>* %5, align 1, !tbaa !7
  %6 = getelementptr inbounds i8, i8* %4, i64 8
  %7 = bitcast i8* %6 to <8 x i8>*
  %wide.load25 = load <8 x i8>, <8 x i8>* %7, align 1, !tbaa !7
  %8 = getelementptr inbounds i8, i8* %4, i64 16
  %9 = bitcast i8* %8 to <8 x i8>*
  %wide.load26 = load <8 x i8>, <8 x i8>* %9, align 1, !tbaa !7
  %10 = getelementptr inbounds i8, i8* %4, i64 24
  %11 = bitcast i8* %10 to <8 x i8>*
  %wide.load27 = load <8 x i8>, <8 x i8>* %11, align 1, !tbaa !7
  %12 = getelementptr inbounds i8, i8* %b, i64 %index
  %13 = bitcast i8* %12 to <8 x i8>*
  %wide.load28 = load <8 x i8>, <8 x i8>* %13, align 1, !tbaa !7
  %14 = getelementptr inbounds i8, i8* %12, i64 8
  %15 = bitcast i8* %14 to <8 x i8>*
  %wide.load29 = load <8 x i8>, <8 x i8>* %15, align 1, !tbaa !7
  %16 = getelementptr inbounds i8, i8* %12, i64 16
  %17 = bitcast i8* %16 to <8 x i8>*
  %wide.load30 = load <8 x i8>, <8 x i8>* %17, align 1, !tbaa !7
  %18 = getelementptr inbounds i8, i8* %12, i64 24
  %19 = bitcast i8* %18 to <8 x i8>*
  %wide.load31 = load <8 x i8>, <8 x i8>* %19, align 1, !tbaa !7
  %20 = xor <8 x i8> %wide.load28, %wide.load
  %21 = xor <8 x i8> %wide.load29, %wide.load25
  %22 = xor <8 x i8> %wide.load30, %wide.load26
  %23 = xor <8 x i8> %wide.load31, %wide.load27
  %24 = zext <8 x i8> %20 to <8 x i32>
  %25 = zext <8 x i8> %21 to <8 x i32>
  %26 = zext <8 x i8> %22 to <8 x i32>
  %27 = zext <8 x i8> %23 to <8 x i32>
  %28 = or <8 x i32> %vec.phi, %24
  %29 = or <8 x i32> %vec.phi22, %25
  %30 = or <8 x i32> %vec.phi23, %26
  %31 = or <8 x i32> %vec.phi24, %27
  %index.next = or i64 %index, 32
  %32 = getelementptr inbounds i8, i8* %a, i64 %index.next
  %33 = bitcast i8* %32 to <8 x i8>*
  %wide.load.1 = load <8 x i8>, <8 x i8>* %33, align 1, !tbaa !7
  %34 = getelementptr inbounds i8, i8* %32, i64 8
  %35 = bitcast i8* %34 to <8 x i8>*
  %wide.load25.1 = load <8 x i8>, <8 x i8>* %35, align 1, !tbaa !7
  %36 = getelementptr inbounds i8, i8* %32, i64 16
  %37 = bitcast i8* %36 to <8 x i8>*
  %wide.load26.1 = load <8 x i8>, <8 x i8>* %37, align 1, !tbaa !7
  %38 = getelementptr inbounds i8, i8* %32, i64 24
  %39 = bitcast i8* %38 to <8 x i8>*
  %wide.load27.1 = load <8 x i8>, <8 x i8>* %39, align 1, !tbaa !7
  %40 = getelementptr inbounds i8, i8* %b, i64 %index.next
  %41 = bitcast i8* %40 to <8 x i8>*
  %wide.load28.1 = load <8 x i8>, <8 x i8>* %41, align 1, !tbaa !7
  %42 = getelementptr inbounds i8, i8* %40, i64 8
  %43 = bitcast i8* %42 to <8 x i8>*
  %wide.load29.1 = load <8 x i8>, <8 x i8>* %43, align 1, !tbaa !7
  %44 = getelementptr inbounds i8, i8* %40, i64 16
  %45 = bitcast i8* %44 to <8 x i8>*
  %wide.load30.1 = load <8 x i8>, <8 x i8>* %45, align 1, !tbaa !7
  %46 = getelementptr inbounds i8, i8* %40, i64 24
  %47 = bitcast i8* %46 to <8 x i8>*
  %wide.load31.1 = load <8 x i8>, <8 x i8>* %47, align 1, !tbaa !7
  %48 = xor <8 x i8> %wide.load28.1, %wide.load.1
  %49 = xor <8 x i8> %wide.load29.1, %wide.load25.1
  %50 = xor <8 x i8> %wide.load30.1, %wide.load26.1
  %51 = xor <8 x i8> %wide.load31.1, %wide.load27.1
  %52 = zext <8 x i8> %48 to <8 x i32>
  %53 = zext <8 x i8> %49 to <8 x i32>
  %54 = zext <8 x i8> %50 to <8 x i32>
  %55 = zext <8 x i8> %51 to <8 x i32>
  %56 = or <8 x i32> %28, %52
  %57 = or <8 x i32> %29, %53
  %58 = or <8 x i32> %30, %54
  %59 = or <8 x i32> %31, %55
  %index.next.1 = add i64 %index, 64
  %niter.nsub.1 = add i64 %niter, -2
  %niter.ncmp.1 = icmp eq i64 %niter.nsub.1, 0
  br i1 %niter.ncmp.1, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !8

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %.lcssa43.ph = phi <8 x i32> [ undef, %vector.ph ], [ %56, %vector.body ]
  %.lcssa42.ph = phi <8 x i32> [ undef, %vector.ph ], [ %57, %vector.body ]
  %.lcssa41.ph = phi <8 x i32> [ undef, %vector.ph ], [ %58, %vector.body ]
  %.lcssa.ph = phi <8 x i32> [ undef, %vector.ph ], [ %59, %vector.body ]
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %vector.body ]
  %vec.phi.unr = phi <8 x i32> [ zeroinitializer, %vector.ph ], [ %56, %vector.body ]
  %vec.phi22.unr = phi <8 x i32> [ zeroinitializer, %vector.ph ], [ %57, %vector.body ]
  %vec.phi23.unr = phi <8 x i32> [ zeroinitializer, %vector.ph ], [ %58, %vector.body ]
  %vec.phi24.unr = phi <8 x i32> [ zeroinitializer, %vector.ph ], [ %59, %vector.body ]
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa
  %60 = getelementptr inbounds i8, i8* %a, i64 %index.unr
  %61 = getelementptr inbounds i8, i8* %b, i64 %index.unr
  %62 = getelementptr inbounds i8, i8* %61, i64 24
  %63 = bitcast i8* %62 to <8 x i8>*
  %wide.load31.epil = load <8 x i8>, <8 x i8>* %63, align 1, !tbaa !7
  %64 = getelementptr inbounds i8, i8* %60, i64 24
  %65 = bitcast i8* %64 to <8 x i8>*
  %wide.load27.epil = load <8 x i8>, <8 x i8>* %65, align 1, !tbaa !7
  %66 = xor <8 x i8> %wide.load31.epil, %wide.load27.epil
  %67 = zext <8 x i8> %66 to <8 x i32>
  %68 = or <8 x i32> %vec.phi24.unr, %67
  %69 = getelementptr inbounds i8, i8* %61, i64 16
  %70 = bitcast i8* %69 to <8 x i8>*
  %wide.load30.epil = load <8 x i8>, <8 x i8>* %70, align 1, !tbaa !7
  %71 = getelementptr inbounds i8, i8* %60, i64 16
  %72 = bitcast i8* %71 to <8 x i8>*
  %wide.load26.epil = load <8 x i8>, <8 x i8>* %72, align 1, !tbaa !7
  %73 = xor <8 x i8> %wide.load30.epil, %wide.load26.epil
  %74 = zext <8 x i8> %73 to <8 x i32>
  %75 = or <8 x i32> %vec.phi23.unr, %74
  %76 = getelementptr inbounds i8, i8* %61, i64 8
  %77 = bitcast i8* %76 to <8 x i8>*
  %wide.load29.epil = load <8 x i8>, <8 x i8>* %77, align 1, !tbaa !7
  %78 = getelementptr inbounds i8, i8* %60, i64 8
  %79 = bitcast i8* %78 to <8 x i8>*
  %wide.load25.epil = load <8 x i8>, <8 x i8>* %79, align 1, !tbaa !7
  %80 = xor <8 x i8> %wide.load29.epil, %wide.load25.epil
  %81 = zext <8 x i8> %80 to <8 x i32>
  %82 = or <8 x i32> %vec.phi22.unr, %81
  %83 = bitcast i8* %61 to <8 x i8>*
  %wide.load28.epil = load <8 x i8>, <8 x i8>* %83, align 1, !tbaa !7
  %84 = bitcast i8* %60 to <8 x i8>*
  %wide.load.epil = load <8 x i8>, <8 x i8>* %84, align 1, !tbaa !7
  %85 = xor <8 x i8> %wide.load28.epil, %wide.load.epil
  %86 = zext <8 x i8> %85 to <8 x i32>
  %87 = or <8 x i32> %vec.phi.unr, %86
  br label %middle.block

middle.block:                                     ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %.lcssa43 = phi <8 x i32> [ %.lcssa43.ph, %middle.block.unr-lcssa ], [ %87, %vector.body.epil ]
  %.lcssa42 = phi <8 x i32> [ %.lcssa42.ph, %middle.block.unr-lcssa ], [ %82, %vector.body.epil ]
  %.lcssa41 = phi <8 x i32> [ %.lcssa41.ph, %middle.block.unr-lcssa ], [ %75, %vector.body.epil ]
  %.lcssa = phi <8 x i32> [ %.lcssa.ph, %middle.block.unr-lcssa ], [ %68, %vector.body.epil ]
  %bin.rdx = or <8 x i32> %.lcssa42, %.lcssa43
  %bin.rdx32 = or <8 x i32> %.lcssa41, %bin.rdx
  %bin.rdx33 = or <8 x i32> %.lcssa, %bin.rdx32
  %rdx.shuf = shufflevector <8 x i32> %bin.rdx33, <8 x i32> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx34 = or <8 x i32> %bin.rdx33, %rdx.shuf
  %rdx.shuf35 = shufflevector <8 x i32> %bin.rdx34, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx36 = or <8 x i32> %bin.rdx34, %rdx.shuf35
  %rdx.shuf37 = shufflevector <8 x i32> %bin.rdx36, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx38 = or <8 x i32> %bin.rdx36, %rdx.shuf37
  %88 = extractelement <8 x i32> %bin.rdx38, i32 0
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count
  br i1 %cmp.n, label %for.cond.cleanup.loopexit, label %for.body.preheader39

for.cond.cleanup.loopexit:                        ; preds = %for.body, %middle.block
  %or.lcssa = phi i32 [ %88, %middle.block ], [ %or, %for.body ]
  %phitmp = sub i32 0, %or.lcssa
  %phitmp17 = ashr i32 %phitmp, 31
  %phitmp18 = trunc i32 %phitmp17 to i8
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %entry
  %r.0.lcssa = phi i8 [ 0, %entry ], [ %phitmp18, %for.cond.cleanup.loopexit ]
  ret i8 %r.0.lcssa

for.body:                                         ; preds = %for.body.preheader39, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ %indvars.iv.ph, %for.body.preheader39 ]
  %r.015 = phi i32 [ %or, %for.body ], [ %r.015.ph, %for.body.preheader39 ]
  %arrayidx = getelementptr inbounds i8, i8* %a, i64 %indvars.iv
  %89 = load i8, i8* %arrayidx, align 1, !tbaa !7
  %arrayidx2 = getelementptr inbounds i8, i8* %b, i64 %indvars.iv
  %90 = load i8, i8* %arrayidx2, align 1, !tbaa !7
  %xor13 = xor i8 %90, %89
  %xor = zext i8 %xor13 to i32
  %or = or i32 %r.015, %xor
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body, !llvm.loop !10
}

; Function Attrs: norecurse nounwind ssp uwtable
define void @ct_cmov(i8* nocapture %r, i8* nocapture readonly %a, i32 %len, i8 signext %selector) local_unnamed_addr #0 {
entry:
  %cmp20 = icmp eq i32 %len, 0
  br i1 %cmp20, label %for.cond.cleanup, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %len to i64
  %min.iters.check = icmp ult i32 %len, 128
  br i1 %min.iters.check, label %for.body.preheader41, label %vector.memcheck

for.body.preheader41:                             ; preds = %middle.block, %vector.memcheck, %for.body.preheader
  %indvars.iv.ph = phi i64 [ 0, %vector.memcheck ], [ 0, %for.body.preheader ], [ %n.vec, %middle.block ]
  %0 = xor i64 %indvars.iv.ph, -1
  %1 = add nsw i64 %0, %wide.trip.count
  %xtraiter = and i64 %wide.trip.count, 3
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %for.body.prol.loopexit, label %for.body.prol

for.body.prol:                                    ; preds = %for.body.preheader41, %for.body.prol
  %indvars.iv.prol = phi i64 [ %indvars.iv.next.prol, %for.body.prol ], [ %indvars.iv.ph, %for.body.preheader41 ]
  %prol.iter = phi i64 [ %prol.iter.sub, %for.body.prol ], [ %xtraiter, %for.body.preheader41 ]
  %arrayidx.prol = getelementptr inbounds i8, i8* %a, i64 %indvars.iv.prol
  %2 = load i8, i8* %arrayidx.prol, align 1, !tbaa !7
  %arrayidx3.prol = getelementptr inbounds i8, i8* %r, i64 %indvars.iv.prol
  %3 = load i8, i8* %arrayidx3.prol, align 1, !tbaa !7
  %xor16.prol = xor i8 %3, %2
  %and18.prol = and i8 %xor16.prol, %selector
  %xor819.prol = xor i8 %and18.prol, %3
  store i8 %xor819.prol, i8* %arrayidx3.prol, align 1, !tbaa !7
  %indvars.iv.next.prol = add nuw nsw i64 %indvars.iv.prol, 1
  %prol.iter.sub = add i64 %prol.iter, -1
  %prol.iter.cmp = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp, label %for.body.prol.loopexit, label %for.body.prol, !llvm.loop !12

for.body.prol.loopexit:                           ; preds = %for.body.prol, %for.body.preheader41
  %indvars.iv.unr = phi i64 [ %indvars.iv.ph, %for.body.preheader41 ], [ %indvars.iv.next.prol, %for.body.prol ]
  %4 = icmp ult i64 %1, 3
  br i1 %4, label %for.cond.cleanup, label %for.body

vector.memcheck:                                  ; preds = %for.body.preheader
  %scevgep = getelementptr i8, i8* %r, i64 %wide.trip.count
  %scevgep22 = getelementptr i8, i8* %a, i64 %wide.trip.count
  %bound0 = icmp ugt i8* %scevgep22, %r
  %bound1 = icmp ugt i8* %scevgep, %a
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %for.body.preheader41, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %wide.trip.count, 4294967168
  %broadcast.splatinsert33 = insertelement <32 x i8> undef, i8 %selector, i32 0
  %broadcast.splat34 = shufflevector <32 x i8> %broadcast.splatinsert33, <32 x i8> undef, <32 x i32> zeroinitializer
  %broadcast.splatinsert35 = insertelement <32 x i8> undef, i8 %selector, i32 0
  %broadcast.splat36 = shufflevector <32 x i8> %broadcast.splatinsert35, <32 x i8> undef, <32 x i32> zeroinitializer
  %broadcast.splatinsert37 = insertelement <32 x i8> undef, i8 %selector, i32 0
  %broadcast.splat38 = shufflevector <32 x i8> %broadcast.splatinsert37, <32 x i8> undef, <32 x i32> zeroinitializer
  %broadcast.splatinsert39 = insertelement <32 x i8> undef, i8 %selector, i32 0
  %broadcast.splat40 = shufflevector <32 x i8> %broadcast.splatinsert39, <32 x i8> undef, <32 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %5 = getelementptr inbounds i8, i8* %a, i64 %index
  %6 = bitcast i8* %5 to <32 x i8>*
  %wide.load = load <32 x i8>, <32 x i8>* %6, align 1, !tbaa !7, !alias.scope !14
  %7 = getelementptr inbounds i8, i8* %5, i64 32
  %8 = bitcast i8* %7 to <32 x i8>*
  %wide.load26 = load <32 x i8>, <32 x i8>* %8, align 1, !tbaa !7, !alias.scope !14
  %9 = getelementptr inbounds i8, i8* %5, i64 64
  %10 = bitcast i8* %9 to <32 x i8>*
  %wide.load27 = load <32 x i8>, <32 x i8>* %10, align 1, !tbaa !7, !alias.scope !14
  %11 = getelementptr inbounds i8, i8* %5, i64 96
  %12 = bitcast i8* %11 to <32 x i8>*
  %wide.load28 = load <32 x i8>, <32 x i8>* %12, align 1, !tbaa !7, !alias.scope !14
  %13 = getelementptr inbounds i8, i8* %r, i64 %index
  %14 = bitcast i8* %13 to <32 x i8>*
  %wide.load29 = load <32 x i8>, <32 x i8>* %14, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %15 = getelementptr inbounds i8, i8* %13, i64 32
  %16 = bitcast i8* %15 to <32 x i8>*
  %wide.load30 = load <32 x i8>, <32 x i8>* %16, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %17 = getelementptr inbounds i8, i8* %13, i64 64
  %18 = bitcast i8* %17 to <32 x i8>*
  %wide.load31 = load <32 x i8>, <32 x i8>* %18, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %19 = getelementptr inbounds i8, i8* %13, i64 96
  %20 = bitcast i8* %19 to <32 x i8>*
  %wide.load32 = load <32 x i8>, <32 x i8>* %20, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %21 = xor <32 x i8> %wide.load29, %wide.load
  %22 = xor <32 x i8> %wide.load30, %wide.load26
  %23 = xor <32 x i8> %wide.load31, %wide.load27
  %24 = xor <32 x i8> %wide.load32, %wide.load28
  %25 = and <32 x i8> %21, %broadcast.splat34
  %26 = and <32 x i8> %22, %broadcast.splat36
  %27 = and <32 x i8> %23, %broadcast.splat38
  %28 = and <32 x i8> %24, %broadcast.splat40
  %29 = xor <32 x i8> %25, %wide.load29
  %30 = xor <32 x i8> %26, %wide.load30
  %31 = xor <32 x i8> %27, %wide.load31
  %32 = xor <32 x i8> %28, %wide.load32
  %33 = bitcast i8* %13 to <32 x i8>*
  store <32 x i8> %29, <32 x i8>* %33, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %34 = bitcast i8* %15 to <32 x i8>*
  store <32 x i8> %30, <32 x i8>* %34, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %35 = bitcast i8* %17 to <32 x i8>*
  store <32 x i8> %31, <32 x i8>* %35, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %36 = bitcast i8* %19 to <32 x i8>*
  store <32 x i8> %32, <32 x i8>* %36, align 1, !tbaa !7, !alias.scope !17, !noalias !14
  %index.next = add i64 %index, 128
  %37 = icmp eq i64 %index.next, %n.vec
  br i1 %37, label %middle.block, label %vector.body, !llvm.loop !19

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count
  br i1 %cmp.n, label %for.cond.cleanup, label %for.body.preheader41

for.cond.cleanup:                                 ; preds = %for.body.prol.loopexit, %for.body, %middle.block, %entry
  ret void

for.body:                                         ; preds = %for.body.prol.loopexit, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next.3, %for.body ], [ %indvars.iv.unr, %for.body.prol.loopexit ]
  %arrayidx = getelementptr inbounds i8, i8* %a, i64 %indvars.iv
  %38 = load i8, i8* %arrayidx, align 1, !tbaa !7
  %arrayidx3 = getelementptr inbounds i8, i8* %r, i64 %indvars.iv
  %39 = load i8, i8* %arrayidx3, align 1, !tbaa !7
  %xor16 = xor i8 %39, %38
  %and18 = and i8 %xor16, %selector
  %xor819 = xor i8 %and18, %39
  store i8 %xor819, i8* %arrayidx3, align 1, !tbaa !7
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx.1 = getelementptr inbounds i8, i8* %a, i64 %indvars.iv.next
  %40 = load i8, i8* %arrayidx.1, align 1, !tbaa !7
  %arrayidx3.1 = getelementptr inbounds i8, i8* %r, i64 %indvars.iv.next
  %41 = load i8, i8* %arrayidx3.1, align 1, !tbaa !7
  %xor16.1 = xor i8 %41, %40
  %and18.1 = and i8 %xor16.1, %selector
  %xor819.1 = xor i8 %and18.1, %41
  store i8 %xor819.1, i8* %arrayidx3.1, align 1, !tbaa !7
  %indvars.iv.next.1 = add nsw i64 %indvars.iv, 2
  %arrayidx.2 = getelementptr inbounds i8, i8* %a, i64 %indvars.iv.next.1
  %42 = load i8, i8* %arrayidx.2, align 1, !tbaa !7
  %arrayidx3.2 = getelementptr inbounds i8, i8* %r, i64 %indvars.iv.next.1
  %43 = load i8, i8* %arrayidx3.2, align 1, !tbaa !7
  %xor16.2 = xor i8 %43, %42
  %and18.2 = and i8 %xor16.2, %selector
  %xor819.2 = xor i8 %and18.2, %43
  store i8 %xor819.2, i8* %arrayidx3.2, align 1, !tbaa !7
  %indvars.iv.next.2 = add nsw i64 %indvars.iv, 3
  %arrayidx.3 = getelementptr inbounds i8, i8* %a, i64 %indvars.iv.next.2
  %44 = load i8, i8* %arrayidx.3, align 1, !tbaa !7
  %arrayidx3.3 = getelementptr inbounds i8, i8* %r, i64 %indvars.iv.next.2
  %45 = load i8, i8* %arrayidx3.3, align 1, !tbaa !7
  %xor16.3 = xor i8 %45, %44
  %and18.3 = and i8 %xor16.3, %selector
  %xor819.3 = xor i8 %and18.3, %45
  store i8 %xor819.3, i8* %arrayidx3.3, align 1, !tbaa !7
  %indvars.iv.next.3 = add nsw i64 %indvars.iv, 4
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, %wide.trip.count
  br i1 %exitcond.3, label %for.cond.cleanup, label %for.body, !llvm.loop !20
}

; Function Attrs: inlinehint norecurse nounwind ssp uwtable
define void @fpcopy610(i64* nocapture readonly %a, i64* nocapture %c) local_unnamed_addr #3 {
entry:
  %0 = load i64, i64* %a, align 8, !tbaa !3
  store i64 %0, i64* %c, align 8, !tbaa !3
  %arrayidx.1 = getelementptr inbounds i64, i64* %a, i64 1
  %1 = load i64, i64* %arrayidx.1, align 8, !tbaa !3
  %arrayidx2.1 = getelementptr inbounds i64, i64* %c, i64 1
  store i64 %1, i64* %arrayidx2.1, align 8, !tbaa !3
  %arrayidx.2 = getelementptr inbounds i64, i64* %a, i64 2
  %2 = load i64, i64* %arrayidx.2, align 8, !tbaa !3
  %arrayidx2.2 = getelementptr inbounds i64, i64* %c, i64 2
  store i64 %2, i64* %arrayidx2.2, align 8, !tbaa !3
  %arrayidx.3 = getelementptr inbounds i64, i64* %a, i64 3
  %3 = load i64, i64* %arrayidx.3, align 8, !tbaa !3
  %arrayidx2.3 = getelementptr inbounds i64, i64* %c, i64 3
  store i64 %3, i64* %arrayidx2.3, align 8, !tbaa !3
  %arrayidx.4 = getelementptr inbounds i64, i64* %a, i64 4
  %4 = load i64, i64* %arrayidx.4, align 8, !tbaa !3
  %arrayidx2.4 = getelementptr inbounds i64, i64* %c, i64 4
  store i64 %4, i64* %arrayidx2.4, align 8, !tbaa !3
  %arrayidx.5 = getelementptr inbounds i64, i64* %a, i64 5
  %5 = load i64, i64* %arrayidx.5, align 8, !tbaa !3
  %arrayidx2.5 = getelementptr inbounds i64, i64* %c, i64 5
  store i64 %5, i64* %arrayidx2.5, align 8, !tbaa !3
  %arrayidx.6 = getelementptr inbounds i64, i64* %a, i64 6
  %6 = load i64, i64* %arrayidx.6, align 8, !tbaa !3
  %arrayidx2.6 = getelementptr inbounds i64, i64* %c, i64 6
  store i64 %6, i64* %arrayidx2.6, align 8, !tbaa !3
  %arrayidx.7 = getelementptr inbounds i64, i64* %a, i64 7
  %7 = load i64, i64* %arrayidx.7, align 8, !tbaa !3
  %arrayidx2.7 = getelementptr inbounds i64, i64* %c, i64 7
  store i64 %7, i64* %arrayidx2.7, align 8, !tbaa !3
  %arrayidx.8 = getelementptr inbounds i64, i64* %a, i64 8
  %8 = load i64, i64* %arrayidx.8, align 8, !tbaa !3
  %arrayidx2.8 = getelementptr inbounds i64, i64* %c, i64 8
  store i64 %8, i64* %arrayidx2.8, align 8, !tbaa !3
  %arrayidx.9 = getelementptr inbounds i64, i64* %a, i64 9
  %9 = load i64, i64* %arrayidx.9, align 8, !tbaa !3
  %arrayidx2.9 = getelementptr inbounds i64, i64* %c, i64 9
  store i64 %9, i64* %arrayidx2.9, align 8, !tbaa !3
  ret void
}

; Function Attrs: inlinehint norecurse nounwind ssp uwtable
define void @fpzero610(i64* nocapture %a) local_unnamed_addr #3 {
entry:
  %a5 = bitcast i64* %a to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %a5, i8 0, i64 80, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @to_mont(i64* %a, i64* %mc) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %0 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* %a, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %mc) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fpmul610_mont(i64* %ma, i64* %mb, i64* %mc) local_unnamed_addr #4 {
entry:
  %temp = alloca [20 x i64], align 16
  %0 = bitcast [20 x i64]* %temp to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 160, i1 false)
  %arraydecay = getelementptr inbounds [20 x i64], [20 x i64]* %temp, i64 0, i64 0
  call void @mp_mul(i64* %ma, i64* %mb, i64* nonnull %arraydecay, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay, i64* %mc) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @from_mont(i64* %ma, i64* %c) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %one = alloca [10 x i64], align 16
  %0 = bitcast [10 x i64]* %one to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 80, i1 false)
  %arrayidx = getelementptr inbounds [10 x i64], [10 x i64]* %one, i64 0, i64 0
  store i64 1, i64* %arrayidx, align 16, !tbaa !3
  %1 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* %ma, i64* nonnull %arrayidx, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %c) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @fpcorrection610(i64* %c) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1) #1

declare void @fpcorrection610(i64*) local_unnamed_addr #5

; Function Attrs: norecurse nounwind ssp uwtable
define void @copy_words(i64* nocapture readonly %a, i64* nocapture %c, i32 %nwords) local_unnamed_addr #0 {
entry:
  %cmp7 = icmp eq i32 %nwords, 0
  br i1 %cmp7, label %for.end, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %nwords to i64
  %min.iters.check = icmp ult i32 %nwords, 16
  br i1 %min.iters.check, label %for.body.preheader21, label %vector.memcheck

vector.memcheck:                                  ; preds = %for.body.preheader
  %scevgep = getelementptr i64, i64* %c, i64 %wide.trip.count
  %scevgep13 = getelementptr i64, i64* %a, i64 %wide.trip.count
  %bound0 = icmp ugt i64* %scevgep13, %c
  %bound1 = icmp ugt i64* %scevgep, %a
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %for.body.preheader21, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %wide.trip.count, 4294967280
  %0 = add nsw i64 %n.vec, -16
  %1 = lshr exact i64 %0, 4
  %2 = add nuw nsw i64 %1, 1
  %xtraiter22 = and i64 %2, 3
  %3 = icmp ult i64 %0, 48
  br i1 %3, label %middle.block.unr-lcssa, label %vector.ph.new

vector.ph.new:                                    ; preds = %vector.ph
  %unroll_iter = sub nsw i64 %2, %xtraiter22
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph.new
  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.3, %vector.body ]
  %niter = phi i64 [ %unroll_iter, %vector.ph.new ], [ %niter.nsub.3, %vector.body ]
  %4 = getelementptr inbounds i64, i64* %a, i64 %index
  %5 = bitcast i64* %4 to <4 x i64>*
  %wide.load = load <4 x i64>, <4 x i64>* %5, align 8, !tbaa !3, !alias.scope !21
  %6 = getelementptr inbounds i64, i64* %4, i64 4
  %7 = bitcast i64* %6 to <4 x i64>*
  %wide.load18 = load <4 x i64>, <4 x i64>* %7, align 8, !tbaa !3, !alias.scope !21
  %8 = getelementptr inbounds i64, i64* %4, i64 8
  %9 = bitcast i64* %8 to <4 x i64>*
  %wide.load19 = load <4 x i64>, <4 x i64>* %9, align 8, !tbaa !3, !alias.scope !21
  %10 = getelementptr inbounds i64, i64* %4, i64 12
  %11 = bitcast i64* %10 to <4 x i64>*
  %wide.load20 = load <4 x i64>, <4 x i64>* %11, align 8, !tbaa !3, !alias.scope !21
  %12 = getelementptr inbounds i64, i64* %c, i64 %index
  %13 = bitcast i64* %12 to <4 x i64>*
  store <4 x i64> %wide.load, <4 x i64>* %13, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %14 = getelementptr inbounds i64, i64* %12, i64 4
  %15 = bitcast i64* %14 to <4 x i64>*
  store <4 x i64> %wide.load18, <4 x i64>* %15, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %16 = getelementptr inbounds i64, i64* %12, i64 8
  %17 = bitcast i64* %16 to <4 x i64>*
  store <4 x i64> %wide.load19, <4 x i64>* %17, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %18 = getelementptr inbounds i64, i64* %12, i64 12
  %19 = bitcast i64* %18 to <4 x i64>*
  store <4 x i64> %wide.load20, <4 x i64>* %19, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %index.next = or i64 %index, 16
  %20 = getelementptr inbounds i64, i64* %a, i64 %index.next
  %21 = bitcast i64* %20 to <4 x i64>*
  %wide.load.1 = load <4 x i64>, <4 x i64>* %21, align 8, !tbaa !3, !alias.scope !21
  %22 = getelementptr inbounds i64, i64* %20, i64 4
  %23 = bitcast i64* %22 to <4 x i64>*
  %wide.load18.1 = load <4 x i64>, <4 x i64>* %23, align 8, !tbaa !3, !alias.scope !21
  %24 = getelementptr inbounds i64, i64* %20, i64 8
  %25 = bitcast i64* %24 to <4 x i64>*
  %wide.load19.1 = load <4 x i64>, <4 x i64>* %25, align 8, !tbaa !3, !alias.scope !21
  %26 = getelementptr inbounds i64, i64* %20, i64 12
  %27 = bitcast i64* %26 to <4 x i64>*
  %wide.load20.1 = load <4 x i64>, <4 x i64>* %27, align 8, !tbaa !3, !alias.scope !21
  %28 = getelementptr inbounds i64, i64* %c, i64 %index.next
  %29 = bitcast i64* %28 to <4 x i64>*
  store <4 x i64> %wide.load.1, <4 x i64>* %29, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %30 = getelementptr inbounds i64, i64* %28, i64 4
  %31 = bitcast i64* %30 to <4 x i64>*
  store <4 x i64> %wide.load18.1, <4 x i64>* %31, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %32 = getelementptr inbounds i64, i64* %28, i64 8
  %33 = bitcast i64* %32 to <4 x i64>*
  store <4 x i64> %wide.load19.1, <4 x i64>* %33, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %34 = getelementptr inbounds i64, i64* %28, i64 12
  %35 = bitcast i64* %34 to <4 x i64>*
  store <4 x i64> %wide.load20.1, <4 x i64>* %35, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %index.next.1 = or i64 %index, 32
  %36 = getelementptr inbounds i64, i64* %a, i64 %index.next.1
  %37 = bitcast i64* %36 to <4 x i64>*
  %wide.load.2 = load <4 x i64>, <4 x i64>* %37, align 8, !tbaa !3, !alias.scope !21
  %38 = getelementptr inbounds i64, i64* %36, i64 4
  %39 = bitcast i64* %38 to <4 x i64>*
  %wide.load18.2 = load <4 x i64>, <4 x i64>* %39, align 8, !tbaa !3, !alias.scope !21
  %40 = getelementptr inbounds i64, i64* %36, i64 8
  %41 = bitcast i64* %40 to <4 x i64>*
  %wide.load19.2 = load <4 x i64>, <4 x i64>* %41, align 8, !tbaa !3, !alias.scope !21
  %42 = getelementptr inbounds i64, i64* %36, i64 12
  %43 = bitcast i64* %42 to <4 x i64>*
  %wide.load20.2 = load <4 x i64>, <4 x i64>* %43, align 8, !tbaa !3, !alias.scope !21
  %44 = getelementptr inbounds i64, i64* %c, i64 %index.next.1
  %45 = bitcast i64* %44 to <4 x i64>*
  store <4 x i64> %wide.load.2, <4 x i64>* %45, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %46 = getelementptr inbounds i64, i64* %44, i64 4
  %47 = bitcast i64* %46 to <4 x i64>*
  store <4 x i64> %wide.load18.2, <4 x i64>* %47, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %48 = getelementptr inbounds i64, i64* %44, i64 8
  %49 = bitcast i64* %48 to <4 x i64>*
  store <4 x i64> %wide.load19.2, <4 x i64>* %49, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %50 = getelementptr inbounds i64, i64* %44, i64 12
  %51 = bitcast i64* %50 to <4 x i64>*
  store <4 x i64> %wide.load20.2, <4 x i64>* %51, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %index.next.2 = or i64 %index, 48
  %52 = getelementptr inbounds i64, i64* %a, i64 %index.next.2
  %53 = bitcast i64* %52 to <4 x i64>*
  %wide.load.3 = load <4 x i64>, <4 x i64>* %53, align 8, !tbaa !3, !alias.scope !21
  %54 = getelementptr inbounds i64, i64* %52, i64 4
  %55 = bitcast i64* %54 to <4 x i64>*
  %wide.load18.3 = load <4 x i64>, <4 x i64>* %55, align 8, !tbaa !3, !alias.scope !21
  %56 = getelementptr inbounds i64, i64* %52, i64 8
  %57 = bitcast i64* %56 to <4 x i64>*
  %wide.load19.3 = load <4 x i64>, <4 x i64>* %57, align 8, !tbaa !3, !alias.scope !21
  %58 = getelementptr inbounds i64, i64* %52, i64 12
  %59 = bitcast i64* %58 to <4 x i64>*
  %wide.load20.3 = load <4 x i64>, <4 x i64>* %59, align 8, !tbaa !3, !alias.scope !21
  %60 = getelementptr inbounds i64, i64* %c, i64 %index.next.2
  %61 = bitcast i64* %60 to <4 x i64>*
  store <4 x i64> %wide.load.3, <4 x i64>* %61, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %62 = getelementptr inbounds i64, i64* %60, i64 4
  %63 = bitcast i64* %62 to <4 x i64>*
  store <4 x i64> %wide.load18.3, <4 x i64>* %63, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %64 = getelementptr inbounds i64, i64* %60, i64 8
  %65 = bitcast i64* %64 to <4 x i64>*
  store <4 x i64> %wide.load19.3, <4 x i64>* %65, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %66 = getelementptr inbounds i64, i64* %60, i64 12
  %67 = bitcast i64* %66 to <4 x i64>*
  store <4 x i64> %wide.load20.3, <4 x i64>* %67, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %index.next.3 = add i64 %index, 64
  %niter.nsub.3 = add i64 %niter, -4
  %niter.ncmp.3 = icmp eq i64 %niter.nsub.3, 0
  br i1 %niter.ncmp.3, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !26

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.3, %vector.body ]
  %lcmp.mod23 = icmp eq i64 %xtraiter22, 0
  br i1 %lcmp.mod23, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %index.epil = phi i64 [ %index.next.epil, %vector.body.epil ], [ %index.unr, %middle.block.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.sub, %vector.body.epil ], [ %xtraiter22, %middle.block.unr-lcssa ]
  %68 = getelementptr inbounds i64, i64* %a, i64 %index.epil
  %69 = bitcast i64* %68 to <4 x i64>*
  %wide.load.epil = load <4 x i64>, <4 x i64>* %69, align 8, !tbaa !3, !alias.scope !21
  %70 = getelementptr inbounds i64, i64* %68, i64 4
  %71 = bitcast i64* %70 to <4 x i64>*
  %wide.load18.epil = load <4 x i64>, <4 x i64>* %71, align 8, !tbaa !3, !alias.scope !21
  %72 = getelementptr inbounds i64, i64* %68, i64 8
  %73 = bitcast i64* %72 to <4 x i64>*
  %wide.load19.epil = load <4 x i64>, <4 x i64>* %73, align 8, !tbaa !3, !alias.scope !21
  %74 = getelementptr inbounds i64, i64* %68, i64 12
  %75 = bitcast i64* %74 to <4 x i64>*
  %wide.load20.epil = load <4 x i64>, <4 x i64>* %75, align 8, !tbaa !3, !alias.scope !21
  %76 = getelementptr inbounds i64, i64* %c, i64 %index.epil
  %77 = bitcast i64* %76 to <4 x i64>*
  store <4 x i64> %wide.load.epil, <4 x i64>* %77, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %78 = getelementptr inbounds i64, i64* %76, i64 4
  %79 = bitcast i64* %78 to <4 x i64>*
  store <4 x i64> %wide.load18.epil, <4 x i64>* %79, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %80 = getelementptr inbounds i64, i64* %76, i64 8
  %81 = bitcast i64* %80 to <4 x i64>*
  store <4 x i64> %wide.load19.epil, <4 x i64>* %81, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %82 = getelementptr inbounds i64, i64* %76, i64 12
  %83 = bitcast i64* %82 to <4 x i64>*
  store <4 x i64> %wide.load20.epil, <4 x i64>* %83, align 8, !tbaa !3, !alias.scope !24, !noalias !21
  %index.next.epil = add i64 %index.epil, 16
  %epil.iter.sub = add i64 %epil.iter, -1
  %epil.iter.cmp = icmp eq i64 %epil.iter.sub, 0
  br i1 %epil.iter.cmp, label %middle.block, label %vector.body.epil, !llvm.loop !27

middle.block:                                     ; preds = %vector.body.epil, %middle.block.unr-lcssa
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count
  br i1 %cmp.n, label %for.end, label %for.body.preheader21

for.body.preheader21:                             ; preds = %middle.block, %vector.memcheck, %for.body.preheader
  %indvars.iv.ph = phi i64 [ 0, %vector.memcheck ], [ 0, %for.body.preheader ], [ %n.vec, %middle.block ]
  %84 = xor i64 %indvars.iv.ph, -1
  %85 = add nsw i64 %84, %wide.trip.count
  %xtraiter = and i64 %wide.trip.count, 7
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %for.body.prol.loopexit, label %for.body.prol

for.body.prol:                                    ; preds = %for.body.preheader21, %for.body.prol
  %indvars.iv.prol = phi i64 [ %indvars.iv.next.prol, %for.body.prol ], [ %indvars.iv.ph, %for.body.preheader21 ]
  %prol.iter = phi i64 [ %prol.iter.sub, %for.body.prol ], [ %xtraiter, %for.body.preheader21 ]
  %arrayidx.prol = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.prol
  %86 = load i64, i64* %arrayidx.prol, align 8, !tbaa !3
  %arrayidx2.prol = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.prol
  store i64 %86, i64* %arrayidx2.prol, align 8, !tbaa !3
  %indvars.iv.next.prol = add nuw nsw i64 %indvars.iv.prol, 1
  %prol.iter.sub = add i64 %prol.iter, -1
  %prol.iter.cmp = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp, label %for.body.prol.loopexit, label %for.body.prol, !llvm.loop !28

for.body.prol.loopexit:                           ; preds = %for.body.prol, %for.body.preheader21
  %indvars.iv.unr = phi i64 [ %indvars.iv.ph, %for.body.preheader21 ], [ %indvars.iv.next.prol, %for.body.prol ]
  %87 = icmp ult i64 %85, 7
  br i1 %87, label %for.end, label %for.body

for.body:                                         ; preds = %for.body.prol.loopexit, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next.7, %for.body ], [ %indvars.iv.unr, %for.body.prol.loopexit ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %indvars.iv
  %88 = load i64, i64* %arrayidx, align 8, !tbaa !3
  %arrayidx2 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv
  store i64 %88, i64* %arrayidx2, align 8, !tbaa !3
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx.1 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next
  %89 = load i64, i64* %arrayidx.1, align 8, !tbaa !3
  %arrayidx2.1 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next
  store i64 %89, i64* %arrayidx2.1, align 8, !tbaa !3
  %indvars.iv.next.1 = add nsw i64 %indvars.iv, 2
  %arrayidx.2 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.1
  %90 = load i64, i64* %arrayidx.2, align 8, !tbaa !3
  %arrayidx2.2 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.1
  store i64 %90, i64* %arrayidx2.2, align 8, !tbaa !3
  %indvars.iv.next.2 = add nsw i64 %indvars.iv, 3
  %arrayidx.3 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.2
  %91 = load i64, i64* %arrayidx.3, align 8, !tbaa !3
  %arrayidx2.3 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.2
  store i64 %91, i64* %arrayidx2.3, align 8, !tbaa !3
  %indvars.iv.next.3 = add nsw i64 %indvars.iv, 4
  %arrayidx.4 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.3
  %92 = load i64, i64* %arrayidx.4, align 8, !tbaa !3
  %arrayidx2.4 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.3
  store i64 %92, i64* %arrayidx2.4, align 8, !tbaa !3
  %indvars.iv.next.4 = add nsw i64 %indvars.iv, 5
  %arrayidx.5 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.4
  %93 = load i64, i64* %arrayidx.5, align 8, !tbaa !3
  %arrayidx2.5 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.4
  store i64 %93, i64* %arrayidx2.5, align 8, !tbaa !3
  %indvars.iv.next.5 = add nsw i64 %indvars.iv, 6
  %arrayidx.6 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.5
  %94 = load i64, i64* %arrayidx.6, align 8, !tbaa !3
  %arrayidx2.6 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.5
  store i64 %94, i64* %arrayidx2.6, align 8, !tbaa !3
  %indvars.iv.next.6 = add nsw i64 %indvars.iv, 7
  %arrayidx.7 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next.6
  %95 = load i64, i64* %arrayidx.7, align 8, !tbaa !3
  %arrayidx2.7 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next.6
  store i64 %95, i64* %arrayidx2.7, align 8, !tbaa !3
  %indvars.iv.next.7 = add nsw i64 %indvars.iv, 8
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, %wide.trip.count
  br i1 %exitcond.7, label %for.end, label %for.body, !llvm.loop !29

for.end:                                          ; preds = %for.body.prol.loopexit, %for.body, %middle.block, %entry
  ret void
}

declare void @mp_mul(i64*, i64*, i64*, i32) local_unnamed_addr #5

declare void @rdc_mont(i64*, i64*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define void @fpsqr610_mont(i64* %ma, i64* %mc) local_unnamed_addr #4 {
entry:
  %temp = alloca [20 x i64], align 16
  %0 = bitcast [20 x i64]* %temp to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 160, i1 false)
  %arraydecay = getelementptr inbounds [20 x i64], [20 x i64]* %temp, i64 0, i64 0
  call void @mp_mul(i64* %ma, i64* %ma, i64* nonnull %arraydecay, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay, i64* %mc) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fpinv610_mont(i64* %a) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %tt = alloca [10 x i64], align 16
  %0 = bitcast [10 x i64]* %tt to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 0
  %1 = bitcast i64* %a to <4 x i64>*
  %2 = load <4 x i64>, <4 x i64>* %1, align 8, !tbaa !3
  %3 = bitcast [10 x i64]* %tt to <4 x i64>*
  store <4 x i64> %2, <4 x i64>* %3, align 16, !tbaa !3
  %arrayidx.4.i = getelementptr inbounds i64, i64* %a, i64 4
  %arrayidx2.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 4
  %4 = bitcast i64* %arrayidx.4.i to <4 x i64>*
  %5 = load <4 x i64>, <4 x i64>* %4, align 8, !tbaa !3
  %6 = bitcast i64* %arrayidx2.4.i to <4 x i64>*
  store <4 x i64> %5, <4 x i64>* %6, align 16, !tbaa !3
  %arrayidx.8.i = getelementptr inbounds i64, i64* %a, i64 8
  %7 = load i64, i64* %arrayidx.8.i, align 8, !tbaa !3
  %arrayidx2.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 8
  store i64 %7, i64* %arrayidx2.8.i, align 16, !tbaa !3
  %arrayidx.9.i = getelementptr inbounds i64, i64* %a, i64 9
  %8 = load i64, i64* %arrayidx.9.i, align 8, !tbaa !3
  %arrayidx2.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 9
  store i64 %8, i64* %arrayidx2.9.i, align 8, !tbaa !3
  call void @fpinv610_chain_mont(i64* nonnull %arraydecay)
  %9 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 160, i1 false) #10
  %arraydecay.i10 = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i10, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i10, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %a, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i10, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i10, i64* %a) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fpinv610_chain_mont(i64* %a) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %t = alloca [31 x [10 x i64]], align 16
  %tt = alloca [10 x i64], align 16
  %0 = bitcast [31 x [10 x i64]]* %t to i8*
  call void @llvm.lifetime.start.p0i8(i64 2480, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %tt to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 0
  %2 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* %a, i64* %a, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay2 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %a, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arraydecay4 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 %indvars.iv, i64 0
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arraydecay8 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 %indvars.iv.next, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay8) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %exitcond928 = icmp eq i64 %indvars.iv.next, 30
  br i1 %exitcond928, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %3 = bitcast i64* %a to <4 x i64>*
  %4 = load <4 x i64>, <4 x i64>* %3, align 8, !tbaa !3
  %5 = bitcast [10 x i64]* %tt to <4 x i64>*
  store <4 x i64> %4, <4 x i64>* %5, align 16, !tbaa !3
  %arrayidx.4.i = getelementptr inbounds i64, i64* %a, i64 4
  %arrayidx2.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 4
  %6 = bitcast i64* %arrayidx.4.i to <4 x i64>*
  %7 = load <4 x i64>, <4 x i64>* %6, align 8, !tbaa !3
  %8 = bitcast i64* %arrayidx2.4.i to <4 x i64>*
  store <4 x i64> %7, <4 x i64>* %8, align 16, !tbaa !3
  %arrayidx.8.i = getelementptr inbounds i64, i64* %a, i64 8
  %9 = load i64, i64* %arrayidx.8.i, align 8, !tbaa !3
  %arrayidx2.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 8
  store i64 %9, i64* %arrayidx2.8.i, align 16, !tbaa !3
  %arrayidx.9.i = getelementptr inbounds i64, i64* %a, i64 9
  %10 = load i64, i64* %arrayidx.9.i, align 8, !tbaa !3
  %arrayidx2.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %tt, i64 0, i64 9
  store i64 %10, i64* %arrayidx2.9.i, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay19 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 6, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay19, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay31 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 30, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay31, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay43 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 25, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay43, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay55 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 28, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay55, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay67 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 7, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay67, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay79 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 11, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay79, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %a, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay113 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 3, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay113, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay125 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 16, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay125, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay137 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 24, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay137, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay55, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay125, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay173 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 4, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay173, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay113, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay197 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 20, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay197, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay79, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay221 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 14, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay221, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay233 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 15, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay233, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay233, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay269 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 19, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay269, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay281 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 9, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay281, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay293 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 5, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay293, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay305 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 27, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay305, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay55, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay329 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 29, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay329, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay341 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay341, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay113, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay365 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 2, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay365, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay31, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay43, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay55, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay413 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 22, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay413, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay113, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay413, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay67, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay281, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay173, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay197, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay497 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 10, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay497, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay509 = getelementptr inbounds [31 x [10 x i64]], [31 x [10 x i64]]* %t, i64 0, i64 26, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay509, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay365, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  br label %for.cond527.preheader

for.cond527.preheader:                            ; preds = %for.cond527.preheader, %for.end
  %j.0840 = phi i32 [ 0, %for.end ], [ %inc540, %for.cond527.preheader ]
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay31, i64* nonnull %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  %inc540 = add nuw nsw i32 %j.0840, 1
  %exitcond = icmp eq i32 %inc540, 50
  br i1 %exitcond, label %for.end541, label %for.cond527.preheader

for.end541:                                       ; preds = %for.cond527.preheader
  %11 = bitcast [10 x i64]* %tt to <4 x i64>*
  %12 = load <4 x i64>, <4 x i64>* %11, align 16, !tbaa !3
  %13 = bitcast i64* %a to <4 x i64>*
  store <4 x i64> %12, <4 x i64>* %13, align 8, !tbaa !3
  %14 = bitcast i64* %arrayidx2.4.i to <4 x i64>*
  %15 = load <4 x i64>, <4 x i64>* %14, align 16, !tbaa !3
  %16 = bitcast i64* %arrayidx.4.i to <4 x i64>*
  store <4 x i64> %15, <4 x i64>* %16, align 8, !tbaa !3
  %17 = load i64, i64* %arrayidx2.8.i, align 16, !tbaa !3
  store i64 %17, i64* %arrayidx.8.i, align 8, !tbaa !3
  %18 = load i64, i64* %arrayidx2.9.i, align 8, !tbaa !3
  store i64 %18, i64* %arrayidx.9.i, align 8, !tbaa !3
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 2480, i8* nonnull %0) #10
  ret void
}

; Function Attrs: norecurse nounwind ssp uwtable
define void @fp2copy610([10 x i64]* nocapture readonly %a, [10 x i64]* nocapture %c) local_unnamed_addr #0 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  %0 = load i64, i64* %arraydecay, align 8, !tbaa !3
  store i64 %0, i64* %arraydecay2, align 8, !tbaa !3
  %arrayidx.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 1
  %1 = load i64, i64* %arrayidx.1.i, align 8, !tbaa !3
  %arrayidx2.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 1
  store i64 %1, i64* %arrayidx2.1.i, align 8, !tbaa !3
  %arrayidx.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 2
  %2 = load i64, i64* %arrayidx.2.i, align 8, !tbaa !3
  %arrayidx2.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 2
  store i64 %2, i64* %arrayidx2.2.i, align 8, !tbaa !3
  %arrayidx.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 3
  %3 = load i64, i64* %arrayidx.3.i, align 8, !tbaa !3
  %arrayidx2.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 3
  store i64 %3, i64* %arrayidx2.3.i, align 8, !tbaa !3
  %arrayidx.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 4
  %4 = load i64, i64* %arrayidx.4.i, align 8, !tbaa !3
  %arrayidx2.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 4
  store i64 %4, i64* %arrayidx2.4.i, align 8, !tbaa !3
  %arrayidx.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 5
  %5 = load i64, i64* %arrayidx.5.i, align 8, !tbaa !3
  %arrayidx2.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 5
  store i64 %5, i64* %arrayidx2.5.i, align 8, !tbaa !3
  %arrayidx.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 6
  %6 = load i64, i64* %arrayidx.6.i, align 8, !tbaa !3
  %arrayidx2.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 6
  store i64 %6, i64* %arrayidx2.6.i, align 8, !tbaa !3
  %arrayidx.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 7
  %7 = load i64, i64* %arrayidx.7.i, align 8, !tbaa !3
  %arrayidx2.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 7
  store i64 %7, i64* %arrayidx2.7.i, align 8, !tbaa !3
  %arrayidx.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 8
  %8 = load i64, i64* %arrayidx.8.i, align 8, !tbaa !3
  %arrayidx2.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 8
  store i64 %8, i64* %arrayidx2.8.i, align 8, !tbaa !3
  %arrayidx.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 9
  %9 = load i64, i64* %arrayidx.9.i, align 8, !tbaa !3
  %arrayidx2.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 9
  store i64 %9, i64* %arrayidx2.9.i, align 8, !tbaa !3
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  %10 = load i64, i64* %arraydecay4, align 8, !tbaa !3
  store i64 %10, i64* %arraydecay6, align 8, !tbaa !3
  %arrayidx.1.i9 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 1
  %11 = load i64, i64* %arrayidx.1.i9, align 8, !tbaa !3
  %arrayidx2.1.i10 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 1
  store i64 %11, i64* %arrayidx2.1.i10, align 8, !tbaa !3
  %arrayidx.2.i11 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 2
  %12 = load i64, i64* %arrayidx.2.i11, align 8, !tbaa !3
  %arrayidx2.2.i12 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 2
  store i64 %12, i64* %arrayidx2.2.i12, align 8, !tbaa !3
  %arrayidx.3.i13 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 3
  %13 = load i64, i64* %arrayidx.3.i13, align 8, !tbaa !3
  %arrayidx2.3.i14 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 3
  store i64 %13, i64* %arrayidx2.3.i14, align 8, !tbaa !3
  %arrayidx.4.i15 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 4
  %14 = load i64, i64* %arrayidx.4.i15, align 8, !tbaa !3
  %arrayidx2.4.i16 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 4
  store i64 %14, i64* %arrayidx2.4.i16, align 8, !tbaa !3
  %arrayidx.5.i17 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 5
  %15 = load i64, i64* %arrayidx.5.i17, align 8, !tbaa !3
  %arrayidx2.5.i18 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 5
  store i64 %15, i64* %arrayidx2.5.i18, align 8, !tbaa !3
  %arrayidx.6.i19 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 6
  %16 = load i64, i64* %arrayidx.6.i19, align 8, !tbaa !3
  %arrayidx2.6.i20 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 6
  store i64 %16, i64* %arrayidx2.6.i20, align 8, !tbaa !3
  %arrayidx.7.i21 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 7
  %17 = load i64, i64* %arrayidx.7.i21, align 8, !tbaa !3
  %arrayidx2.7.i22 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 7
  store i64 %17, i64* %arrayidx2.7.i22, align 8, !tbaa !3
  %arrayidx.8.i23 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 8
  %18 = load i64, i64* %arrayidx.8.i23, align 8, !tbaa !3
  %arrayidx2.8.i24 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 8
  store i64 %18, i64* %arrayidx2.8.i24, align 8, !tbaa !3
  %arrayidx.9.i25 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 9
  %19 = load i64, i64* %arrayidx.9.i25, align 8, !tbaa !3
  %arrayidx2.9.i26 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 9
  store i64 %19, i64* %arrayidx2.9.i26, align 8, !tbaa !3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fp2zero610([10 x i64]* nocapture %a) local_unnamed_addr #4 {
entry:
  %0 = bitcast [10 x i64]* %a to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %0, i8 0, i64 160, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fp2neg610([10 x i64]* %a) local_unnamed_addr #4 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  tail call void @fpneg610(i64* %arraydecay) #10
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  tail call void @fpneg610(i64* nonnull %arraydecay2) #10
  ret void
}

declare void @fpneg610(i64*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define void @fp2add610([10 x i64]* %a, [10 x i64]* %b, [10 x i64]* %c) local_unnamed_addr #6 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 0, i64 0
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  tail call void @fpadd610(i64* %arraydecay, i64* %arraydecay2, i64* %arraydecay4) #10
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay8 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 1, i64 0
  %arraydecay10 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  tail call void @fpadd610(i64* nonnull %arraydecay6, i64* nonnull %arraydecay8, i64* nonnull %arraydecay10) #10
  ret void
}

declare void @fpadd610(i64*, i64*, i64*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define void @fp2sub610([10 x i64]* %a, [10 x i64]* %b, [10 x i64]* %c) local_unnamed_addr #6 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 0, i64 0
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  tail call void @fpsub610(i64* %arraydecay, i64* %arraydecay2, i64* %arraydecay4) #10
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay8 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 1, i64 0
  %arraydecay10 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  tail call void @fpsub610(i64* nonnull %arraydecay6, i64* nonnull %arraydecay8, i64* nonnull %arraydecay10) #10
  ret void
}

declare void @fpsub610(i64*, i64*, i64*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define void @fp2div2_610([10 x i64]* %a, [10 x i64]* %c) local_unnamed_addr #4 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  tail call void @fpdiv2_610(i64* %arraydecay, i64* %arraydecay2) #10
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  tail call void @fpdiv2_610(i64* nonnull %arraydecay4, i64* nonnull %arraydecay6) #10
  ret void
}

declare void @fpdiv2_610(i64*, i64*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define void @fp2correction610([10 x i64]* %a) local_unnamed_addr #4 {
entry:
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  tail call void @fpcorrection610(i64* %arraydecay) #10
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  tail call void @fpcorrection610(i64* nonnull %arraydecay2) #10
  ret void
}

; Function Attrs: inlinehint norecurse nounwind ssp uwtable
define i32 @mp_add(i64* nocapture readonly %a, i64* nocapture readonly %b, i64* nocapture %c, i32 %nwords) local_unnamed_addr #3 {
entry:
  %cmp31 = icmp eq i32 %nwords, 0
  br i1 %cmp31, label %for.end, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %nwords to i64
  %xtraiter = and i64 %wide.trip.count, 1
  %0 = icmp eq i32 %nwords, 1
  br i1 %0, label %for.cond.for.end_crit_edge.unr-lcssa, label %for.body.preheader.new

for.body.preheader.new:                           ; preds = %for.body.preheader
  %unroll_iter = sub nsw i64 %wide.trip.count, %xtraiter
  br label %for.body

for.body:                                         ; preds = %for.body, %for.body.preheader.new
  %indvars.iv = phi i64 [ 0, %for.body.preheader.new ], [ %indvars.iv.next.1, %for.body ]
  %carry.032 = phi i64 [ 0, %for.body.preheader.new ], [ %or29.1, %for.body ]
  %niter = phi i64 [ %unroll_iter, %for.body.preheader.new ], [ %niter.nsub.1, %for.body ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %indvars.iv
  %1 = load i64, i64* %arrayidx, align 8, !tbaa !3
  %add = add i64 %1, %carry.032
  %arrayidx2 = getelementptr inbounds i64, i64* %b, i64 %indvars.iv
  %2 = load i64, i64* %arrayidx2, align 8, !tbaa !3
  %add3 = add i64 %2, %add
  %arrayidx5 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv
  store i64 %add3, i64* %arrayidx5, align 8, !tbaa !3
  %3 = xor i64 %add, -9223372036854775808
  %xor2.i = and i64 %3, %1
  %xor.i23 = xor i64 %add3, %add
  %xor1.i24 = xor i64 %2, %add
  %or.i25 = or i64 %xor.i23, %xor1.i24
  %xor2.i26 = xor i64 %or.i25, %add3
  %shr.i30 = or i64 %xor2.i26, %xor2.i
  %or29 = lshr i64 %shr.i30, 63
  %indvars.iv.next = or i64 %indvars.iv, 1
  %arrayidx.1 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next
  %4 = load i64, i64* %arrayidx.1, align 8, !tbaa !3
  %add.1 = add i64 %4, %or29
  %arrayidx2.1 = getelementptr inbounds i64, i64* %b, i64 %indvars.iv.next
  %5 = load i64, i64* %arrayidx2.1, align 8, !tbaa !3
  %add3.1 = add i64 %5, %add.1
  %arrayidx5.1 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next
  store i64 %add3.1, i64* %arrayidx5.1, align 8, !tbaa !3
  %6 = xor i64 %add.1, -9223372036854775808
  %xor2.i.1 = and i64 %6, %4
  %xor.i23.1 = xor i64 %add3.1, %add.1
  %xor1.i24.1 = xor i64 %5, %add.1
  %or.i25.1 = or i64 %xor.i23.1, %xor1.i24.1
  %xor2.i26.1 = xor i64 %or.i25.1, %add3.1
  %shr.i30.1 = or i64 %xor2.i26.1, %xor2.i.1
  %or29.1 = lshr i64 %shr.i30.1, 63
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv, 2
  %niter.nsub.1 = add i64 %niter, -2
  %niter.ncmp.1 = icmp eq i64 %niter.nsub.1, 0
  br i1 %niter.ncmp.1, label %for.cond.for.end_crit_edge.unr-lcssa, label %for.body

for.cond.for.end_crit_edge.unr-lcssa:             ; preds = %for.body, %for.body.preheader
  %or29.lcssa.ph = phi i64 [ undef, %for.body.preheader ], [ %or29.1, %for.body ]
  %indvars.iv.unr = phi i64 [ 0, %for.body.preheader ], [ %indvars.iv.next.1, %for.body ]
  %carry.032.unr = phi i64 [ 0, %for.body.preheader ], [ %or29.1, %for.body ]
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %for.cond.for.end_crit_edge, label %for.body.epil

for.body.epil:                                    ; preds = %for.cond.for.end_crit_edge.unr-lcssa
  %arrayidx.epil = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.unr
  %7 = load i64, i64* %arrayidx.epil, align 8, !tbaa !3
  %add.epil = add i64 %7, %carry.032.unr
  %arrayidx2.epil = getelementptr inbounds i64, i64* %b, i64 %indvars.iv.unr
  %8 = load i64, i64* %arrayidx2.epil, align 8, !tbaa !3
  %add3.epil = add i64 %8, %add.epil
  %arrayidx5.epil = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.unr
  store i64 %add3.epil, i64* %arrayidx5.epil, align 8, !tbaa !3
  %xor.i23.epil = xor i64 %add3.epil, %add.epil
  %xor1.i24.epil = xor i64 %8, %add.epil
  %or.i25.epil = or i64 %xor.i23.epil, %xor1.i24.epil
  %xor2.i26.epil = xor i64 %or.i25.epil, %add3.epil
  %9 = xor i64 %add.epil, -9223372036854775808
  %xor2.i.epil = and i64 %9, %7
  %shr.i30.epil = or i64 %xor2.i26.epil, %xor2.i.epil
  %or29.epil = lshr i64 %shr.i30.epil, 63
  br label %for.cond.for.end_crit_edge

for.cond.for.end_crit_edge:                       ; preds = %for.cond.for.end_crit_edge.unr-lcssa, %for.body.epil
  %or29.lcssa = phi i64 [ %or29.lcssa.ph, %for.cond.for.end_crit_edge.unr-lcssa ], [ %or29.epil, %for.body.epil ]
  %or.le = trunc i64 %or29.lcssa to i32
  br label %for.end

for.end:                                          ; preds = %entry, %for.cond.for.end_crit_edge
  %carry.0.lcssa = phi i32 [ %or.le, %for.cond.for.end_crit_edge ], [ 0, %entry ]
  ret i32 %carry.0.lcssa
}

; Function Attrs: nounwind ssp uwtable
define void @fp2sqr610_mont([10 x i64]* %a, [10 x i64]* %c) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %t1 = alloca [10 x i64], align 16
  %t2 = alloca [10 x i64], align 16
  %t3 = alloca [10 x i64], align 16
  %0 = bitcast [10 x i64]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %2 = bitcast [10 x i64]* %t3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay3 = getelementptr inbounds [10 x i64], [10 x i64]* %t1, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay, i64* nonnull %arraydecay2, i64* nonnull %arraydecay3)
  %arraydecay8 = getelementptr inbounds [10 x i64], [10 x i64]* %t2, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay, i64* nonnull %arraydecay2, i64* nonnull %arraydecay8) #10
  %arraydecay13 = getelementptr inbounds [10 x i64], [10 x i64]* %t3, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay, i64* %arraydecay, i64* nonnull %arraydecay13)
  %arraydecay17 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  %3 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3, i64* nonnull %arraydecay8, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %arraydecay17) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13, i64* nonnull %arraydecay2, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay22) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: inlinehint norecurse nounwind ssp uwtable
define internal fastcc void @mp_addfast(i64* nocapture readonly %a, i64* nocapture readonly %b, i64* nocapture %c) unnamed_addr #3 {
entry:
  %0 = load i64, i64* %a, align 8, !tbaa !3
  %1 = load i64, i64* %b, align 8, !tbaa !3
  %add3.i = add i64 %1, %0
  store i64 %add3.i, i64* %c, align 8, !tbaa !3
  %xor.i23.i = xor i64 %add3.i, %0
  %xor1.i24.i = xor i64 %1, %0
  %or.i25.i = or i64 %xor.i23.i, %xor1.i24.i
  %xor2.i26.i = xor i64 %or.i25.i, %add3.i
  %or29.i = lshr i64 %xor2.i26.i, 63
  %arrayidx.i.1 = getelementptr inbounds i64, i64* %a, i64 1
  %2 = load i64, i64* %arrayidx.i.1, align 8, !tbaa !3
  %add.i.1 = add i64 %2, %or29.i
  %arrayidx2.i.1 = getelementptr inbounds i64, i64* %b, i64 1
  %3 = load i64, i64* %arrayidx2.i.1, align 8, !tbaa !3
  %add3.i.1 = add i64 %3, %add.i.1
  %arrayidx5.i.1 = getelementptr inbounds i64, i64* %c, i64 1
  store i64 %add3.i.1, i64* %arrayidx5.i.1, align 8, !tbaa !3
  %4 = xor i64 %add.i.1, -9223372036854775808
  %xor2.i.i.1 = and i64 %4, %2
  %xor.i23.i.1 = xor i64 %add3.i.1, %add.i.1
  %xor1.i24.i.1 = xor i64 %3, %add.i.1
  %or.i25.i.1 = or i64 %xor.i23.i.1, %xor1.i24.i.1
  %xor2.i26.i.1 = xor i64 %or.i25.i.1, %add3.i.1
  %shr.i30.i.1 = or i64 %xor2.i26.i.1, %xor2.i.i.1
  %or29.i.1 = lshr i64 %shr.i30.i.1, 63
  %arrayidx.i.2 = getelementptr inbounds i64, i64* %a, i64 2
  %5 = load i64, i64* %arrayidx.i.2, align 8, !tbaa !3
  %add.i.2 = add i64 %5, %or29.i.1
  %arrayidx2.i.2 = getelementptr inbounds i64, i64* %b, i64 2
  %6 = load i64, i64* %arrayidx2.i.2, align 8, !tbaa !3
  %add3.i.2 = add i64 %6, %add.i.2
  %arrayidx5.i.2 = getelementptr inbounds i64, i64* %c, i64 2
  store i64 %add3.i.2, i64* %arrayidx5.i.2, align 8, !tbaa !3
  %7 = xor i64 %add.i.2, -9223372036854775808
  %xor2.i.i.2 = and i64 %7, %5
  %xor.i23.i.2 = xor i64 %add3.i.2, %add.i.2
  %xor1.i24.i.2 = xor i64 %6, %add.i.2
  %or.i25.i.2 = or i64 %xor.i23.i.2, %xor1.i24.i.2
  %xor2.i26.i.2 = xor i64 %or.i25.i.2, %add3.i.2
  %shr.i30.i.2 = or i64 %xor2.i26.i.2, %xor2.i.i.2
  %or29.i.2 = lshr i64 %shr.i30.i.2, 63
  %arrayidx.i.3 = getelementptr inbounds i64, i64* %a, i64 3
  %8 = load i64, i64* %arrayidx.i.3, align 8, !tbaa !3
  %add.i.3 = add i64 %8, %or29.i.2
  %arrayidx2.i.3 = getelementptr inbounds i64, i64* %b, i64 3
  %9 = load i64, i64* %arrayidx2.i.3, align 8, !tbaa !3
  %add3.i.3 = add i64 %9, %add.i.3
  %arrayidx5.i.3 = getelementptr inbounds i64, i64* %c, i64 3
  store i64 %add3.i.3, i64* %arrayidx5.i.3, align 8, !tbaa !3
  %10 = xor i64 %add.i.3, -9223372036854775808
  %xor2.i.i.3 = and i64 %10, %8
  %xor.i23.i.3 = xor i64 %add3.i.3, %add.i.3
  %xor1.i24.i.3 = xor i64 %9, %add.i.3
  %or.i25.i.3 = or i64 %xor.i23.i.3, %xor1.i24.i.3
  %xor2.i26.i.3 = xor i64 %or.i25.i.3, %add3.i.3
  %shr.i30.i.3 = or i64 %xor2.i26.i.3, %xor2.i.i.3
  %or29.i.3 = lshr i64 %shr.i30.i.3, 63
  %arrayidx.i.4 = getelementptr inbounds i64, i64* %a, i64 4
  %11 = load i64, i64* %arrayidx.i.4, align 8, !tbaa !3
  %add.i.4 = add i64 %11, %or29.i.3
  %arrayidx2.i.4 = getelementptr inbounds i64, i64* %b, i64 4
  %12 = load i64, i64* %arrayidx2.i.4, align 8, !tbaa !3
  %add3.i.4 = add i64 %12, %add.i.4
  %arrayidx5.i.4 = getelementptr inbounds i64, i64* %c, i64 4
  store i64 %add3.i.4, i64* %arrayidx5.i.4, align 8, !tbaa !3
  %13 = xor i64 %add.i.4, -9223372036854775808
  %xor2.i.i.4 = and i64 %13, %11
  %xor.i23.i.4 = xor i64 %add3.i.4, %add.i.4
  %xor1.i24.i.4 = xor i64 %12, %add.i.4
  %or.i25.i.4 = or i64 %xor.i23.i.4, %xor1.i24.i.4
  %xor2.i26.i.4 = xor i64 %or.i25.i.4, %add3.i.4
  %shr.i30.i.4 = or i64 %xor2.i26.i.4, %xor2.i.i.4
  %or29.i.4 = lshr i64 %shr.i30.i.4, 63
  %arrayidx.i.5 = getelementptr inbounds i64, i64* %a, i64 5
  %14 = load i64, i64* %arrayidx.i.5, align 8, !tbaa !3
  %add.i.5 = add i64 %14, %or29.i.4
  %arrayidx2.i.5 = getelementptr inbounds i64, i64* %b, i64 5
  %15 = load i64, i64* %arrayidx2.i.5, align 8, !tbaa !3
  %add3.i.5 = add i64 %15, %add.i.5
  %arrayidx5.i.5 = getelementptr inbounds i64, i64* %c, i64 5
  store i64 %add3.i.5, i64* %arrayidx5.i.5, align 8, !tbaa !3
  %16 = xor i64 %add.i.5, -9223372036854775808
  %xor2.i.i.5 = and i64 %16, %14
  %xor.i23.i.5 = xor i64 %add3.i.5, %add.i.5
  %xor1.i24.i.5 = xor i64 %15, %add.i.5
  %or.i25.i.5 = or i64 %xor.i23.i.5, %xor1.i24.i.5
  %xor2.i26.i.5 = xor i64 %or.i25.i.5, %add3.i.5
  %shr.i30.i.5 = or i64 %xor2.i26.i.5, %xor2.i.i.5
  %or29.i.5 = lshr i64 %shr.i30.i.5, 63
  %arrayidx.i.6 = getelementptr inbounds i64, i64* %a, i64 6
  %17 = load i64, i64* %arrayidx.i.6, align 8, !tbaa !3
  %add.i.6 = add i64 %17, %or29.i.5
  %arrayidx2.i.6 = getelementptr inbounds i64, i64* %b, i64 6
  %18 = load i64, i64* %arrayidx2.i.6, align 8, !tbaa !3
  %add3.i.6 = add i64 %18, %add.i.6
  %arrayidx5.i.6 = getelementptr inbounds i64, i64* %c, i64 6
  store i64 %add3.i.6, i64* %arrayidx5.i.6, align 8, !tbaa !3
  %19 = xor i64 %add.i.6, -9223372036854775808
  %xor2.i.i.6 = and i64 %19, %17
  %xor.i23.i.6 = xor i64 %add3.i.6, %add.i.6
  %xor1.i24.i.6 = xor i64 %18, %add.i.6
  %or.i25.i.6 = or i64 %xor.i23.i.6, %xor1.i24.i.6
  %xor2.i26.i.6 = xor i64 %or.i25.i.6, %add3.i.6
  %shr.i30.i.6 = or i64 %xor2.i26.i.6, %xor2.i.i.6
  %or29.i.6 = lshr i64 %shr.i30.i.6, 63
  %arrayidx.i.7 = getelementptr inbounds i64, i64* %a, i64 7
  %20 = load i64, i64* %arrayidx.i.7, align 8, !tbaa !3
  %add.i.7 = add i64 %20, %or29.i.6
  %arrayidx2.i.7 = getelementptr inbounds i64, i64* %b, i64 7
  %21 = load i64, i64* %arrayidx2.i.7, align 8, !tbaa !3
  %add3.i.7 = add i64 %21, %add.i.7
  %arrayidx5.i.7 = getelementptr inbounds i64, i64* %c, i64 7
  store i64 %add3.i.7, i64* %arrayidx5.i.7, align 8, !tbaa !3
  %22 = xor i64 %add.i.7, -9223372036854775808
  %xor2.i.i.7 = and i64 %22, %20
  %xor.i23.i.7 = xor i64 %add3.i.7, %add.i.7
  %xor1.i24.i.7 = xor i64 %21, %add.i.7
  %or.i25.i.7 = or i64 %xor.i23.i.7, %xor1.i24.i.7
  %xor2.i26.i.7 = xor i64 %or.i25.i.7, %add3.i.7
  %shr.i30.i.7 = or i64 %xor2.i26.i.7, %xor2.i.i.7
  %or29.i.7 = lshr i64 %shr.i30.i.7, 63
  %arrayidx.i.8 = getelementptr inbounds i64, i64* %a, i64 8
  %23 = load i64, i64* %arrayidx.i.8, align 8, !tbaa !3
  %add.i.8 = add i64 %23, %or29.i.7
  %arrayidx2.i.8 = getelementptr inbounds i64, i64* %b, i64 8
  %24 = load i64, i64* %arrayidx2.i.8, align 8, !tbaa !3
  %add3.i.8 = add i64 %24, %add.i.8
  %arrayidx5.i.8 = getelementptr inbounds i64, i64* %c, i64 8
  store i64 %add3.i.8, i64* %arrayidx5.i.8, align 8, !tbaa !3
  %25 = xor i64 %add.i.8, -9223372036854775808
  %xor2.i.i.8 = and i64 %25, %23
  %xor.i23.i.8 = xor i64 %add3.i.8, %add.i.8
  %xor1.i24.i.8 = xor i64 %24, %add.i.8
  %or.i25.i.8 = or i64 %xor.i23.i.8, %xor1.i24.i.8
  %xor2.i26.i.8 = xor i64 %or.i25.i.8, %add3.i.8
  %shr.i30.i.8 = or i64 %xor2.i26.i.8, %xor2.i.i.8
  %or29.i.8 = lshr i64 %shr.i30.i.8, 63
  %arrayidx.i.9 = getelementptr inbounds i64, i64* %a, i64 9
  %26 = load i64, i64* %arrayidx.i.9, align 8, !tbaa !3
  %add.i.9 = add i64 %26, %or29.i.8
  %arrayidx2.i.9 = getelementptr inbounds i64, i64* %b, i64 9
  %27 = load i64, i64* %arrayidx2.i.9, align 8, !tbaa !3
  %add3.i.9 = add i64 %27, %add.i.9
  %arrayidx5.i.9 = getelementptr inbounds i64, i64* %c, i64 9
  store i64 %add3.i.9, i64* %arrayidx5.i.9, align 8, !tbaa !3
  ret void
}

declare void @mp_sub610_p4(i64*, i64*, i64*) local_unnamed_addr #5

; Function Attrs: inlinehint norecurse nounwind ssp uwtable
define i32 @mp_sub(i64* nocapture readonly %a, i64* nocapture readonly %b, i64* nocapture %c, i32 %nwords) local_unnamed_addr #3 {
entry:
  %cmp27 = icmp eq i32 %nwords, 0
  br i1 %cmp27, label %for.end, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %nwords to i64
  %xtraiter = and i64 %wide.trip.count, 1
  %0 = icmp eq i32 %nwords, 1
  br i1 %0, label %for.end.loopexit.unr-lcssa, label %for.body.preheader.new

for.body.preheader.new:                           ; preds = %for.body.preheader
  %unroll_iter = sub nsw i64 %wide.trip.count, %xtraiter
  br label %for.body

for.body:                                         ; preds = %for.body, %for.body.preheader.new
  %indvars.iv = phi i64 [ 0, %for.body.preheader.new ], [ %indvars.iv.next.1, %for.body ]
  %borrow.028 = phi i32 [ 0, %for.body.preheader.new ], [ %or.1, %for.body ]
  %niter = phi i64 [ %unroll_iter, %for.body.preheader.new ], [ %niter.nsub.1, %for.body ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %indvars.iv
  %1 = load i64, i64* %arrayidx, align 8, !tbaa !3
  %arrayidx2 = getelementptr inbounds i64, i64* %b, i64 %indvars.iv
  %2 = load i64, i64* %arrayidx2, align 8, !tbaa !3
  %sub = sub i64 %1, %2
  %xor.i = xor i64 %2, %1
  %xor1.i = xor i64 %sub, %2
  %or.i = or i64 %xor1.i, %xor.i
  %xor2.i = xor i64 %or.i, %1
  %shr.i = lshr i64 %xor2.i, 63
  %conv.i = trunc i64 %shr.i to i32
  %sub.i.i = sub i64 0, %sub
  %or.i.i = or i64 %sub, %sub.i.i
  %shr.i.i = lshr i64 %or.i.i, 63
  %conv.i.i = trunc i64 %shr.i.i to i32
  %xor.i26 = xor i32 %conv.i.i, 1
  %and = and i32 %xor.i26, %borrow.028
  %or = or i32 %and, %conv.i
  %conv = zext i32 %borrow.028 to i64
  %sub8 = sub i64 %sub, %conv
  %arrayidx10 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv
  store i64 %sub8, i64* %arrayidx10, align 8, !tbaa !3
  %indvars.iv.next = or i64 %indvars.iv, 1
  %arrayidx.1 = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.next
  %3 = load i64, i64* %arrayidx.1, align 8, !tbaa !3
  %arrayidx2.1 = getelementptr inbounds i64, i64* %b, i64 %indvars.iv.next
  %4 = load i64, i64* %arrayidx2.1, align 8, !tbaa !3
  %sub.1 = sub i64 %3, %4
  %xor.i.1 = xor i64 %4, %3
  %xor1.i.1 = xor i64 %sub.1, %4
  %or.i.1 = or i64 %xor1.i.1, %xor.i.1
  %xor2.i.1 = xor i64 %or.i.1, %3
  %shr.i.1 = lshr i64 %xor2.i.1, 63
  %conv.i.1 = trunc i64 %shr.i.1 to i32
  %sub.i.i.1 = sub i64 0, %sub.1
  %or.i.i.1 = or i64 %sub.1, %sub.i.i.1
  %shr.i.i.1 = lshr i64 %or.i.i.1, 63
  %conv.i.i.1 = trunc i64 %shr.i.i.1 to i32
  %xor.i26.1 = xor i32 %conv.i.i.1, 1
  %and.1 = and i32 %xor.i26.1, %or
  %or.1 = or i32 %and.1, %conv.i.1
  %conv.1 = zext i32 %or to i64
  %sub8.1 = sub i64 %sub.1, %conv.1
  %arrayidx10.1 = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.next
  store i64 %sub8.1, i64* %arrayidx10.1, align 8, !tbaa !3
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv, 2
  %niter.nsub.1 = add i64 %niter, -2
  %niter.ncmp.1 = icmp eq i64 %niter.nsub.1, 0
  br i1 %niter.ncmp.1, label %for.end.loopexit.unr-lcssa, label %for.body

for.end.loopexit.unr-lcssa:                       ; preds = %for.body, %for.body.preheader
  %or.lcssa.ph = phi i32 [ undef, %for.body.preheader ], [ %or.1, %for.body ]
  %indvars.iv.unr = phi i64 [ 0, %for.body.preheader ], [ %indvars.iv.next.1, %for.body ]
  %borrow.028.unr = phi i32 [ 0, %for.body.preheader ], [ %or.1, %for.body ]
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %for.end, label %for.body.epil

for.body.epil:                                    ; preds = %for.end.loopexit.unr-lcssa
  %arrayidx.epil = getelementptr inbounds i64, i64* %a, i64 %indvars.iv.unr
  %5 = load i64, i64* %arrayidx.epil, align 8, !tbaa !3
  %arrayidx2.epil = getelementptr inbounds i64, i64* %b, i64 %indvars.iv.unr
  %6 = load i64, i64* %arrayidx2.epil, align 8, !tbaa !3
  %sub.epil = sub i64 %5, %6
  %conv.epil = zext i32 %borrow.028.unr to i64
  %sub8.epil = sub i64 %sub.epil, %conv.epil
  %arrayidx10.epil = getelementptr inbounds i64, i64* %c, i64 %indvars.iv.unr
  store i64 %sub8.epil, i64* %arrayidx10.epil, align 8, !tbaa !3
  %sub.i.i.epil = sub i64 0, %sub.epil
  %or.i.i.epil = or i64 %sub.epil, %sub.i.i.epil
  %shr.i.i.epil = lshr i64 %or.i.i.epil, 63
  %conv.i.i.epil = trunc i64 %shr.i.i.epil to i32
  %xor.i26.epil = xor i32 %conv.i.i.epil, 1
  %and.epil = and i32 %xor.i26.epil, %borrow.028.unr
  %xor1.i.epil = xor i64 %sub.epil, %6
  %xor.i.epil = xor i64 %6, %5
  %or.i.epil = or i64 %xor1.i.epil, %xor.i.epil
  %xor2.i.epil = xor i64 %or.i.epil, %5
  %shr.i.epil = lshr i64 %xor2.i.epil, 63
  %conv.i.epil = trunc i64 %shr.i.epil to i32
  %or.epil = or i32 %and.epil, %conv.i.epil
  br label %for.end

for.end:                                          ; preds = %for.body.epil, %for.end.loopexit.unr-lcssa, %entry
  %borrow.0.lcssa = phi i32 [ 0, %entry ], [ %or.lcssa.ph, %for.end.loopexit.unr-lcssa ], [ %or.epil, %for.body.epil ]
  ret i32 %borrow.0.lcssa
}

; Function Attrs: nounwind ssp uwtable
define void @fp2mul610_mont([10 x i64]* %a, [10 x i64]* %b, [10 x i64]* %c) local_unnamed_addr #4 {
entry:
  %t1 = alloca [10 x i64], align 16
  %t2 = alloca [10 x i64], align 16
  %tt1 = alloca [20 x i64], align 16
  %tt2 = alloca [20 x i64], align 16
  %tt3 = alloca [20 x i64], align 16
  %0 = bitcast [10 x i64]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %2 = bitcast [20 x i64]* %tt1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = bitcast [20 x i64]* %tt2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  %4 = bitcast [20 x i64]* %tt3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay3 = getelementptr inbounds [10 x i64], [10 x i64]* %t1, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay, i64* nonnull %arraydecay2, i64* nonnull %arraydecay3)
  %arraydecay5 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 0, i64 0
  %arraydecay7 = getelementptr inbounds [10 x i64], [10 x i64]* %b, i64 1, i64 0
  %arraydecay8 = getelementptr inbounds [10 x i64], [10 x i64]* %t2, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay5, i64* nonnull %arraydecay7, i64* nonnull %arraydecay8)
  %arraydecay13 = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 0
  call void @mp_mul(i64* %arraydecay, i64* %arraydecay5, i64* nonnull %arraydecay13, i32 10) #10
  %arraydecay18 = getelementptr inbounds [20 x i64], [20 x i64]* %tt2, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay2, i64* nonnull %arraydecay7, i64* nonnull %arraydecay18, i32 10) #10
  %arraydecay21 = getelementptr inbounds [20 x i64], [20 x i64]* %tt3, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3, i64* nonnull %arraydecay8, i64* nonnull %arraydecay21, i32 10) #10
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i, %entry
  %indvars.iv.i.i = phi i64 [ 0, %entry ], [ %indvars.iv.next.i.i.1, %for.body.i.i ]
  %borrow.028.i.i = phi i32 [ 0, %entry ], [ %or.i.i.1, %for.body.i.i ]
  %arrayidx.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt3, i64 0, i64 %indvars.iv.i.i
  %5 = load i64, i64* %arrayidx.i.i, align 16, !tbaa !3
  %arrayidx2.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 %indvars.iv.i.i
  %6 = load i64, i64* %arrayidx2.i.i, align 16, !tbaa !3
  %sub.i.i = sub i64 %5, %6
  %xor.i.i.i = xor i64 %6, %5
  %xor1.i.i.i = xor i64 %sub.i.i, %6
  %or.i.i.i = or i64 %xor1.i.i.i, %xor.i.i.i
  %xor2.i.i.i = xor i64 %or.i.i.i, %5
  %shr.i.i.i = lshr i64 %xor2.i.i.i, 63
  %conv.i.i.i = trunc i64 %shr.i.i.i to i32
  %sub.i.i.i.i = sub i64 0, %sub.i.i
  %or.i.i.i.i = or i64 %sub.i.i, %sub.i.i.i.i
  %shr.i.i.i.i = lshr i64 %or.i.i.i.i, 63
  %conv.i.i.i.i = trunc i64 %shr.i.i.i.i to i32
  %xor.i26.i.i = xor i32 %conv.i.i.i.i, 1
  %and.i.i = and i32 %xor.i26.i.i, %borrow.028.i.i
  %or.i.i = or i32 %and.i.i, %conv.i.i.i
  %conv.i.i = zext i32 %borrow.028.i.i to i64
  %sub8.i.i = sub i64 %sub.i.i, %conv.i.i
  store i64 %sub8.i.i, i64* %arrayidx.i.i, align 16, !tbaa !3
  %indvars.iv.next.i.i = or i64 %indvars.iv.i.i, 1
  %arrayidx.i.i.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt3, i64 0, i64 %indvars.iv.next.i.i
  %7 = load i64, i64* %arrayidx.i.i.1, align 8, !tbaa !3
  %arrayidx2.i.i.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 %indvars.iv.next.i.i
  %8 = load i64, i64* %arrayidx2.i.i.1, align 8, !tbaa !3
  %sub.i.i.1 = sub i64 %7, %8
  %xor.i.i.i.1 = xor i64 %8, %7
  %xor1.i.i.i.1 = xor i64 %sub.i.i.1, %8
  %or.i.i.i.1 = or i64 %xor1.i.i.i.1, %xor.i.i.i.1
  %xor2.i.i.i.1 = xor i64 %or.i.i.i.1, %7
  %shr.i.i.i.1 = lshr i64 %xor2.i.i.i.1, 63
  %conv.i.i.i.1 = trunc i64 %shr.i.i.i.1 to i32
  %sub.i.i.i.i.1 = sub i64 0, %sub.i.i.1
  %or.i.i.i.i.1 = or i64 %sub.i.i.1, %sub.i.i.i.i.1
  %shr.i.i.i.i.1 = lshr i64 %or.i.i.i.i.1, 63
  %conv.i.i.i.i.1 = trunc i64 %shr.i.i.i.i.1 to i32
  %xor.i26.i.i.1 = xor i32 %conv.i.i.i.i.1, 1
  %and.i.i.1 = and i32 %xor.i26.i.i.1, %or.i.i
  %or.i.i.1 = or i32 %and.i.i.1, %conv.i.i.i.1
  %conv.i.i.1 = zext i32 %or.i.i to i64
  %sub8.i.i.1 = sub i64 %sub.i.i.1, %conv.i.i.1
  store i64 %sub8.i.i.1, i64* %arrayidx.i.i.1, align 8, !tbaa !3
  %indvars.iv.next.i.i.1 = add nuw nsw i64 %indvars.iv.i.i, 2
  %exitcond.i.i.1 = icmp eq i64 %indvars.iv.next.i.i.1, 20
  br i1 %exitcond.i.i.1, label %for.body.i28.i, label %for.body.i.i

for.body.i28.i:                                   ; preds = %for.body.i.i, %for.body.i28.i
  %indvars.iv.i5.i = phi i64 [ %indvars.iv.next.i26.i.1, %for.body.i28.i ], [ 0, %for.body.i.i ]
  %borrow.028.i6.i = phi i32 [ %or.i22.i.1, %for.body.i28.i ], [ 0, %for.body.i.i ]
  %arrayidx.i7.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt3, i64 0, i64 %indvars.iv.i5.i
  %9 = load i64, i64* %arrayidx.i7.i, align 16, !tbaa !3
  %arrayidx2.i8.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt2, i64 0, i64 %indvars.iv.i5.i
  %10 = load i64, i64* %arrayidx2.i8.i, align 16, !tbaa !3
  %sub.i9.i = sub i64 %9, %10
  %xor.i.i10.i = xor i64 %10, %9
  %xor1.i.i11.i = xor i64 %sub.i9.i, %10
  %or.i.i12.i = or i64 %xor1.i.i11.i, %xor.i.i10.i
  %xor2.i.i13.i = xor i64 %or.i.i12.i, %9
  %shr.i.i14.i = lshr i64 %xor2.i.i13.i, 63
  %conv.i.i15.i = trunc i64 %shr.i.i14.i to i32
  %sub.i.i.i16.i = sub i64 0, %sub.i9.i
  %or.i.i.i17.i = or i64 %sub.i9.i, %sub.i.i.i16.i
  %shr.i.i.i18.i = lshr i64 %or.i.i.i17.i, 63
  %conv.i.i.i19.i = trunc i64 %shr.i.i.i18.i to i32
  %xor.i26.i20.i = xor i32 %conv.i.i.i19.i, 1
  %and.i21.i = and i32 %xor.i26.i20.i, %borrow.028.i6.i
  %or.i22.i = or i32 %and.i21.i, %conv.i.i15.i
  %conv.i23.i = zext i32 %borrow.028.i6.i to i64
  %sub8.i24.i = sub i64 %sub.i9.i, %conv.i23.i
  store i64 %sub8.i24.i, i64* %arrayidx.i7.i, align 16, !tbaa !3
  %indvars.iv.next.i26.i = or i64 %indvars.iv.i5.i, 1
  %arrayidx.i7.i.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt3, i64 0, i64 %indvars.iv.next.i26.i
  %11 = load i64, i64* %arrayidx.i7.i.1, align 8, !tbaa !3
  %arrayidx2.i8.i.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt2, i64 0, i64 %indvars.iv.next.i26.i
  %12 = load i64, i64* %arrayidx2.i8.i.1, align 8, !tbaa !3
  %sub.i9.i.1 = sub i64 %11, %12
  %xor.i.i10.i.1 = xor i64 %12, %11
  %xor1.i.i11.i.1 = xor i64 %sub.i9.i.1, %12
  %or.i.i12.i.1 = or i64 %xor1.i.i11.i.1, %xor.i.i10.i.1
  %xor2.i.i13.i.1 = xor i64 %or.i.i12.i.1, %11
  %shr.i.i14.i.1 = lshr i64 %xor2.i.i13.i.1, 63
  %conv.i.i15.i.1 = trunc i64 %shr.i.i14.i.1 to i32
  %sub.i.i.i16.i.1 = sub i64 0, %sub.i9.i.1
  %or.i.i.i17.i.1 = or i64 %sub.i9.i.1, %sub.i.i.i16.i.1
  %shr.i.i.i18.i.1 = lshr i64 %or.i.i.i17.i.1, 63
  %conv.i.i.i19.i.1 = trunc i64 %shr.i.i.i18.i.1 to i32
  %xor.i26.i20.i.1 = xor i32 %conv.i.i.i19.i.1, 1
  %and.i21.i.1 = and i32 %xor.i26.i20.i.1, %or.i22.i
  %or.i22.i.1 = or i32 %and.i21.i.1, %conv.i.i15.i.1
  %conv.i23.i.1 = zext i32 %or.i22.i to i64
  %sub8.i24.i.1 = sub i64 %sub.i9.i.1, %conv.i23.i.1
  store i64 %sub8.i24.i.1, i64* %arrayidx.i7.i.1, align 8, !tbaa !3
  %indvars.iv.next.i26.i.1 = add nuw nsw i64 %indvars.iv.i5.i, 2
  %exitcond.i27.i.1 = icmp eq i64 %indvars.iv.next.i26.i.1, 20
  br i1 %exitcond.i27.i.1, label %for.body.i.i63, label %for.body.i28.i

for.body.i.i63:                                   ; preds = %for.body.i28.i, %for.body.i.i63
  %indvars.iv.i.i41 = phi i64 [ %indvars.iv.next.i.i61.1, %for.body.i.i63 ], [ 0, %for.body.i28.i ]
  %borrow.028.i.i42 = phi i32 [ %or.i.i58.1, %for.body.i.i63 ], [ 0, %for.body.i28.i ]
  %arrayidx.i.i43 = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 %indvars.iv.i.i41
  %13 = load i64, i64* %arrayidx.i.i43, align 16, !tbaa !3
  %arrayidx2.i.i44 = getelementptr inbounds [20 x i64], [20 x i64]* %tt2, i64 0, i64 %indvars.iv.i.i41
  %14 = load i64, i64* %arrayidx2.i.i44, align 16, !tbaa !3
  %sub.i.i45 = sub i64 %13, %14
  %xor.i.i.i46 = xor i64 %14, %13
  %xor1.i.i.i47 = xor i64 %sub.i.i45, %14
  %or.i.i.i48 = or i64 %xor1.i.i.i47, %xor.i.i.i46
  %xor2.i.i.i49 = xor i64 %or.i.i.i48, %13
  %shr.i.i.i50 = lshr i64 %xor2.i.i.i49, 63
  %conv.i.i.i51 = trunc i64 %shr.i.i.i50 to i32
  %sub.i.i.i.i52 = sub i64 0, %sub.i.i45
  %or.i.i.i.i53 = or i64 %sub.i.i45, %sub.i.i.i.i52
  %shr.i.i.i.i54 = lshr i64 %or.i.i.i.i53, 63
  %conv.i.i.i.i55 = trunc i64 %shr.i.i.i.i54 to i32
  %xor.i26.i.i56 = xor i32 %conv.i.i.i.i55, 1
  %and.i.i57 = and i32 %xor.i26.i.i56, %borrow.028.i.i42
  %or.i.i58 = or i32 %and.i.i57, %conv.i.i.i51
  %conv.i.i59 = zext i32 %borrow.028.i.i42 to i64
  %sub8.i.i60 = sub i64 %sub.i.i45, %conv.i.i59
  store i64 %sub8.i.i60, i64* %arrayidx.i.i43, align 16, !tbaa !3
  %indvars.iv.next.i.i61 = or i64 %indvars.iv.i.i41, 1
  %arrayidx.i.i43.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 %indvars.iv.next.i.i61
  %15 = load i64, i64* %arrayidx.i.i43.1, align 8, !tbaa !3
  %arrayidx2.i.i44.1 = getelementptr inbounds [20 x i64], [20 x i64]* %tt2, i64 0, i64 %indvars.iv.next.i.i61
  %16 = load i64, i64* %arrayidx2.i.i44.1, align 8, !tbaa !3
  %sub.i.i45.1 = sub i64 %15, %16
  %xor.i.i.i46.1 = xor i64 %16, %15
  %xor1.i.i.i47.1 = xor i64 %sub.i.i45.1, %16
  %or.i.i.i48.1 = or i64 %xor1.i.i.i47.1, %xor.i.i.i46.1
  %xor2.i.i.i49.1 = xor i64 %or.i.i.i48.1, %15
  %shr.i.i.i50.1 = lshr i64 %xor2.i.i.i49.1, 63
  %conv.i.i.i51.1 = trunc i64 %shr.i.i.i50.1 to i32
  %sub.i.i.i.i52.1 = sub i64 0, %sub.i.i45.1
  %or.i.i.i.i53.1 = or i64 %sub.i.i45.1, %sub.i.i.i.i52.1
  %shr.i.i.i.i54.1 = lshr i64 %or.i.i.i.i53.1, 63
  %conv.i.i.i.i55.1 = trunc i64 %shr.i.i.i.i54.1 to i32
  %xor.i26.i.i56.1 = xor i32 %conv.i.i.i.i55.1, 1
  %and.i.i57.1 = and i32 %xor.i26.i.i56.1, %or.i.i58
  %or.i.i58.1 = or i32 %and.i.i57.1, %conv.i.i.i51.1
  %conv.i.i59.1 = zext i32 %or.i.i58 to i64
  %sub8.i.i60.1 = sub i64 %sub.i.i45.1, %conv.i.i59.1
  store i64 %sub8.i.i60.1, i64* %arrayidx.i.i43.1, align 8, !tbaa !3
  %indvars.iv.next.i.i61.1 = add nuw nsw i64 %indvars.iv.i.i41, 2
  %exitcond.i.i62.1 = icmp eq i64 %indvars.iv.next.i.i61.1, 20
  br i1 %exitcond.i.i62.1, label %mp_subaddfast.exit, label %for.body.i.i63

mp_subaddfast.exit:                               ; preds = %for.body.i.i63
  %conv.i = zext i32 %or.i.i58.1 to i64
  %sub.i = sub nsw i64 0, %conv.i
  %and.4.i = and i64 %sub.i, 7926898294125494271
  %and.5.i = and i64 %sub.i, -5658687270105206738
  %and.6.i = and i64 %sub.i, -7284643569098294869
  %and.7.i = and i64 %sub.i, -5596370174845115094
  %and.8.i = and i64 %sub.i, -9110763619386664820
  %and.9.i = and i64 %sub.i, 10669696872
  %arrayidx4.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 10
  %17 = load i64, i64* %arrayidx4.i, align 16, !tbaa !3
  %add3.i.i = sub i64 %17, %conv.i
  store i64 %add3.i.i, i64* %arrayidx4.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %17
  %xor1.i24.i.i = xor i64 %17, %sub.i
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 11
  %18 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %18
  %add3.i.1.i = sub i64 %add.i.1.i, %conv.i
  store i64 %add3.i.1.i, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %19 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %19, %18
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %sub.i
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 12
  %20 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %20
  %add3.i.2.i = sub i64 %add.i.2.i, %conv.i
  store i64 %add3.i.2.i, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %21 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %21, %20
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %sub.i
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 13
  %22 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %22
  %add3.i.3.i = sub i64 %add.i.3.i, %conv.i
  store i64 %add3.i.3.i, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %23 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %23, %22
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %sub.i
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 14
  %24 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %24
  %add3.i.4.i = add i64 %add.i.4.i, %and.4.i
  store i64 %add3.i.4.i, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %25 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %25, %24
  %26 = xor i64 %add3.i.4.i, -9223372036854775808
  %xor2.i26.i.4.i = and i64 %26, %add.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 15
  %27 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %27
  %add3.i.5.i = add i64 %add.i.5.i, %and.5.i
  store i64 %add3.i.5.i, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %28 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %28, %27
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %sub.i
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 16
  %29 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %29
  %add3.i.6.i = add i64 %add.i.6.i, %and.6.i
  store i64 %add3.i.6.i, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %30 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %30, %29
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %sub.i
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 17
  %31 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %31
  %add3.i.7.i = add i64 %add.i.7.i, %and.7.i
  store i64 %add3.i.7.i, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %32 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %32, %31
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %sub.i
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 18
  %33 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %33
  %add3.i.8.i = add i64 %add.i.8.i, %and.8.i
  store i64 %add3.i.8.i, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %34 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %34, %33
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %sub.i
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [20 x i64], [20 x i64]* %tt1, i64 0, i64 19
  %35 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %35, %and.9.i
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  store i64 %add3.i.9.i, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arraydecay30 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  call void @rdc_mont(i64* nonnull %arraydecay21, i64* nonnull %arraydecay30) #10
  %arraydecay33 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  call void @rdc_mont(i64* nonnull %arraydecay13, i64* %arraydecay33) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @fp2inv610_mont([10 x i64]* %a) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  %1 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* %arraydecay, i64* %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay6 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4, i64* nonnull %arraydecay4, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @fpadd610(i64* nonnull %arraydecay2, i64* nonnull %arraydecay6, i64* nonnull %arraydecay2) #10
  call void @fpinv610_mont(i64* nonnull %arraydecay2)
  call void @fpneg610(i64* nonnull %arraydecay4) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %arraydecay, i64* nonnull %arraydecay2, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %arraydecay) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4, i64* nonnull %arraydecay2, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay4) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @to_fp2mont([10 x i64]* %a, [10 x i64]* %mc) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %mc, i64 0, i64 0
  %0 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* %arraydecay, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %mc, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @from_fp2mont([10 x i64]* %ma, [10 x i64]* %c) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %one.i = alloca [10 x i64], align 16
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %ma, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 0, i64 0
  %0 = bitcast [10 x i64]* %one.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 80, i1 false) #10
  %arrayidx.i = getelementptr inbounds [10 x i64], [10 x i64]* %one.i, i64 0, i64 0
  store i64 1, i64* %arrayidx.i, align 16, !tbaa !3
  %1 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* %arraydecay, i64* nonnull %arrayidx.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @fpcorrection610(i64* %arraydecay2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %ma, i64 1, i64 0
  %arraydecay6 = getelementptr inbounds [10 x i64], [10 x i64]* %c, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4, i64* nonnull %arrayidx.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: norecurse nounwind ssp uwtable
define void @mp_shiftleft(i64* nocapture %x, i32 %shift, i32 %nwords) local_unnamed_addr #0 {
entry:
  %cmp81 = icmp ugt i32 %shift, 64
  br i1 %cmp81, label %while.body.preheader, label %for.cond.preheader

while.body.preheader:                             ; preds = %entry
  %0 = add i32 %shift, -65
  %1 = lshr i32 %0, 6
  %2 = add nuw nsw i32 %1, 1
  %3 = and i32 %0, -64
  %4 = add i32 %shift, -64
  %5 = sub i32 %4, %3
  br label %for.cond.preheader

for.cond.preheader:                               ; preds = %while.body.preheader, %entry
  %shift.addr.0.lcssa = phi i32 [ %shift, %entry ], [ %5, %while.body.preheader ]
  %j.0.lcssa = phi i32 [ 0, %entry ], [ %2, %while.body.preheader ]
  %sub1 = sub i32 %nwords, %j.0.lcssa
  %cmp279 = icmp eq i32 %sub1, 0
  br i1 %cmp279, label %for.cond11.preheader, label %for.body.preheader

for.body.preheader:                               ; preds = %for.cond.preheader
  %wide.trip.count90 = zext i32 %sub1 to i64
  %min.iters.check = icmp ult i32 %sub1, 16
  br i1 %min.iters.check, label %for.body.preheader255, label %vector.scevcheck

for.body.preheader255:                            ; preds = %middle.block, %vector.memcheck, %vector.scevcheck, %for.body.preheader
  %indvars.iv88.ph = phi i64 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %for.body.preheader ], [ %n.vec, %middle.block ]
  %i.080.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %for.body.preheader ], [ %cast.crd, %middle.block ]
  %6 = xor i64 %indvars.iv88.ph, -1
  %7 = add nsw i64 %6, %wide.trip.count90
  %xtraiter261 = and i64 %wide.trip.count90, 3
  %lcmp.mod262 = icmp eq i64 %xtraiter261, 0
  br i1 %lcmp.mod262, label %for.body.prol.loopexit, label %for.body.prol

for.body.prol:                                    ; preds = %for.body.preheader255, %for.body.prol
  %indvars.iv88.prol = phi i64 [ %indvars.iv.next89.prol, %for.body.prol ], [ %indvars.iv88.ph, %for.body.preheader255 ]
  %i.080.prol = phi i32 [ %inc.prol, %for.body.prol ], [ %i.080.ph, %for.body.preheader255 ]
  %prol.iter263 = phi i64 [ %prol.iter263.sub, %for.body.prol ], [ %xtraiter261, %for.body.preheader255 ]
  %8 = xor i32 %i.080.prol, -1
  %sub4.prol = add i32 %8, %nwords
  %sub5.prol = sub i32 %sub4.prol, %j.0.lcssa
  %idxprom.prol = zext i32 %sub5.prol to i64
  %arrayidx.prol = getelementptr inbounds i64, i64* %x, i64 %idxprom.prol
  %9 = load i64, i64* %arrayidx.prol, align 8, !tbaa !3
  %idxprom8.prol = zext i32 %sub4.prol to i64
  %arrayidx9.prol = getelementptr inbounds i64, i64* %x, i64 %idxprom8.prol
  store i64 %9, i64* %arrayidx9.prol, align 8, !tbaa !3
  %indvars.iv.next89.prol = add nuw nsw i64 %indvars.iv88.prol, 1
  %inc.prol = add nuw i32 %i.080.prol, 1
  %prol.iter263.sub = add i64 %prol.iter263, -1
  %prol.iter263.cmp = icmp eq i64 %prol.iter263.sub, 0
  br i1 %prol.iter263.cmp, label %for.body.prol.loopexit, label %for.body.prol, !llvm.loop !30

for.body.prol.loopexit:                           ; preds = %for.body.prol, %for.body.preheader255
  %indvars.iv88.unr = phi i64 [ %indvars.iv88.ph, %for.body.preheader255 ], [ %indvars.iv.next89.prol, %for.body.prol ]
  %i.080.unr = phi i32 [ %i.080.ph, %for.body.preheader255 ], [ %inc.prol, %for.body.prol ]
  %10 = icmp ult i64 %7, 3
  br i1 %10, label %for.cond11.preheader, label %for.body

vector.scevcheck:                                 ; preds = %for.body.preheader
  %11 = add nsw i64 %wide.trip.count90, -1
  %12 = add i32 %nwords, -1
  %13 = trunc i64 %11 to i32
  %14 = icmp ult i32 %12, %13
  %15 = icmp ugt i64 %11, 4294967295
  %16 = or i1 %14, %15
  %17 = xor i32 %j.0.lcssa, -1
  %18 = add i32 %17, %nwords
  %19 = trunc i64 %11 to i32
  %20 = icmp ult i32 %18, %19
  %21 = icmp ugt i64 %11, 4294967295
  %22 = or i1 %20, %21
  %23 = or i1 %16, %22
  %24 = zext i32 %12 to i64
  %scevgep = getelementptr i64, i64* %x, i64 %24
  %scevgep96 = ptrtoint i64* %scevgep to i64
  %mul97 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 %11, i64 8)
  %mul.result98 = extractvalue { i64, i1 } %mul97, 0
  %mul.overflow99 = extractvalue { i64, i1 } %mul97, 1
  %25 = icmp ugt i64 %mul.result98, %scevgep96
  %26 = or i1 %25, %mul.overflow99
  %27 = or i1 %23, %26
  %28 = zext i32 %18 to i64
  %scevgep100 = getelementptr i64, i64* %x, i64 %28
  %scevgep100101 = ptrtoint i64* %scevgep100 to i64
  %mul102 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 %11, i64 8)
  %mul.result103 = extractvalue { i64, i1 } %mul102, 0
  %mul.overflow104 = extractvalue { i64, i1 } %mul102, 1
  %29 = icmp ugt i64 %mul.result103, %scevgep100101
  %30 = or i1 %29, %mul.overflow104
  %31 = or i1 %27, %30
  br i1 %31, label %for.body.preheader255, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %32 = add i32 %nwords, -1
  %33 = zext i32 %32 to i64
  %34 = add nuw nsw i64 %33, 1
  %35 = sub nsw i64 %34, %wide.trip.count90
  %scevgep105 = getelementptr i64, i64* %x, i64 %35
  %scevgep107 = getelementptr i64, i64* %x, i64 %34
  %36 = xor i32 %j.0.lcssa, -1
  %37 = add i32 %36, %nwords
  %38 = zext i32 %37 to i64
  %39 = add nuw nsw i64 %38, 1
  %40 = sub nsw i64 %39, %wide.trip.count90
  %scevgep109 = getelementptr i64, i64* %x, i64 %40
  %scevgep111 = getelementptr i64, i64* %x, i64 %39
  %bound0 = icmp ult i64* %scevgep105, %scevgep111
  %bound1 = icmp ult i64* %scevgep109, %scevgep107
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %for.body.preheader255, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %wide.trip.count90, 4294967280
  %cast.crd = trunc i64 %n.vec to i32
  %41 = add nsw i64 %n.vec, -16
  %42 = lshr exact i64 %41, 4
  %43 = add nuw nsw i64 %42, 1
  %xtraiter264 = and i64 %43, 3
  %44 = icmp ult i64 %41, 48
  br i1 %44, label %middle.block.unr-lcssa, label %vector.ph.new

vector.ph.new:                                    ; preds = %vector.ph
  %unroll_iter267 = sub nsw i64 %43, %xtraiter264
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph.new
  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.3, %vector.body ]
  %niter268 = phi i64 [ %unroll_iter267, %vector.ph.new ], [ %niter268.nsub.3, %vector.body ]
  %45 = trunc i64 %index to i32
  %46 = xor i32 %45, -1
  %47 = add i32 %46, %nwords
  %48 = sub i32 %47, %j.0.lcssa
  %49 = zext i32 %48 to i64
  %50 = getelementptr inbounds i64, i64* %x, i64 %49
  %51 = getelementptr inbounds i64, i64* %50, i64 -3
  %52 = bitcast i64* %51 to <4 x i64>*
  %wide.load = load <4 x i64>, <4 x i64>* %52, align 8, !tbaa !3, !alias.scope !31
  %53 = getelementptr inbounds i64, i64* %50, i64 -4
  %54 = getelementptr inbounds i64, i64* %53, i64 -3
  %55 = bitcast i64* %54 to <4 x i64>*
  %wide.load123 = load <4 x i64>, <4 x i64>* %55, align 8, !tbaa !3, !alias.scope !31
  %56 = getelementptr inbounds i64, i64* %50, i64 -8
  %57 = getelementptr inbounds i64, i64* %56, i64 -3
  %58 = bitcast i64* %57 to <4 x i64>*
  %wide.load125 = load <4 x i64>, <4 x i64>* %58, align 8, !tbaa !3, !alias.scope !31
  %59 = getelementptr inbounds i64, i64* %50, i64 -12
  %60 = getelementptr inbounds i64, i64* %59, i64 -3
  %61 = bitcast i64* %60 to <4 x i64>*
  %wide.load127 = load <4 x i64>, <4 x i64>* %61, align 8, !tbaa !3, !alias.scope !31
  %62 = zext i32 %47 to i64
  %63 = getelementptr inbounds i64, i64* %x, i64 %62
  %64 = getelementptr inbounds i64, i64* %63, i64 -3
  %65 = bitcast i64* %64 to <4 x i64>*
  store <4 x i64> %wide.load, <4 x i64>* %65, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %66 = getelementptr inbounds i64, i64* %63, i64 -4
  %67 = getelementptr inbounds i64, i64* %66, i64 -3
  %68 = bitcast i64* %67 to <4 x i64>*
  store <4 x i64> %wide.load123, <4 x i64>* %68, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %69 = getelementptr inbounds i64, i64* %63, i64 -8
  %70 = getelementptr inbounds i64, i64* %69, i64 -3
  %71 = bitcast i64* %70 to <4 x i64>*
  store <4 x i64> %wide.load125, <4 x i64>* %71, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %72 = getelementptr inbounds i64, i64* %63, i64 -12
  %73 = getelementptr inbounds i64, i64* %72, i64 -3
  %74 = bitcast i64* %73 to <4 x i64>*
  store <4 x i64> %wide.load127, <4 x i64>* %74, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %75 = trunc i64 %index to i32
  %76 = xor i32 %75, -17
  %77 = add i32 %76, %nwords
  %78 = sub i32 %77, %j.0.lcssa
  %79 = zext i32 %78 to i64
  %80 = getelementptr inbounds i64, i64* %x, i64 %79
  %81 = getelementptr inbounds i64, i64* %80, i64 -3
  %82 = bitcast i64* %81 to <4 x i64>*
  %wide.load.1 = load <4 x i64>, <4 x i64>* %82, align 8, !tbaa !3, !alias.scope !31
  %83 = getelementptr inbounds i64, i64* %80, i64 -4
  %84 = getelementptr inbounds i64, i64* %83, i64 -3
  %85 = bitcast i64* %84 to <4 x i64>*
  %wide.load123.1 = load <4 x i64>, <4 x i64>* %85, align 8, !tbaa !3, !alias.scope !31
  %86 = getelementptr inbounds i64, i64* %80, i64 -8
  %87 = getelementptr inbounds i64, i64* %86, i64 -3
  %88 = bitcast i64* %87 to <4 x i64>*
  %wide.load125.1 = load <4 x i64>, <4 x i64>* %88, align 8, !tbaa !3, !alias.scope !31
  %89 = getelementptr inbounds i64, i64* %80, i64 -12
  %90 = getelementptr inbounds i64, i64* %89, i64 -3
  %91 = bitcast i64* %90 to <4 x i64>*
  %wide.load127.1 = load <4 x i64>, <4 x i64>* %91, align 8, !tbaa !3, !alias.scope !31
  %92 = zext i32 %77 to i64
  %93 = getelementptr inbounds i64, i64* %x, i64 %92
  %94 = getelementptr inbounds i64, i64* %93, i64 -3
  %95 = bitcast i64* %94 to <4 x i64>*
  store <4 x i64> %wide.load.1, <4 x i64>* %95, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %96 = getelementptr inbounds i64, i64* %93, i64 -4
  %97 = getelementptr inbounds i64, i64* %96, i64 -3
  %98 = bitcast i64* %97 to <4 x i64>*
  store <4 x i64> %wide.load123.1, <4 x i64>* %98, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %99 = getelementptr inbounds i64, i64* %93, i64 -8
  %100 = getelementptr inbounds i64, i64* %99, i64 -3
  %101 = bitcast i64* %100 to <4 x i64>*
  store <4 x i64> %wide.load125.1, <4 x i64>* %101, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %102 = getelementptr inbounds i64, i64* %93, i64 -12
  %103 = getelementptr inbounds i64, i64* %102, i64 -3
  %104 = bitcast i64* %103 to <4 x i64>*
  store <4 x i64> %wide.load127.1, <4 x i64>* %104, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %105 = trunc i64 %index to i32
  %106 = xor i32 %105, -33
  %107 = add i32 %106, %nwords
  %108 = sub i32 %107, %j.0.lcssa
  %109 = zext i32 %108 to i64
  %110 = getelementptr inbounds i64, i64* %x, i64 %109
  %111 = getelementptr inbounds i64, i64* %110, i64 -3
  %112 = bitcast i64* %111 to <4 x i64>*
  %wide.load.2 = load <4 x i64>, <4 x i64>* %112, align 8, !tbaa !3, !alias.scope !31
  %113 = getelementptr inbounds i64, i64* %110, i64 -4
  %114 = getelementptr inbounds i64, i64* %113, i64 -3
  %115 = bitcast i64* %114 to <4 x i64>*
  %wide.load123.2 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !3, !alias.scope !31
  %116 = getelementptr inbounds i64, i64* %110, i64 -8
  %117 = getelementptr inbounds i64, i64* %116, i64 -3
  %118 = bitcast i64* %117 to <4 x i64>*
  %wide.load125.2 = load <4 x i64>, <4 x i64>* %118, align 8, !tbaa !3, !alias.scope !31
  %119 = getelementptr inbounds i64, i64* %110, i64 -12
  %120 = getelementptr inbounds i64, i64* %119, i64 -3
  %121 = bitcast i64* %120 to <4 x i64>*
  %wide.load127.2 = load <4 x i64>, <4 x i64>* %121, align 8, !tbaa !3, !alias.scope !31
  %122 = zext i32 %107 to i64
  %123 = getelementptr inbounds i64, i64* %x, i64 %122
  %124 = getelementptr inbounds i64, i64* %123, i64 -3
  %125 = bitcast i64* %124 to <4 x i64>*
  store <4 x i64> %wide.load.2, <4 x i64>* %125, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %126 = getelementptr inbounds i64, i64* %123, i64 -4
  %127 = getelementptr inbounds i64, i64* %126, i64 -3
  %128 = bitcast i64* %127 to <4 x i64>*
  store <4 x i64> %wide.load123.2, <4 x i64>* %128, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %129 = getelementptr inbounds i64, i64* %123, i64 -8
  %130 = getelementptr inbounds i64, i64* %129, i64 -3
  %131 = bitcast i64* %130 to <4 x i64>*
  store <4 x i64> %wide.load125.2, <4 x i64>* %131, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %132 = getelementptr inbounds i64, i64* %123, i64 -12
  %133 = getelementptr inbounds i64, i64* %132, i64 -3
  %134 = bitcast i64* %133 to <4 x i64>*
  store <4 x i64> %wide.load127.2, <4 x i64>* %134, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %135 = trunc i64 %index to i32
  %136 = xor i32 %135, -49
  %137 = add i32 %136, %nwords
  %138 = sub i32 %137, %j.0.lcssa
  %139 = zext i32 %138 to i64
  %140 = getelementptr inbounds i64, i64* %x, i64 %139
  %141 = getelementptr inbounds i64, i64* %140, i64 -3
  %142 = bitcast i64* %141 to <4 x i64>*
  %wide.load.3 = load <4 x i64>, <4 x i64>* %142, align 8, !tbaa !3, !alias.scope !31
  %143 = getelementptr inbounds i64, i64* %140, i64 -4
  %144 = getelementptr inbounds i64, i64* %143, i64 -3
  %145 = bitcast i64* %144 to <4 x i64>*
  %wide.load123.3 = load <4 x i64>, <4 x i64>* %145, align 8, !tbaa !3, !alias.scope !31
  %146 = getelementptr inbounds i64, i64* %140, i64 -8
  %147 = getelementptr inbounds i64, i64* %146, i64 -3
  %148 = bitcast i64* %147 to <4 x i64>*
  %wide.load125.3 = load <4 x i64>, <4 x i64>* %148, align 8, !tbaa !3, !alias.scope !31
  %149 = getelementptr inbounds i64, i64* %140, i64 -12
  %150 = getelementptr inbounds i64, i64* %149, i64 -3
  %151 = bitcast i64* %150 to <4 x i64>*
  %wide.load127.3 = load <4 x i64>, <4 x i64>* %151, align 8, !tbaa !3, !alias.scope !31
  %152 = zext i32 %137 to i64
  %153 = getelementptr inbounds i64, i64* %x, i64 %152
  %154 = getelementptr inbounds i64, i64* %153, i64 -3
  %155 = bitcast i64* %154 to <4 x i64>*
  store <4 x i64> %wide.load.3, <4 x i64>* %155, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %156 = getelementptr inbounds i64, i64* %153, i64 -4
  %157 = getelementptr inbounds i64, i64* %156, i64 -3
  %158 = bitcast i64* %157 to <4 x i64>*
  store <4 x i64> %wide.load123.3, <4 x i64>* %158, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %159 = getelementptr inbounds i64, i64* %153, i64 -8
  %160 = getelementptr inbounds i64, i64* %159, i64 -3
  %161 = bitcast i64* %160 to <4 x i64>*
  store <4 x i64> %wide.load125.3, <4 x i64>* %161, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %162 = getelementptr inbounds i64, i64* %153, i64 -12
  %163 = getelementptr inbounds i64, i64* %162, i64 -3
  %164 = bitcast i64* %163 to <4 x i64>*
  store <4 x i64> %wide.load127.3, <4 x i64>* %164, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %index.next.3 = add i64 %index, 64
  %niter268.nsub.3 = add i64 %niter268, -4
  %niter268.ncmp.3 = icmp eq i64 %niter268.nsub.3, 0
  br i1 %niter268.ncmp.3, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !36

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.3, %vector.body ]
  %lcmp.mod266 = icmp eq i64 %xtraiter264, 0
  br i1 %lcmp.mod266, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %index.epil = phi i64 [ %index.next.epil, %vector.body.epil ], [ %index.unr, %middle.block.unr-lcssa ]
  %epil.iter265 = phi i64 [ %epil.iter265.sub, %vector.body.epil ], [ %xtraiter264, %middle.block.unr-lcssa ]
  %165 = trunc i64 %index.epil to i32
  %166 = xor i32 %165, -1
  %167 = add i32 %166, %nwords
  %168 = sub i32 %167, %j.0.lcssa
  %169 = zext i32 %168 to i64
  %170 = getelementptr inbounds i64, i64* %x, i64 %169
  %171 = getelementptr inbounds i64, i64* %170, i64 -3
  %172 = bitcast i64* %171 to <4 x i64>*
  %wide.load.epil = load <4 x i64>, <4 x i64>* %172, align 8, !tbaa !3, !alias.scope !31
  %173 = getelementptr inbounds i64, i64* %170, i64 -4
  %174 = getelementptr inbounds i64, i64* %173, i64 -3
  %175 = bitcast i64* %174 to <4 x i64>*
  %wide.load123.epil = load <4 x i64>, <4 x i64>* %175, align 8, !tbaa !3, !alias.scope !31
  %176 = getelementptr inbounds i64, i64* %170, i64 -8
  %177 = getelementptr inbounds i64, i64* %176, i64 -3
  %178 = bitcast i64* %177 to <4 x i64>*
  %wide.load125.epil = load <4 x i64>, <4 x i64>* %178, align 8, !tbaa !3, !alias.scope !31
  %179 = getelementptr inbounds i64, i64* %170, i64 -12
  %180 = getelementptr inbounds i64, i64* %179, i64 -3
  %181 = bitcast i64* %180 to <4 x i64>*
  %wide.load127.epil = load <4 x i64>, <4 x i64>* %181, align 8, !tbaa !3, !alias.scope !31
  %182 = zext i32 %167 to i64
  %183 = getelementptr inbounds i64, i64* %x, i64 %182
  %184 = getelementptr inbounds i64, i64* %183, i64 -3
  %185 = bitcast i64* %184 to <4 x i64>*
  store <4 x i64> %wide.load.epil, <4 x i64>* %185, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %186 = getelementptr inbounds i64, i64* %183, i64 -4
  %187 = getelementptr inbounds i64, i64* %186, i64 -3
  %188 = bitcast i64* %187 to <4 x i64>*
  store <4 x i64> %wide.load123.epil, <4 x i64>* %188, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %189 = getelementptr inbounds i64, i64* %183, i64 -8
  %190 = getelementptr inbounds i64, i64* %189, i64 -3
  %191 = bitcast i64* %190 to <4 x i64>*
  store <4 x i64> %wide.load125.epil, <4 x i64>* %191, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %192 = getelementptr inbounds i64, i64* %183, i64 -12
  %193 = getelementptr inbounds i64, i64* %192, i64 -3
  %194 = bitcast i64* %193 to <4 x i64>*
  store <4 x i64> %wide.load127.epil, <4 x i64>* %194, align 8, !tbaa !3, !alias.scope !34, !noalias !31
  %index.next.epil = add i64 %index.epil, 16
  %epil.iter265.sub = add i64 %epil.iter265, -1
  %epil.iter265.cmp = icmp eq i64 %epil.iter265.sub, 0
  br i1 %epil.iter265.cmp, label %middle.block, label %vector.body.epil, !llvm.loop !37

middle.block:                                     ; preds = %vector.body.epil, %middle.block.unr-lcssa
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count90
  br i1 %cmp.n, label %for.cond11.preheader, label %for.body.preheader255

for.cond11.preheader:                             ; preds = %for.body.prol.loopexit, %for.body, %middle.block, %for.cond.preheader
  %cmp1277 = icmp ult i32 %sub1, %nwords
  br i1 %cmp1277, label %for.body13.preheader, label %for.end20

for.body13.preheader:                             ; preds = %for.cond11.preheader
  %195 = zext i32 %sub1 to i64
  %wide.trip.count = zext i32 %nwords to i64
  %196 = sub nsw i64 %wide.trip.count, %195
  %min.iters.check136 = icmp ult i64 %196, 16
  br i1 %min.iters.check136, label %for.body13.preheader254, label %vector.scevcheck141

for.body13.preheader254:                          ; preds = %middle.block134, %vector.scevcheck141, %for.body13.preheader
  %indvars.iv86.ph = phi i64 [ %195, %vector.scevcheck141 ], [ %195, %for.body13.preheader ], [ %ind.end148, %middle.block134 ]
  %197 = sub nsw i64 %wide.trip.count, %indvars.iv86.ph
  %198 = xor i64 %indvars.iv86.ph, -1
  %199 = add nsw i64 %198, %wide.trip.count
  %xtraiter256 = and i64 %197, 7
  %lcmp.mod257 = icmp eq i64 %xtraiter256, 0
  br i1 %lcmp.mod257, label %for.body13.prol.loopexit, label %for.body13.prol

for.body13.prol:                                  ; preds = %for.body13.preheader254, %for.body13.prol
  %indvars.iv86.prol = phi i64 [ %indvars.iv.next87.prol, %for.body13.prol ], [ %indvars.iv86.ph, %for.body13.preheader254 ]
  %prol.iter258 = phi i64 [ %prol.iter258.sub, %for.body13.prol ], [ %xtraiter256, %for.body13.preheader254 ]
  %200 = trunc i64 %indvars.iv86.prol to i32
  %201 = xor i32 %200, -1
  %sub15.prol = add i32 %201, %nwords
  %idxprom16.prol = zext i32 %sub15.prol to i64
  %arrayidx17.prol = getelementptr inbounds i64, i64* %x, i64 %idxprom16.prol
  store i64 0, i64* %arrayidx17.prol, align 8, !tbaa !3
  %indvars.iv.next87.prol = add nuw nsw i64 %indvars.iv86.prol, 1
  %prol.iter258.sub = add i64 %prol.iter258, -1
  %prol.iter258.cmp = icmp eq i64 %prol.iter258.sub, 0
  br i1 %prol.iter258.cmp, label %for.body13.prol.loopexit, label %for.body13.prol, !llvm.loop !38

for.body13.prol.loopexit:                         ; preds = %for.body13.prol, %for.body13.preheader254
  %indvars.iv86.unr = phi i64 [ %indvars.iv86.ph, %for.body13.preheader254 ], [ %indvars.iv.next87.prol, %for.body13.prol ]
  %202 = icmp ult i64 %199, 7
  br i1 %202, label %for.end20, label %for.body13

vector.scevcheck141:                              ; preds = %for.body13.preheader
  %203 = xor i64 %195, -1
  %204 = add nsw i64 %203, %wide.trip.count
  %205 = add nsw i32 %j.0.lcssa, -1
  %206 = trunc i64 %204 to i32
  %207 = icmp ult i32 %205, %206
  %208 = icmp ugt i64 %204, 4294967295
  %209 = or i1 %207, %208
  br i1 %209, label %for.body13.preheader254, label %vector.ph142

vector.ph142:                                     ; preds = %vector.scevcheck141
  %n.vec144 = and i64 %196, -16
  %ind.end148 = add nsw i64 %n.vec144, %195
  %210 = add nsw i64 %n.vec144, -16
  %211 = lshr exact i64 %210, 4
  %212 = add nuw nsw i64 %211, 1
  %xtraiter259 = and i64 %212, 3
  %213 = icmp ult i64 %210, 48
  br i1 %213, label %middle.block134.unr-lcssa, label %vector.ph142.new

vector.ph142.new:                                 ; preds = %vector.ph142
  %unroll_iter = sub nsw i64 %212, %xtraiter259
  br label %vector.body133

vector.body133:                                   ; preds = %vector.body133, %vector.ph142.new
  %index145 = phi i64 [ 0, %vector.ph142.new ], [ %index.next146.3, %vector.body133 ]
  %niter = phi i64 [ %unroll_iter, %vector.ph142.new ], [ %niter.nsub.3, %vector.body133 ]
  %214 = trunc i64 %index145 to i32
  %215 = add i32 %sub1, %214
  %216 = xor i32 %215, -1
  %217 = add i32 %216, %nwords
  %218 = zext i32 %217 to i64
  %219 = getelementptr inbounds i64, i64* %x, i64 %218
  %220 = getelementptr inbounds i64, i64* %219, i64 -3
  %221 = bitcast i64* %220 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %221, align 8, !tbaa !3
  %222 = getelementptr inbounds i64, i64* %219, i64 -4
  %223 = getelementptr inbounds i64, i64* %222, i64 -3
  %224 = bitcast i64* %223 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %224, align 8, !tbaa !3
  %225 = getelementptr inbounds i64, i64* %219, i64 -8
  %226 = getelementptr inbounds i64, i64* %225, i64 -3
  %227 = bitcast i64* %226 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %227, align 8, !tbaa !3
  %228 = getelementptr inbounds i64, i64* %219, i64 -12
  %229 = getelementptr inbounds i64, i64* %228, i64 -3
  %230 = bitcast i64* %229 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %230, align 8, !tbaa !3
  %231 = trunc i64 %index145 to i32
  %232 = or i32 %231, 16
  %233 = add i32 %sub1, %232
  %234 = xor i32 %233, -1
  %235 = add i32 %234, %nwords
  %236 = zext i32 %235 to i64
  %237 = getelementptr inbounds i64, i64* %x, i64 %236
  %238 = getelementptr inbounds i64, i64* %237, i64 -3
  %239 = bitcast i64* %238 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %239, align 8, !tbaa !3
  %240 = getelementptr inbounds i64, i64* %237, i64 -4
  %241 = getelementptr inbounds i64, i64* %240, i64 -3
  %242 = bitcast i64* %241 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %242, align 8, !tbaa !3
  %243 = getelementptr inbounds i64, i64* %237, i64 -8
  %244 = getelementptr inbounds i64, i64* %243, i64 -3
  %245 = bitcast i64* %244 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %245, align 8, !tbaa !3
  %246 = getelementptr inbounds i64, i64* %237, i64 -12
  %247 = getelementptr inbounds i64, i64* %246, i64 -3
  %248 = bitcast i64* %247 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %248, align 8, !tbaa !3
  %249 = trunc i64 %index145 to i32
  %250 = or i32 %249, 32
  %251 = add i32 %sub1, %250
  %252 = xor i32 %251, -1
  %253 = add i32 %252, %nwords
  %254 = zext i32 %253 to i64
  %255 = getelementptr inbounds i64, i64* %x, i64 %254
  %256 = getelementptr inbounds i64, i64* %255, i64 -3
  %257 = bitcast i64* %256 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %257, align 8, !tbaa !3
  %258 = getelementptr inbounds i64, i64* %255, i64 -4
  %259 = getelementptr inbounds i64, i64* %258, i64 -3
  %260 = bitcast i64* %259 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %260, align 8, !tbaa !3
  %261 = getelementptr inbounds i64, i64* %255, i64 -8
  %262 = getelementptr inbounds i64, i64* %261, i64 -3
  %263 = bitcast i64* %262 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %263, align 8, !tbaa !3
  %264 = getelementptr inbounds i64, i64* %255, i64 -12
  %265 = getelementptr inbounds i64, i64* %264, i64 -3
  %266 = bitcast i64* %265 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %266, align 8, !tbaa !3
  %267 = trunc i64 %index145 to i32
  %268 = or i32 %267, 48
  %269 = add i32 %sub1, %268
  %270 = xor i32 %269, -1
  %271 = add i32 %270, %nwords
  %272 = zext i32 %271 to i64
  %273 = getelementptr inbounds i64, i64* %x, i64 %272
  %274 = getelementptr inbounds i64, i64* %273, i64 -3
  %275 = bitcast i64* %274 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %275, align 8, !tbaa !3
  %276 = getelementptr inbounds i64, i64* %273, i64 -4
  %277 = getelementptr inbounds i64, i64* %276, i64 -3
  %278 = bitcast i64* %277 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %278, align 8, !tbaa !3
  %279 = getelementptr inbounds i64, i64* %273, i64 -8
  %280 = getelementptr inbounds i64, i64* %279, i64 -3
  %281 = bitcast i64* %280 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %281, align 8, !tbaa !3
  %282 = getelementptr inbounds i64, i64* %273, i64 -12
  %283 = getelementptr inbounds i64, i64* %282, i64 -3
  %284 = bitcast i64* %283 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %284, align 8, !tbaa !3
  %index.next146.3 = add i64 %index145, 64
  %niter.nsub.3 = add i64 %niter, -4
  %niter.ncmp.3 = icmp eq i64 %niter.nsub.3, 0
  br i1 %niter.ncmp.3, label %middle.block134.unr-lcssa, label %vector.body133, !llvm.loop !39

middle.block134.unr-lcssa:                        ; preds = %vector.body133, %vector.ph142
  %index145.unr = phi i64 [ 0, %vector.ph142 ], [ %index.next146.3, %vector.body133 ]
  %lcmp.mod260 = icmp eq i64 %xtraiter259, 0
  br i1 %lcmp.mod260, label %middle.block134, label %vector.body133.epil

vector.body133.epil:                              ; preds = %middle.block134.unr-lcssa, %vector.body133.epil
  %index145.epil = phi i64 [ %index.next146.epil, %vector.body133.epil ], [ %index145.unr, %middle.block134.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.sub, %vector.body133.epil ], [ %xtraiter259, %middle.block134.unr-lcssa ]
  %285 = trunc i64 %index145.epil to i32
  %286 = add i32 %sub1, %285
  %287 = xor i32 %286, -1
  %288 = add i32 %287, %nwords
  %289 = zext i32 %288 to i64
  %290 = getelementptr inbounds i64, i64* %x, i64 %289
  %291 = getelementptr inbounds i64, i64* %290, i64 -3
  %292 = bitcast i64* %291 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %292, align 8, !tbaa !3
  %293 = getelementptr inbounds i64, i64* %290, i64 -4
  %294 = getelementptr inbounds i64, i64* %293, i64 -3
  %295 = bitcast i64* %294 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %295, align 8, !tbaa !3
  %296 = getelementptr inbounds i64, i64* %290, i64 -8
  %297 = getelementptr inbounds i64, i64* %296, i64 -3
  %298 = bitcast i64* %297 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %298, align 8, !tbaa !3
  %299 = getelementptr inbounds i64, i64* %290, i64 -12
  %300 = getelementptr inbounds i64, i64* %299, i64 -3
  %301 = bitcast i64* %300 to <4 x i64>*
  store <4 x i64> zeroinitializer, <4 x i64>* %301, align 8, !tbaa !3
  %index.next146.epil = add i64 %index145.epil, 16
  %epil.iter.sub = add i64 %epil.iter, -1
  %epil.iter.cmp = icmp eq i64 %epil.iter.sub, 0
  br i1 %epil.iter.cmp, label %middle.block134, label %vector.body133.epil, !llvm.loop !40

middle.block134:                                  ; preds = %vector.body133.epil, %middle.block134.unr-lcssa
  %cmp.n149 = icmp eq i64 %196, %n.vec144
  br i1 %cmp.n149, label %for.end20, label %for.body13.preheader254

for.body:                                         ; preds = %for.body.prol.loopexit, %for.body
  %indvars.iv88 = phi i64 [ %indvars.iv.next89.3, %for.body ], [ %indvars.iv88.unr, %for.body.prol.loopexit ]
  %i.080 = phi i32 [ %inc.3, %for.body ], [ %i.080.unr, %for.body.prol.loopexit ]
  %302 = xor i32 %i.080, -1
  %sub4 = add i32 %302, %nwords
  %sub5 = sub i32 %sub4, %j.0.lcssa
  %idxprom = zext i32 %sub5 to i64
  %arrayidx = getelementptr inbounds i64, i64* %x, i64 %idxprom
  %303 = load i64, i64* %arrayidx, align 8, !tbaa !3
  %idxprom8 = zext i32 %sub4 to i64
  %arrayidx9 = getelementptr inbounds i64, i64* %x, i64 %idxprom8
  store i64 %303, i64* %arrayidx9, align 8, !tbaa !3
  %304 = sub i32 -2, %i.080
  %sub4.1 = add i32 %304, %nwords
  %sub5.1 = sub i32 %sub4.1, %j.0.lcssa
  %idxprom.1 = zext i32 %sub5.1 to i64
  %arrayidx.1 = getelementptr inbounds i64, i64* %x, i64 %idxprom.1
  %305 = load i64, i64* %arrayidx.1, align 8, !tbaa !3
  %idxprom8.1 = zext i32 %sub4.1 to i64
  %arrayidx9.1 = getelementptr inbounds i64, i64* %x, i64 %idxprom8.1
  store i64 %305, i64* %arrayidx9.1, align 8, !tbaa !3
  %306 = sub i32 -3, %i.080
  %sub4.2 = add i32 %306, %nwords
  %sub5.2 = sub i32 %sub4.2, %j.0.lcssa
  %idxprom.2 = zext i32 %sub5.2 to i64
  %arrayidx.2 = getelementptr inbounds i64, i64* %x, i64 %idxprom.2
  %307 = load i64, i64* %arrayidx.2, align 8, !tbaa !3
  %idxprom8.2 = zext i32 %sub4.2 to i64
  %arrayidx9.2 = getelementptr inbounds i64, i64* %x, i64 %idxprom8.2
  store i64 %307, i64* %arrayidx9.2, align 8, !tbaa !3
  %308 = sub i32 -4, %i.080
  %sub4.3 = add i32 %308, %nwords
  %sub5.3 = sub i32 %sub4.3, %j.0.lcssa
  %idxprom.3 = zext i32 %sub5.3 to i64
  %arrayidx.3 = getelementptr inbounds i64, i64* %x, i64 %idxprom.3
  %309 = load i64, i64* %arrayidx.3, align 8, !tbaa !3
  %idxprom8.3 = zext i32 %sub4.3 to i64
  %arrayidx9.3 = getelementptr inbounds i64, i64* %x, i64 %idxprom8.3
  store i64 %309, i64* %arrayidx9.3, align 8, !tbaa !3
  %indvars.iv.next89.3 = add nsw i64 %indvars.iv88, 4
  %inc.3 = add i32 %i.080, 4
  %exitcond91.3 = icmp eq i64 %indvars.iv.next89.3, %wide.trip.count90
  br i1 %exitcond91.3, label %for.cond11.preheader, label %for.body, !llvm.loop !41

for.body13:                                       ; preds = %for.body13.prol.loopexit, %for.body13
  %indvars.iv86 = phi i64 [ %indvars.iv.next87.7, %for.body13 ], [ %indvars.iv86.unr, %for.body13.prol.loopexit ]
  %310 = trunc i64 %indvars.iv86 to i32
  %311 = xor i32 %310, -1
  %sub15 = add i32 %311, %nwords
  %idxprom16 = zext i32 %sub15 to i64
  %arrayidx17 = getelementptr inbounds i64, i64* %x, i64 %idxprom16
  store i64 0, i64* %arrayidx17, align 8, !tbaa !3
  %312 = trunc i64 %indvars.iv86 to i32
  %313 = sub i32 -2, %312
  %sub15.1 = add i32 %313, %nwords
  %idxprom16.1 = zext i32 %sub15.1 to i64
  %arrayidx17.1 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.1
  store i64 0, i64* %arrayidx17.1, align 8, !tbaa !3
  %314 = trunc i64 %indvars.iv86 to i32
  %315 = sub i32 -3, %314
  %sub15.2 = add i32 %315, %nwords
  %idxprom16.2 = zext i32 %sub15.2 to i64
  %arrayidx17.2 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.2
  store i64 0, i64* %arrayidx17.2, align 8, !tbaa !3
  %316 = trunc i64 %indvars.iv86 to i32
  %317 = sub i32 -4, %316
  %sub15.3 = add i32 %317, %nwords
  %idxprom16.3 = zext i32 %sub15.3 to i64
  %arrayidx17.3 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.3
  store i64 0, i64* %arrayidx17.3, align 8, !tbaa !3
  %318 = trunc i64 %indvars.iv86 to i32
  %319 = sub i32 -5, %318
  %sub15.4 = add i32 %319, %nwords
  %idxprom16.4 = zext i32 %sub15.4 to i64
  %arrayidx17.4 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.4
  store i64 0, i64* %arrayidx17.4, align 8, !tbaa !3
  %320 = trunc i64 %indvars.iv86 to i32
  %321 = sub i32 -6, %320
  %sub15.5 = add i32 %321, %nwords
  %idxprom16.5 = zext i32 %sub15.5 to i64
  %arrayidx17.5 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.5
  store i64 0, i64* %arrayidx17.5, align 8, !tbaa !3
  %322 = trunc i64 %indvars.iv86 to i32
  %323 = sub i32 -7, %322
  %sub15.6 = add i32 %323, %nwords
  %idxprom16.6 = zext i32 %sub15.6 to i64
  %arrayidx17.6 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.6
  store i64 0, i64* %arrayidx17.6, align 8, !tbaa !3
  %324 = trunc i64 %indvars.iv86 to i32
  %325 = sub i32 -8, %324
  %sub15.7 = add i32 %325, %nwords
  %idxprom16.7 = zext i32 %sub15.7 to i64
  %arrayidx17.7 = getelementptr inbounds i64, i64* %x, i64 %idxprom16.7
  store i64 0, i64* %arrayidx17.7, align 8, !tbaa !3
  %indvars.iv.next87.7 = add nsw i64 %indvars.iv86, 8
  %exitcond.7 = icmp eq i64 %indvars.iv.next87.7, %wide.trip.count
  br i1 %exitcond.7, label %for.end20, label %for.body13, !llvm.loop !42

for.end20:                                        ; preds = %for.body13.prol.loopexit, %for.body13, %middle.block134, %for.cond11.preheader
  %cmp21 = icmp eq i32 %shift.addr.0.lcssa, 0
  br i1 %cmp21, label %if.end, label %for.cond23.preheader

for.cond23.preheader:                             ; preds = %for.end20
  %j.173 = add i32 %nwords, -1
  %cmp2474 = icmp eq i32 %j.173, 0
  %.pre = zext i32 %shift.addr.0.lcssa to i64
  br i1 %cmp2474, label %for.end36, label %for.body25.lr.ph

for.body25.lr.ph:                                 ; preds = %for.cond23.preheader
  %sub31 = sub i32 64, %shift.addr.0.lcssa
  %sh_prom32 = zext i32 %sub31 to i64
  %326 = zext i32 %j.173 to i64
  %327 = add i32 %nwords, -2
  %328 = zext i32 %327 to i64
  %329 = add nuw nsw i64 %328, 1
  %min.iters.check167 = icmp ult i64 %329, 16
  br i1 %min.iters.check167, label %for.body25.preheader, label %vector.scevcheck179

vector.scevcheck179:                              ; preds = %for.body25.lr.ph
  %330 = add i32 %nwords, -2
  %scevgep169 = getelementptr i64, i64* %x, i64 %326
  %scevgep169170 = ptrtoint i64* %scevgep169 to i64
  %331 = zext i32 %330 to i64
  %mul171 = shl nuw nsw i64 %331, 3
  %332 = icmp ugt i64 %mul171, %scevgep169170
  %333 = zext i32 %330 to i64
  %scevgep174 = getelementptr i64, i64* %x, i64 %333
  %scevgep174175 = ptrtoint i64* %scevgep174 to i64
  %334 = zext i32 %330 to i64
  %mul176 = shl nuw nsw i64 %334, 3
  %335 = icmp ugt i64 %mul176, %scevgep174175
  %336 = or i1 %332, %335
  br i1 %336, label %for.body25.preheader, label %vector.memcheck192

vector.memcheck192:                               ; preds = %vector.scevcheck179
  %337 = add i32 %nwords, -2
  %338 = zext i32 %337 to i64
  %339 = sub nsw i64 %326, %338
  %scevgep181 = getelementptr i64, i64* %x, i64 %339
  %340 = add nuw nsw i64 %326, 1
  %scevgep183 = getelementptr i64, i64* %x, i64 %340
  %341 = add nuw nsw i64 %338, 1
  %scevgep186 = getelementptr i64, i64* %x, i64 %341
  %bound0188 = icmp ult i64* %scevgep181, %scevgep186
  %bound1189 = icmp ugt i64* %scevgep183, %x
  %found.conflict190 = and i1 %bound0188, %bound1189
  br i1 %found.conflict190, label %for.body25.preheader, label %vector.ph193

vector.ph193:                                     ; preds = %vector.memcheck192
  %342 = add i32 %nwords, 15
  %343 = and i32 %342, 15
  %n.mod.vf194 = zext i32 %343 to i64
  %n.vec195 = sub nsw i64 %329, %n.mod.vf194
  %ind.end199 = sub nsw i64 %326, %n.vec195
  %cast.crd201 = trunc i64 %n.vec195 to i32
  %ind.end202 = sub i32 %nwords, %cast.crd201
  %broadcast.splatinsert226 = insertelement <4 x i64> undef, i64 %.pre, i32 0
  %broadcast.splat227 = shufflevector <4 x i64> %broadcast.splatinsert226, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert228 = insertelement <4 x i64> undef, i64 %.pre, i32 0
  %broadcast.splat229 = shufflevector <4 x i64> %broadcast.splatinsert228, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert230 = insertelement <4 x i64> undef, i64 %.pre, i32 0
  %broadcast.splat231 = shufflevector <4 x i64> %broadcast.splatinsert230, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert232 = insertelement <4 x i64> undef, i64 %.pre, i32 0
  %broadcast.splat233 = shufflevector <4 x i64> %broadcast.splatinsert232, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert242 = insertelement <4 x i64> undef, i64 %sh_prom32, i32 0
  %broadcast.splat243 = shufflevector <4 x i64> %broadcast.splatinsert242, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert244 = insertelement <4 x i64> undef, i64 %sh_prom32, i32 0
  %broadcast.splat245 = shufflevector <4 x i64> %broadcast.splatinsert244, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert246 = insertelement <4 x i64> undef, i64 %sh_prom32, i32 0
  %broadcast.splat247 = shufflevector <4 x i64> %broadcast.splatinsert246, <4 x i64> undef, <4 x i32> zeroinitializer
  %broadcast.splatinsert248 = insertelement <4 x i64> undef, i64 %sh_prom32, i32 0
  %broadcast.splat249 = shufflevector <4 x i64> %broadcast.splatinsert248, <4 x i64> undef, <4 x i32> zeroinitializer
  br label %vector.body164

vector.body164:                                   ; preds = %vector.body164, %vector.ph193
  %index196 = phi i64 [ 0, %vector.ph193 ], [ %index.next197, %vector.body164 ]
  %offset.idx204 = sub i64 %326, %index196
  %344 = trunc i64 %index196 to i32
  %offset.idx211 = sub i32 %nwords, %344
  %345 = getelementptr inbounds i64, i64* %x, i64 %offset.idx204
  %346 = getelementptr inbounds i64, i64* %345, i64 -3
  %347 = bitcast i64* %346 to <4 x i64>*
  %wide.load218 = load <4 x i64>, <4 x i64>* %347, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse219 = shufflevector <4 x i64> %wide.load218, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %348 = getelementptr inbounds i64, i64* %345, i64 -4
  %349 = getelementptr inbounds i64, i64* %348, i64 -3
  %350 = bitcast i64* %349 to <4 x i64>*
  %wide.load220 = load <4 x i64>, <4 x i64>* %350, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse221 = shufflevector <4 x i64> %wide.load220, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %351 = getelementptr inbounds i64, i64* %345, i64 -8
  %352 = getelementptr inbounds i64, i64* %351, i64 -3
  %353 = bitcast i64* %352 to <4 x i64>*
  %wide.load222 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse223 = shufflevector <4 x i64> %wide.load222, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %354 = getelementptr inbounds i64, i64* %345, i64 -12
  %355 = getelementptr inbounds i64, i64* %354, i64 -3
  %356 = bitcast i64* %355 to <4 x i64>*
  %wide.load224 = load <4 x i64>, <4 x i64>* %356, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse225 = shufflevector <4 x i64> %wide.load224, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %357 = shl <4 x i64> %reverse219, %broadcast.splat227
  %358 = shl <4 x i64> %reverse221, %broadcast.splat229
  %359 = shl <4 x i64> %reverse223, %broadcast.splat231
  %360 = shl <4 x i64> %reverse225, %broadcast.splat233
  %361 = add i32 %offset.idx211, -2
  %362 = zext i32 %361 to i64
  %363 = getelementptr inbounds i64, i64* %x, i64 %362
  %364 = getelementptr inbounds i64, i64* %363, i64 -3
  %365 = bitcast i64* %364 to <4 x i64>*
  %wide.load234 = load <4 x i64>, <4 x i64>* %365, align 8, !tbaa !3, !alias.scope !46
  %reverse235 = shufflevector <4 x i64> %wide.load234, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %366 = getelementptr inbounds i64, i64* %363, i64 -4
  %367 = getelementptr inbounds i64, i64* %366, i64 -3
  %368 = bitcast i64* %367 to <4 x i64>*
  %wide.load236 = load <4 x i64>, <4 x i64>* %368, align 8, !tbaa !3, !alias.scope !46
  %reverse237 = shufflevector <4 x i64> %wide.load236, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %369 = getelementptr inbounds i64, i64* %363, i64 -8
  %370 = getelementptr inbounds i64, i64* %369, i64 -3
  %371 = bitcast i64* %370 to <4 x i64>*
  %wide.load238 = load <4 x i64>, <4 x i64>* %371, align 8, !tbaa !3, !alias.scope !46
  %reverse239 = shufflevector <4 x i64> %wide.load238, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %372 = getelementptr inbounds i64, i64* %363, i64 -12
  %373 = getelementptr inbounds i64, i64* %372, i64 -3
  %374 = bitcast i64* %373 to <4 x i64>*
  %wide.load240 = load <4 x i64>, <4 x i64>* %374, align 8, !tbaa !3, !alias.scope !46
  %reverse241 = shufflevector <4 x i64> %wide.load240, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %375 = lshr <4 x i64> %reverse235, %broadcast.splat243
  %376 = lshr <4 x i64> %reverse237, %broadcast.splat245
  %377 = lshr <4 x i64> %reverse239, %broadcast.splat247
  %378 = lshr <4 x i64> %reverse241, %broadcast.splat249
  %379 = xor <4 x i64> %375, %357
  %380 = xor <4 x i64> %376, %358
  %381 = xor <4 x i64> %377, %359
  %382 = xor <4 x i64> %378, %360
  %reverse250 = shufflevector <4 x i64> %379, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %383 = bitcast i64* %346 to <4 x i64>*
  store <4 x i64> %reverse250, <4 x i64>* %383, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse251 = shufflevector <4 x i64> %380, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %384 = bitcast i64* %349 to <4 x i64>*
  store <4 x i64> %reverse251, <4 x i64>* %384, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse252 = shufflevector <4 x i64> %381, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %385 = bitcast i64* %352 to <4 x i64>*
  store <4 x i64> %reverse252, <4 x i64>* %385, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %reverse253 = shufflevector <4 x i64> %382, <4 x i64> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %386 = bitcast i64* %355 to <4 x i64>*
  store <4 x i64> %reverse253, <4 x i64>* %386, align 8, !tbaa !3, !alias.scope !43, !noalias !46
  %index.next197 = add i64 %index196, 16
  %387 = icmp eq i64 %index.next197, %n.vec195
  br i1 %387, label %middle.block165, label %vector.body164, !llvm.loop !48

middle.block165:                                  ; preds = %vector.body164
  %cmp.n203 = icmp eq i32 %343, 0
  br i1 %cmp.n203, label %for.end36, label %for.body25.preheader

for.body25.preheader:                             ; preds = %middle.block165, %vector.memcheck192, %vector.scevcheck179, %for.body25.lr.ph
  %indvars.iv.ph = phi i64 [ %326, %vector.memcheck192 ], [ %326, %vector.scevcheck179 ], [ %326, %for.body25.lr.ph ], [ %ind.end199, %middle.block165 ]
  %j.1.in75.ph = phi i32 [ %nwords, %vector.memcheck192 ], [ %nwords, %vector.scevcheck179 ], [ %nwords, %for.body25.lr.ph ], [ %ind.end202, %middle.block165 ]
  %388 = trunc i64 %indvars.iv.ph to i32
  %389 = add i32 %388, -1
  %xtraiter = and i32 %388, 3
  %lcmp.mod = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod, label %for.body25.prol.loopexit, label %for.body25.prol

for.body25.prol:                                  ; preds = %for.body25.preheader, %for.body25.prol
  %indvars.iv.prol = phi i64 [ %indvars.iv.next.prol, %for.body25.prol ], [ %indvars.iv.ph, %for.body25.preheader ]
  %j.1.in75.prol = phi i32 [ %392, %for.body25.prol ], [ %j.1.in75.ph, %for.body25.preheader ]
  %prol.iter = phi i32 [ %prol.iter.sub, %for.body25.prol ], [ %xtraiter, %for.body25.preheader ]
  %arrayidx27.prol = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.prol
  %390 = load i64, i64* %arrayidx27.prol, align 8, !tbaa !3
  %shl.prol = shl i64 %390, %.pre
  %sub28.prol = add i32 %j.1.in75.prol, -2
  %idxprom29.prol = zext i32 %sub28.prol to i64
  %arrayidx30.prol = getelementptr inbounds i64, i64* %x, i64 %idxprom29.prol
  %391 = load i64, i64* %arrayidx30.prol, align 8, !tbaa !3
  %shr.prol = lshr i64 %391, %sh_prom32
  %xor.prol = xor i64 %shr.prol, %shl.prol
  store i64 %xor.prol, i64* %arrayidx27.prol, align 8, !tbaa !3
  %392 = trunc i64 %indvars.iv.prol to i32
  %indvars.iv.next.prol = add nsw i64 %indvars.iv.prol, -1
  %prol.iter.sub = add i32 %prol.iter, -1
  %prol.iter.cmp = icmp eq i32 %prol.iter.sub, 0
  br i1 %prol.iter.cmp, label %for.body25.prol.loopexit.unr-lcssa, label %for.body25.prol, !llvm.loop !49

for.body25.prol.loopexit.unr-lcssa:               ; preds = %for.body25.prol
  %393 = trunc i64 %indvars.iv.prol to i32
  br label %for.body25.prol.loopexit

for.body25.prol.loopexit:                         ; preds = %for.body25.preheader, %for.body25.prol.loopexit.unr-lcssa
  %indvars.iv.unr = phi i64 [ %indvars.iv.ph, %for.body25.preheader ], [ %indvars.iv.next.prol, %for.body25.prol.loopexit.unr-lcssa ]
  %j.1.in75.unr = phi i32 [ %j.1.in75.ph, %for.body25.preheader ], [ %393, %for.body25.prol.loopexit.unr-lcssa ]
  %394 = icmp ult i32 %389, 3
  br i1 %394, label %for.end36, label %for.body25

for.body25:                                       ; preds = %for.body25.prol.loopexit, %for.body25
  %indvars.iv = phi i64 [ %indvars.iv.next.3, %for.body25 ], [ %indvars.iv.unr, %for.body25.prol.loopexit ]
  %j.1.in75 = phi i32 [ %403, %for.body25 ], [ %j.1.in75.unr, %for.body25.prol.loopexit ]
  %arrayidx27 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv
  %395 = load i64, i64* %arrayidx27, align 8, !tbaa !3
  %shl = shl i64 %395, %.pre
  %sub28 = add i32 %j.1.in75, -2
  %idxprom29 = zext i32 %sub28 to i64
  %arrayidx30 = getelementptr inbounds i64, i64* %x, i64 %idxprom29
  %396 = load i64, i64* %arrayidx30, align 8, !tbaa !3
  %shr = lshr i64 %396, %sh_prom32
  %xor = xor i64 %shr, %shl
  store i64 %xor, i64* %arrayidx27, align 8, !tbaa !3
  %indvars.iv.next = add nsw i64 %indvars.iv, -1
  %arrayidx27.1 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next
  %397 = load i64, i64* %arrayidx27.1, align 8, !tbaa !3
  %shl.1 = shl i64 %397, %.pre
  %sub28.1 = add i64 %indvars.iv, 4294967294
  %idxprom29.1 = and i64 %sub28.1, 4294967295
  %arrayidx30.1 = getelementptr inbounds i64, i64* %x, i64 %idxprom29.1
  %398 = load i64, i64* %arrayidx30.1, align 8, !tbaa !3
  %shr.1 = lshr i64 %398, %sh_prom32
  %xor.1 = xor i64 %shr.1, %shl.1
  store i64 %xor.1, i64* %arrayidx27.1, align 8, !tbaa !3
  %indvars.iv.next.1 = add nsw i64 %indvars.iv, -2
  %arrayidx27.2 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.1
  %399 = load i64, i64* %arrayidx27.2, align 8, !tbaa !3
  %shl.2 = shl i64 %399, %.pre
  %sub28.2 = add i64 %indvars.iv, 4294967293
  %idxprom29.2 = and i64 %sub28.2, 4294967295
  %arrayidx30.2 = getelementptr inbounds i64, i64* %x, i64 %idxprom29.2
  %400 = load i64, i64* %arrayidx30.2, align 8, !tbaa !3
  %shr.2 = lshr i64 %400, %sh_prom32
  %xor.2 = xor i64 %shr.2, %shl.2
  store i64 %xor.2, i64* %arrayidx27.2, align 8, !tbaa !3
  %indvars.iv.next.2 = add nsw i64 %indvars.iv, -3
  %arrayidx27.3 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.2
  %401 = load i64, i64* %arrayidx27.3, align 8, !tbaa !3
  %shl.3 = shl i64 %401, %.pre
  %sub28.3 = add i64 %indvars.iv, 4294967292
  %idxprom29.3 = and i64 %sub28.3, 4294967295
  %arrayidx30.3 = getelementptr inbounds i64, i64* %x, i64 %idxprom29.3
  %402 = load i64, i64* %arrayidx30.3, align 8, !tbaa !3
  %shr.3 = lshr i64 %402, %sh_prom32
  %xor.3 = xor i64 %shr.3, %shl.3
  store i64 %xor.3, i64* %arrayidx27.3, align 8, !tbaa !3
  %403 = trunc i64 %indvars.iv.next.2 to i32
  %cmp24.3 = icmp eq i32 %403, 1
  %indvars.iv.next.3 = add nsw i64 %indvars.iv, -4
  br i1 %cmp24.3, label %for.end36, label %for.body25, !llvm.loop !50

for.end36:                                        ; preds = %for.body25.prol.loopexit, %for.body25, %middle.block165, %for.cond23.preheader
  %404 = load i64, i64* %x, align 8, !tbaa !3
  %shl39 = shl i64 %404, %.pre
  store i64 %shl39, i64* %x, align 8, !tbaa !3
  br label %if.end

if.end:                                           ; preds = %for.end20, %for.end36
  ret void
}

; Function Attrs: norecurse nounwind ssp uwtable
define void @mp_shiftr1(i64* nocapture %x, i32 %nwords) local_unnamed_addr #0 {
entry:
  %sub = add i32 %nwords, -1
  %cmp19 = icmp eq i32 %sub, 0
  br i1 %cmp19, label %for.cond.cleanup, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %.pre = load i64, i64* %x, align 8, !tbaa !3
  %wide.trip.count = zext i32 %sub to i64
  %0 = add nsw i64 %wide.trip.count, -1
  %xtraiter = and i64 %wide.trip.count, 3
  %1 = icmp ult i64 %0, 3
  br i1 %1, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body.preheader.new

for.body.preheader.new:                           ; preds = %for.body.preheader
  %unroll_iter = sub nsw i64 %wide.trip.count, %xtraiter
  br label %for.body

for.cond.cleanup.loopexit.unr-lcssa:              ; preds = %for.body, %for.body.preheader
  %.unr = phi i64 [ %.pre, %for.body.preheader ], [ %9, %for.body ]
  %indvars.iv.unr = phi i64 [ 0, %for.body.preheader ], [ %indvars.iv.next.3, %for.body ]
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %for.cond.cleanup.loopexit, label %for.body.epil

for.body.epil:                                    ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %for.body.epil
  %2 = phi i64 [ %3, %for.body.epil ], [ %.unr, %for.cond.cleanup.loopexit.unr-lcssa ]
  %indvars.iv.epil = phi i64 [ %indvars.iv.next.epil, %for.body.epil ], [ %indvars.iv.unr, %for.cond.cleanup.loopexit.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.sub, %for.body.epil ], [ %xtraiter, %for.cond.cleanup.loopexit.unr-lcssa ]
  %arrayidx.epil = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.epil
  %shr.epil = lshr i64 %2, 1
  %indvars.iv.next.epil = add nuw nsw i64 %indvars.iv.epil, 1
  %arrayidx2.epil = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.epil
  %3 = load i64, i64* %arrayidx2.epil, align 8, !tbaa !3
  %shl.epil = shl i64 %3, 63
  %xor18.epil = or i64 %shl.epil, %shr.epil
  store i64 %xor18.epil, i64* %arrayidx.epil, align 8, !tbaa !3
  %epil.iter.sub = add i64 %epil.iter, -1
  %epil.iter.cmp = icmp eq i64 %epil.iter.sub, 0
  br i1 %epil.iter.cmp, label %for.cond.cleanup.loopexit, label %for.body.epil, !llvm.loop !51

for.cond.cleanup.loopexit:                        ; preds = %for.body.epil, %for.cond.cleanup.loopexit.unr-lcssa
  %wide.trip.count.le = zext i32 %sub to i64
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %entry, %for.cond.cleanup.loopexit
  %idxprom6.pre-phi = phi i64 [ %wide.trip.count.le, %for.cond.cleanup.loopexit ], [ 0, %entry ]
  %arrayidx7 = getelementptr inbounds i64, i64* %x, i64 %idxprom6.pre-phi
  %4 = load i64, i64* %arrayidx7, align 8, !tbaa !3
  %shr8 = lshr i64 %4, 1
  store i64 %shr8, i64* %arrayidx7, align 8, !tbaa !3
  ret void

for.body:                                         ; preds = %for.body, %for.body.preheader.new
  %5 = phi i64 [ %.pre, %for.body.preheader.new ], [ %9, %for.body ]
  %indvars.iv = phi i64 [ 0, %for.body.preheader.new ], [ %indvars.iv.next.3, %for.body ]
  %niter = phi i64 [ %unroll_iter, %for.body.preheader.new ], [ %niter.nsub.3, %for.body ]
  %arrayidx = getelementptr inbounds i64, i64* %x, i64 %indvars.iv
  %shr = lshr i64 %5, 1
  %indvars.iv.next = or i64 %indvars.iv, 1
  %arrayidx2 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next
  %6 = load i64, i64* %arrayidx2, align 8, !tbaa !3
  %shl = shl i64 %6, 63
  %xor18 = or i64 %shl, %shr
  store i64 %xor18, i64* %arrayidx, align 8, !tbaa !3
  %arrayidx.1 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next
  %shr.1 = lshr i64 %6, 1
  %indvars.iv.next.1 = or i64 %indvars.iv, 2
  %arrayidx2.1 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.1
  %7 = load i64, i64* %arrayidx2.1, align 8, !tbaa !3
  %shl.1 = shl i64 %7, 63
  %xor18.1 = or i64 %shl.1, %shr.1
  store i64 %xor18.1, i64* %arrayidx.1, align 8, !tbaa !3
  %arrayidx.2 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.1
  %shr.2 = lshr i64 %7, 1
  %indvars.iv.next.2 = or i64 %indvars.iv, 3
  %arrayidx2.2 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.2
  %8 = load i64, i64* %arrayidx2.2, align 8, !tbaa !3
  %shl.2 = shl i64 %8, 63
  %xor18.2 = or i64 %shl.2, %shr.2
  store i64 %xor18.2, i64* %arrayidx.2, align 8, !tbaa !3
  %arrayidx.3 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.2
  %shr.3 = lshr i64 %8, 1
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv, 4
  %arrayidx2.3 = getelementptr inbounds i64, i64* %x, i64 %indvars.iv.next.3
  %9 = load i64, i64* %arrayidx2.3, align 8, !tbaa !3
  %shl.3 = shl i64 %9, 63
  %xor18.3 = or i64 %shl.3, %shr.3
  store i64 %xor18.3, i64* %arrayidx.3, align 8, !tbaa !3
  %niter.nsub.3 = add i64 %niter, -4
  %niter.ncmp.3 = icmp eq i64 %niter.nsub.3, 0
  br i1 %niter.ncmp.3, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body
}

; Function Attrs: norecurse nounwind ssp uwtable
define void @mp_shiftl1(i64* nocapture %x, i32 %nwords) local_unnamed_addr #0 {
entry:
  %i.017 = add i32 %nwords, -1
  %cmp18 = icmp sgt i32 %i.017, 0
  br i1 %cmp18, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  %0 = sext i32 %i.017 to i64
  %1 = add i32 %nwords, -2
  %2 = zext i32 %1 to i64
  %3 = add nuw nsw i64 %2, 1
  %min.iters.check = icmp ult i64 %3, 16
  br i1 %min.iters.check, label %for.body.preheader75, label %vector.scevcheck

for.body.preheader75:                             ; preds = %middle.block, %vector.memcheck, %vector.scevcheck, %for.body.preheader
  %indvars.iv.ph = phi i64 [ %0, %vector.memcheck ], [ %0, %vector.scevcheck ], [ %0, %for.body.preheader ], [ %ind.end, %middle.block ]
  %i.020.ph = phi i32 [ %i.017, %vector.memcheck ], [ %i.017, %vector.scevcheck ], [ %i.017, %for.body.preheader ], [ %ind.end36, %middle.block ]
  %i.0.in19.ph = phi i32 [ %nwords, %vector.memcheck ], [ %nwords, %vector.scevcheck ], [ %nwords, %for.body.preheader ], [ %ind.end39, %middle.block ]
  br label %for.body

vector.scevcheck:                                 ; preds = %for.body.preheader
  %4 = add i32 %nwords, -2
  %scevgep = getelementptr i64, i64* %x, i64 %0
  %scevgep21 = ptrtoint i64* %scevgep to i64
  %5 = zext i32 %4 to i64
  %mul = shl nuw nsw i64 %5, 3
  %6 = icmp ugt i64 %mul, %scevgep21
  %7 = sext i32 %4 to i64
  %scevgep22 = getelementptr i64, i64* %x, i64 %7
  %scevgep2223 = ptrtoint i64* %scevgep22 to i64
  %8 = zext i32 %4 to i64
  %mul24 = shl nuw nsw i64 %8, 3
  %9 = icmp ugt i64 %mul24, %scevgep2223
  %10 = or i1 %6, %9
  br i1 %10, label %for.body.preheader75, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %11 = add i32 %nwords, -2
  %12 = zext i32 %11 to i64
  %13 = sub nsw i64 %0, %12
  %scevgep27 = getelementptr i64, i64* %x, i64 %13
  %14 = add nsw i64 %0, 1
  %scevgep29 = getelementptr i64, i64* %x, i64 %14
  %15 = sext i32 %11 to i64
  %16 = sub nsw i64 %15, %12
  %scevgep31 = getelementptr i64, i64* %x, i64 %16
  %17 = add nsw i64 %15, 1
  %scevgep33 = getelementptr i64, i64* %x, i64 %17
  %bound0 = icmp ult i64* %scevgep27, %scevgep33
  %bound1 = icmp ult i64* %scevgep31, %scevgep29
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %for.body.preheader75, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %18 = add i32 %nwords, 15
  %19 = and i32 %18, 15
  %n.mod.vf = zext i32 %19 to i64
  %n.vec = sub nsw i64 %3, %n.mod.vf
  %ind.end = sub nsw i64 %0, %n.vec
  %cast.crd = trunc i64 %n.vec to i32
  %ind.end36 = sub i32 %i.017, %cast.crd
  %cast.crd38 = trunc i64 %n.vec to i32
  %ind.end39 = sub i32 %nwords, %cast.crd38
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %offset.idx = sub i64 %0, %index
  %20 = trunc i64 %index to i32
  %offset.idx50 = sub i32 %nwords, %20
  %21 = getelementptr inbounds i64, i64* %x, i64 %offset.idx
  %22 = getelementptr inbounds i64, i64* %21, i64 -3
  %23 = bitcast i64* %22 to <4 x i64>*
  %wide.load = load <4 x i64>, <4 x i64>* %23, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %24 = getelementptr inbounds i64, i64* %21, i64 -4
  %25 = getelementptr inbounds i64, i64* %24, i64 -3
  %26 = bitcast i64* %25 to <4 x i64>*
  %wide.load57 = load <4 x i64>, <4 x i64>* %26, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %27 = getelementptr inbounds i64, i64* %21, i64 -8
  %28 = getelementptr inbounds i64, i64* %27, i64 -3
  %29 = bitcast i64* %28 to <4 x i64>*
  %wide.load59 = load <4 x i64>, <4 x i64>* %29, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %30 = getelementptr inbounds i64, i64* %21, i64 -12
  %31 = getelementptr inbounds i64, i64* %30, i64 -3
  %32 = bitcast i64* %31 to <4 x i64>*
  %wide.load61 = load <4 x i64>, <4 x i64>* %32, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %33 = shl <4 x i64> %wide.load, <i64 1, i64 1, i64 1, i64 1>
  %34 = shl <4 x i64> %wide.load57, <i64 1, i64 1, i64 1, i64 1>
  %35 = shl <4 x i64> %wide.load59, <i64 1, i64 1, i64 1, i64 1>
  %36 = shl <4 x i64> %wide.load61, <i64 1, i64 1, i64 1, i64 1>
  %37 = add i32 %offset.idx50, -2
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i64, i64* %x, i64 %38
  %40 = getelementptr inbounds i64, i64* %39, i64 -3
  %41 = bitcast i64* %40 to <4 x i64>*
  %wide.load63 = load <4 x i64>, <4 x i64>* %41, align 8, !tbaa !3, !alias.scope !55
  %42 = getelementptr inbounds i64, i64* %39, i64 -4
  %43 = getelementptr inbounds i64, i64* %42, i64 -3
  %44 = bitcast i64* %43 to <4 x i64>*
  %wide.load65 = load <4 x i64>, <4 x i64>* %44, align 8, !tbaa !3, !alias.scope !55
  %45 = getelementptr inbounds i64, i64* %39, i64 -8
  %46 = getelementptr inbounds i64, i64* %45, i64 -3
  %47 = bitcast i64* %46 to <4 x i64>*
  %wide.load67 = load <4 x i64>, <4 x i64>* %47, align 8, !tbaa !3, !alias.scope !55
  %48 = getelementptr inbounds i64, i64* %39, i64 -12
  %49 = getelementptr inbounds i64, i64* %48, i64 -3
  %50 = bitcast i64* %49 to <4 x i64>*
  %wide.load69 = load <4 x i64>, <4 x i64>* %50, align 8, !tbaa !3, !alias.scope !55
  %51 = lshr <4 x i64> %wide.load63, <i64 63, i64 63, i64 63, i64 63>
  %52 = lshr <4 x i64> %wide.load65, <i64 63, i64 63, i64 63, i64 63>
  %53 = lshr <4 x i64> %wide.load67, <i64 63, i64 63, i64 63, i64 63>
  %54 = lshr <4 x i64> %wide.load69, <i64 63, i64 63, i64 63, i64 63>
  %55 = or <4 x i64> %51, %33
  %56 = or <4 x i64> %52, %34
  %57 = or <4 x i64> %53, %35
  %58 = or <4 x i64> %54, %36
  %59 = bitcast i64* %22 to <4 x i64>*
  store <4 x i64> %55, <4 x i64>* %59, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %60 = bitcast i64* %25 to <4 x i64>*
  store <4 x i64> %56, <4 x i64>* %60, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %61 = bitcast i64* %28 to <4 x i64>*
  store <4 x i64> %57, <4 x i64>* %61, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %62 = bitcast i64* %31 to <4 x i64>*
  store <4 x i64> %58, <4 x i64>* %62, align 8, !tbaa !3, !alias.scope !52, !noalias !55
  %index.next = add i64 %index, 16
  %63 = icmp eq i64 %index.next, %n.vec
  br i1 %63, label %middle.block, label %vector.body, !llvm.loop !57

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %19, 0
  br i1 %cmp.n, label %for.cond.cleanup, label %for.body.preheader75

for.cond.cleanup:                                 ; preds = %for.body, %middle.block, %entry
  %64 = load i64, i64* %x, align 8, !tbaa !3
  %shl7 = shl i64 %64, 1
  store i64 %shl7, i64* %x, align 8, !tbaa !3
  ret void

for.body:                                         ; preds = %for.body.preheader75, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ %indvars.iv.ph, %for.body.preheader75 ]
  %i.020 = phi i32 [ %i.0, %for.body ], [ %i.020.ph, %for.body.preheader75 ]
  %i.0.in19 = phi i32 [ %67, %for.body ], [ %i.0.in19.ph, %for.body.preheader75 ]
  %arrayidx = getelementptr inbounds i64, i64* %x, i64 %indvars.iv
  %65 = load i64, i64* %arrayidx, align 8, !tbaa !3
  %shl = shl i64 %65, 1
  %sub1 = add i32 %i.0.in19, -2
  %idxprom2 = sext i32 %sub1 to i64
  %arrayidx3 = getelementptr inbounds i64, i64* %x, i64 %idxprom2
  %66 = load i64, i64* %arrayidx3, align 8, !tbaa !3
  %shr = lshr i64 %66, 63
  %xor16 = or i64 %shr, %shl
  store i64 %xor16, i64* %arrayidx, align 8, !tbaa !3
  %i.0 = add i32 %i.020, -1
  %cmp = icmp sgt i32 %i.0, 0
  %indvars.iv.next = add nsw i64 %indvars.iv, -1
  %67 = trunc i64 %indvars.iv to i32
  br i1 %cmp, label %for.body, label %for.cond.cleanup, !llvm.loop !58
}

; Function Attrs: nounwind ssp uwtable
define zeroext i8 @is_sqr_fp2([10 x i64]* %a, i64* %s) local_unnamed_addr #4 {
entry:
  %temp.i = alloca [20 x i64], align 16
  %a0 = alloca [10 x i64], align 16
  %a1 = alloca [10 x i64], align 16
  %z = alloca [10 x i64], align 16
  %temp = alloca [10 x i64], align 16
  %0 = bitcast [10 x i64]* %a0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %a1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %2 = bitcast [10 x i64]* %z to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %3 = bitcast [10 x i64]* %temp to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  %arraydecay = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 0, i64 0
  %arraydecay1 = getelementptr inbounds [10 x i64], [10 x i64]* %a0, i64 0, i64 0
  %4 = bitcast [20 x i64]* %temp.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  %arraydecay.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i, i64 0, i64 0
  call void @mp_mul(i64* %arraydecay, i64* %arraydecay, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  %arraydecay3 = getelementptr inbounds [10 x i64], [10 x i64]* %a, i64 1, i64 0
  %arraydecay4 = getelementptr inbounds [10 x i64], [10 x i64]* %a1, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3, i64* nonnull %arraydecay3, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay4) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  %arraydecay7 = getelementptr inbounds [10 x i64], [10 x i64]* %z, i64 0, i64 0
  call void @fpadd610(i64* nonnull %arraydecay1, i64* nonnull %arraydecay4, i64* nonnull %arraydecay7) #10
  %5 = bitcast [10 x i64]* %z to <4 x i64>*
  %6 = load <4 x i64>, <4 x i64>* %5, align 16, !tbaa !3
  %7 = bitcast i64* %s to <4 x i64>*
  store <4 x i64> %6, <4 x i64>* %7, align 8, !tbaa !3
  %arrayidx.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %z, i64 0, i64 4
  %arrayidx2.4.i = getelementptr inbounds i64, i64* %s, i64 4
  %8 = bitcast i64* %arrayidx.4.i to <4 x i64>*
  %9 = load <4 x i64>, <4 x i64>* %8, align 16, !tbaa !3
  %10 = bitcast i64* %arrayidx2.4.i to <4 x i64>*
  store <4 x i64> %9, <4 x i64>* %10, align 8, !tbaa !3
  %arrayidx.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %z, i64 0, i64 8
  %11 = load i64, i64* %arrayidx.8.i, align 16, !tbaa !3
  %arrayidx2.8.i = getelementptr inbounds i64, i64* %s, i64 8
  store i64 %11, i64* %arrayidx2.8.i, align 8, !tbaa !3
  %arrayidx.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %z, i64 0, i64 9
  %12 = load i64, i64* %arrayidx.9.i, align 8, !tbaa !3
  %arrayidx2.9.i = getelementptr inbounds i64, i64* %s, i64 9
  store i64 %12, i64* %arrayidx2.9.i, align 8, !tbaa !3
  br label %for.body

for.cond9.preheader:                              ; preds = %for.body
  %arraydecay12 = getelementptr inbounds [10 x i64], [10 x i64]* %temp, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %s, i64* %s, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay12) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  br label %for.body11

for.body:                                         ; preds = %for.body, %entry
  %i.046 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %s, i64* %s, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %s) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  %inc = add nuw nsw i32 %i.046, 1
  %exitcond47 = icmp eq i32 %inc, 303
  br i1 %exitcond47, label %for.cond9.preheader, label %for.body

for.body11:                                       ; preds = %for.body11, %for.cond9.preheader
  %i.145 = phi i32 [ 0, %for.cond9.preheader ], [ %inc15, %for.body11 ]
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %s, i64* nonnull %arraydecay12, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* %s) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  %inc15 = add nuw nsw i32 %i.145, 1
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* %s, i64* %s, i64* nonnull %arraydecay.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i, i64* nonnull %arraydecay12) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  %exitcond = icmp eq i32 %inc15, 192
  br i1 %exitcond, label %for.end16, label %for.body11

for.end16:                                        ; preds = %for.body11
  call void @fpcorrection610(i64* nonnull %arraydecay12) #10
  call void @fpcorrection610(i64* nonnull %arraydecay7) #10
  %call = call i32 @memcmp(i8* nonnull %3, i8* nonnull %2, i64 77)
  %cmp22 = icmp eq i32 %call, 0
  %. = zext i1 %cmp22 to i8
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret i8 %.
}

; Function Attrs: nounwind readonly
declare i32 @memcmp(i8* nocapture, i8* nocapture, i64) local_unnamed_addr #7

; Function Attrs: nounwind ssp uwtable
define void @xDBL(%struct.point_proj* %P, %struct.point_proj* %Q, [10 x i64]* %A24plus, [10 x i64]* %C24) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i46 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i46) #10
  %arraydecay10.i49 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i49) #10
  %2 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %3 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  %4 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  %5 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %6 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i = add i64 %6, %5
  store i64 %add3.i.i, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %5
  %xor1.i24.i.i = xor i64 %6, %5
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %7 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %7
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %8 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %8
  %arrayidx5.i.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %9 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %9, %7
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %8
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %10 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %10
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %11 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %11
  %arrayidx5.i.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %12 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %12, %10
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %11
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %13 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %13
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %14 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %14
  %arrayidx5.i.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %15 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %15, %13
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %14
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %16 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %16
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %17 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %17
  %arrayidx5.i.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %18 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %18, %16
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %17
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %19 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %19
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %20 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %20
  %arrayidx5.i.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %21 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %21, %19
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %20
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %22 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %22
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %23 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %23
  %arrayidx5.i.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %24 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %24, %22
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %23
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %25 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %25
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %26 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %26
  %arrayidx5.i.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %27 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %27, %25
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %26
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %28 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %28
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %29 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %29
  %arrayidx5.i.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %30 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %30, %28
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %29
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %31 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %32 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %32, %31
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %arraydecay8.i52 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i52) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  %33 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i77 = shl i64 %33, 1
  store i64 %add3.i.i77, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i82 = lshr i64 %33, 63
  %34 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i84 = add i64 %34, %or29.i.i82
  %add3.i.1.i86 = add i64 %add.i.1.i84, %34
  %arrayidx5.i.1.i87 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i86, i64* %arrayidx5.i.1.i87, align 8, !tbaa !3
  %35 = xor i64 %add.i.1.i84, -9223372036854775808
  %xor2.i.i.1.i88 = and i64 %35, %34
  %xor.i23.i.1.i89 = xor i64 %add3.i.1.i86, %add.i.1.i84
  %xor1.i24.i.1.i90 = xor i64 %add.i.1.i84, %34
  %or.i25.i.1.i91 = or i64 %xor.i23.i.1.i89, %xor1.i24.i.1.i90
  %xor2.i26.i.1.i92 = xor i64 %or.i25.i.1.i91, %add3.i.1.i86
  %shr.i30.i.1.i93 = or i64 %xor2.i26.i.1.i92, %xor2.i.i.1.i88
  %or29.i.1.i94 = lshr i64 %shr.i30.i.1.i93, 63
  %36 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i96 = add i64 %or29.i.1.i94, %36
  %add3.i.2.i98 = add i64 %add.i.2.i96, %36
  %arrayidx5.i.2.i99 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i98, i64* %arrayidx5.i.2.i99, align 16, !tbaa !3
  %37 = xor i64 %add.i.2.i96, -9223372036854775808
  %xor2.i.i.2.i100 = and i64 %37, %36
  %xor.i23.i.2.i101 = xor i64 %add3.i.2.i98, %add.i.2.i96
  %xor1.i24.i.2.i102 = xor i64 %add.i.2.i96, %36
  %or.i25.i.2.i103 = or i64 %xor.i23.i.2.i101, %xor1.i24.i.2.i102
  %xor2.i26.i.2.i104 = xor i64 %or.i25.i.2.i103, %add3.i.2.i98
  %shr.i30.i.2.i105 = or i64 %xor2.i26.i.2.i104, %xor2.i.i.2.i100
  %or29.i.2.i106 = lshr i64 %shr.i30.i.2.i105, 63
  %38 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i108 = add i64 %or29.i.2.i106, %38
  %add3.i.3.i110 = add i64 %add.i.3.i108, %38
  %arrayidx5.i.3.i111 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i110, i64* %arrayidx5.i.3.i111, align 8, !tbaa !3
  %39 = xor i64 %add.i.3.i108, -9223372036854775808
  %xor2.i.i.3.i112 = and i64 %39, %38
  %xor.i23.i.3.i113 = xor i64 %add3.i.3.i110, %add.i.3.i108
  %xor1.i24.i.3.i114 = xor i64 %add.i.3.i108, %38
  %or.i25.i.3.i115 = or i64 %xor.i23.i.3.i113, %xor1.i24.i.3.i114
  %xor2.i26.i.3.i116 = xor i64 %or.i25.i.3.i115, %add3.i.3.i110
  %shr.i30.i.3.i117 = or i64 %xor2.i26.i.3.i116, %xor2.i.i.3.i112
  %or29.i.3.i118 = lshr i64 %shr.i30.i.3.i117, 63
  %40 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i120 = add i64 %or29.i.3.i118, %40
  %add3.i.4.i122 = add i64 %add.i.4.i120, %40
  %arrayidx5.i.4.i123 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i122, i64* %arrayidx5.i.4.i123, align 16, !tbaa !3
  %41 = xor i64 %add.i.4.i120, -9223372036854775808
  %xor2.i.i.4.i124 = and i64 %41, %40
  %xor.i23.i.4.i125 = xor i64 %add3.i.4.i122, %add.i.4.i120
  %xor1.i24.i.4.i126 = xor i64 %add.i.4.i120, %40
  %or.i25.i.4.i127 = or i64 %xor.i23.i.4.i125, %xor1.i24.i.4.i126
  %xor2.i26.i.4.i128 = xor i64 %or.i25.i.4.i127, %add3.i.4.i122
  %shr.i30.i.4.i129 = or i64 %xor2.i26.i.4.i128, %xor2.i.i.4.i124
  %or29.i.4.i130 = lshr i64 %shr.i30.i.4.i129, 63
  %42 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i132 = add i64 %or29.i.4.i130, %42
  %add3.i.5.i134 = add i64 %add.i.5.i132, %42
  %arrayidx5.i.5.i135 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i134, i64* %arrayidx5.i.5.i135, align 8, !tbaa !3
  %43 = xor i64 %add.i.5.i132, -9223372036854775808
  %xor2.i.i.5.i136 = and i64 %43, %42
  %xor.i23.i.5.i137 = xor i64 %add3.i.5.i134, %add.i.5.i132
  %xor1.i24.i.5.i138 = xor i64 %add.i.5.i132, %42
  %or.i25.i.5.i139 = or i64 %xor.i23.i.5.i137, %xor1.i24.i.5.i138
  %xor2.i26.i.5.i140 = xor i64 %or.i25.i.5.i139, %add3.i.5.i134
  %shr.i30.i.5.i141 = or i64 %xor2.i26.i.5.i140, %xor2.i.i.5.i136
  %or29.i.5.i142 = lshr i64 %shr.i30.i.5.i141, 63
  %44 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i144 = add i64 %or29.i.5.i142, %44
  %add3.i.6.i146 = add i64 %add.i.6.i144, %44
  %arrayidx5.i.6.i147 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i146, i64* %arrayidx5.i.6.i147, align 16, !tbaa !3
  %45 = xor i64 %add.i.6.i144, -9223372036854775808
  %xor2.i.i.6.i148 = and i64 %45, %44
  %xor.i23.i.6.i149 = xor i64 %add3.i.6.i146, %add.i.6.i144
  %xor1.i24.i.6.i150 = xor i64 %add.i.6.i144, %44
  %or.i25.i.6.i151 = or i64 %xor.i23.i.6.i149, %xor1.i24.i.6.i150
  %xor2.i26.i.6.i152 = xor i64 %or.i25.i.6.i151, %add3.i.6.i146
  %shr.i30.i.6.i153 = or i64 %xor2.i26.i.6.i152, %xor2.i.i.6.i148
  %or29.i.6.i154 = lshr i64 %shr.i30.i.6.i153, 63
  %46 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i156 = add i64 %or29.i.6.i154, %46
  %add3.i.7.i158 = add i64 %add.i.7.i156, %46
  %arrayidx5.i.7.i159 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i158, i64* %arrayidx5.i.7.i159, align 8, !tbaa !3
  %47 = xor i64 %add.i.7.i156, -9223372036854775808
  %xor2.i.i.7.i160 = and i64 %47, %46
  %xor.i23.i.7.i161 = xor i64 %add3.i.7.i158, %add.i.7.i156
  %xor1.i24.i.7.i162 = xor i64 %add.i.7.i156, %46
  %or.i25.i.7.i163 = or i64 %xor.i23.i.7.i161, %xor1.i24.i.7.i162
  %xor2.i26.i.7.i164 = xor i64 %or.i25.i.7.i163, %add3.i.7.i158
  %shr.i30.i.7.i165 = or i64 %xor2.i26.i.7.i164, %xor2.i.i.7.i160
  %or29.i.7.i166 = lshr i64 %shr.i30.i.7.i165, 63
  %48 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i168 = add i64 %or29.i.7.i166, %48
  %add3.i.8.i170 = add i64 %add.i.8.i168, %48
  %arrayidx5.i.8.i171 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i170, i64* %arrayidx5.i.8.i171, align 16, !tbaa !3
  %49 = xor i64 %add.i.8.i168, -9223372036854775808
  %xor2.i.i.8.i172 = and i64 %49, %48
  %xor.i23.i.8.i173 = xor i64 %add3.i.8.i170, %add.i.8.i168
  %xor1.i24.i.8.i174 = xor i64 %add.i.8.i168, %48
  %or.i25.i.8.i175 = or i64 %xor.i23.i.8.i173, %xor1.i24.i.8.i174
  %xor2.i26.i.8.i176 = xor i64 %or.i25.i.8.i175, %add3.i.8.i170
  %shr.i30.i.8.i177 = or i64 %xor2.i26.i.8.i176, %xor2.i.i.8.i172
  %or29.i.8.i178 = lshr i64 %shr.i30.i.8.i177, 63
  %50 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor = shl i64 %50, 1
  %add3.i.9.i182 = or i64 %or29.i.8.i178, %factor
  %arrayidx5.i.9.i183 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i182, i64* %arrayidx5.i.9.i183, align 8, !tbaa !3
  %51 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i52, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %52 = load i64, i64* %arraydecay4.i46, align 16, !tbaa !3
  %53 = load i64, i64* %arraydecay10.i49, align 16, !tbaa !3
  %add3.i.i184 = add i64 %53, %52
  store i64 %add3.i.i184, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i185 = xor i64 %add3.i.i184, %52
  %xor1.i24.i.i186 = xor i64 %53, %52
  %or.i25.i.i187 = or i64 %xor.i23.i.i185, %xor1.i24.i.i186
  %xor2.i26.i.i188 = xor i64 %or.i25.i.i187, %add3.i.i184
  %or29.i.i189 = lshr i64 %xor2.i26.i.i188, 63
  %arrayidx.i.1.i190 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %54 = load i64, i64* %arrayidx.i.1.i190, align 8, !tbaa !3
  %add.i.1.i191 = add i64 %or29.i.i189, %54
  %arrayidx2.i.1.i192 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %55 = load i64, i64* %arrayidx2.i.1.i192, align 8, !tbaa !3
  %add3.i.1.i193 = add i64 %add.i.1.i191, %55
  store i64 %add3.i.1.i193, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %56 = xor i64 %add.i.1.i191, -9223372036854775808
  %xor2.i.i.1.i195 = and i64 %56, %54
  %xor.i23.i.1.i196 = xor i64 %add3.i.1.i193, %add.i.1.i191
  %xor1.i24.i.1.i197 = xor i64 %add.i.1.i191, %55
  %or.i25.i.1.i198 = or i64 %xor.i23.i.1.i196, %xor1.i24.i.1.i197
  %xor2.i26.i.1.i199 = xor i64 %or.i25.i.1.i198, %add3.i.1.i193
  %shr.i30.i.1.i200 = or i64 %xor2.i26.i.1.i199, %xor2.i.i.1.i195
  %or29.i.1.i201 = lshr i64 %shr.i30.i.1.i200, 63
  %arrayidx.i.2.i202 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %57 = load i64, i64* %arrayidx.i.2.i202, align 16, !tbaa !3
  %add.i.2.i203 = add i64 %or29.i.1.i201, %57
  %arrayidx2.i.2.i204 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %58 = load i64, i64* %arrayidx2.i.2.i204, align 16, !tbaa !3
  %add3.i.2.i205 = add i64 %add.i.2.i203, %58
  store i64 %add3.i.2.i205, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %59 = xor i64 %add.i.2.i203, -9223372036854775808
  %xor2.i.i.2.i207 = and i64 %59, %57
  %xor.i23.i.2.i208 = xor i64 %add3.i.2.i205, %add.i.2.i203
  %xor1.i24.i.2.i209 = xor i64 %add.i.2.i203, %58
  %or.i25.i.2.i210 = or i64 %xor.i23.i.2.i208, %xor1.i24.i.2.i209
  %xor2.i26.i.2.i211 = xor i64 %or.i25.i.2.i210, %add3.i.2.i205
  %shr.i30.i.2.i212 = or i64 %xor2.i26.i.2.i211, %xor2.i.i.2.i207
  %or29.i.2.i213 = lshr i64 %shr.i30.i.2.i212, 63
  %arrayidx.i.3.i214 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %60 = load i64, i64* %arrayidx.i.3.i214, align 8, !tbaa !3
  %add.i.3.i215 = add i64 %or29.i.2.i213, %60
  %arrayidx2.i.3.i216 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %61 = load i64, i64* %arrayidx2.i.3.i216, align 8, !tbaa !3
  %add3.i.3.i217 = add i64 %add.i.3.i215, %61
  store i64 %add3.i.3.i217, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %62 = xor i64 %add.i.3.i215, -9223372036854775808
  %xor2.i.i.3.i219 = and i64 %62, %60
  %xor.i23.i.3.i220 = xor i64 %add3.i.3.i217, %add.i.3.i215
  %xor1.i24.i.3.i221 = xor i64 %add.i.3.i215, %61
  %or.i25.i.3.i222 = or i64 %xor.i23.i.3.i220, %xor1.i24.i.3.i221
  %xor2.i26.i.3.i223 = xor i64 %or.i25.i.3.i222, %add3.i.3.i217
  %shr.i30.i.3.i224 = or i64 %xor2.i26.i.3.i223, %xor2.i.i.3.i219
  %or29.i.3.i225 = lshr i64 %shr.i30.i.3.i224, 63
  %arrayidx.i.4.i226 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %63 = load i64, i64* %arrayidx.i.4.i226, align 16, !tbaa !3
  %add.i.4.i227 = add i64 %or29.i.3.i225, %63
  %arrayidx2.i.4.i228 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %64 = load i64, i64* %arrayidx2.i.4.i228, align 16, !tbaa !3
  %add3.i.4.i229 = add i64 %add.i.4.i227, %64
  store i64 %add3.i.4.i229, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %65 = xor i64 %add.i.4.i227, -9223372036854775808
  %xor2.i.i.4.i231 = and i64 %65, %63
  %xor.i23.i.4.i232 = xor i64 %add3.i.4.i229, %add.i.4.i227
  %xor1.i24.i.4.i233 = xor i64 %add.i.4.i227, %64
  %or.i25.i.4.i234 = or i64 %xor.i23.i.4.i232, %xor1.i24.i.4.i233
  %xor2.i26.i.4.i235 = xor i64 %or.i25.i.4.i234, %add3.i.4.i229
  %shr.i30.i.4.i236 = or i64 %xor2.i26.i.4.i235, %xor2.i.i.4.i231
  %or29.i.4.i237 = lshr i64 %shr.i30.i.4.i236, 63
  %arrayidx.i.5.i238 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %66 = load i64, i64* %arrayidx.i.5.i238, align 8, !tbaa !3
  %add.i.5.i239 = add i64 %or29.i.4.i237, %66
  %arrayidx2.i.5.i240 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %67 = load i64, i64* %arrayidx2.i.5.i240, align 8, !tbaa !3
  %add3.i.5.i241 = add i64 %add.i.5.i239, %67
  store i64 %add3.i.5.i241, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %68 = xor i64 %add.i.5.i239, -9223372036854775808
  %xor2.i.i.5.i243 = and i64 %68, %66
  %xor.i23.i.5.i244 = xor i64 %add3.i.5.i241, %add.i.5.i239
  %xor1.i24.i.5.i245 = xor i64 %add.i.5.i239, %67
  %or.i25.i.5.i246 = or i64 %xor.i23.i.5.i244, %xor1.i24.i.5.i245
  %xor2.i26.i.5.i247 = xor i64 %or.i25.i.5.i246, %add3.i.5.i241
  %shr.i30.i.5.i248 = or i64 %xor2.i26.i.5.i247, %xor2.i.i.5.i243
  %or29.i.5.i249 = lshr i64 %shr.i30.i.5.i248, 63
  %arrayidx.i.6.i250 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %69 = load i64, i64* %arrayidx.i.6.i250, align 16, !tbaa !3
  %add.i.6.i251 = add i64 %or29.i.5.i249, %69
  %arrayidx2.i.6.i252 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %70 = load i64, i64* %arrayidx2.i.6.i252, align 16, !tbaa !3
  %add3.i.6.i253 = add i64 %add.i.6.i251, %70
  store i64 %add3.i.6.i253, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %71 = xor i64 %add.i.6.i251, -9223372036854775808
  %xor2.i.i.6.i255 = and i64 %71, %69
  %xor.i23.i.6.i256 = xor i64 %add3.i.6.i253, %add.i.6.i251
  %xor1.i24.i.6.i257 = xor i64 %add.i.6.i251, %70
  %or.i25.i.6.i258 = or i64 %xor.i23.i.6.i256, %xor1.i24.i.6.i257
  %xor2.i26.i.6.i259 = xor i64 %or.i25.i.6.i258, %add3.i.6.i253
  %shr.i30.i.6.i260 = or i64 %xor2.i26.i.6.i259, %xor2.i.i.6.i255
  %or29.i.6.i261 = lshr i64 %shr.i30.i.6.i260, 63
  %arrayidx.i.7.i262 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %72 = load i64, i64* %arrayidx.i.7.i262, align 8, !tbaa !3
  %add.i.7.i263 = add i64 %or29.i.6.i261, %72
  %arrayidx2.i.7.i264 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %73 = load i64, i64* %arrayidx2.i.7.i264, align 8, !tbaa !3
  %add3.i.7.i265 = add i64 %add.i.7.i263, %73
  store i64 %add3.i.7.i265, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %74 = xor i64 %add.i.7.i263, -9223372036854775808
  %xor2.i.i.7.i267 = and i64 %74, %72
  %xor.i23.i.7.i268 = xor i64 %add3.i.7.i265, %add.i.7.i263
  %xor1.i24.i.7.i269 = xor i64 %add.i.7.i263, %73
  %or.i25.i.7.i270 = or i64 %xor.i23.i.7.i268, %xor1.i24.i.7.i269
  %xor2.i26.i.7.i271 = xor i64 %or.i25.i.7.i270, %add3.i.7.i265
  %shr.i30.i.7.i272 = or i64 %xor2.i26.i.7.i271, %xor2.i.i.7.i267
  %or29.i.7.i273 = lshr i64 %shr.i30.i.7.i272, 63
  %arrayidx.i.8.i274 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %75 = load i64, i64* %arrayidx.i.8.i274, align 16, !tbaa !3
  %add.i.8.i275 = add i64 %or29.i.7.i273, %75
  %arrayidx2.i.8.i276 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %76 = load i64, i64* %arrayidx2.i.8.i276, align 16, !tbaa !3
  %add3.i.8.i277 = add i64 %add.i.8.i275, %76
  store i64 %add3.i.8.i277, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %77 = xor i64 %add.i.8.i275, -9223372036854775808
  %xor2.i.i.8.i279 = and i64 %77, %75
  %xor.i23.i.8.i280 = xor i64 %add3.i.8.i277, %add.i.8.i275
  %xor1.i24.i.8.i281 = xor i64 %add.i.8.i275, %76
  %or.i25.i.8.i282 = or i64 %xor.i23.i.8.i280, %xor1.i24.i.8.i281
  %xor2.i26.i.8.i283 = xor i64 %or.i25.i.8.i282, %add3.i.8.i277
  %shr.i30.i.8.i284 = or i64 %xor2.i26.i.8.i283, %xor2.i.i.8.i279
  %or29.i.8.i285 = lshr i64 %shr.i30.i.8.i284, 63
  %arrayidx.i.9.i286 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %78 = load i64, i64* %arrayidx.i.9.i286, align 8, !tbaa !3
  %arrayidx2.i.9.i288 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %79 = load i64, i64* %arrayidx2.i.9.i288, align 8, !tbaa !3
  %add.i.9.i287 = add i64 %79, %78
  %add3.i.9.i289 = add i64 %add.i.9.i287, %or29.i.8.i285
  store i64 %add3.i.9.i289, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i46, i64* nonnull %arraydecay10.i49, i64* nonnull %arraydecay8.i52) #10
  %80 = load i64, i64* %arraydecay4.i46, align 16, !tbaa !3
  %add3.i.i291 = shl i64 %80, 1
  store i64 %add3.i.i291, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i296 = lshr i64 %80, 63
  %81 = load i64, i64* %arrayidx.i.1.i190, align 8, !tbaa !3
  %add.i.1.i298 = add i64 %81, %or29.i.i296
  %add3.i.1.i300 = add i64 %add.i.1.i298, %81
  store i64 %add3.i.1.i300, i64* %arrayidx5.i.1.i87, align 8, !tbaa !3
  %82 = xor i64 %add.i.1.i298, -9223372036854775808
  %xor2.i.i.1.i302 = and i64 %82, %81
  %xor.i23.i.1.i303 = xor i64 %add3.i.1.i300, %add.i.1.i298
  %xor1.i24.i.1.i304 = xor i64 %add.i.1.i298, %81
  %or.i25.i.1.i305 = or i64 %xor.i23.i.1.i303, %xor1.i24.i.1.i304
  %xor2.i26.i.1.i306 = xor i64 %or.i25.i.1.i305, %add3.i.1.i300
  %shr.i30.i.1.i307 = or i64 %xor2.i26.i.1.i306, %xor2.i.i.1.i302
  %or29.i.1.i308 = lshr i64 %shr.i30.i.1.i307, 63
  %83 = load i64, i64* %arrayidx.i.2.i202, align 16, !tbaa !3
  %add.i.2.i310 = add i64 %or29.i.1.i308, %83
  %add3.i.2.i312 = add i64 %add.i.2.i310, %83
  store i64 %add3.i.2.i312, i64* %arrayidx5.i.2.i99, align 16, !tbaa !3
  %84 = xor i64 %add.i.2.i310, -9223372036854775808
  %xor2.i.i.2.i314 = and i64 %84, %83
  %xor.i23.i.2.i315 = xor i64 %add3.i.2.i312, %add.i.2.i310
  %xor1.i24.i.2.i316 = xor i64 %add.i.2.i310, %83
  %or.i25.i.2.i317 = or i64 %xor.i23.i.2.i315, %xor1.i24.i.2.i316
  %xor2.i26.i.2.i318 = xor i64 %or.i25.i.2.i317, %add3.i.2.i312
  %shr.i30.i.2.i319 = or i64 %xor2.i26.i.2.i318, %xor2.i.i.2.i314
  %or29.i.2.i320 = lshr i64 %shr.i30.i.2.i319, 63
  %85 = load i64, i64* %arrayidx.i.3.i214, align 8, !tbaa !3
  %add.i.3.i322 = add i64 %or29.i.2.i320, %85
  %add3.i.3.i324 = add i64 %add.i.3.i322, %85
  store i64 %add3.i.3.i324, i64* %arrayidx5.i.3.i111, align 8, !tbaa !3
  %86 = xor i64 %add.i.3.i322, -9223372036854775808
  %xor2.i.i.3.i326 = and i64 %86, %85
  %xor.i23.i.3.i327 = xor i64 %add3.i.3.i324, %add.i.3.i322
  %xor1.i24.i.3.i328 = xor i64 %add.i.3.i322, %85
  %or.i25.i.3.i329 = or i64 %xor.i23.i.3.i327, %xor1.i24.i.3.i328
  %xor2.i26.i.3.i330 = xor i64 %or.i25.i.3.i329, %add3.i.3.i324
  %shr.i30.i.3.i331 = or i64 %xor2.i26.i.3.i330, %xor2.i.i.3.i326
  %or29.i.3.i332 = lshr i64 %shr.i30.i.3.i331, 63
  %87 = load i64, i64* %arrayidx.i.4.i226, align 16, !tbaa !3
  %add.i.4.i334 = add i64 %or29.i.3.i332, %87
  %add3.i.4.i336 = add i64 %add.i.4.i334, %87
  store i64 %add3.i.4.i336, i64* %arrayidx5.i.4.i123, align 16, !tbaa !3
  %88 = xor i64 %add.i.4.i334, -9223372036854775808
  %xor2.i.i.4.i338 = and i64 %88, %87
  %xor.i23.i.4.i339 = xor i64 %add3.i.4.i336, %add.i.4.i334
  %xor1.i24.i.4.i340 = xor i64 %add.i.4.i334, %87
  %or.i25.i.4.i341 = or i64 %xor.i23.i.4.i339, %xor1.i24.i.4.i340
  %xor2.i26.i.4.i342 = xor i64 %or.i25.i.4.i341, %add3.i.4.i336
  %shr.i30.i.4.i343 = or i64 %xor2.i26.i.4.i342, %xor2.i.i.4.i338
  %or29.i.4.i344 = lshr i64 %shr.i30.i.4.i343, 63
  %89 = load i64, i64* %arrayidx.i.5.i238, align 8, !tbaa !3
  %add.i.5.i346 = add i64 %or29.i.4.i344, %89
  %add3.i.5.i348 = add i64 %add.i.5.i346, %89
  store i64 %add3.i.5.i348, i64* %arrayidx5.i.5.i135, align 8, !tbaa !3
  %90 = xor i64 %add.i.5.i346, -9223372036854775808
  %xor2.i.i.5.i350 = and i64 %90, %89
  %xor.i23.i.5.i351 = xor i64 %add3.i.5.i348, %add.i.5.i346
  %xor1.i24.i.5.i352 = xor i64 %add.i.5.i346, %89
  %or.i25.i.5.i353 = or i64 %xor.i23.i.5.i351, %xor1.i24.i.5.i352
  %xor2.i26.i.5.i354 = xor i64 %or.i25.i.5.i353, %add3.i.5.i348
  %shr.i30.i.5.i355 = or i64 %xor2.i26.i.5.i354, %xor2.i.i.5.i350
  %or29.i.5.i356 = lshr i64 %shr.i30.i.5.i355, 63
  %91 = load i64, i64* %arrayidx.i.6.i250, align 16, !tbaa !3
  %add.i.6.i358 = add i64 %or29.i.5.i356, %91
  %add3.i.6.i360 = add i64 %add.i.6.i358, %91
  store i64 %add3.i.6.i360, i64* %arrayidx5.i.6.i147, align 16, !tbaa !3
  %92 = xor i64 %add.i.6.i358, -9223372036854775808
  %xor2.i.i.6.i362 = and i64 %92, %91
  %xor.i23.i.6.i363 = xor i64 %add3.i.6.i360, %add.i.6.i358
  %xor1.i24.i.6.i364 = xor i64 %add.i.6.i358, %91
  %or.i25.i.6.i365 = or i64 %xor.i23.i.6.i363, %xor1.i24.i.6.i364
  %xor2.i26.i.6.i366 = xor i64 %or.i25.i.6.i365, %add3.i.6.i360
  %shr.i30.i.6.i367 = or i64 %xor2.i26.i.6.i366, %xor2.i.i.6.i362
  %or29.i.6.i368 = lshr i64 %shr.i30.i.6.i367, 63
  %93 = load i64, i64* %arrayidx.i.7.i262, align 8, !tbaa !3
  %add.i.7.i370 = add i64 %or29.i.6.i368, %93
  %add3.i.7.i372 = add i64 %add.i.7.i370, %93
  store i64 %add3.i.7.i372, i64* %arrayidx5.i.7.i159, align 8, !tbaa !3
  %94 = xor i64 %add.i.7.i370, -9223372036854775808
  %xor2.i.i.7.i374 = and i64 %94, %93
  %xor.i23.i.7.i375 = xor i64 %add3.i.7.i372, %add.i.7.i370
  %xor1.i24.i.7.i376 = xor i64 %add.i.7.i370, %93
  %or.i25.i.7.i377 = or i64 %xor.i23.i.7.i375, %xor1.i24.i.7.i376
  %xor2.i26.i.7.i378 = xor i64 %or.i25.i.7.i377, %add3.i.7.i372
  %shr.i30.i.7.i379 = or i64 %xor2.i26.i.7.i378, %xor2.i.i.7.i374
  %or29.i.7.i380 = lshr i64 %shr.i30.i.7.i379, 63
  %95 = load i64, i64* %arrayidx.i.8.i274, align 16, !tbaa !3
  %add.i.8.i382 = add i64 %or29.i.7.i380, %95
  %add3.i.8.i384 = add i64 %add.i.8.i382, %95
  store i64 %add3.i.8.i384, i64* %arrayidx5.i.8.i171, align 16, !tbaa !3
  %96 = xor i64 %add.i.8.i382, -9223372036854775808
  %xor2.i.i.8.i386 = and i64 %96, %95
  %xor.i23.i.8.i387 = xor i64 %add3.i.8.i384, %add.i.8.i382
  %xor1.i24.i.8.i388 = xor i64 %add.i.8.i382, %95
  %or.i25.i.8.i389 = or i64 %xor.i23.i.8.i387, %xor1.i24.i.8.i388
  %xor2.i26.i.8.i390 = xor i64 %or.i25.i.8.i389, %add3.i.8.i384
  %shr.i30.i.8.i391 = or i64 %xor2.i26.i.8.i390, %xor2.i.i.8.i386
  %or29.i.8.i392 = lshr i64 %shr.i30.i.8.i391, 63
  %97 = load i64, i64* %arrayidx.i.9.i286, align 8, !tbaa !3
  %factor398 = shl i64 %97, 1
  %add3.i.9.i396 = or i64 %or29.i.8.i392, %factor398
  store i64 %add3.i.9.i396, i64* %arrayidx5.i.9.i183, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i52, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i46) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i49, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i49) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0
  call void @fp2mul610_mont([10 x i64]* %C24, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay14)
  %arraydecay19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay14, [10 x i64]* %arraydecay19)
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i46, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i46) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i49, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i49) #10
  call void @fp2mul610_mont([10 x i64]* %A24plus, [10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay2)
  %arraydecay.i71 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay14, i64 0, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay.i71, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay.i71) #10
  %arraydecay6.i74 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i74, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay6.i74) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay14, [10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay14)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xDBLe(%struct.point_proj* nocapture readonly %P, %struct.point_proj* %Q, [10 x i64]* %A24plus, [10 x i64]* %C24, i32 %e) local_unnamed_addr #4 {
entry:
  %arrayidx.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %0 = load i64, i64* %arrayidx.i, align 8, !tbaa !3
  %arrayidx2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  store i64 %0, i64* %arrayidx2.i, align 8, !tbaa !3
  %arrayidx.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 1
  %1 = load i64, i64* %arrayidx.i.1, align 8, !tbaa !3
  %arrayidx2.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 1
  store i64 %1, i64* %arrayidx2.i.1, align 8, !tbaa !3
  %arrayidx.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 2
  %2 = load i64, i64* %arrayidx.i.2, align 8, !tbaa !3
  %arrayidx2.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 2
  store i64 %2, i64* %arrayidx2.i.2, align 8, !tbaa !3
  %arrayidx.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 3
  %3 = load i64, i64* %arrayidx.i.3, align 8, !tbaa !3
  %arrayidx2.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 3
  store i64 %3, i64* %arrayidx2.i.3, align 8, !tbaa !3
  %arrayidx.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 4
  %4 = load i64, i64* %arrayidx.i.4, align 8, !tbaa !3
  %arrayidx2.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 4
  store i64 %4, i64* %arrayidx2.i.4, align 8, !tbaa !3
  %arrayidx.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 5
  %5 = load i64, i64* %arrayidx.i.5, align 8, !tbaa !3
  %arrayidx2.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 5
  store i64 %5, i64* %arrayidx2.i.5, align 8, !tbaa !3
  %arrayidx.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 6
  %6 = load i64, i64* %arrayidx.i.6, align 8, !tbaa !3
  %arrayidx2.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 6
  store i64 %6, i64* %arrayidx2.i.6, align 8, !tbaa !3
  %arrayidx.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 7
  %7 = load i64, i64* %arrayidx.i.7, align 8, !tbaa !3
  %arrayidx2.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 7
  store i64 %7, i64* %arrayidx2.i.7, align 8, !tbaa !3
  %arrayidx.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 8
  %8 = load i64, i64* %arrayidx.i.8, align 8, !tbaa !3
  %arrayidx2.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 8
  store i64 %8, i64* %arrayidx2.i.8, align 8, !tbaa !3
  %arrayidx.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 9
  %9 = load i64, i64* %arrayidx.i.9, align 8, !tbaa !3
  %arrayidx2.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 9
  store i64 %9, i64* %arrayidx2.i.9, align 8, !tbaa !3
  %arrayidx.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 10
  %10 = load i64, i64* %arrayidx.i.10, align 8, !tbaa !3
  %arrayidx2.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 10
  store i64 %10, i64* %arrayidx2.i.10, align 8, !tbaa !3
  %arrayidx.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 11
  %11 = load i64, i64* %arrayidx.i.11, align 8, !tbaa !3
  %arrayidx2.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 11
  store i64 %11, i64* %arrayidx2.i.11, align 8, !tbaa !3
  %arrayidx.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 12
  %12 = load i64, i64* %arrayidx.i.12, align 8, !tbaa !3
  %arrayidx2.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 12
  store i64 %12, i64* %arrayidx2.i.12, align 8, !tbaa !3
  %arrayidx.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 13
  %13 = load i64, i64* %arrayidx.i.13, align 8, !tbaa !3
  %arrayidx2.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 13
  store i64 %13, i64* %arrayidx2.i.13, align 8, !tbaa !3
  %arrayidx.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 14
  %14 = load i64, i64* %arrayidx.i.14, align 8, !tbaa !3
  %arrayidx2.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 14
  store i64 %14, i64* %arrayidx2.i.14, align 8, !tbaa !3
  %arrayidx.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 15
  %15 = load i64, i64* %arrayidx.i.15, align 8, !tbaa !3
  %arrayidx2.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 15
  store i64 %15, i64* %arrayidx2.i.15, align 8, !tbaa !3
  %arrayidx.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 16
  %16 = load i64, i64* %arrayidx.i.16, align 8, !tbaa !3
  %arrayidx2.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 16
  store i64 %16, i64* %arrayidx2.i.16, align 8, !tbaa !3
  %arrayidx.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 17
  %17 = load i64, i64* %arrayidx.i.17, align 8, !tbaa !3
  %arrayidx2.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 17
  store i64 %17, i64* %arrayidx2.i.17, align 8, !tbaa !3
  %arrayidx.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 18
  %18 = load i64, i64* %arrayidx.i.18, align 8, !tbaa !3
  %arrayidx2.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 18
  store i64 %18, i64* %arrayidx2.i.18, align 8, !tbaa !3
  %arrayidx.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 19
  %19 = load i64, i64* %arrayidx.i.19, align 8, !tbaa !3
  %arrayidx2.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 19
  store i64 %19, i64* %arrayidx2.i.19, align 8, !tbaa !3
  %arrayidx.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 20
  %20 = load i64, i64* %arrayidx.i.20, align 8, !tbaa !3
  %arrayidx2.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 20
  store i64 %20, i64* %arrayidx2.i.20, align 8, !tbaa !3
  %arrayidx.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 21
  %21 = load i64, i64* %arrayidx.i.21, align 8, !tbaa !3
  %arrayidx2.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 21
  store i64 %21, i64* %arrayidx2.i.21, align 8, !tbaa !3
  %arrayidx.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 22
  %22 = load i64, i64* %arrayidx.i.22, align 8, !tbaa !3
  %arrayidx2.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 22
  store i64 %22, i64* %arrayidx2.i.22, align 8, !tbaa !3
  %arrayidx.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 23
  %23 = load i64, i64* %arrayidx.i.23, align 8, !tbaa !3
  %arrayidx2.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 23
  store i64 %23, i64* %arrayidx2.i.23, align 8, !tbaa !3
  %arrayidx.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 24
  %24 = load i64, i64* %arrayidx.i.24, align 8, !tbaa !3
  %arrayidx2.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 24
  store i64 %24, i64* %arrayidx2.i.24, align 8, !tbaa !3
  %arrayidx.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 25
  %25 = load i64, i64* %arrayidx.i.25, align 8, !tbaa !3
  %arrayidx2.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 25
  store i64 %25, i64* %arrayidx2.i.25, align 8, !tbaa !3
  %arrayidx.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 26
  %26 = load i64, i64* %arrayidx.i.26, align 8, !tbaa !3
  %arrayidx2.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 26
  store i64 %26, i64* %arrayidx2.i.26, align 8, !tbaa !3
  %arrayidx.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 27
  %27 = load i64, i64* %arrayidx.i.27, align 8, !tbaa !3
  %arrayidx2.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 27
  store i64 %27, i64* %arrayidx2.i.27, align 8, !tbaa !3
  %arrayidx.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 28
  %28 = load i64, i64* %arrayidx.i.28, align 8, !tbaa !3
  %arrayidx2.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 28
  store i64 %28, i64* %arrayidx2.i.28, align 8, !tbaa !3
  %arrayidx.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 29
  %29 = load i64, i64* %arrayidx.i.29, align 8, !tbaa !3
  %arrayidx2.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 29
  store i64 %29, i64* %arrayidx2.i.29, align 8, !tbaa !3
  %arrayidx.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 30
  %30 = load i64, i64* %arrayidx.i.30, align 8, !tbaa !3
  %arrayidx2.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 30
  store i64 %30, i64* %arrayidx2.i.30, align 8, !tbaa !3
  %arrayidx.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 31
  %31 = load i64, i64* %arrayidx.i.31, align 8, !tbaa !3
  %arrayidx2.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 31
  store i64 %31, i64* %arrayidx2.i.31, align 8, !tbaa !3
  %arrayidx.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 32
  %32 = load i64, i64* %arrayidx.i.32, align 8, !tbaa !3
  %arrayidx2.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 32
  store i64 %32, i64* %arrayidx2.i.32, align 8, !tbaa !3
  %arrayidx.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 33
  %33 = load i64, i64* %arrayidx.i.33, align 8, !tbaa !3
  %arrayidx2.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 33
  store i64 %33, i64* %arrayidx2.i.33, align 8, !tbaa !3
  %arrayidx.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 34
  %34 = load i64, i64* %arrayidx.i.34, align 8, !tbaa !3
  %arrayidx2.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 34
  store i64 %34, i64* %arrayidx2.i.34, align 8, !tbaa !3
  %arrayidx.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 35
  %35 = load i64, i64* %arrayidx.i.35, align 8, !tbaa !3
  %arrayidx2.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 35
  store i64 %35, i64* %arrayidx2.i.35, align 8, !tbaa !3
  %arrayidx.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 36
  %36 = load i64, i64* %arrayidx.i.36, align 8, !tbaa !3
  %arrayidx2.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 36
  store i64 %36, i64* %arrayidx2.i.36, align 8, !tbaa !3
  %arrayidx.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 37
  %37 = load i64, i64* %arrayidx.i.37, align 8, !tbaa !3
  %arrayidx2.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 37
  store i64 %37, i64* %arrayidx2.i.37, align 8, !tbaa !3
  %arrayidx.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 38
  %38 = load i64, i64* %arrayidx.i.38, align 8, !tbaa !3
  %arrayidx2.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 38
  store i64 %38, i64* %arrayidx2.i.38, align 8, !tbaa !3
  %arrayidx.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 39
  %39 = load i64, i64* %arrayidx.i.39, align 8, !tbaa !3
  %arrayidx2.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 39
  store i64 %39, i64* %arrayidx2.i.39, align 8, !tbaa !3
  %cmp5 = icmp sgt i32 %e, 0
  br i1 %cmp5, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body, %entry
  ret void

for.body:                                         ; preds = %entry, %for.body
  %i.06 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  tail call void @xDBL(%struct.point_proj* %Q, %struct.point_proj* %Q, [10 x i64]* %A24plus, [10 x i64]* %C24)
  %inc = add nuw nsw i32 %i.06, 1
  %exitcond = icmp eq i32 %inc, %e
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

; Function Attrs: nounwind ssp uwtable
define void @get_2_isog(%struct.point_proj* %P, [10 x i64]* %A24plus, [10 x i64]* %C24) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %0 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %2 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i = getelementptr inbounds [10 x i64], [10 x i64]* %A24plus, i64 0, i64 0
  %3 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22.i = getelementptr inbounds [10 x i64], [10 x i64]* %A24plus, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay.i10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0, i64 0
  %arraydecay2.i11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay2.i11, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay2.i11, i64* nonnull %arraydecay8.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay.i10, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i15 = getelementptr inbounds [10 x i64], [10 x i64]* %C24, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i15) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22.i17 = getelementptr inbounds [10 x i64], [10 x i64]* %C24, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i11, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i17) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  call void @mp_sub610_p2(i64* %arraydecay17.i15, i64* %arraydecay17.i, i64* %arraydecay17.i) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay22.i17, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @eval_2_isog(%struct.point_proj* %P, %struct.point_proj* %Q) local_unnamed_addr #4 {
entry:
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %t3 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = bitcast [2 x [10 x i64]]* %t3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i52 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i52) #10
  %arraydecay10.i55 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i55) #10
  %arraydecay9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0
  %arraydecay11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  %arraydecay.i56 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i57 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay11, i64 0, i64 0
  %arraydecay4.i58 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i56, i64* nonnull %arraydecay2.i57, i64* nonnull %arraydecay4.i58) #10
  %arraydecay6.i59 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i60 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i61 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i59, i64* nonnull %arraydecay8.i60, i64* nonnull %arraydecay10.i61) #10
  %arraydecay17 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0
  %arraydecay4.i64 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i56, i64* nonnull %arraydecay2.i57, i64* nonnull %arraydecay4.i64) #10
  %arraydecay10.i67 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i59, i64* nonnull %arraydecay8.i60, i64* nonnull %arraydecay10.i67) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay2)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay12, [10 x i64]* nonnull %arraydecay7)
  %4 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %5 = load i64, i64* %arraydecay4.i52, align 16, !tbaa !3
  %add3.i.i74 = add i64 %5, %4
  store i64 %add3.i.i74, i64* %arraydecay4.i58, align 16, !tbaa !3
  %xor.i23.i.i75 = xor i64 %add3.i.i74, %4
  %xor1.i24.i.i76 = xor i64 %5, %4
  %or.i25.i.i77 = or i64 %xor.i23.i.i75, %xor1.i24.i.i76
  %xor2.i26.i.i78 = xor i64 %or.i25.i.i77, %add3.i.i74
  %or29.i.i79 = lshr i64 %xor2.i26.i.i78, 63
  %arrayidx.i.1.i80 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %6 = load i64, i64* %arrayidx.i.1.i80, align 8, !tbaa !3
  %add.i.1.i81 = add i64 %or29.i.i79, %6
  %arrayidx2.i.1.i82 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %7 = load i64, i64* %arrayidx2.i.1.i82, align 8, !tbaa !3
  %add3.i.1.i83 = add i64 %add.i.1.i81, %7
  %arrayidx5.i.1.i84 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 1
  store i64 %add3.i.1.i83, i64* %arrayidx5.i.1.i84, align 8, !tbaa !3
  %8 = xor i64 %add.i.1.i81, -9223372036854775808
  %xor2.i.i.1.i85 = and i64 %8, %6
  %xor.i23.i.1.i86 = xor i64 %add3.i.1.i83, %add.i.1.i81
  %xor1.i24.i.1.i87 = xor i64 %add.i.1.i81, %7
  %or.i25.i.1.i88 = or i64 %xor.i23.i.1.i86, %xor1.i24.i.1.i87
  %xor2.i26.i.1.i89 = xor i64 %or.i25.i.1.i88, %add3.i.1.i83
  %shr.i30.i.1.i90 = or i64 %xor2.i26.i.1.i89, %xor2.i.i.1.i85
  %or29.i.1.i91 = lshr i64 %shr.i30.i.1.i90, 63
  %arrayidx.i.2.i92 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %9 = load i64, i64* %arrayidx.i.2.i92, align 16, !tbaa !3
  %add.i.2.i93 = add i64 %or29.i.1.i91, %9
  %arrayidx2.i.2.i94 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %10 = load i64, i64* %arrayidx2.i.2.i94, align 16, !tbaa !3
  %add3.i.2.i95 = add i64 %add.i.2.i93, %10
  %arrayidx5.i.2.i96 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 2
  store i64 %add3.i.2.i95, i64* %arrayidx5.i.2.i96, align 16, !tbaa !3
  %11 = xor i64 %add.i.2.i93, -9223372036854775808
  %xor2.i.i.2.i97 = and i64 %11, %9
  %xor.i23.i.2.i98 = xor i64 %add3.i.2.i95, %add.i.2.i93
  %xor1.i24.i.2.i99 = xor i64 %add.i.2.i93, %10
  %or.i25.i.2.i100 = or i64 %xor.i23.i.2.i98, %xor1.i24.i.2.i99
  %xor2.i26.i.2.i101 = xor i64 %or.i25.i.2.i100, %add3.i.2.i95
  %shr.i30.i.2.i102 = or i64 %xor2.i26.i.2.i101, %xor2.i.i.2.i97
  %or29.i.2.i103 = lshr i64 %shr.i30.i.2.i102, 63
  %arrayidx.i.3.i104 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %12 = load i64, i64* %arrayidx.i.3.i104, align 8, !tbaa !3
  %add.i.3.i105 = add i64 %or29.i.2.i103, %12
  %arrayidx2.i.3.i106 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %13 = load i64, i64* %arrayidx2.i.3.i106, align 8, !tbaa !3
  %add3.i.3.i107 = add i64 %add.i.3.i105, %13
  %arrayidx5.i.3.i108 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 3
  store i64 %add3.i.3.i107, i64* %arrayidx5.i.3.i108, align 8, !tbaa !3
  %14 = xor i64 %add.i.3.i105, -9223372036854775808
  %xor2.i.i.3.i109 = and i64 %14, %12
  %xor.i23.i.3.i110 = xor i64 %add3.i.3.i107, %add.i.3.i105
  %xor1.i24.i.3.i111 = xor i64 %add.i.3.i105, %13
  %or.i25.i.3.i112 = or i64 %xor.i23.i.3.i110, %xor1.i24.i.3.i111
  %xor2.i26.i.3.i113 = xor i64 %or.i25.i.3.i112, %add3.i.3.i107
  %shr.i30.i.3.i114 = or i64 %xor2.i26.i.3.i113, %xor2.i.i.3.i109
  %or29.i.3.i115 = lshr i64 %shr.i30.i.3.i114, 63
  %arrayidx.i.4.i116 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %15 = load i64, i64* %arrayidx.i.4.i116, align 16, !tbaa !3
  %add.i.4.i117 = add i64 %or29.i.3.i115, %15
  %arrayidx2.i.4.i118 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %16 = load i64, i64* %arrayidx2.i.4.i118, align 16, !tbaa !3
  %add3.i.4.i119 = add i64 %add.i.4.i117, %16
  %arrayidx5.i.4.i120 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 4
  store i64 %add3.i.4.i119, i64* %arrayidx5.i.4.i120, align 16, !tbaa !3
  %17 = xor i64 %add.i.4.i117, -9223372036854775808
  %xor2.i.i.4.i121 = and i64 %17, %15
  %xor.i23.i.4.i122 = xor i64 %add3.i.4.i119, %add.i.4.i117
  %xor1.i24.i.4.i123 = xor i64 %add.i.4.i117, %16
  %or.i25.i.4.i124 = or i64 %xor.i23.i.4.i122, %xor1.i24.i.4.i123
  %xor2.i26.i.4.i125 = xor i64 %or.i25.i.4.i124, %add3.i.4.i119
  %shr.i30.i.4.i126 = or i64 %xor2.i26.i.4.i125, %xor2.i.i.4.i121
  %or29.i.4.i127 = lshr i64 %shr.i30.i.4.i126, 63
  %arrayidx.i.5.i128 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %18 = load i64, i64* %arrayidx.i.5.i128, align 8, !tbaa !3
  %add.i.5.i129 = add i64 %or29.i.4.i127, %18
  %arrayidx2.i.5.i130 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %19 = load i64, i64* %arrayidx2.i.5.i130, align 8, !tbaa !3
  %add3.i.5.i131 = add i64 %add.i.5.i129, %19
  %arrayidx5.i.5.i132 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 5
  store i64 %add3.i.5.i131, i64* %arrayidx5.i.5.i132, align 8, !tbaa !3
  %20 = xor i64 %add.i.5.i129, -9223372036854775808
  %xor2.i.i.5.i133 = and i64 %20, %18
  %xor.i23.i.5.i134 = xor i64 %add3.i.5.i131, %add.i.5.i129
  %xor1.i24.i.5.i135 = xor i64 %add.i.5.i129, %19
  %or.i25.i.5.i136 = or i64 %xor.i23.i.5.i134, %xor1.i24.i.5.i135
  %xor2.i26.i.5.i137 = xor i64 %or.i25.i.5.i136, %add3.i.5.i131
  %shr.i30.i.5.i138 = or i64 %xor2.i26.i.5.i137, %xor2.i.i.5.i133
  %or29.i.5.i139 = lshr i64 %shr.i30.i.5.i138, 63
  %arrayidx.i.6.i140 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %21 = load i64, i64* %arrayidx.i.6.i140, align 16, !tbaa !3
  %add.i.6.i141 = add i64 %or29.i.5.i139, %21
  %arrayidx2.i.6.i142 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %22 = load i64, i64* %arrayidx2.i.6.i142, align 16, !tbaa !3
  %add3.i.6.i143 = add i64 %add.i.6.i141, %22
  %arrayidx5.i.6.i144 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 6
  store i64 %add3.i.6.i143, i64* %arrayidx5.i.6.i144, align 16, !tbaa !3
  %23 = xor i64 %add.i.6.i141, -9223372036854775808
  %xor2.i.i.6.i145 = and i64 %23, %21
  %xor.i23.i.6.i146 = xor i64 %add3.i.6.i143, %add.i.6.i141
  %xor1.i24.i.6.i147 = xor i64 %add.i.6.i141, %22
  %or.i25.i.6.i148 = or i64 %xor.i23.i.6.i146, %xor1.i24.i.6.i147
  %xor2.i26.i.6.i149 = xor i64 %or.i25.i.6.i148, %add3.i.6.i143
  %shr.i30.i.6.i150 = or i64 %xor2.i26.i.6.i149, %xor2.i.i.6.i145
  %or29.i.6.i151 = lshr i64 %shr.i30.i.6.i150, 63
  %arrayidx.i.7.i152 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %24 = load i64, i64* %arrayidx.i.7.i152, align 8, !tbaa !3
  %add.i.7.i153 = add i64 %or29.i.6.i151, %24
  %arrayidx2.i.7.i154 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %25 = load i64, i64* %arrayidx2.i.7.i154, align 8, !tbaa !3
  %add3.i.7.i155 = add i64 %add.i.7.i153, %25
  %arrayidx5.i.7.i156 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 7
  store i64 %add3.i.7.i155, i64* %arrayidx5.i.7.i156, align 8, !tbaa !3
  %26 = xor i64 %add.i.7.i153, -9223372036854775808
  %xor2.i.i.7.i157 = and i64 %26, %24
  %xor.i23.i.7.i158 = xor i64 %add3.i.7.i155, %add.i.7.i153
  %xor1.i24.i.7.i159 = xor i64 %add.i.7.i153, %25
  %or.i25.i.7.i160 = or i64 %xor.i23.i.7.i158, %xor1.i24.i.7.i159
  %xor2.i26.i.7.i161 = xor i64 %or.i25.i.7.i160, %add3.i.7.i155
  %shr.i30.i.7.i162 = or i64 %xor2.i26.i.7.i161, %xor2.i.i.7.i157
  %or29.i.7.i163 = lshr i64 %shr.i30.i.7.i162, 63
  %arrayidx.i.8.i164 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %27 = load i64, i64* %arrayidx.i.8.i164, align 16, !tbaa !3
  %add.i.8.i165 = add i64 %or29.i.7.i163, %27
  %arrayidx2.i.8.i166 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %28 = load i64, i64* %arrayidx2.i.8.i166, align 16, !tbaa !3
  %add3.i.8.i167 = add i64 %add.i.8.i165, %28
  %arrayidx5.i.8.i168 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 8
  store i64 %add3.i.8.i167, i64* %arrayidx5.i.8.i168, align 16, !tbaa !3
  %29 = xor i64 %add.i.8.i165, -9223372036854775808
  %xor2.i.i.8.i169 = and i64 %29, %27
  %xor.i23.i.8.i170 = xor i64 %add3.i.8.i167, %add.i.8.i165
  %xor1.i24.i.8.i171 = xor i64 %add.i.8.i165, %28
  %or.i25.i.8.i172 = or i64 %xor.i23.i.8.i170, %xor1.i24.i.8.i171
  %xor2.i26.i.8.i173 = xor i64 %or.i25.i.8.i172, %add3.i.8.i167
  %shr.i30.i.8.i174 = or i64 %xor2.i26.i.8.i173, %xor2.i.i.8.i169
  %or29.i.8.i175 = lshr i64 %shr.i30.i.8.i174, 63
  %arrayidx.i.9.i176 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %30 = load i64, i64* %arrayidx.i.9.i176, align 8, !tbaa !3
  %arrayidx2.i.9.i178 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %31 = load i64, i64* %arrayidx2.i.9.i178, align 8, !tbaa !3
  %add.i.9.i177 = add i64 %31, %30
  %add3.i.9.i179 = add i64 %add.i.9.i177, %or29.i.8.i175
  %arrayidx5.i.9.i180 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 9
  store i64 %add3.i.9.i179, i64* %arrayidx5.i.9.i180, align 8, !tbaa !3
  %32 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %33 = load i64, i64* %arraydecay10.i55, align 16, !tbaa !3
  %add3.i.i = add i64 %33, %32
  store i64 %add3.i.i, i64* %arraydecay10.i61, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %32
  %xor1.i24.i.i = xor i64 %33, %32
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %34 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %34
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %35 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %35
  %arrayidx5.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %36 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %36, %34
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %35
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %37 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %37
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %38 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %38
  %arrayidx5.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %39 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %39, %37
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %38
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %40 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %40
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %41 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %41
  %arrayidx5.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %42 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %42, %40
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %41
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %43 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %43
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %44 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %44
  %arrayidx5.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %45 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %45, %43
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %44
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %46 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %46
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %47 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %47
  %arrayidx5.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %48 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %48, %46
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %47
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %49 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %49
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %50 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %50
  %arrayidx5.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %51 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %51, %49
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %50
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %52 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %52
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %53 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %53
  %arrayidx5.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %54 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %54, %52
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %53
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %55 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %55
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %56 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %56
  %arrayidx5.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %57 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %57, %55
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %56
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %58 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %59 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %59, %58
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i52, i64* nonnull %arraydecay4.i64) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i55, i64* nonnull %arraydecay10.i67) #10
  call void @fp2mul610_mont([10 x i64]* %arraydecay9, [10 x i64]* nonnull %arraydecay12, [10 x i64]* %arraydecay9)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay11)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @get_4_isog(%struct.point_proj* %P, [10 x i64]* %A24plus, [10 x i64]* %C24, [2 x [10 x i64]]* %coeff) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 0, i64 0
  tail call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 1, i64 0
  tail call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay4.i50 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 2, i64 0, i64 0
  tail call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i50) #10
  %arraydecay10.i53 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 2, i64 1, i64 0
  tail call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i53) #10
  %0 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  %1 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  %2 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i56 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i56) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 0, i64 0
  %3 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i56, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i, i64* %arraydecay17.i, i64* %arraydecay17.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* %arraydecay17.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay8.i56) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i, i64* %arraydecay17.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i72 = getelementptr inbounds [10 x i64], [10 x i64]* %C24, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i56, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22.i74 = getelementptr inbounds [10 x i64], [10 x i64]* %C24, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i74) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i, i64* %arraydecay17.i, i64* %arraydecay17.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* %arraydecay.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i56) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i90 = getelementptr inbounds [10 x i64], [10 x i64]* %A24plus, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i56, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i90) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay22.i92 = getelementptr inbounds [10 x i64], [10 x i64]* %A24plus, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i92) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i90, i64* %arraydecay17.i90, i64* %arraydecay17.i90) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay22.i92, i64* nonnull %arraydecay22.i92, i64* nonnull %arraydecay22.i92) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %0) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i90, i64* nonnull %arraydecay22.i92, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* %arraydecay17.i90, i64* nonnull %arraydecay22.i92, i64* nonnull %arraydecay8.i56) #10
  call fastcc void @mp_addfast(i64* %arraydecay17.i90, i64* %arraydecay17.i90, i64* nonnull %arraydecay13.i) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i56, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i90) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i92, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i92) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @eval_4_isog(%struct.point_proj* %P, [2 x [10 x i64]]* %coeff) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %arraydecay = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0
  %arraydecay1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i81 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i81) #10
  %arraydecay10.i84 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i84) #10
  %arraydecay9 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay9, [10 x i64]* %arraydecay)
  %arraydecay14 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 2, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay14, [10 x i64]* nonnull %arraydecay1)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay2)
  %arraydecay21 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %arraydecay21, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay2)
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i81) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i84) #10
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i) #10
  %2 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %3 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  %4 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  %5 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %6 = load i64, i64* %arraydecay10.i84, align 16, !tbaa !3
  %add3.i.i231 = add i64 %6, %5
  store i64 %add3.i.i231, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i232 = xor i64 %add3.i.i231, %5
  %xor1.i24.i.i233 = xor i64 %6, %5
  %or.i25.i.i234 = or i64 %xor.i23.i.i232, %xor1.i24.i.i233
  %xor2.i26.i.i235 = xor i64 %or.i25.i.i234, %add3.i.i231
  %or29.i.i236 = lshr i64 %xor2.i26.i.i235, 63
  %arrayidx.i.1.i237 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %7 = load i64, i64* %arrayidx.i.1.i237, align 8, !tbaa !3
  %add.i.1.i238 = add i64 %or29.i.i236, %7
  %arrayidx2.i.1.i239 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %8 = load i64, i64* %arrayidx2.i.1.i239, align 8, !tbaa !3
  %add3.i.1.i240 = add i64 %add.i.1.i238, %8
  %arrayidx5.i.1.i241 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i240, i64* %arrayidx5.i.1.i241, align 8, !tbaa !3
  %9 = xor i64 %add.i.1.i238, -9223372036854775808
  %xor2.i.i.1.i242 = and i64 %9, %7
  %xor.i23.i.1.i243 = xor i64 %add3.i.1.i240, %add.i.1.i238
  %xor1.i24.i.1.i244 = xor i64 %add.i.1.i238, %8
  %or.i25.i.1.i245 = or i64 %xor.i23.i.1.i243, %xor1.i24.i.1.i244
  %xor2.i26.i.1.i246 = xor i64 %or.i25.i.1.i245, %add3.i.1.i240
  %shr.i30.i.1.i247 = or i64 %xor2.i26.i.1.i246, %xor2.i.i.1.i242
  %or29.i.1.i248 = lshr i64 %shr.i30.i.1.i247, 63
  %arrayidx.i.2.i249 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %10 = load i64, i64* %arrayidx.i.2.i249, align 16, !tbaa !3
  %add.i.2.i250 = add i64 %or29.i.1.i248, %10
  %arrayidx2.i.2.i251 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %11 = load i64, i64* %arrayidx2.i.2.i251, align 16, !tbaa !3
  %add3.i.2.i252 = add i64 %add.i.2.i250, %11
  %arrayidx5.i.2.i253 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i252, i64* %arrayidx5.i.2.i253, align 16, !tbaa !3
  %12 = xor i64 %add.i.2.i250, -9223372036854775808
  %xor2.i.i.2.i254 = and i64 %12, %10
  %xor.i23.i.2.i255 = xor i64 %add3.i.2.i252, %add.i.2.i250
  %xor1.i24.i.2.i256 = xor i64 %add.i.2.i250, %11
  %or.i25.i.2.i257 = or i64 %xor.i23.i.2.i255, %xor1.i24.i.2.i256
  %xor2.i26.i.2.i258 = xor i64 %or.i25.i.2.i257, %add3.i.2.i252
  %shr.i30.i.2.i259 = or i64 %xor2.i26.i.2.i258, %xor2.i.i.2.i254
  %or29.i.2.i260 = lshr i64 %shr.i30.i.2.i259, 63
  %arrayidx.i.3.i261 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %13 = load i64, i64* %arrayidx.i.3.i261, align 8, !tbaa !3
  %add.i.3.i262 = add i64 %or29.i.2.i260, %13
  %arrayidx2.i.3.i263 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %14 = load i64, i64* %arrayidx2.i.3.i263, align 8, !tbaa !3
  %add3.i.3.i264 = add i64 %add.i.3.i262, %14
  %arrayidx5.i.3.i265 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i264, i64* %arrayidx5.i.3.i265, align 8, !tbaa !3
  %15 = xor i64 %add.i.3.i262, -9223372036854775808
  %xor2.i.i.3.i266 = and i64 %15, %13
  %xor.i23.i.3.i267 = xor i64 %add3.i.3.i264, %add.i.3.i262
  %xor1.i24.i.3.i268 = xor i64 %add.i.3.i262, %14
  %or.i25.i.3.i269 = or i64 %xor.i23.i.3.i267, %xor1.i24.i.3.i268
  %xor2.i26.i.3.i270 = xor i64 %or.i25.i.3.i269, %add3.i.3.i264
  %shr.i30.i.3.i271 = or i64 %xor2.i26.i.3.i270, %xor2.i.i.3.i266
  %or29.i.3.i272 = lshr i64 %shr.i30.i.3.i271, 63
  %arrayidx.i.4.i273 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %16 = load i64, i64* %arrayidx.i.4.i273, align 16, !tbaa !3
  %add.i.4.i274 = add i64 %or29.i.3.i272, %16
  %arrayidx2.i.4.i275 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %17 = load i64, i64* %arrayidx2.i.4.i275, align 16, !tbaa !3
  %add3.i.4.i276 = add i64 %add.i.4.i274, %17
  %arrayidx5.i.4.i277 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i276, i64* %arrayidx5.i.4.i277, align 16, !tbaa !3
  %18 = xor i64 %add.i.4.i274, -9223372036854775808
  %xor2.i.i.4.i278 = and i64 %18, %16
  %xor.i23.i.4.i279 = xor i64 %add3.i.4.i276, %add.i.4.i274
  %xor1.i24.i.4.i280 = xor i64 %add.i.4.i274, %17
  %or.i25.i.4.i281 = or i64 %xor.i23.i.4.i279, %xor1.i24.i.4.i280
  %xor2.i26.i.4.i282 = xor i64 %or.i25.i.4.i281, %add3.i.4.i276
  %shr.i30.i.4.i283 = or i64 %xor2.i26.i.4.i282, %xor2.i.i.4.i278
  %or29.i.4.i284 = lshr i64 %shr.i30.i.4.i283, 63
  %arrayidx.i.5.i285 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %19 = load i64, i64* %arrayidx.i.5.i285, align 8, !tbaa !3
  %add.i.5.i286 = add i64 %or29.i.4.i284, %19
  %arrayidx2.i.5.i287 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %20 = load i64, i64* %arrayidx2.i.5.i287, align 8, !tbaa !3
  %add3.i.5.i288 = add i64 %add.i.5.i286, %20
  %arrayidx5.i.5.i289 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i288, i64* %arrayidx5.i.5.i289, align 8, !tbaa !3
  %21 = xor i64 %add.i.5.i286, -9223372036854775808
  %xor2.i.i.5.i290 = and i64 %21, %19
  %xor.i23.i.5.i291 = xor i64 %add3.i.5.i288, %add.i.5.i286
  %xor1.i24.i.5.i292 = xor i64 %add.i.5.i286, %20
  %or.i25.i.5.i293 = or i64 %xor.i23.i.5.i291, %xor1.i24.i.5.i292
  %xor2.i26.i.5.i294 = xor i64 %or.i25.i.5.i293, %add3.i.5.i288
  %shr.i30.i.5.i295 = or i64 %xor2.i26.i.5.i294, %xor2.i.i.5.i290
  %or29.i.5.i296 = lshr i64 %shr.i30.i.5.i295, 63
  %arrayidx.i.6.i297 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %22 = load i64, i64* %arrayidx.i.6.i297, align 16, !tbaa !3
  %add.i.6.i298 = add i64 %or29.i.5.i296, %22
  %arrayidx2.i.6.i299 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %23 = load i64, i64* %arrayidx2.i.6.i299, align 16, !tbaa !3
  %add3.i.6.i300 = add i64 %add.i.6.i298, %23
  %arrayidx5.i.6.i301 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i300, i64* %arrayidx5.i.6.i301, align 16, !tbaa !3
  %24 = xor i64 %add.i.6.i298, -9223372036854775808
  %xor2.i.i.6.i302 = and i64 %24, %22
  %xor.i23.i.6.i303 = xor i64 %add3.i.6.i300, %add.i.6.i298
  %xor1.i24.i.6.i304 = xor i64 %add.i.6.i298, %23
  %or.i25.i.6.i305 = or i64 %xor.i23.i.6.i303, %xor1.i24.i.6.i304
  %xor2.i26.i.6.i306 = xor i64 %or.i25.i.6.i305, %add3.i.6.i300
  %shr.i30.i.6.i307 = or i64 %xor2.i26.i.6.i306, %xor2.i.i.6.i302
  %or29.i.6.i308 = lshr i64 %shr.i30.i.6.i307, 63
  %arrayidx.i.7.i309 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %25 = load i64, i64* %arrayidx.i.7.i309, align 8, !tbaa !3
  %add.i.7.i310 = add i64 %or29.i.6.i308, %25
  %arrayidx2.i.7.i311 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %26 = load i64, i64* %arrayidx2.i.7.i311, align 8, !tbaa !3
  %add3.i.7.i312 = add i64 %add.i.7.i310, %26
  %arrayidx5.i.7.i313 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i312, i64* %arrayidx5.i.7.i313, align 8, !tbaa !3
  %27 = xor i64 %add.i.7.i310, -9223372036854775808
  %xor2.i.i.7.i314 = and i64 %27, %25
  %xor.i23.i.7.i315 = xor i64 %add3.i.7.i312, %add.i.7.i310
  %xor1.i24.i.7.i316 = xor i64 %add.i.7.i310, %26
  %or.i25.i.7.i317 = or i64 %xor.i23.i.7.i315, %xor1.i24.i.7.i316
  %xor2.i26.i.7.i318 = xor i64 %or.i25.i.7.i317, %add3.i.7.i312
  %shr.i30.i.7.i319 = or i64 %xor2.i26.i.7.i318, %xor2.i.i.7.i314
  %or29.i.7.i320 = lshr i64 %shr.i30.i.7.i319, 63
  %arrayidx.i.8.i321 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %28 = load i64, i64* %arrayidx.i.8.i321, align 16, !tbaa !3
  %add.i.8.i322 = add i64 %or29.i.7.i320, %28
  %arrayidx2.i.8.i323 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %29 = load i64, i64* %arrayidx2.i.8.i323, align 16, !tbaa !3
  %add3.i.8.i324 = add i64 %add.i.8.i322, %29
  %arrayidx5.i.8.i325 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i324, i64* %arrayidx5.i.8.i325, align 16, !tbaa !3
  %30 = xor i64 %add.i.8.i322, -9223372036854775808
  %xor2.i.i.8.i326 = and i64 %30, %28
  %xor.i23.i.8.i327 = xor i64 %add3.i.8.i324, %add.i.8.i322
  %xor1.i24.i.8.i328 = xor i64 %add.i.8.i322, %29
  %or.i25.i.8.i329 = or i64 %xor.i23.i.8.i327, %xor1.i24.i.8.i328
  %xor2.i26.i.8.i330 = xor i64 %or.i25.i.8.i329, %add3.i.8.i324
  %shr.i30.i.8.i331 = or i64 %xor2.i26.i.8.i330, %xor2.i.i.8.i326
  %or29.i.8.i332 = lshr i64 %shr.i30.i.8.i331, 63
  %arrayidx.i.9.i333 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %31 = load i64, i64* %arrayidx.i.9.i333, align 8, !tbaa !3
  %arrayidx2.i.9.i335 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %32 = load i64, i64* %arrayidx2.i.9.i335, align 8, !tbaa !3
  %add.i.9.i334 = add i64 %32, %31
  %add3.i.9.i336 = add i64 %add.i.9.i334, %or29.i.8.i332
  %arrayidx5.i.9.i337 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i336, i64* %arrayidx5.i.9.i337, align 8, !tbaa !3
  %arraydecay8.i99 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i81, i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay8.i99) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  %33 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %add3.i.i338 = shl i64 %33, 1
  store i64 %add3.i.i338, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i343 = lshr i64 %33, 63
  %34 = load i64, i64* %arrayidx.i.1.i237, align 8, !tbaa !3
  %add.i.1.i345 = add i64 %34, %or29.i.i343
  %add3.i.1.i347 = add i64 %add.i.1.i345, %34
  %arrayidx5.i.1.i348 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i347, i64* %arrayidx5.i.1.i348, align 8, !tbaa !3
  %35 = xor i64 %add.i.1.i345, -9223372036854775808
  %xor2.i.i.1.i349 = and i64 %35, %34
  %xor.i23.i.1.i350 = xor i64 %add3.i.1.i347, %add.i.1.i345
  %xor1.i24.i.1.i351 = xor i64 %add.i.1.i345, %34
  %or.i25.i.1.i352 = or i64 %xor.i23.i.1.i350, %xor1.i24.i.1.i351
  %xor2.i26.i.1.i353 = xor i64 %or.i25.i.1.i352, %add3.i.1.i347
  %shr.i30.i.1.i354 = or i64 %xor2.i26.i.1.i353, %xor2.i.i.1.i349
  %or29.i.1.i355 = lshr i64 %shr.i30.i.1.i354, 63
  %36 = load i64, i64* %arrayidx.i.2.i249, align 16, !tbaa !3
  %add.i.2.i357 = add i64 %or29.i.1.i355, %36
  %add3.i.2.i359 = add i64 %add.i.2.i357, %36
  %arrayidx5.i.2.i360 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i359, i64* %arrayidx5.i.2.i360, align 16, !tbaa !3
  %37 = xor i64 %add.i.2.i357, -9223372036854775808
  %xor2.i.i.2.i361 = and i64 %37, %36
  %xor.i23.i.2.i362 = xor i64 %add3.i.2.i359, %add.i.2.i357
  %xor1.i24.i.2.i363 = xor i64 %add.i.2.i357, %36
  %or.i25.i.2.i364 = or i64 %xor.i23.i.2.i362, %xor1.i24.i.2.i363
  %xor2.i26.i.2.i365 = xor i64 %or.i25.i.2.i364, %add3.i.2.i359
  %shr.i30.i.2.i366 = or i64 %xor2.i26.i.2.i365, %xor2.i.i.2.i361
  %or29.i.2.i367 = lshr i64 %shr.i30.i.2.i366, 63
  %38 = load i64, i64* %arrayidx.i.3.i261, align 8, !tbaa !3
  %add.i.3.i369 = add i64 %or29.i.2.i367, %38
  %add3.i.3.i371 = add i64 %add.i.3.i369, %38
  %arrayidx5.i.3.i372 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i371, i64* %arrayidx5.i.3.i372, align 8, !tbaa !3
  %39 = xor i64 %add.i.3.i369, -9223372036854775808
  %xor2.i.i.3.i373 = and i64 %39, %38
  %xor.i23.i.3.i374 = xor i64 %add3.i.3.i371, %add.i.3.i369
  %xor1.i24.i.3.i375 = xor i64 %add.i.3.i369, %38
  %or.i25.i.3.i376 = or i64 %xor.i23.i.3.i374, %xor1.i24.i.3.i375
  %xor2.i26.i.3.i377 = xor i64 %or.i25.i.3.i376, %add3.i.3.i371
  %shr.i30.i.3.i378 = or i64 %xor2.i26.i.3.i377, %xor2.i.i.3.i373
  %or29.i.3.i379 = lshr i64 %shr.i30.i.3.i378, 63
  %40 = load i64, i64* %arrayidx.i.4.i273, align 16, !tbaa !3
  %add.i.4.i381 = add i64 %or29.i.3.i379, %40
  %add3.i.4.i383 = add i64 %add.i.4.i381, %40
  %arrayidx5.i.4.i384 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i383, i64* %arrayidx5.i.4.i384, align 16, !tbaa !3
  %41 = xor i64 %add.i.4.i381, -9223372036854775808
  %xor2.i.i.4.i385 = and i64 %41, %40
  %xor.i23.i.4.i386 = xor i64 %add3.i.4.i383, %add.i.4.i381
  %xor1.i24.i.4.i387 = xor i64 %add.i.4.i381, %40
  %or.i25.i.4.i388 = or i64 %xor.i23.i.4.i386, %xor1.i24.i.4.i387
  %xor2.i26.i.4.i389 = xor i64 %or.i25.i.4.i388, %add3.i.4.i383
  %shr.i30.i.4.i390 = or i64 %xor2.i26.i.4.i389, %xor2.i.i.4.i385
  %or29.i.4.i391 = lshr i64 %shr.i30.i.4.i390, 63
  %42 = load i64, i64* %arrayidx.i.5.i285, align 8, !tbaa !3
  %add.i.5.i393 = add i64 %or29.i.4.i391, %42
  %add3.i.5.i395 = add i64 %add.i.5.i393, %42
  %arrayidx5.i.5.i396 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i395, i64* %arrayidx5.i.5.i396, align 8, !tbaa !3
  %43 = xor i64 %add.i.5.i393, -9223372036854775808
  %xor2.i.i.5.i397 = and i64 %43, %42
  %xor.i23.i.5.i398 = xor i64 %add3.i.5.i395, %add.i.5.i393
  %xor1.i24.i.5.i399 = xor i64 %add.i.5.i393, %42
  %or.i25.i.5.i400 = or i64 %xor.i23.i.5.i398, %xor1.i24.i.5.i399
  %xor2.i26.i.5.i401 = xor i64 %or.i25.i.5.i400, %add3.i.5.i395
  %shr.i30.i.5.i402 = or i64 %xor2.i26.i.5.i401, %xor2.i.i.5.i397
  %or29.i.5.i403 = lshr i64 %shr.i30.i.5.i402, 63
  %44 = load i64, i64* %arrayidx.i.6.i297, align 16, !tbaa !3
  %add.i.6.i405 = add i64 %or29.i.5.i403, %44
  %add3.i.6.i407 = add i64 %add.i.6.i405, %44
  %arrayidx5.i.6.i408 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i407, i64* %arrayidx5.i.6.i408, align 16, !tbaa !3
  %45 = xor i64 %add.i.6.i405, -9223372036854775808
  %xor2.i.i.6.i409 = and i64 %45, %44
  %xor.i23.i.6.i410 = xor i64 %add3.i.6.i407, %add.i.6.i405
  %xor1.i24.i.6.i411 = xor i64 %add.i.6.i405, %44
  %or.i25.i.6.i412 = or i64 %xor.i23.i.6.i410, %xor1.i24.i.6.i411
  %xor2.i26.i.6.i413 = xor i64 %or.i25.i.6.i412, %add3.i.6.i407
  %shr.i30.i.6.i414 = or i64 %xor2.i26.i.6.i413, %xor2.i.i.6.i409
  %or29.i.6.i415 = lshr i64 %shr.i30.i.6.i414, 63
  %46 = load i64, i64* %arrayidx.i.7.i309, align 8, !tbaa !3
  %add.i.7.i417 = add i64 %or29.i.6.i415, %46
  %add3.i.7.i419 = add i64 %add.i.7.i417, %46
  %arrayidx5.i.7.i420 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i419, i64* %arrayidx5.i.7.i420, align 8, !tbaa !3
  %47 = xor i64 %add.i.7.i417, -9223372036854775808
  %xor2.i.i.7.i421 = and i64 %47, %46
  %xor.i23.i.7.i422 = xor i64 %add3.i.7.i419, %add.i.7.i417
  %xor1.i24.i.7.i423 = xor i64 %add.i.7.i417, %46
  %or.i25.i.7.i424 = or i64 %xor.i23.i.7.i422, %xor1.i24.i.7.i423
  %xor2.i26.i.7.i425 = xor i64 %or.i25.i.7.i424, %add3.i.7.i419
  %shr.i30.i.7.i426 = or i64 %xor2.i26.i.7.i425, %xor2.i.i.7.i421
  %or29.i.7.i427 = lshr i64 %shr.i30.i.7.i426, 63
  %48 = load i64, i64* %arrayidx.i.8.i321, align 16, !tbaa !3
  %add.i.8.i429 = add i64 %or29.i.7.i427, %48
  %add3.i.8.i431 = add i64 %add.i.8.i429, %48
  %arrayidx5.i.8.i432 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i431, i64* %arrayidx5.i.8.i432, align 16, !tbaa !3
  %49 = xor i64 %add.i.8.i429, -9223372036854775808
  %xor2.i.i.8.i433 = and i64 %49, %48
  %xor.i23.i.8.i434 = xor i64 %add3.i.8.i431, %add.i.8.i429
  %xor1.i24.i.8.i435 = xor i64 %add.i.8.i429, %48
  %or.i25.i.8.i436 = or i64 %xor.i23.i.8.i434, %xor1.i24.i.8.i435
  %xor2.i26.i.8.i437 = xor i64 %or.i25.i.8.i436, %add3.i.8.i431
  %shr.i30.i.8.i438 = or i64 %xor2.i26.i.8.i437, %xor2.i.i.8.i433
  %or29.i.8.i439 = lshr i64 %shr.i30.i.8.i438, 63
  %50 = load i64, i64* %arrayidx.i.9.i333, align 8, !tbaa !3
  %factor = shl i64 %50, 1
  %add3.i.9.i443 = or i64 %or29.i.8.i439, %factor
  %arrayidx5.i.9.i444 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i443, i64* %arrayidx5.i.9.i444, align 8, !tbaa !3
  %51 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i99, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i81) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i84) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i99) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay13.i) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i99, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay2.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %51, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay8.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %51) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  %52 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %53 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i118 = add i64 %53, %52
  store i64 %add3.i.i118, i64* %arraydecay.i, align 8, !tbaa !3
  %xor.i23.i.i119 = xor i64 %add3.i.i118, %52
  %xor1.i24.i.i120 = xor i64 %53, %52
  %or.i25.i.i121 = or i64 %xor.i23.i.i119, %xor1.i24.i.i120
  %xor2.i26.i.i122 = xor i64 %or.i25.i.i121, %add3.i.i118
  %or29.i.i123 = lshr i64 %xor2.i26.i.i122, 63
  %54 = load i64, i64* %arrayidx.i.1.i237, align 8, !tbaa !3
  %add.i.1.i125 = add i64 %or29.i.i123, %54
  %arrayidx2.i.1.i126 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %55 = load i64, i64* %arrayidx2.i.1.i126, align 8, !tbaa !3
  %add3.i.1.i127 = add i64 %add.i.1.i125, %55
  %arrayidx5.i.1.i128 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 1
  store i64 %add3.i.1.i127, i64* %arrayidx5.i.1.i128, align 8, !tbaa !3
  %56 = xor i64 %add.i.1.i125, -9223372036854775808
  %xor2.i.i.1.i129 = and i64 %56, %54
  %xor.i23.i.1.i130 = xor i64 %add3.i.1.i127, %add.i.1.i125
  %xor1.i24.i.1.i131 = xor i64 %add.i.1.i125, %55
  %or.i25.i.1.i132 = or i64 %xor.i23.i.1.i130, %xor1.i24.i.1.i131
  %xor2.i26.i.1.i133 = xor i64 %or.i25.i.1.i132, %add3.i.1.i127
  %shr.i30.i.1.i134 = or i64 %xor2.i26.i.1.i133, %xor2.i.i.1.i129
  %or29.i.1.i135 = lshr i64 %shr.i30.i.1.i134, 63
  %57 = load i64, i64* %arrayidx.i.2.i249, align 16, !tbaa !3
  %add.i.2.i137 = add i64 %or29.i.1.i135, %57
  %arrayidx2.i.2.i138 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %58 = load i64, i64* %arrayidx2.i.2.i138, align 16, !tbaa !3
  %add3.i.2.i139 = add i64 %add.i.2.i137, %58
  %arrayidx5.i.2.i140 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 2
  store i64 %add3.i.2.i139, i64* %arrayidx5.i.2.i140, align 8, !tbaa !3
  %59 = xor i64 %add.i.2.i137, -9223372036854775808
  %xor2.i.i.2.i141 = and i64 %59, %57
  %xor.i23.i.2.i142 = xor i64 %add3.i.2.i139, %add.i.2.i137
  %xor1.i24.i.2.i143 = xor i64 %add.i.2.i137, %58
  %or.i25.i.2.i144 = or i64 %xor.i23.i.2.i142, %xor1.i24.i.2.i143
  %xor2.i26.i.2.i145 = xor i64 %or.i25.i.2.i144, %add3.i.2.i139
  %shr.i30.i.2.i146 = or i64 %xor2.i26.i.2.i145, %xor2.i.i.2.i141
  %or29.i.2.i147 = lshr i64 %shr.i30.i.2.i146, 63
  %60 = load i64, i64* %arrayidx.i.3.i261, align 8, !tbaa !3
  %add.i.3.i149 = add i64 %or29.i.2.i147, %60
  %arrayidx2.i.3.i150 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %61 = load i64, i64* %arrayidx2.i.3.i150, align 8, !tbaa !3
  %add3.i.3.i151 = add i64 %add.i.3.i149, %61
  %arrayidx5.i.3.i152 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 3
  store i64 %add3.i.3.i151, i64* %arrayidx5.i.3.i152, align 8, !tbaa !3
  %62 = xor i64 %add.i.3.i149, -9223372036854775808
  %xor2.i.i.3.i153 = and i64 %62, %60
  %xor.i23.i.3.i154 = xor i64 %add3.i.3.i151, %add.i.3.i149
  %xor1.i24.i.3.i155 = xor i64 %add.i.3.i149, %61
  %or.i25.i.3.i156 = or i64 %xor.i23.i.3.i154, %xor1.i24.i.3.i155
  %xor2.i26.i.3.i157 = xor i64 %or.i25.i.3.i156, %add3.i.3.i151
  %shr.i30.i.3.i158 = or i64 %xor2.i26.i.3.i157, %xor2.i.i.3.i153
  %or29.i.3.i159 = lshr i64 %shr.i30.i.3.i158, 63
  %63 = load i64, i64* %arrayidx.i.4.i273, align 16, !tbaa !3
  %add.i.4.i161 = add i64 %or29.i.3.i159, %63
  %arrayidx2.i.4.i162 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %64 = load i64, i64* %arrayidx2.i.4.i162, align 16, !tbaa !3
  %add3.i.4.i163 = add i64 %add.i.4.i161, %64
  %arrayidx5.i.4.i164 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 4
  store i64 %add3.i.4.i163, i64* %arrayidx5.i.4.i164, align 8, !tbaa !3
  %65 = xor i64 %add.i.4.i161, -9223372036854775808
  %xor2.i.i.4.i165 = and i64 %65, %63
  %xor.i23.i.4.i166 = xor i64 %add3.i.4.i163, %add.i.4.i161
  %xor1.i24.i.4.i167 = xor i64 %add.i.4.i161, %64
  %or.i25.i.4.i168 = or i64 %xor.i23.i.4.i166, %xor1.i24.i.4.i167
  %xor2.i26.i.4.i169 = xor i64 %or.i25.i.4.i168, %add3.i.4.i163
  %shr.i30.i.4.i170 = or i64 %xor2.i26.i.4.i169, %xor2.i.i.4.i165
  %or29.i.4.i171 = lshr i64 %shr.i30.i.4.i170, 63
  %66 = load i64, i64* %arrayidx.i.5.i285, align 8, !tbaa !3
  %add.i.5.i173 = add i64 %or29.i.4.i171, %66
  %arrayidx2.i.5.i174 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %67 = load i64, i64* %arrayidx2.i.5.i174, align 8, !tbaa !3
  %add3.i.5.i175 = add i64 %add.i.5.i173, %67
  %arrayidx5.i.5.i176 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 5
  store i64 %add3.i.5.i175, i64* %arrayidx5.i.5.i176, align 8, !tbaa !3
  %68 = xor i64 %add.i.5.i173, -9223372036854775808
  %xor2.i.i.5.i177 = and i64 %68, %66
  %xor.i23.i.5.i178 = xor i64 %add3.i.5.i175, %add.i.5.i173
  %xor1.i24.i.5.i179 = xor i64 %add.i.5.i173, %67
  %or.i25.i.5.i180 = or i64 %xor.i23.i.5.i178, %xor1.i24.i.5.i179
  %xor2.i26.i.5.i181 = xor i64 %or.i25.i.5.i180, %add3.i.5.i175
  %shr.i30.i.5.i182 = or i64 %xor2.i26.i.5.i181, %xor2.i.i.5.i177
  %or29.i.5.i183 = lshr i64 %shr.i30.i.5.i182, 63
  %69 = load i64, i64* %arrayidx.i.6.i297, align 16, !tbaa !3
  %add.i.6.i185 = add i64 %or29.i.5.i183, %69
  %arrayidx2.i.6.i186 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %70 = load i64, i64* %arrayidx2.i.6.i186, align 16, !tbaa !3
  %add3.i.6.i187 = add i64 %add.i.6.i185, %70
  %arrayidx5.i.6.i188 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 6
  store i64 %add3.i.6.i187, i64* %arrayidx5.i.6.i188, align 8, !tbaa !3
  %71 = xor i64 %add.i.6.i185, -9223372036854775808
  %xor2.i.i.6.i189 = and i64 %71, %69
  %xor.i23.i.6.i190 = xor i64 %add3.i.6.i187, %add.i.6.i185
  %xor1.i24.i.6.i191 = xor i64 %add.i.6.i185, %70
  %or.i25.i.6.i192 = or i64 %xor.i23.i.6.i190, %xor1.i24.i.6.i191
  %xor2.i26.i.6.i193 = xor i64 %or.i25.i.6.i192, %add3.i.6.i187
  %shr.i30.i.6.i194 = or i64 %xor2.i26.i.6.i193, %xor2.i.i.6.i189
  %or29.i.6.i195 = lshr i64 %shr.i30.i.6.i194, 63
  %72 = load i64, i64* %arrayidx.i.7.i309, align 8, !tbaa !3
  %add.i.7.i197 = add i64 %or29.i.6.i195, %72
  %arrayidx2.i.7.i198 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %73 = load i64, i64* %arrayidx2.i.7.i198, align 8, !tbaa !3
  %add3.i.7.i199 = add i64 %add.i.7.i197, %73
  %arrayidx5.i.7.i200 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 7
  store i64 %add3.i.7.i199, i64* %arrayidx5.i.7.i200, align 8, !tbaa !3
  %74 = xor i64 %add.i.7.i197, -9223372036854775808
  %xor2.i.i.7.i201 = and i64 %74, %72
  %xor.i23.i.7.i202 = xor i64 %add3.i.7.i199, %add.i.7.i197
  %xor1.i24.i.7.i203 = xor i64 %add.i.7.i197, %73
  %or.i25.i.7.i204 = or i64 %xor.i23.i.7.i202, %xor1.i24.i.7.i203
  %xor2.i26.i.7.i205 = xor i64 %or.i25.i.7.i204, %add3.i.7.i199
  %shr.i30.i.7.i206 = or i64 %xor2.i26.i.7.i205, %xor2.i.i.7.i201
  %or29.i.7.i207 = lshr i64 %shr.i30.i.7.i206, 63
  %75 = load i64, i64* %arrayidx.i.8.i321, align 16, !tbaa !3
  %add.i.8.i209 = add i64 %or29.i.7.i207, %75
  %arrayidx2.i.8.i210 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %76 = load i64, i64* %arrayidx2.i.8.i210, align 16, !tbaa !3
  %add3.i.8.i211 = add i64 %add.i.8.i209, %76
  %arrayidx5.i.8.i212 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 8
  store i64 %add3.i.8.i211, i64* %arrayidx5.i.8.i212, align 8, !tbaa !3
  %77 = xor i64 %add.i.8.i209, -9223372036854775808
  %xor2.i.i.8.i213 = and i64 %77, %75
  %xor.i23.i.8.i214 = xor i64 %add3.i.8.i211, %add.i.8.i209
  %xor1.i24.i.8.i215 = xor i64 %add.i.8.i209, %76
  %or.i25.i.8.i216 = or i64 %xor.i23.i.8.i214, %xor1.i24.i.8.i215
  %xor2.i26.i.8.i217 = xor i64 %or.i25.i.8.i216, %add3.i.8.i211
  %shr.i30.i.8.i218 = or i64 %xor2.i26.i.8.i217, %xor2.i.i.8.i213
  %or29.i.8.i219 = lshr i64 %shr.i30.i.8.i218, 63
  %78 = load i64, i64* %arrayidx.i.9.i333, align 8, !tbaa !3
  %arrayidx2.i.9.i222 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %79 = load i64, i64* %arrayidx2.i.9.i222, align 8, !tbaa !3
  %add.i.9.i221 = add i64 %79, %78
  %add3.i.9.i223 = add i64 %add.i.9.i221, %or29.i.8.i219
  %arrayidx5.i.9.i224 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 9
  store i64 %add3.i.9.i223, i64* %arrayidx5.i.9.i224, align 8, !tbaa !3
  %80 = load i64, i64* %arraydecay10.i84, align 16, !tbaa !3
  %81 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i = add i64 %81, %80
  store i64 %add3.i.i, i64* %arraydecay6.i, align 8, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %80
  %xor1.i24.i.i = xor i64 %81, %80
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %82 = load i64, i64* %arrayidx2.i.1.i239, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %82
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %83 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %83
  %arrayidx5.i.1.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %84 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %84, %82
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %83
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %85 = load i64, i64* %arrayidx2.i.2.i251, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %85
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %86 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %86
  %arrayidx5.i.2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 8, !tbaa !3
  %87 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %87, %85
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %86
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %88 = load i64, i64* %arrayidx2.i.3.i263, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %88
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %89 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %89
  %arrayidx5.i.3.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %90 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %90, %88
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %89
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %91 = load i64, i64* %arrayidx2.i.4.i275, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %91
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %92 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %92
  %arrayidx5.i.4.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 8, !tbaa !3
  %93 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %93, %91
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %92
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %94 = load i64, i64* %arrayidx2.i.5.i287, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %94
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %95 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %95
  %arrayidx5.i.5.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %96 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %96, %94
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %95
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %97 = load i64, i64* %arrayidx2.i.6.i299, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %97
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %98 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %98
  %arrayidx5.i.6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 8, !tbaa !3
  %99 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %99, %97
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %98
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %100 = load i64, i64* %arrayidx2.i.7.i311, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %100
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %101 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %101
  %arrayidx5.i.7.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %102 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %102, %100
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %101
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %103 = load i64, i64* %arrayidx2.i.8.i323, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %103
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %104 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %104
  %arrayidx5.i.8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 8, !tbaa !3
  %105 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %105, %103
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %104
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %106 = load i64, i64* %arrayidx2.i.9.i335, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %107 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %107, %106
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p2(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @fp2mul610_mont([10 x i64]* %arraydecay, [10 x i64]* nonnull %arraydecay7, [10 x i64]* %arraydecay)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay1)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xTPL(%struct.point_proj* %P, %struct.point_proj* %Q, [10 x i64]* %A24minus, [10 x i64]* %A24plus) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %t3 = alloca [2 x [10 x i64]], align 16
  %t4 = alloca [2 x [10 x i64]], align 16
  %t5 = alloca [2 x [10 x i64]], align 16
  %t6 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = bitcast [2 x [10 x i64]]* %t3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  %4 = bitcast [2 x [10 x i64]]* %t4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  %5 = bitcast [2 x [10 x i64]]* %t5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  %6 = bitcast [2 x [10 x i64]]* %t6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %6) #10
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay4 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  %7 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  %8 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  %9 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  %10 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %11 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i = add i64 %11, %10
  store i64 %add3.i.i, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %10
  %xor1.i24.i.i = xor i64 %11, %10
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %12 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %12
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %13 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %13
  %arrayidx5.i.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %14 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %14, %12
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %13
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %15 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %15
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %16 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %16
  %arrayidx5.i.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %17 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %17, %15
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %16
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %18 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %18
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %19 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %19
  %arrayidx5.i.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %20 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %20, %18
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %19
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %21 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %21
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %22 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %22
  %arrayidx5.i.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %23 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %23, %21
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %22
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %24 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %24
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %25 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %25
  %arrayidx5.i.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %26 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %26, %24
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %25
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %27 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %27
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %28 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %28
  %arrayidx5.i.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %29 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %29, %27
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %28
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %30 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %30
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %31 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %31
  %arrayidx5.i.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %32 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %32, %30
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %31
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %33 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %33
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %34 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %34
  %arrayidx5.i.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %35 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %35, %33
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %34
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %36 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %37 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %37, %36
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %arraydecay8.i77 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i77) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  %38 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i180 = shl i64 %38, 1
  store i64 %add3.i.i180, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i185 = lshr i64 %38, 63
  %39 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i187 = add i64 %39, %or29.i.i185
  %add3.i.1.i189 = add i64 %add.i.1.i187, %39
  %arrayidx5.i.1.i190 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i189, i64* %arrayidx5.i.1.i190, align 8, !tbaa !3
  %40 = xor i64 %add.i.1.i187, -9223372036854775808
  %xor2.i.i.1.i191 = and i64 %40, %39
  %xor.i23.i.1.i192 = xor i64 %add3.i.1.i189, %add.i.1.i187
  %xor1.i24.i.1.i193 = xor i64 %add.i.1.i187, %39
  %or.i25.i.1.i194 = or i64 %xor.i23.i.1.i192, %xor1.i24.i.1.i193
  %xor2.i26.i.1.i195 = xor i64 %or.i25.i.1.i194, %add3.i.1.i189
  %shr.i30.i.1.i196 = or i64 %xor2.i26.i.1.i195, %xor2.i.i.1.i191
  %or29.i.1.i197 = lshr i64 %shr.i30.i.1.i196, 63
  %41 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i199 = add i64 %or29.i.1.i197, %41
  %add3.i.2.i201 = add i64 %add.i.2.i199, %41
  %arrayidx5.i.2.i202 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i201, i64* %arrayidx5.i.2.i202, align 16, !tbaa !3
  %42 = xor i64 %add.i.2.i199, -9223372036854775808
  %xor2.i.i.2.i203 = and i64 %42, %41
  %xor.i23.i.2.i204 = xor i64 %add3.i.2.i201, %add.i.2.i199
  %xor1.i24.i.2.i205 = xor i64 %add.i.2.i199, %41
  %or.i25.i.2.i206 = or i64 %xor.i23.i.2.i204, %xor1.i24.i.2.i205
  %xor2.i26.i.2.i207 = xor i64 %or.i25.i.2.i206, %add3.i.2.i201
  %shr.i30.i.2.i208 = or i64 %xor2.i26.i.2.i207, %xor2.i.i.2.i203
  %or29.i.2.i209 = lshr i64 %shr.i30.i.2.i208, 63
  %43 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i211 = add i64 %or29.i.2.i209, %43
  %add3.i.3.i213 = add i64 %add.i.3.i211, %43
  %arrayidx5.i.3.i214 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i213, i64* %arrayidx5.i.3.i214, align 8, !tbaa !3
  %44 = xor i64 %add.i.3.i211, -9223372036854775808
  %xor2.i.i.3.i215 = and i64 %44, %43
  %xor.i23.i.3.i216 = xor i64 %add3.i.3.i213, %add.i.3.i211
  %xor1.i24.i.3.i217 = xor i64 %add.i.3.i211, %43
  %or.i25.i.3.i218 = or i64 %xor.i23.i.3.i216, %xor1.i24.i.3.i217
  %xor2.i26.i.3.i219 = xor i64 %or.i25.i.3.i218, %add3.i.3.i213
  %shr.i30.i.3.i220 = or i64 %xor2.i26.i.3.i219, %xor2.i.i.3.i215
  %or29.i.3.i221 = lshr i64 %shr.i30.i.3.i220, 63
  %45 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i223 = add i64 %or29.i.3.i221, %45
  %add3.i.4.i225 = add i64 %add.i.4.i223, %45
  %arrayidx5.i.4.i226 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i225, i64* %arrayidx5.i.4.i226, align 16, !tbaa !3
  %46 = xor i64 %add.i.4.i223, -9223372036854775808
  %xor2.i.i.4.i227 = and i64 %46, %45
  %xor.i23.i.4.i228 = xor i64 %add3.i.4.i225, %add.i.4.i223
  %xor1.i24.i.4.i229 = xor i64 %add.i.4.i223, %45
  %or.i25.i.4.i230 = or i64 %xor.i23.i.4.i228, %xor1.i24.i.4.i229
  %xor2.i26.i.4.i231 = xor i64 %or.i25.i.4.i230, %add3.i.4.i225
  %shr.i30.i.4.i232 = or i64 %xor2.i26.i.4.i231, %xor2.i.i.4.i227
  %or29.i.4.i233 = lshr i64 %shr.i30.i.4.i232, 63
  %47 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i235 = add i64 %or29.i.4.i233, %47
  %add3.i.5.i237 = add i64 %add.i.5.i235, %47
  %arrayidx5.i.5.i238 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i237, i64* %arrayidx5.i.5.i238, align 8, !tbaa !3
  %48 = xor i64 %add.i.5.i235, -9223372036854775808
  %xor2.i.i.5.i239 = and i64 %48, %47
  %xor.i23.i.5.i240 = xor i64 %add3.i.5.i237, %add.i.5.i235
  %xor1.i24.i.5.i241 = xor i64 %add.i.5.i235, %47
  %or.i25.i.5.i242 = or i64 %xor.i23.i.5.i240, %xor1.i24.i.5.i241
  %xor2.i26.i.5.i243 = xor i64 %or.i25.i.5.i242, %add3.i.5.i237
  %shr.i30.i.5.i244 = or i64 %xor2.i26.i.5.i243, %xor2.i.i.5.i239
  %or29.i.5.i245 = lshr i64 %shr.i30.i.5.i244, 63
  %49 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i247 = add i64 %or29.i.5.i245, %49
  %add3.i.6.i249 = add i64 %add.i.6.i247, %49
  %arrayidx5.i.6.i250 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i249, i64* %arrayidx5.i.6.i250, align 16, !tbaa !3
  %50 = xor i64 %add.i.6.i247, -9223372036854775808
  %xor2.i.i.6.i251 = and i64 %50, %49
  %xor.i23.i.6.i252 = xor i64 %add3.i.6.i249, %add.i.6.i247
  %xor1.i24.i.6.i253 = xor i64 %add.i.6.i247, %49
  %or.i25.i.6.i254 = or i64 %xor.i23.i.6.i252, %xor1.i24.i.6.i253
  %xor2.i26.i.6.i255 = xor i64 %or.i25.i.6.i254, %add3.i.6.i249
  %shr.i30.i.6.i256 = or i64 %xor2.i26.i.6.i255, %xor2.i.i.6.i251
  %or29.i.6.i257 = lshr i64 %shr.i30.i.6.i256, 63
  %51 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i259 = add i64 %or29.i.6.i257, %51
  %add3.i.7.i261 = add i64 %add.i.7.i259, %51
  %arrayidx5.i.7.i262 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i261, i64* %arrayidx5.i.7.i262, align 8, !tbaa !3
  %52 = xor i64 %add.i.7.i259, -9223372036854775808
  %xor2.i.i.7.i263 = and i64 %52, %51
  %xor.i23.i.7.i264 = xor i64 %add3.i.7.i261, %add.i.7.i259
  %xor1.i24.i.7.i265 = xor i64 %add.i.7.i259, %51
  %or.i25.i.7.i266 = or i64 %xor.i23.i.7.i264, %xor1.i24.i.7.i265
  %xor2.i26.i.7.i267 = xor i64 %or.i25.i.7.i266, %add3.i.7.i261
  %shr.i30.i.7.i268 = or i64 %xor2.i26.i.7.i267, %xor2.i.i.7.i263
  %or29.i.7.i269 = lshr i64 %shr.i30.i.7.i268, 63
  %53 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i271 = add i64 %or29.i.7.i269, %53
  %add3.i.8.i273 = add i64 %add.i.8.i271, %53
  %arrayidx5.i.8.i274 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i273, i64* %arrayidx5.i.8.i274, align 16, !tbaa !3
  %54 = xor i64 %add.i.8.i271, -9223372036854775808
  %xor2.i.i.8.i275 = and i64 %54, %53
  %xor.i23.i.8.i276 = xor i64 %add3.i.8.i273, %add.i.8.i271
  %xor1.i24.i.8.i277 = xor i64 %add.i.8.i271, %53
  %or.i25.i.8.i278 = or i64 %xor.i23.i.8.i276, %xor1.i24.i.8.i277
  %xor2.i26.i.8.i279 = xor i64 %or.i25.i.8.i278, %add3.i.8.i273
  %shr.i30.i.8.i280 = or i64 %xor2.i26.i.8.i279, %xor2.i.i.8.i275
  %or29.i.8.i281 = lshr i64 %shr.i30.i.8.i280, 63
  %55 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor = shl i64 %55, 1
  %add3.i.9.i285 = or i64 %or29.i.8.i281, %factor
  %arrayidx5.i.9.i286 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i285, i64* %arrayidx5.i.9.i286, align 8, !tbaa !3
  %arraydecay17.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  %56 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i77, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  %arraydecay22.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  %arraydecay9 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i80 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i80) #10
  %arraydecay10.i83 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i83) #10
  %arraydecay11 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %57 = load i64, i64* %arraydecay4.i80, align 16, !tbaa !3
  %58 = load i64, i64* %arraydecay10.i83, align 16, !tbaa !3
  %add3.i.i287 = add i64 %58, %57
  store i64 %add3.i.i287, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i288 = xor i64 %add3.i.i287, %57
  %xor1.i24.i.i289 = xor i64 %58, %57
  %or.i25.i.i290 = or i64 %xor.i23.i.i288, %xor1.i24.i.i289
  %xor2.i26.i.i291 = xor i64 %or.i25.i.i290, %add3.i.i287
  %or29.i.i292 = lshr i64 %xor2.i26.i.i291, 63
  %arrayidx.i.1.i293 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %59 = load i64, i64* %arrayidx.i.1.i293, align 8, !tbaa !3
  %add.i.1.i294 = add i64 %or29.i.i292, %59
  %arrayidx2.i.1.i295 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %60 = load i64, i64* %arrayidx2.i.1.i295, align 8, !tbaa !3
  %add3.i.1.i296 = add i64 %add.i.1.i294, %60
  store i64 %add3.i.1.i296, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %61 = xor i64 %add.i.1.i294, -9223372036854775808
  %xor2.i.i.1.i298 = and i64 %61, %59
  %xor.i23.i.1.i299 = xor i64 %add3.i.1.i296, %add.i.1.i294
  %xor1.i24.i.1.i300 = xor i64 %add.i.1.i294, %60
  %or.i25.i.1.i301 = or i64 %xor.i23.i.1.i299, %xor1.i24.i.1.i300
  %xor2.i26.i.1.i302 = xor i64 %or.i25.i.1.i301, %add3.i.1.i296
  %shr.i30.i.1.i303 = or i64 %xor2.i26.i.1.i302, %xor2.i.i.1.i298
  %or29.i.1.i304 = lshr i64 %shr.i30.i.1.i303, 63
  %arrayidx.i.2.i305 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %62 = load i64, i64* %arrayidx.i.2.i305, align 16, !tbaa !3
  %add.i.2.i306 = add i64 %or29.i.1.i304, %62
  %arrayidx2.i.2.i307 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %63 = load i64, i64* %arrayidx2.i.2.i307, align 16, !tbaa !3
  %add3.i.2.i308 = add i64 %add.i.2.i306, %63
  store i64 %add3.i.2.i308, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %64 = xor i64 %add.i.2.i306, -9223372036854775808
  %xor2.i.i.2.i310 = and i64 %64, %62
  %xor.i23.i.2.i311 = xor i64 %add3.i.2.i308, %add.i.2.i306
  %xor1.i24.i.2.i312 = xor i64 %add.i.2.i306, %63
  %or.i25.i.2.i313 = or i64 %xor.i23.i.2.i311, %xor1.i24.i.2.i312
  %xor2.i26.i.2.i314 = xor i64 %or.i25.i.2.i313, %add3.i.2.i308
  %shr.i30.i.2.i315 = or i64 %xor2.i26.i.2.i314, %xor2.i.i.2.i310
  %or29.i.2.i316 = lshr i64 %shr.i30.i.2.i315, 63
  %arrayidx.i.3.i317 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %65 = load i64, i64* %arrayidx.i.3.i317, align 8, !tbaa !3
  %add.i.3.i318 = add i64 %or29.i.2.i316, %65
  %arrayidx2.i.3.i319 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %66 = load i64, i64* %arrayidx2.i.3.i319, align 8, !tbaa !3
  %add3.i.3.i320 = add i64 %add.i.3.i318, %66
  store i64 %add3.i.3.i320, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %67 = xor i64 %add.i.3.i318, -9223372036854775808
  %xor2.i.i.3.i322 = and i64 %67, %65
  %xor.i23.i.3.i323 = xor i64 %add3.i.3.i320, %add.i.3.i318
  %xor1.i24.i.3.i324 = xor i64 %add.i.3.i318, %66
  %or.i25.i.3.i325 = or i64 %xor.i23.i.3.i323, %xor1.i24.i.3.i324
  %xor2.i26.i.3.i326 = xor i64 %or.i25.i.3.i325, %add3.i.3.i320
  %shr.i30.i.3.i327 = or i64 %xor2.i26.i.3.i326, %xor2.i.i.3.i322
  %or29.i.3.i328 = lshr i64 %shr.i30.i.3.i327, 63
  %arrayidx.i.4.i329 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %68 = load i64, i64* %arrayidx.i.4.i329, align 16, !tbaa !3
  %add.i.4.i330 = add i64 %or29.i.3.i328, %68
  %arrayidx2.i.4.i331 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %69 = load i64, i64* %arrayidx2.i.4.i331, align 16, !tbaa !3
  %add3.i.4.i332 = add i64 %add.i.4.i330, %69
  store i64 %add3.i.4.i332, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %70 = xor i64 %add.i.4.i330, -9223372036854775808
  %xor2.i.i.4.i334 = and i64 %70, %68
  %xor.i23.i.4.i335 = xor i64 %add3.i.4.i332, %add.i.4.i330
  %xor1.i24.i.4.i336 = xor i64 %add.i.4.i330, %69
  %or.i25.i.4.i337 = or i64 %xor.i23.i.4.i335, %xor1.i24.i.4.i336
  %xor2.i26.i.4.i338 = xor i64 %or.i25.i.4.i337, %add3.i.4.i332
  %shr.i30.i.4.i339 = or i64 %xor2.i26.i.4.i338, %xor2.i.i.4.i334
  %or29.i.4.i340 = lshr i64 %shr.i30.i.4.i339, 63
  %arrayidx.i.5.i341 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %71 = load i64, i64* %arrayidx.i.5.i341, align 8, !tbaa !3
  %add.i.5.i342 = add i64 %or29.i.4.i340, %71
  %arrayidx2.i.5.i343 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %72 = load i64, i64* %arrayidx2.i.5.i343, align 8, !tbaa !3
  %add3.i.5.i344 = add i64 %add.i.5.i342, %72
  store i64 %add3.i.5.i344, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %73 = xor i64 %add.i.5.i342, -9223372036854775808
  %xor2.i.i.5.i346 = and i64 %73, %71
  %xor.i23.i.5.i347 = xor i64 %add3.i.5.i344, %add.i.5.i342
  %xor1.i24.i.5.i348 = xor i64 %add.i.5.i342, %72
  %or.i25.i.5.i349 = or i64 %xor.i23.i.5.i347, %xor1.i24.i.5.i348
  %xor2.i26.i.5.i350 = xor i64 %or.i25.i.5.i349, %add3.i.5.i344
  %shr.i30.i.5.i351 = or i64 %xor2.i26.i.5.i350, %xor2.i.i.5.i346
  %or29.i.5.i352 = lshr i64 %shr.i30.i.5.i351, 63
  %arrayidx.i.6.i353 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %74 = load i64, i64* %arrayidx.i.6.i353, align 16, !tbaa !3
  %add.i.6.i354 = add i64 %or29.i.5.i352, %74
  %arrayidx2.i.6.i355 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %75 = load i64, i64* %arrayidx2.i.6.i355, align 16, !tbaa !3
  %add3.i.6.i356 = add i64 %add.i.6.i354, %75
  store i64 %add3.i.6.i356, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %76 = xor i64 %add.i.6.i354, -9223372036854775808
  %xor2.i.i.6.i358 = and i64 %76, %74
  %xor.i23.i.6.i359 = xor i64 %add3.i.6.i356, %add.i.6.i354
  %xor1.i24.i.6.i360 = xor i64 %add.i.6.i354, %75
  %or.i25.i.6.i361 = or i64 %xor.i23.i.6.i359, %xor1.i24.i.6.i360
  %xor2.i26.i.6.i362 = xor i64 %or.i25.i.6.i361, %add3.i.6.i356
  %shr.i30.i.6.i363 = or i64 %xor2.i26.i.6.i362, %xor2.i.i.6.i358
  %or29.i.6.i364 = lshr i64 %shr.i30.i.6.i363, 63
  %arrayidx.i.7.i365 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %77 = load i64, i64* %arrayidx.i.7.i365, align 8, !tbaa !3
  %add.i.7.i366 = add i64 %or29.i.6.i364, %77
  %arrayidx2.i.7.i367 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %78 = load i64, i64* %arrayidx2.i.7.i367, align 8, !tbaa !3
  %add3.i.7.i368 = add i64 %add.i.7.i366, %78
  store i64 %add3.i.7.i368, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %79 = xor i64 %add.i.7.i366, -9223372036854775808
  %xor2.i.i.7.i370 = and i64 %79, %77
  %xor.i23.i.7.i371 = xor i64 %add3.i.7.i368, %add.i.7.i366
  %xor1.i24.i.7.i372 = xor i64 %add.i.7.i366, %78
  %or.i25.i.7.i373 = or i64 %xor.i23.i.7.i371, %xor1.i24.i.7.i372
  %xor2.i26.i.7.i374 = xor i64 %or.i25.i.7.i373, %add3.i.7.i368
  %shr.i30.i.7.i375 = or i64 %xor2.i26.i.7.i374, %xor2.i.i.7.i370
  %or29.i.7.i376 = lshr i64 %shr.i30.i.7.i375, 63
  %arrayidx.i.8.i377 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %80 = load i64, i64* %arrayidx.i.8.i377, align 16, !tbaa !3
  %add.i.8.i378 = add i64 %or29.i.7.i376, %80
  %arrayidx2.i.8.i379 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %81 = load i64, i64* %arrayidx2.i.8.i379, align 16, !tbaa !3
  %add3.i.8.i380 = add i64 %add.i.8.i378, %81
  store i64 %add3.i.8.i380, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %82 = xor i64 %add.i.8.i378, -9223372036854775808
  %xor2.i.i.8.i382 = and i64 %82, %80
  %xor.i23.i.8.i383 = xor i64 %add3.i.8.i380, %add.i.8.i378
  %xor1.i24.i.8.i384 = xor i64 %add.i.8.i378, %81
  %or.i25.i.8.i385 = or i64 %xor.i23.i.8.i383, %xor1.i24.i.8.i384
  %xor2.i26.i.8.i386 = xor i64 %or.i25.i.8.i385, %add3.i.8.i380
  %shr.i30.i.8.i387 = or i64 %xor2.i26.i.8.i386, %xor2.i.i.8.i382
  %or29.i.8.i388 = lshr i64 %shr.i30.i.8.i387, 63
  %arrayidx.i.9.i389 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %83 = load i64, i64* %arrayidx.i.9.i389, align 8, !tbaa !3
  %arrayidx2.i.9.i391 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %84 = load i64, i64* %arrayidx2.i.9.i391, align 8, !tbaa !3
  %add.i.9.i390 = add i64 %84, %83
  %add3.i.9.i392 = add i64 %add.i.9.i390, %or29.i.8.i388
  store i64 %add3.i.9.i392, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay8.i77) #10
  %85 = load i64, i64* %arraydecay4.i80, align 16, !tbaa !3
  %add3.i.i394 = shl i64 %85, 1
  store i64 %add3.i.i394, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i399 = lshr i64 %85, 63
  %86 = load i64, i64* %arrayidx.i.1.i293, align 8, !tbaa !3
  %add.i.1.i401 = add i64 %86, %or29.i.i399
  %add3.i.1.i403 = add i64 %add.i.1.i401, %86
  store i64 %add3.i.1.i403, i64* %arrayidx5.i.1.i190, align 8, !tbaa !3
  %87 = xor i64 %add.i.1.i401, -9223372036854775808
  %xor2.i.i.1.i405 = and i64 %87, %86
  %xor.i23.i.1.i406 = xor i64 %add3.i.1.i403, %add.i.1.i401
  %xor1.i24.i.1.i407 = xor i64 %add.i.1.i401, %86
  %or.i25.i.1.i408 = or i64 %xor.i23.i.1.i406, %xor1.i24.i.1.i407
  %xor2.i26.i.1.i409 = xor i64 %or.i25.i.1.i408, %add3.i.1.i403
  %shr.i30.i.1.i410 = or i64 %xor2.i26.i.1.i409, %xor2.i.i.1.i405
  %or29.i.1.i411 = lshr i64 %shr.i30.i.1.i410, 63
  %88 = load i64, i64* %arrayidx.i.2.i305, align 16, !tbaa !3
  %add.i.2.i413 = add i64 %or29.i.1.i411, %88
  %add3.i.2.i415 = add i64 %add.i.2.i413, %88
  store i64 %add3.i.2.i415, i64* %arrayidx5.i.2.i202, align 16, !tbaa !3
  %89 = xor i64 %add.i.2.i413, -9223372036854775808
  %xor2.i.i.2.i417 = and i64 %89, %88
  %xor.i23.i.2.i418 = xor i64 %add3.i.2.i415, %add.i.2.i413
  %xor1.i24.i.2.i419 = xor i64 %add.i.2.i413, %88
  %or.i25.i.2.i420 = or i64 %xor.i23.i.2.i418, %xor1.i24.i.2.i419
  %xor2.i26.i.2.i421 = xor i64 %or.i25.i.2.i420, %add3.i.2.i415
  %shr.i30.i.2.i422 = or i64 %xor2.i26.i.2.i421, %xor2.i.i.2.i417
  %or29.i.2.i423 = lshr i64 %shr.i30.i.2.i422, 63
  %90 = load i64, i64* %arrayidx.i.3.i317, align 8, !tbaa !3
  %add.i.3.i425 = add i64 %or29.i.2.i423, %90
  %add3.i.3.i427 = add i64 %add.i.3.i425, %90
  store i64 %add3.i.3.i427, i64* %arrayidx5.i.3.i214, align 8, !tbaa !3
  %91 = xor i64 %add.i.3.i425, -9223372036854775808
  %xor2.i.i.3.i429 = and i64 %91, %90
  %xor.i23.i.3.i430 = xor i64 %add3.i.3.i427, %add.i.3.i425
  %xor1.i24.i.3.i431 = xor i64 %add.i.3.i425, %90
  %or.i25.i.3.i432 = or i64 %xor.i23.i.3.i430, %xor1.i24.i.3.i431
  %xor2.i26.i.3.i433 = xor i64 %or.i25.i.3.i432, %add3.i.3.i427
  %shr.i30.i.3.i434 = or i64 %xor2.i26.i.3.i433, %xor2.i.i.3.i429
  %or29.i.3.i435 = lshr i64 %shr.i30.i.3.i434, 63
  %92 = load i64, i64* %arrayidx.i.4.i329, align 16, !tbaa !3
  %add.i.4.i437 = add i64 %or29.i.3.i435, %92
  %add3.i.4.i439 = add i64 %add.i.4.i437, %92
  store i64 %add3.i.4.i439, i64* %arrayidx5.i.4.i226, align 16, !tbaa !3
  %93 = xor i64 %add.i.4.i437, -9223372036854775808
  %xor2.i.i.4.i441 = and i64 %93, %92
  %xor.i23.i.4.i442 = xor i64 %add3.i.4.i439, %add.i.4.i437
  %xor1.i24.i.4.i443 = xor i64 %add.i.4.i437, %92
  %or.i25.i.4.i444 = or i64 %xor.i23.i.4.i442, %xor1.i24.i.4.i443
  %xor2.i26.i.4.i445 = xor i64 %or.i25.i.4.i444, %add3.i.4.i439
  %shr.i30.i.4.i446 = or i64 %xor2.i26.i.4.i445, %xor2.i.i.4.i441
  %or29.i.4.i447 = lshr i64 %shr.i30.i.4.i446, 63
  %94 = load i64, i64* %arrayidx.i.5.i341, align 8, !tbaa !3
  %add.i.5.i449 = add i64 %or29.i.4.i447, %94
  %add3.i.5.i451 = add i64 %add.i.5.i449, %94
  store i64 %add3.i.5.i451, i64* %arrayidx5.i.5.i238, align 8, !tbaa !3
  %95 = xor i64 %add.i.5.i449, -9223372036854775808
  %xor2.i.i.5.i453 = and i64 %95, %94
  %xor.i23.i.5.i454 = xor i64 %add3.i.5.i451, %add.i.5.i449
  %xor1.i24.i.5.i455 = xor i64 %add.i.5.i449, %94
  %or.i25.i.5.i456 = or i64 %xor.i23.i.5.i454, %xor1.i24.i.5.i455
  %xor2.i26.i.5.i457 = xor i64 %or.i25.i.5.i456, %add3.i.5.i451
  %shr.i30.i.5.i458 = or i64 %xor2.i26.i.5.i457, %xor2.i.i.5.i453
  %or29.i.5.i459 = lshr i64 %shr.i30.i.5.i458, 63
  %96 = load i64, i64* %arrayidx.i.6.i353, align 16, !tbaa !3
  %add.i.6.i461 = add i64 %or29.i.5.i459, %96
  %add3.i.6.i463 = add i64 %add.i.6.i461, %96
  store i64 %add3.i.6.i463, i64* %arrayidx5.i.6.i250, align 16, !tbaa !3
  %97 = xor i64 %add.i.6.i461, -9223372036854775808
  %xor2.i.i.6.i465 = and i64 %97, %96
  %xor.i23.i.6.i466 = xor i64 %add3.i.6.i463, %add.i.6.i461
  %xor1.i24.i.6.i467 = xor i64 %add.i.6.i461, %96
  %or.i25.i.6.i468 = or i64 %xor.i23.i.6.i466, %xor1.i24.i.6.i467
  %xor2.i26.i.6.i469 = xor i64 %or.i25.i.6.i468, %add3.i.6.i463
  %shr.i30.i.6.i470 = or i64 %xor2.i26.i.6.i469, %xor2.i.i.6.i465
  %or29.i.6.i471 = lshr i64 %shr.i30.i.6.i470, 63
  %98 = load i64, i64* %arrayidx.i.7.i365, align 8, !tbaa !3
  %add.i.7.i473 = add i64 %or29.i.6.i471, %98
  %add3.i.7.i475 = add i64 %add.i.7.i473, %98
  store i64 %add3.i.7.i475, i64* %arrayidx5.i.7.i262, align 8, !tbaa !3
  %99 = xor i64 %add.i.7.i473, -9223372036854775808
  %xor2.i.i.7.i477 = and i64 %99, %98
  %xor.i23.i.7.i478 = xor i64 %add3.i.7.i475, %add.i.7.i473
  %xor1.i24.i.7.i479 = xor i64 %add.i.7.i473, %98
  %or.i25.i.7.i480 = or i64 %xor.i23.i.7.i478, %xor1.i24.i.7.i479
  %xor2.i26.i.7.i481 = xor i64 %or.i25.i.7.i480, %add3.i.7.i475
  %shr.i30.i.7.i482 = or i64 %xor2.i26.i.7.i481, %xor2.i.i.7.i477
  %or29.i.7.i483 = lshr i64 %shr.i30.i.7.i482, 63
  %100 = load i64, i64* %arrayidx.i.8.i377, align 16, !tbaa !3
  %add.i.8.i485 = add i64 %or29.i.7.i483, %100
  %add3.i.8.i487 = add i64 %add.i.8.i485, %100
  store i64 %add3.i.8.i487, i64* %arrayidx5.i.8.i274, align 16, !tbaa !3
  %101 = xor i64 %add.i.8.i485, -9223372036854775808
  %xor2.i.i.8.i489 = and i64 %101, %100
  %xor.i23.i.8.i490 = xor i64 %add3.i.8.i487, %add.i.8.i485
  %xor1.i24.i.8.i491 = xor i64 %add.i.8.i485, %100
  %or.i25.i.8.i492 = or i64 %xor.i23.i.8.i490, %xor1.i24.i.8.i491
  %xor2.i26.i.8.i493 = xor i64 %or.i25.i.8.i492, %add3.i.8.i487
  %shr.i30.i.8.i494 = or i64 %xor2.i26.i.8.i493, %xor2.i.i.8.i489
  %or29.i.8.i495 = lshr i64 %shr.i30.i.8.i494, 63
  %102 = load i64, i64* %arrayidx.i.9.i389, align 8, !tbaa !3
  %factor1143 = shl i64 %102, 1
  %add3.i.9.i499 = or i64 %or29.i.8.i495, %factor1143
  store i64 %add3.i.9.i499, i64* %arrayidx5.i.9.i286, align 8, !tbaa !3
  %arraydecay17.i93 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i77, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i93) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  %arraydecay22.i95 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i95) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  %arraydecay16 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0
  %arraydecay4.i98 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay4.i98) #10
  %arraydecay10.i101 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay10.i101) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %103 = load i64, i64* %arraydecay4.i98, align 16, !tbaa !3
  %104 = load i64, i64* %arraydecay10.i101, align 16, !tbaa !3
  %add3.i.i608 = add i64 %104, %103
  store i64 %add3.i.i608, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i609 = xor i64 %add3.i.i608, %103
  %xor1.i24.i.i610 = xor i64 %104, %103
  %or.i25.i.i611 = or i64 %xor.i23.i.i609, %xor1.i24.i.i610
  %xor2.i26.i.i612 = xor i64 %or.i25.i.i611, %add3.i.i608
  %or29.i.i613 = lshr i64 %xor2.i26.i.i612, 63
  %arrayidx.i.1.i614 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 1
  %105 = load i64, i64* %arrayidx.i.1.i614, align 8, !tbaa !3
  %add.i.1.i615 = add i64 %or29.i.i613, %105
  %arrayidx2.i.1.i616 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 1
  %106 = load i64, i64* %arrayidx2.i.1.i616, align 8, !tbaa !3
  %add3.i.1.i617 = add i64 %add.i.1.i615, %106
  store i64 %add3.i.1.i617, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %107 = xor i64 %add.i.1.i615, -9223372036854775808
  %xor2.i.i.1.i619 = and i64 %107, %105
  %xor.i23.i.1.i620 = xor i64 %add3.i.1.i617, %add.i.1.i615
  %xor1.i24.i.1.i621 = xor i64 %add.i.1.i615, %106
  %or.i25.i.1.i622 = or i64 %xor.i23.i.1.i620, %xor1.i24.i.1.i621
  %xor2.i26.i.1.i623 = xor i64 %or.i25.i.1.i622, %add3.i.1.i617
  %shr.i30.i.1.i624 = or i64 %xor2.i26.i.1.i623, %xor2.i.i.1.i619
  %or29.i.1.i625 = lshr i64 %shr.i30.i.1.i624, 63
  %arrayidx.i.2.i626 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 2
  %108 = load i64, i64* %arrayidx.i.2.i626, align 16, !tbaa !3
  %add.i.2.i627 = add i64 %or29.i.1.i625, %108
  %arrayidx2.i.2.i628 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 2
  %109 = load i64, i64* %arrayidx2.i.2.i628, align 16, !tbaa !3
  %add3.i.2.i629 = add i64 %add.i.2.i627, %109
  store i64 %add3.i.2.i629, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %110 = xor i64 %add.i.2.i627, -9223372036854775808
  %xor2.i.i.2.i631 = and i64 %110, %108
  %xor.i23.i.2.i632 = xor i64 %add3.i.2.i629, %add.i.2.i627
  %xor1.i24.i.2.i633 = xor i64 %add.i.2.i627, %109
  %or.i25.i.2.i634 = or i64 %xor.i23.i.2.i632, %xor1.i24.i.2.i633
  %xor2.i26.i.2.i635 = xor i64 %or.i25.i.2.i634, %add3.i.2.i629
  %shr.i30.i.2.i636 = or i64 %xor2.i26.i.2.i635, %xor2.i.i.2.i631
  %or29.i.2.i637 = lshr i64 %shr.i30.i.2.i636, 63
  %arrayidx.i.3.i638 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 3
  %111 = load i64, i64* %arrayidx.i.3.i638, align 8, !tbaa !3
  %add.i.3.i639 = add i64 %or29.i.2.i637, %111
  %arrayidx2.i.3.i640 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 3
  %112 = load i64, i64* %arrayidx2.i.3.i640, align 8, !tbaa !3
  %add3.i.3.i641 = add i64 %add.i.3.i639, %112
  store i64 %add3.i.3.i641, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %113 = xor i64 %add.i.3.i639, -9223372036854775808
  %xor2.i.i.3.i643 = and i64 %113, %111
  %xor.i23.i.3.i644 = xor i64 %add3.i.3.i641, %add.i.3.i639
  %xor1.i24.i.3.i645 = xor i64 %add.i.3.i639, %112
  %or.i25.i.3.i646 = or i64 %xor.i23.i.3.i644, %xor1.i24.i.3.i645
  %xor2.i26.i.3.i647 = xor i64 %or.i25.i.3.i646, %add3.i.3.i641
  %shr.i30.i.3.i648 = or i64 %xor2.i26.i.3.i647, %xor2.i.i.3.i643
  %or29.i.3.i649 = lshr i64 %shr.i30.i.3.i648, 63
  %arrayidx.i.4.i650 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 4
  %114 = load i64, i64* %arrayidx.i.4.i650, align 16, !tbaa !3
  %add.i.4.i651 = add i64 %or29.i.3.i649, %114
  %arrayidx2.i.4.i652 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 4
  %115 = load i64, i64* %arrayidx2.i.4.i652, align 16, !tbaa !3
  %add3.i.4.i653 = add i64 %add.i.4.i651, %115
  store i64 %add3.i.4.i653, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %116 = xor i64 %add.i.4.i651, -9223372036854775808
  %xor2.i.i.4.i655 = and i64 %116, %114
  %xor.i23.i.4.i656 = xor i64 %add3.i.4.i653, %add.i.4.i651
  %xor1.i24.i.4.i657 = xor i64 %add.i.4.i651, %115
  %or.i25.i.4.i658 = or i64 %xor.i23.i.4.i656, %xor1.i24.i.4.i657
  %xor2.i26.i.4.i659 = xor i64 %or.i25.i.4.i658, %add3.i.4.i653
  %shr.i30.i.4.i660 = or i64 %xor2.i26.i.4.i659, %xor2.i.i.4.i655
  %or29.i.4.i661 = lshr i64 %shr.i30.i.4.i660, 63
  %arrayidx.i.5.i662 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 5
  %117 = load i64, i64* %arrayidx.i.5.i662, align 8, !tbaa !3
  %add.i.5.i663 = add i64 %or29.i.4.i661, %117
  %arrayidx2.i.5.i664 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 5
  %118 = load i64, i64* %arrayidx2.i.5.i664, align 8, !tbaa !3
  %add3.i.5.i665 = add i64 %add.i.5.i663, %118
  store i64 %add3.i.5.i665, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %119 = xor i64 %add.i.5.i663, -9223372036854775808
  %xor2.i.i.5.i667 = and i64 %119, %117
  %xor.i23.i.5.i668 = xor i64 %add3.i.5.i665, %add.i.5.i663
  %xor1.i24.i.5.i669 = xor i64 %add.i.5.i663, %118
  %or.i25.i.5.i670 = or i64 %xor.i23.i.5.i668, %xor1.i24.i.5.i669
  %xor2.i26.i.5.i671 = xor i64 %or.i25.i.5.i670, %add3.i.5.i665
  %shr.i30.i.5.i672 = or i64 %xor2.i26.i.5.i671, %xor2.i.i.5.i667
  %or29.i.5.i673 = lshr i64 %shr.i30.i.5.i672, 63
  %arrayidx.i.6.i674 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 6
  %120 = load i64, i64* %arrayidx.i.6.i674, align 16, !tbaa !3
  %add.i.6.i675 = add i64 %or29.i.5.i673, %120
  %arrayidx2.i.6.i676 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 6
  %121 = load i64, i64* %arrayidx2.i.6.i676, align 16, !tbaa !3
  %add3.i.6.i677 = add i64 %add.i.6.i675, %121
  store i64 %add3.i.6.i677, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %122 = xor i64 %add.i.6.i675, -9223372036854775808
  %xor2.i.i.6.i679 = and i64 %122, %120
  %xor.i23.i.6.i680 = xor i64 %add3.i.6.i677, %add.i.6.i675
  %xor1.i24.i.6.i681 = xor i64 %add.i.6.i675, %121
  %or.i25.i.6.i682 = or i64 %xor.i23.i.6.i680, %xor1.i24.i.6.i681
  %xor2.i26.i.6.i683 = xor i64 %or.i25.i.6.i682, %add3.i.6.i677
  %shr.i30.i.6.i684 = or i64 %xor2.i26.i.6.i683, %xor2.i.i.6.i679
  %or29.i.6.i685 = lshr i64 %shr.i30.i.6.i684, 63
  %arrayidx.i.7.i686 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 7
  %123 = load i64, i64* %arrayidx.i.7.i686, align 8, !tbaa !3
  %add.i.7.i687 = add i64 %or29.i.6.i685, %123
  %arrayidx2.i.7.i688 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 7
  %124 = load i64, i64* %arrayidx2.i.7.i688, align 8, !tbaa !3
  %add3.i.7.i689 = add i64 %add.i.7.i687, %124
  store i64 %add3.i.7.i689, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %125 = xor i64 %add.i.7.i687, -9223372036854775808
  %xor2.i.i.7.i691 = and i64 %125, %123
  %xor.i23.i.7.i692 = xor i64 %add3.i.7.i689, %add.i.7.i687
  %xor1.i24.i.7.i693 = xor i64 %add.i.7.i687, %124
  %or.i25.i.7.i694 = or i64 %xor.i23.i.7.i692, %xor1.i24.i.7.i693
  %xor2.i26.i.7.i695 = xor i64 %or.i25.i.7.i694, %add3.i.7.i689
  %shr.i30.i.7.i696 = or i64 %xor2.i26.i.7.i695, %xor2.i.i.7.i691
  %or29.i.7.i697 = lshr i64 %shr.i30.i.7.i696, 63
  %arrayidx.i.8.i698 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 8
  %126 = load i64, i64* %arrayidx.i.8.i698, align 16, !tbaa !3
  %add.i.8.i699 = add i64 %or29.i.7.i697, %126
  %arrayidx2.i.8.i700 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 8
  %127 = load i64, i64* %arrayidx2.i.8.i700, align 16, !tbaa !3
  %add3.i.8.i701 = add i64 %add.i.8.i699, %127
  store i64 %add3.i.8.i701, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %128 = xor i64 %add.i.8.i699, -9223372036854775808
  %xor2.i.i.8.i703 = and i64 %128, %126
  %xor.i23.i.8.i704 = xor i64 %add3.i.8.i701, %add.i.8.i699
  %xor1.i24.i.8.i705 = xor i64 %add.i.8.i699, %127
  %or.i25.i.8.i706 = or i64 %xor.i23.i.8.i704, %xor1.i24.i.8.i705
  %xor2.i26.i.8.i707 = xor i64 %or.i25.i.8.i706, %add3.i.8.i701
  %shr.i30.i.8.i708 = or i64 %xor2.i26.i.8.i707, %xor2.i.i.8.i703
  %or29.i.8.i709 = lshr i64 %shr.i30.i.8.i708, 63
  %arrayidx.i.9.i710 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 9
  %129 = load i64, i64* %arrayidx.i.9.i710, align 8, !tbaa !3
  %arrayidx2.i.9.i712 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 9
  %130 = load i64, i64* %arrayidx2.i.9.i712, align 8, !tbaa !3
  %add.i.9.i711 = add i64 %130, %129
  %add3.i.9.i713 = add i64 %add.i.9.i711, %or29.i.8.i709
  store i64 %add3.i.9.i713, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i98, i64* nonnull %arraydecay10.i101, i64* nonnull %arraydecay8.i77) #10
  %131 = load i64, i64* %arraydecay4.i98, align 16, !tbaa !3
  %add3.i.i822 = shl i64 %131, 1
  store i64 %add3.i.i822, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i827 = lshr i64 %131, 63
  %132 = load i64, i64* %arrayidx.i.1.i614, align 8, !tbaa !3
  %add.i.1.i829 = add i64 %132, %or29.i.i827
  %add3.i.1.i831 = add i64 %add.i.1.i829, %132
  store i64 %add3.i.1.i831, i64* %arrayidx5.i.1.i190, align 8, !tbaa !3
  %133 = xor i64 %add.i.1.i829, -9223372036854775808
  %xor2.i.i.1.i833 = and i64 %133, %132
  %xor.i23.i.1.i834 = xor i64 %add3.i.1.i831, %add.i.1.i829
  %xor1.i24.i.1.i835 = xor i64 %add.i.1.i829, %132
  %or.i25.i.1.i836 = or i64 %xor.i23.i.1.i834, %xor1.i24.i.1.i835
  %xor2.i26.i.1.i837 = xor i64 %or.i25.i.1.i836, %add3.i.1.i831
  %shr.i30.i.1.i838 = or i64 %xor2.i26.i.1.i837, %xor2.i.i.1.i833
  %or29.i.1.i839 = lshr i64 %shr.i30.i.1.i838, 63
  %134 = load i64, i64* %arrayidx.i.2.i626, align 16, !tbaa !3
  %add.i.2.i841 = add i64 %or29.i.1.i839, %134
  %add3.i.2.i843 = add i64 %add.i.2.i841, %134
  store i64 %add3.i.2.i843, i64* %arrayidx5.i.2.i202, align 16, !tbaa !3
  %135 = xor i64 %add.i.2.i841, -9223372036854775808
  %xor2.i.i.2.i845 = and i64 %135, %134
  %xor.i23.i.2.i846 = xor i64 %add3.i.2.i843, %add.i.2.i841
  %xor1.i24.i.2.i847 = xor i64 %add.i.2.i841, %134
  %or.i25.i.2.i848 = or i64 %xor.i23.i.2.i846, %xor1.i24.i.2.i847
  %xor2.i26.i.2.i849 = xor i64 %or.i25.i.2.i848, %add3.i.2.i843
  %shr.i30.i.2.i850 = or i64 %xor2.i26.i.2.i849, %xor2.i.i.2.i845
  %or29.i.2.i851 = lshr i64 %shr.i30.i.2.i850, 63
  %136 = load i64, i64* %arrayidx.i.3.i638, align 8, !tbaa !3
  %add.i.3.i853 = add i64 %or29.i.2.i851, %136
  %add3.i.3.i855 = add i64 %add.i.3.i853, %136
  store i64 %add3.i.3.i855, i64* %arrayidx5.i.3.i214, align 8, !tbaa !3
  %137 = xor i64 %add.i.3.i853, -9223372036854775808
  %xor2.i.i.3.i857 = and i64 %137, %136
  %xor.i23.i.3.i858 = xor i64 %add3.i.3.i855, %add.i.3.i853
  %xor1.i24.i.3.i859 = xor i64 %add.i.3.i853, %136
  %or.i25.i.3.i860 = or i64 %xor.i23.i.3.i858, %xor1.i24.i.3.i859
  %xor2.i26.i.3.i861 = xor i64 %or.i25.i.3.i860, %add3.i.3.i855
  %shr.i30.i.3.i862 = or i64 %xor2.i26.i.3.i861, %xor2.i.i.3.i857
  %or29.i.3.i863 = lshr i64 %shr.i30.i.3.i862, 63
  %138 = load i64, i64* %arrayidx.i.4.i650, align 16, !tbaa !3
  %add.i.4.i865 = add i64 %or29.i.3.i863, %138
  %add3.i.4.i867 = add i64 %add.i.4.i865, %138
  store i64 %add3.i.4.i867, i64* %arrayidx5.i.4.i226, align 16, !tbaa !3
  %139 = xor i64 %add.i.4.i865, -9223372036854775808
  %xor2.i.i.4.i869 = and i64 %139, %138
  %xor.i23.i.4.i870 = xor i64 %add3.i.4.i867, %add.i.4.i865
  %xor1.i24.i.4.i871 = xor i64 %add.i.4.i865, %138
  %or.i25.i.4.i872 = or i64 %xor.i23.i.4.i870, %xor1.i24.i.4.i871
  %xor2.i26.i.4.i873 = xor i64 %or.i25.i.4.i872, %add3.i.4.i867
  %shr.i30.i.4.i874 = or i64 %xor2.i26.i.4.i873, %xor2.i.i.4.i869
  %or29.i.4.i875 = lshr i64 %shr.i30.i.4.i874, 63
  %140 = load i64, i64* %arrayidx.i.5.i662, align 8, !tbaa !3
  %add.i.5.i877 = add i64 %or29.i.4.i875, %140
  %add3.i.5.i879 = add i64 %add.i.5.i877, %140
  store i64 %add3.i.5.i879, i64* %arrayidx5.i.5.i238, align 8, !tbaa !3
  %141 = xor i64 %add.i.5.i877, -9223372036854775808
  %xor2.i.i.5.i881 = and i64 %141, %140
  %xor.i23.i.5.i882 = xor i64 %add3.i.5.i879, %add.i.5.i877
  %xor1.i24.i.5.i883 = xor i64 %add.i.5.i877, %140
  %or.i25.i.5.i884 = or i64 %xor.i23.i.5.i882, %xor1.i24.i.5.i883
  %xor2.i26.i.5.i885 = xor i64 %or.i25.i.5.i884, %add3.i.5.i879
  %shr.i30.i.5.i886 = or i64 %xor2.i26.i.5.i885, %xor2.i.i.5.i881
  %or29.i.5.i887 = lshr i64 %shr.i30.i.5.i886, 63
  %142 = load i64, i64* %arrayidx.i.6.i674, align 16, !tbaa !3
  %add.i.6.i889 = add i64 %or29.i.5.i887, %142
  %add3.i.6.i891 = add i64 %add.i.6.i889, %142
  store i64 %add3.i.6.i891, i64* %arrayidx5.i.6.i250, align 16, !tbaa !3
  %143 = xor i64 %add.i.6.i889, -9223372036854775808
  %xor2.i.i.6.i893 = and i64 %143, %142
  %xor.i23.i.6.i894 = xor i64 %add3.i.6.i891, %add.i.6.i889
  %xor1.i24.i.6.i895 = xor i64 %add.i.6.i889, %142
  %or.i25.i.6.i896 = or i64 %xor.i23.i.6.i894, %xor1.i24.i.6.i895
  %xor2.i26.i.6.i897 = xor i64 %or.i25.i.6.i896, %add3.i.6.i891
  %shr.i30.i.6.i898 = or i64 %xor2.i26.i.6.i897, %xor2.i.i.6.i893
  %or29.i.6.i899 = lshr i64 %shr.i30.i.6.i898, 63
  %144 = load i64, i64* %arrayidx.i.7.i686, align 8, !tbaa !3
  %add.i.7.i901 = add i64 %or29.i.6.i899, %144
  %add3.i.7.i903 = add i64 %add.i.7.i901, %144
  store i64 %add3.i.7.i903, i64* %arrayidx5.i.7.i262, align 8, !tbaa !3
  %145 = xor i64 %add.i.7.i901, -9223372036854775808
  %xor2.i.i.7.i905 = and i64 %145, %144
  %xor.i23.i.7.i906 = xor i64 %add3.i.7.i903, %add.i.7.i901
  %xor1.i24.i.7.i907 = xor i64 %add.i.7.i901, %144
  %or.i25.i.7.i908 = or i64 %xor.i23.i.7.i906, %xor1.i24.i.7.i907
  %xor2.i26.i.7.i909 = xor i64 %or.i25.i.7.i908, %add3.i.7.i903
  %shr.i30.i.7.i910 = or i64 %xor2.i26.i.7.i909, %xor2.i.i.7.i905
  %or29.i.7.i911 = lshr i64 %shr.i30.i.7.i910, 63
  %146 = load i64, i64* %arrayidx.i.8.i698, align 16, !tbaa !3
  %add.i.8.i913 = add i64 %or29.i.7.i911, %146
  %add3.i.8.i915 = add i64 %add.i.8.i913, %146
  store i64 %add3.i.8.i915, i64* %arrayidx5.i.8.i274, align 16, !tbaa !3
  %147 = xor i64 %add.i.8.i913, -9223372036854775808
  %xor2.i.i.8.i917 = and i64 %147, %146
  %xor.i23.i.8.i918 = xor i64 %add3.i.8.i915, %add.i.8.i913
  %xor1.i24.i.8.i919 = xor i64 %add.i.8.i913, %146
  %or.i25.i.8.i920 = or i64 %xor.i23.i.8.i918, %xor1.i24.i.8.i919
  %xor2.i26.i.8.i921 = xor i64 %or.i25.i.8.i920, %add3.i.8.i915
  %shr.i30.i.8.i922 = or i64 %xor2.i26.i.8.i921, %xor2.i.i.8.i917
  %or29.i.8.i923 = lshr i64 %shr.i30.i.8.i922, 63
  %148 = load i64, i64* %arrayidx.i.9.i710, align 8, !tbaa !3
  %factor1144 = shl i64 %148, 1
  %add3.i.9.i927 = or i64 %or29.i.8.i923, %factor1144
  store i64 %add3.i.9.i927, i64* %arrayidx5.i.9.i286, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i77, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i80) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i101, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i83) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay17.i93, i64* nonnull %arraydecay4.i80) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay22.i95, i64* nonnull %arraydecay10.i83) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay4.i80) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay10.i83) #10
  %arraydecay31 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t5, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %A24plus, [10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay31)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay31, [10 x i64]* nonnull %arraydecay11)
  %arraydecay36 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t6, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %A24minus, [10 x i64]* nonnull %arraydecay4, [10 x i64]* nonnull %arraydecay36)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay4, [10 x i64]* nonnull %arraydecay36, [10 x i64]* nonnull %arraydecay4)
  call void @mp_sub610_p2(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i93, i64* nonnull %arraydecay17.i93) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i95, i64* nonnull %arraydecay22.i95) #10
  %arraydecay.i138 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t5, i64 0, i64 0, i64 0
  %arraydecay2.i139 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t6, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay.i138, i64* nonnull %arraydecay2.i139, i64* nonnull %arraydecay17.i) #10
  %arraydecay6.i141 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t5, i64 0, i64 1, i64 0
  %arraydecay8.i142 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t6, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i141, i64* nonnull %arraydecay8.i142, i64* nonnull %arraydecay22.i) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay9, [10 x i64]* nonnull %arraydecay4, [10 x i64]* nonnull %arraydecay9)
  call void @fpadd610(i64* nonnull %arraydecay17.i93, i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay17.i) #10
  call void @fpadd610(i64* nonnull %arraydecay22.i95, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %149 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %150 = load i64, i64* %arraydecay22.i, align 16, !tbaa !3
  %add3.i.i929 = add i64 %150, %149
  store i64 %add3.i.i929, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i930 = xor i64 %add3.i.i929, %149
  %xor1.i24.i.i931 = xor i64 %150, %149
  %or.i25.i.i932 = or i64 %xor.i23.i.i930, %xor1.i24.i.i931
  %xor2.i26.i.i933 = xor i64 %or.i25.i.i932, %add3.i.i929
  %or29.i.i934 = lshr i64 %xor2.i26.i.i933, 63
  %arrayidx.i.1.i935 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 1
  %151 = load i64, i64* %arrayidx.i.1.i935, align 8, !tbaa !3
  %add.i.1.i936 = add i64 %or29.i.i934, %151
  %arrayidx2.i.1.i937 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 1
  %152 = load i64, i64* %arrayidx2.i.1.i937, align 8, !tbaa !3
  %add3.i.1.i938 = add i64 %add.i.1.i936, %152
  store i64 %add3.i.1.i938, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %153 = xor i64 %add.i.1.i936, -9223372036854775808
  %xor2.i.i.1.i940 = and i64 %153, %151
  %xor.i23.i.1.i941 = xor i64 %add3.i.1.i938, %add.i.1.i936
  %xor1.i24.i.1.i942 = xor i64 %add.i.1.i936, %152
  %or.i25.i.1.i943 = or i64 %xor.i23.i.1.i941, %xor1.i24.i.1.i942
  %xor2.i26.i.1.i944 = xor i64 %or.i25.i.1.i943, %add3.i.1.i938
  %shr.i30.i.1.i945 = or i64 %xor2.i26.i.1.i944, %xor2.i.i.1.i940
  %or29.i.1.i946 = lshr i64 %shr.i30.i.1.i945, 63
  %arrayidx.i.2.i947 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 2
  %154 = load i64, i64* %arrayidx.i.2.i947, align 16, !tbaa !3
  %add.i.2.i948 = add i64 %or29.i.1.i946, %154
  %arrayidx2.i.2.i949 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 2
  %155 = load i64, i64* %arrayidx2.i.2.i949, align 16, !tbaa !3
  %add3.i.2.i950 = add i64 %add.i.2.i948, %155
  store i64 %add3.i.2.i950, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %156 = xor i64 %add.i.2.i948, -9223372036854775808
  %xor2.i.i.2.i952 = and i64 %156, %154
  %xor.i23.i.2.i953 = xor i64 %add3.i.2.i950, %add.i.2.i948
  %xor1.i24.i.2.i954 = xor i64 %add.i.2.i948, %155
  %or.i25.i.2.i955 = or i64 %xor.i23.i.2.i953, %xor1.i24.i.2.i954
  %xor2.i26.i.2.i956 = xor i64 %or.i25.i.2.i955, %add3.i.2.i950
  %shr.i30.i.2.i957 = or i64 %xor2.i26.i.2.i956, %xor2.i.i.2.i952
  %or29.i.2.i958 = lshr i64 %shr.i30.i.2.i957, 63
  %arrayidx.i.3.i959 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 3
  %157 = load i64, i64* %arrayidx.i.3.i959, align 8, !tbaa !3
  %add.i.3.i960 = add i64 %or29.i.2.i958, %157
  %arrayidx2.i.3.i961 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 3
  %158 = load i64, i64* %arrayidx2.i.3.i961, align 8, !tbaa !3
  %add3.i.3.i962 = add i64 %add.i.3.i960, %158
  store i64 %add3.i.3.i962, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %159 = xor i64 %add.i.3.i960, -9223372036854775808
  %xor2.i.i.3.i964 = and i64 %159, %157
  %xor.i23.i.3.i965 = xor i64 %add3.i.3.i962, %add.i.3.i960
  %xor1.i24.i.3.i966 = xor i64 %add.i.3.i960, %158
  %or.i25.i.3.i967 = or i64 %xor.i23.i.3.i965, %xor1.i24.i.3.i966
  %xor2.i26.i.3.i968 = xor i64 %or.i25.i.3.i967, %add3.i.3.i962
  %shr.i30.i.3.i969 = or i64 %xor2.i26.i.3.i968, %xor2.i.i.3.i964
  %or29.i.3.i970 = lshr i64 %shr.i30.i.3.i969, 63
  %arrayidx.i.4.i971 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 4
  %160 = load i64, i64* %arrayidx.i.4.i971, align 16, !tbaa !3
  %add.i.4.i972 = add i64 %or29.i.3.i970, %160
  %arrayidx2.i.4.i973 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 4
  %161 = load i64, i64* %arrayidx2.i.4.i973, align 16, !tbaa !3
  %add3.i.4.i974 = add i64 %add.i.4.i972, %161
  store i64 %add3.i.4.i974, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %162 = xor i64 %add.i.4.i972, -9223372036854775808
  %xor2.i.i.4.i976 = and i64 %162, %160
  %xor.i23.i.4.i977 = xor i64 %add3.i.4.i974, %add.i.4.i972
  %xor1.i24.i.4.i978 = xor i64 %add.i.4.i972, %161
  %or.i25.i.4.i979 = or i64 %xor.i23.i.4.i977, %xor1.i24.i.4.i978
  %xor2.i26.i.4.i980 = xor i64 %or.i25.i.4.i979, %add3.i.4.i974
  %shr.i30.i.4.i981 = or i64 %xor2.i26.i.4.i980, %xor2.i.i.4.i976
  %or29.i.4.i982 = lshr i64 %shr.i30.i.4.i981, 63
  %arrayidx.i.5.i983 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 5
  %163 = load i64, i64* %arrayidx.i.5.i983, align 8, !tbaa !3
  %add.i.5.i984 = add i64 %or29.i.4.i982, %163
  %arrayidx2.i.5.i985 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 5
  %164 = load i64, i64* %arrayidx2.i.5.i985, align 8, !tbaa !3
  %add3.i.5.i986 = add i64 %add.i.5.i984, %164
  store i64 %add3.i.5.i986, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %165 = xor i64 %add.i.5.i984, -9223372036854775808
  %xor2.i.i.5.i988 = and i64 %165, %163
  %xor.i23.i.5.i989 = xor i64 %add3.i.5.i986, %add.i.5.i984
  %xor1.i24.i.5.i990 = xor i64 %add.i.5.i984, %164
  %or.i25.i.5.i991 = or i64 %xor.i23.i.5.i989, %xor1.i24.i.5.i990
  %xor2.i26.i.5.i992 = xor i64 %or.i25.i.5.i991, %add3.i.5.i986
  %shr.i30.i.5.i993 = or i64 %xor2.i26.i.5.i992, %xor2.i.i.5.i988
  %or29.i.5.i994 = lshr i64 %shr.i30.i.5.i993, 63
  %arrayidx.i.6.i995 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 6
  %166 = load i64, i64* %arrayidx.i.6.i995, align 16, !tbaa !3
  %add.i.6.i996 = add i64 %or29.i.5.i994, %166
  %arrayidx2.i.6.i997 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 6
  %167 = load i64, i64* %arrayidx2.i.6.i997, align 16, !tbaa !3
  %add3.i.6.i998 = add i64 %add.i.6.i996, %167
  store i64 %add3.i.6.i998, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %168 = xor i64 %add.i.6.i996, -9223372036854775808
  %xor2.i.i.6.i1000 = and i64 %168, %166
  %xor.i23.i.6.i1001 = xor i64 %add3.i.6.i998, %add.i.6.i996
  %xor1.i24.i.6.i1002 = xor i64 %add.i.6.i996, %167
  %or.i25.i.6.i1003 = or i64 %xor.i23.i.6.i1001, %xor1.i24.i.6.i1002
  %xor2.i26.i.6.i1004 = xor i64 %or.i25.i.6.i1003, %add3.i.6.i998
  %shr.i30.i.6.i1005 = or i64 %xor2.i26.i.6.i1004, %xor2.i.i.6.i1000
  %or29.i.6.i1006 = lshr i64 %shr.i30.i.6.i1005, 63
  %arrayidx.i.7.i1007 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 7
  %169 = load i64, i64* %arrayidx.i.7.i1007, align 8, !tbaa !3
  %add.i.7.i1008 = add i64 %or29.i.6.i1006, %169
  %arrayidx2.i.7.i1009 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 7
  %170 = load i64, i64* %arrayidx2.i.7.i1009, align 8, !tbaa !3
  %add3.i.7.i1010 = add i64 %add.i.7.i1008, %170
  store i64 %add3.i.7.i1010, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %171 = xor i64 %add.i.7.i1008, -9223372036854775808
  %xor2.i.i.7.i1012 = and i64 %171, %169
  %xor.i23.i.7.i1013 = xor i64 %add3.i.7.i1010, %add.i.7.i1008
  %xor1.i24.i.7.i1014 = xor i64 %add.i.7.i1008, %170
  %or.i25.i.7.i1015 = or i64 %xor.i23.i.7.i1013, %xor1.i24.i.7.i1014
  %xor2.i26.i.7.i1016 = xor i64 %or.i25.i.7.i1015, %add3.i.7.i1010
  %shr.i30.i.7.i1017 = or i64 %xor2.i26.i.7.i1016, %xor2.i.i.7.i1012
  %or29.i.7.i1018 = lshr i64 %shr.i30.i.7.i1017, 63
  %arrayidx.i.8.i1019 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 8
  %172 = load i64, i64* %arrayidx.i.8.i1019, align 16, !tbaa !3
  %add.i.8.i1020 = add i64 %or29.i.7.i1018, %172
  %arrayidx2.i.8.i1021 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 8
  %173 = load i64, i64* %arrayidx2.i.8.i1021, align 16, !tbaa !3
  %add3.i.8.i1022 = add i64 %add.i.8.i1020, %173
  store i64 %add3.i.8.i1022, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %174 = xor i64 %add.i.8.i1020, -9223372036854775808
  %xor2.i.i.8.i1024 = and i64 %174, %172
  %xor.i23.i.8.i1025 = xor i64 %add3.i.8.i1022, %add.i.8.i1020
  %xor1.i24.i.8.i1026 = xor i64 %add.i.8.i1020, %173
  %or.i25.i.8.i1027 = or i64 %xor.i23.i.8.i1025, %xor1.i24.i.8.i1026
  %xor2.i26.i.8.i1028 = xor i64 %or.i25.i.8.i1027, %add3.i.8.i1022
  %shr.i30.i.8.i1029 = or i64 %xor2.i26.i.8.i1028, %xor2.i.i.8.i1024
  %or29.i.8.i1030 = lshr i64 %shr.i30.i.8.i1029, 63
  %arrayidx.i.9.i1031 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 9
  %175 = load i64, i64* %arrayidx.i.9.i1031, align 8, !tbaa !3
  %arrayidx2.i.9.i1033 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 9
  %176 = load i64, i64* %arrayidx2.i.9.i1033, align 8, !tbaa !3
  %add.i.9.i1032 = add i64 %176, %175
  %add3.i.9.i1034 = add i64 %add.i.9.i1032, %or29.i.8.i1030
  store i64 %add3.i.9.i1034, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay8.i77) #10
  %177 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %add3.i.i1036 = shl i64 %177, 1
  store i64 %add3.i.i1036, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i1041 = lshr i64 %177, 63
  %178 = load i64, i64* %arrayidx.i.1.i935, align 8, !tbaa !3
  %add.i.1.i1043 = add i64 %178, %or29.i.i1041
  %add3.i.1.i1045 = add i64 %add.i.1.i1043, %178
  store i64 %add3.i.1.i1045, i64* %arrayidx5.i.1.i190, align 8, !tbaa !3
  %179 = xor i64 %add.i.1.i1043, -9223372036854775808
  %xor2.i.i.1.i1047 = and i64 %179, %178
  %xor.i23.i.1.i1048 = xor i64 %add3.i.1.i1045, %add.i.1.i1043
  %xor1.i24.i.1.i1049 = xor i64 %add.i.1.i1043, %178
  %or.i25.i.1.i1050 = or i64 %xor.i23.i.1.i1048, %xor1.i24.i.1.i1049
  %xor2.i26.i.1.i1051 = xor i64 %or.i25.i.1.i1050, %add3.i.1.i1045
  %shr.i30.i.1.i1052 = or i64 %xor2.i26.i.1.i1051, %xor2.i.i.1.i1047
  %or29.i.1.i1053 = lshr i64 %shr.i30.i.1.i1052, 63
  %180 = load i64, i64* %arrayidx.i.2.i947, align 16, !tbaa !3
  %add.i.2.i1055 = add i64 %or29.i.1.i1053, %180
  %add3.i.2.i1057 = add i64 %add.i.2.i1055, %180
  store i64 %add3.i.2.i1057, i64* %arrayidx5.i.2.i202, align 16, !tbaa !3
  %181 = xor i64 %add.i.2.i1055, -9223372036854775808
  %xor2.i.i.2.i1059 = and i64 %181, %180
  %xor.i23.i.2.i1060 = xor i64 %add3.i.2.i1057, %add.i.2.i1055
  %xor1.i24.i.2.i1061 = xor i64 %add.i.2.i1055, %180
  %or.i25.i.2.i1062 = or i64 %xor.i23.i.2.i1060, %xor1.i24.i.2.i1061
  %xor2.i26.i.2.i1063 = xor i64 %or.i25.i.2.i1062, %add3.i.2.i1057
  %shr.i30.i.2.i1064 = or i64 %xor2.i26.i.2.i1063, %xor2.i.i.2.i1059
  %or29.i.2.i1065 = lshr i64 %shr.i30.i.2.i1064, 63
  %182 = load i64, i64* %arrayidx.i.3.i959, align 8, !tbaa !3
  %add.i.3.i1067 = add i64 %or29.i.2.i1065, %182
  %add3.i.3.i1069 = add i64 %add.i.3.i1067, %182
  store i64 %add3.i.3.i1069, i64* %arrayidx5.i.3.i214, align 8, !tbaa !3
  %183 = xor i64 %add.i.3.i1067, -9223372036854775808
  %xor2.i.i.3.i1071 = and i64 %183, %182
  %xor.i23.i.3.i1072 = xor i64 %add3.i.3.i1069, %add.i.3.i1067
  %xor1.i24.i.3.i1073 = xor i64 %add.i.3.i1067, %182
  %or.i25.i.3.i1074 = or i64 %xor.i23.i.3.i1072, %xor1.i24.i.3.i1073
  %xor2.i26.i.3.i1075 = xor i64 %or.i25.i.3.i1074, %add3.i.3.i1069
  %shr.i30.i.3.i1076 = or i64 %xor2.i26.i.3.i1075, %xor2.i.i.3.i1071
  %or29.i.3.i1077 = lshr i64 %shr.i30.i.3.i1076, 63
  %184 = load i64, i64* %arrayidx.i.4.i971, align 16, !tbaa !3
  %add.i.4.i1079 = add i64 %or29.i.3.i1077, %184
  %add3.i.4.i1081 = add i64 %add.i.4.i1079, %184
  store i64 %add3.i.4.i1081, i64* %arrayidx5.i.4.i226, align 16, !tbaa !3
  %185 = xor i64 %add.i.4.i1079, -9223372036854775808
  %xor2.i.i.4.i1083 = and i64 %185, %184
  %xor.i23.i.4.i1084 = xor i64 %add3.i.4.i1081, %add.i.4.i1079
  %xor1.i24.i.4.i1085 = xor i64 %add.i.4.i1079, %184
  %or.i25.i.4.i1086 = or i64 %xor.i23.i.4.i1084, %xor1.i24.i.4.i1085
  %xor2.i26.i.4.i1087 = xor i64 %or.i25.i.4.i1086, %add3.i.4.i1081
  %shr.i30.i.4.i1088 = or i64 %xor2.i26.i.4.i1087, %xor2.i.i.4.i1083
  %or29.i.4.i1089 = lshr i64 %shr.i30.i.4.i1088, 63
  %186 = load i64, i64* %arrayidx.i.5.i983, align 8, !tbaa !3
  %add.i.5.i1091 = add i64 %or29.i.4.i1089, %186
  %add3.i.5.i1093 = add i64 %add.i.5.i1091, %186
  store i64 %add3.i.5.i1093, i64* %arrayidx5.i.5.i238, align 8, !tbaa !3
  %187 = xor i64 %add.i.5.i1091, -9223372036854775808
  %xor2.i.i.5.i1095 = and i64 %187, %186
  %xor.i23.i.5.i1096 = xor i64 %add3.i.5.i1093, %add.i.5.i1091
  %xor1.i24.i.5.i1097 = xor i64 %add.i.5.i1091, %186
  %or.i25.i.5.i1098 = or i64 %xor.i23.i.5.i1096, %xor1.i24.i.5.i1097
  %xor2.i26.i.5.i1099 = xor i64 %or.i25.i.5.i1098, %add3.i.5.i1093
  %shr.i30.i.5.i1100 = or i64 %xor2.i26.i.5.i1099, %xor2.i.i.5.i1095
  %or29.i.5.i1101 = lshr i64 %shr.i30.i.5.i1100, 63
  %188 = load i64, i64* %arrayidx.i.6.i995, align 16, !tbaa !3
  %add.i.6.i1103 = add i64 %or29.i.5.i1101, %188
  %add3.i.6.i1105 = add i64 %add.i.6.i1103, %188
  store i64 %add3.i.6.i1105, i64* %arrayidx5.i.6.i250, align 16, !tbaa !3
  %189 = xor i64 %add.i.6.i1103, -9223372036854775808
  %xor2.i.i.6.i1107 = and i64 %189, %188
  %xor.i23.i.6.i1108 = xor i64 %add3.i.6.i1105, %add.i.6.i1103
  %xor1.i24.i.6.i1109 = xor i64 %add.i.6.i1103, %188
  %or.i25.i.6.i1110 = or i64 %xor.i23.i.6.i1108, %xor1.i24.i.6.i1109
  %xor2.i26.i.6.i1111 = xor i64 %or.i25.i.6.i1110, %add3.i.6.i1105
  %shr.i30.i.6.i1112 = or i64 %xor2.i26.i.6.i1111, %xor2.i.i.6.i1107
  %or29.i.6.i1113 = lshr i64 %shr.i30.i.6.i1112, 63
  %190 = load i64, i64* %arrayidx.i.7.i1007, align 8, !tbaa !3
  %add.i.7.i1115 = add i64 %or29.i.6.i1113, %190
  %add3.i.7.i1117 = add i64 %add.i.7.i1115, %190
  store i64 %add3.i.7.i1117, i64* %arrayidx5.i.7.i262, align 8, !tbaa !3
  %191 = xor i64 %add.i.7.i1115, -9223372036854775808
  %xor2.i.i.7.i1119 = and i64 %191, %190
  %xor.i23.i.7.i1120 = xor i64 %add3.i.7.i1117, %add.i.7.i1115
  %xor1.i24.i.7.i1121 = xor i64 %add.i.7.i1115, %190
  %or.i25.i.7.i1122 = or i64 %xor.i23.i.7.i1120, %xor1.i24.i.7.i1121
  %xor2.i26.i.7.i1123 = xor i64 %or.i25.i.7.i1122, %add3.i.7.i1117
  %shr.i30.i.7.i1124 = or i64 %xor2.i26.i.7.i1123, %xor2.i.i.7.i1119
  %or29.i.7.i1125 = lshr i64 %shr.i30.i.7.i1124, 63
  %192 = load i64, i64* %arrayidx.i.8.i1019, align 16, !tbaa !3
  %add.i.8.i1127 = add i64 %or29.i.7.i1125, %192
  %add3.i.8.i1129 = add i64 %add.i.8.i1127, %192
  store i64 %add3.i.8.i1129, i64* %arrayidx5.i.8.i274, align 16, !tbaa !3
  %193 = xor i64 %add.i.8.i1127, -9223372036854775808
  %xor2.i.i.8.i1131 = and i64 %193, %192
  %xor.i23.i.8.i1132 = xor i64 %add3.i.8.i1129, %add.i.8.i1127
  %xor1.i24.i.8.i1133 = xor i64 %add.i.8.i1127, %192
  %or.i25.i.8.i1134 = or i64 %xor.i23.i.8.i1132, %xor1.i24.i.8.i1133
  %xor2.i26.i.8.i1135 = xor i64 %or.i25.i.8.i1134, %add3.i.8.i1129
  %shr.i30.i.8.i1136 = or i64 %xor2.i26.i.8.i1135, %xor2.i.i.8.i1131
  %or29.i.8.i1137 = lshr i64 %shr.i30.i.8.i1136, 63
  %194 = load i64, i64* %arrayidx.i.9.i1031, align 8, !tbaa !3
  %factor1145 = shl i64 %194, 1
  %add3.i.9.i1141 = or i64 %or29.i.8.i1137, %factor1145
  store i64 %add3.i.9.i1141, i64* %arrayidx5.i.9.i286, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i77, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  %arraydecay57 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay16, [10 x i64]* nonnull %arraydecay4, [10 x i64]* %arraydecay57)
  call void @fpsub610(i64* nonnull %arraydecay17.i93, i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay4.i80) #10
  call void @fpsub610(i64* nonnull %arraydecay22.i95, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay10.i83) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %195 = load i64, i64* %arraydecay4.i80, align 16, !tbaa !3
  %196 = load i64, i64* %arraydecay10.i83, align 16, !tbaa !3
  %add3.i.i715 = add i64 %196, %195
  store i64 %add3.i.i715, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i716 = xor i64 %add3.i.i715, %195
  %xor1.i24.i.i717 = xor i64 %196, %195
  %or.i25.i.i718 = or i64 %xor.i23.i.i716, %xor1.i24.i.i717
  %xor2.i26.i.i719 = xor i64 %or.i25.i.i718, %add3.i.i715
  %or29.i.i720 = lshr i64 %xor2.i26.i.i719, 63
  %197 = load i64, i64* %arrayidx.i.1.i293, align 8, !tbaa !3
  %add.i.1.i722 = add i64 %or29.i.i720, %197
  %198 = load i64, i64* %arrayidx2.i.1.i295, align 8, !tbaa !3
  %add3.i.1.i724 = add i64 %add.i.1.i722, %198
  store i64 %add3.i.1.i724, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %199 = xor i64 %add.i.1.i722, -9223372036854775808
  %xor2.i.i.1.i726 = and i64 %199, %197
  %xor.i23.i.1.i727 = xor i64 %add3.i.1.i724, %add.i.1.i722
  %xor1.i24.i.1.i728 = xor i64 %add.i.1.i722, %198
  %or.i25.i.1.i729 = or i64 %xor.i23.i.1.i727, %xor1.i24.i.1.i728
  %xor2.i26.i.1.i730 = xor i64 %or.i25.i.1.i729, %add3.i.1.i724
  %shr.i30.i.1.i731 = or i64 %xor2.i26.i.1.i730, %xor2.i.i.1.i726
  %or29.i.1.i732 = lshr i64 %shr.i30.i.1.i731, 63
  %200 = load i64, i64* %arrayidx.i.2.i305, align 16, !tbaa !3
  %add.i.2.i734 = add i64 %or29.i.1.i732, %200
  %201 = load i64, i64* %arrayidx2.i.2.i307, align 16, !tbaa !3
  %add3.i.2.i736 = add i64 %add.i.2.i734, %201
  store i64 %add3.i.2.i736, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %202 = xor i64 %add.i.2.i734, -9223372036854775808
  %xor2.i.i.2.i738 = and i64 %202, %200
  %xor.i23.i.2.i739 = xor i64 %add3.i.2.i736, %add.i.2.i734
  %xor1.i24.i.2.i740 = xor i64 %add.i.2.i734, %201
  %or.i25.i.2.i741 = or i64 %xor.i23.i.2.i739, %xor1.i24.i.2.i740
  %xor2.i26.i.2.i742 = xor i64 %or.i25.i.2.i741, %add3.i.2.i736
  %shr.i30.i.2.i743 = or i64 %xor2.i26.i.2.i742, %xor2.i.i.2.i738
  %or29.i.2.i744 = lshr i64 %shr.i30.i.2.i743, 63
  %203 = load i64, i64* %arrayidx.i.3.i317, align 8, !tbaa !3
  %add.i.3.i746 = add i64 %or29.i.2.i744, %203
  %204 = load i64, i64* %arrayidx2.i.3.i319, align 8, !tbaa !3
  %add3.i.3.i748 = add i64 %add.i.3.i746, %204
  store i64 %add3.i.3.i748, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %205 = xor i64 %add.i.3.i746, -9223372036854775808
  %xor2.i.i.3.i750 = and i64 %205, %203
  %xor.i23.i.3.i751 = xor i64 %add3.i.3.i748, %add.i.3.i746
  %xor1.i24.i.3.i752 = xor i64 %add.i.3.i746, %204
  %or.i25.i.3.i753 = or i64 %xor.i23.i.3.i751, %xor1.i24.i.3.i752
  %xor2.i26.i.3.i754 = xor i64 %or.i25.i.3.i753, %add3.i.3.i748
  %shr.i30.i.3.i755 = or i64 %xor2.i26.i.3.i754, %xor2.i.i.3.i750
  %or29.i.3.i756 = lshr i64 %shr.i30.i.3.i755, 63
  %206 = load i64, i64* %arrayidx.i.4.i329, align 16, !tbaa !3
  %add.i.4.i758 = add i64 %or29.i.3.i756, %206
  %207 = load i64, i64* %arrayidx2.i.4.i331, align 16, !tbaa !3
  %add3.i.4.i760 = add i64 %add.i.4.i758, %207
  store i64 %add3.i.4.i760, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %208 = xor i64 %add.i.4.i758, -9223372036854775808
  %xor2.i.i.4.i762 = and i64 %208, %206
  %xor.i23.i.4.i763 = xor i64 %add3.i.4.i760, %add.i.4.i758
  %xor1.i24.i.4.i764 = xor i64 %add.i.4.i758, %207
  %or.i25.i.4.i765 = or i64 %xor.i23.i.4.i763, %xor1.i24.i.4.i764
  %xor2.i26.i.4.i766 = xor i64 %or.i25.i.4.i765, %add3.i.4.i760
  %shr.i30.i.4.i767 = or i64 %xor2.i26.i.4.i766, %xor2.i.i.4.i762
  %or29.i.4.i768 = lshr i64 %shr.i30.i.4.i767, 63
  %209 = load i64, i64* %arrayidx.i.5.i341, align 8, !tbaa !3
  %add.i.5.i770 = add i64 %or29.i.4.i768, %209
  %210 = load i64, i64* %arrayidx2.i.5.i343, align 8, !tbaa !3
  %add3.i.5.i772 = add i64 %add.i.5.i770, %210
  store i64 %add3.i.5.i772, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %211 = xor i64 %add.i.5.i770, -9223372036854775808
  %xor2.i.i.5.i774 = and i64 %211, %209
  %xor.i23.i.5.i775 = xor i64 %add3.i.5.i772, %add.i.5.i770
  %xor1.i24.i.5.i776 = xor i64 %add.i.5.i770, %210
  %or.i25.i.5.i777 = or i64 %xor.i23.i.5.i775, %xor1.i24.i.5.i776
  %xor2.i26.i.5.i778 = xor i64 %or.i25.i.5.i777, %add3.i.5.i772
  %shr.i30.i.5.i779 = or i64 %xor2.i26.i.5.i778, %xor2.i.i.5.i774
  %or29.i.5.i780 = lshr i64 %shr.i30.i.5.i779, 63
  %212 = load i64, i64* %arrayidx.i.6.i353, align 16, !tbaa !3
  %add.i.6.i782 = add i64 %or29.i.5.i780, %212
  %213 = load i64, i64* %arrayidx2.i.6.i355, align 16, !tbaa !3
  %add3.i.6.i784 = add i64 %add.i.6.i782, %213
  store i64 %add3.i.6.i784, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %214 = xor i64 %add.i.6.i782, -9223372036854775808
  %xor2.i.i.6.i786 = and i64 %214, %212
  %xor.i23.i.6.i787 = xor i64 %add3.i.6.i784, %add.i.6.i782
  %xor1.i24.i.6.i788 = xor i64 %add.i.6.i782, %213
  %or.i25.i.6.i789 = or i64 %xor.i23.i.6.i787, %xor1.i24.i.6.i788
  %xor2.i26.i.6.i790 = xor i64 %or.i25.i.6.i789, %add3.i.6.i784
  %shr.i30.i.6.i791 = or i64 %xor2.i26.i.6.i790, %xor2.i.i.6.i786
  %or29.i.6.i792 = lshr i64 %shr.i30.i.6.i791, 63
  %215 = load i64, i64* %arrayidx.i.7.i365, align 8, !tbaa !3
  %add.i.7.i794 = add i64 %or29.i.6.i792, %215
  %216 = load i64, i64* %arrayidx2.i.7.i367, align 8, !tbaa !3
  %add3.i.7.i796 = add i64 %add.i.7.i794, %216
  store i64 %add3.i.7.i796, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %217 = xor i64 %add.i.7.i794, -9223372036854775808
  %xor2.i.i.7.i798 = and i64 %217, %215
  %xor.i23.i.7.i799 = xor i64 %add3.i.7.i796, %add.i.7.i794
  %xor1.i24.i.7.i800 = xor i64 %add.i.7.i794, %216
  %or.i25.i.7.i801 = or i64 %xor.i23.i.7.i799, %xor1.i24.i.7.i800
  %xor2.i26.i.7.i802 = xor i64 %or.i25.i.7.i801, %add3.i.7.i796
  %shr.i30.i.7.i803 = or i64 %xor2.i26.i.7.i802, %xor2.i.i.7.i798
  %or29.i.7.i804 = lshr i64 %shr.i30.i.7.i803, 63
  %218 = load i64, i64* %arrayidx.i.8.i377, align 16, !tbaa !3
  %add.i.8.i806 = add i64 %or29.i.7.i804, %218
  %219 = load i64, i64* %arrayidx2.i.8.i379, align 16, !tbaa !3
  %add3.i.8.i808 = add i64 %add.i.8.i806, %219
  store i64 %add3.i.8.i808, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %220 = xor i64 %add.i.8.i806, -9223372036854775808
  %xor2.i.i.8.i810 = and i64 %220, %218
  %xor.i23.i.8.i811 = xor i64 %add3.i.8.i808, %add.i.8.i806
  %xor1.i24.i.8.i812 = xor i64 %add.i.8.i806, %219
  %or.i25.i.8.i813 = or i64 %xor.i23.i.8.i811, %xor1.i24.i.8.i812
  %xor2.i26.i.8.i814 = xor i64 %or.i25.i.8.i813, %add3.i.8.i808
  %shr.i30.i.8.i815 = or i64 %xor2.i26.i.8.i814, %xor2.i.i.8.i810
  %or29.i.8.i816 = lshr i64 %shr.i30.i.8.i815, 63
  %221 = load i64, i64* %arrayidx.i.9.i389, align 8, !tbaa !3
  %222 = load i64, i64* %arrayidx2.i.9.i391, align 8, !tbaa !3
  %add.i.9.i818 = add i64 %222, %221
  %add3.i.9.i820 = add i64 %add.i.9.i818, %or29.i.8.i816
  store i64 %add3.i.9.i820, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i80, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay8.i77) #10
  %223 = load i64, i64* %arraydecay4.i80, align 16, !tbaa !3
  %add3.i.i501 = shl i64 %223, 1
  store i64 %add3.i.i501, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i506 = lshr i64 %223, 63
  %224 = load i64, i64* %arrayidx.i.1.i293, align 8, !tbaa !3
  %add.i.1.i508 = add i64 %224, %or29.i.i506
  %add3.i.1.i510 = add i64 %add.i.1.i508, %224
  store i64 %add3.i.1.i510, i64* %arrayidx5.i.1.i190, align 8, !tbaa !3
  %225 = xor i64 %add.i.1.i508, -9223372036854775808
  %xor2.i.i.1.i512 = and i64 %225, %224
  %xor.i23.i.1.i513 = xor i64 %add3.i.1.i510, %add.i.1.i508
  %xor1.i24.i.1.i514 = xor i64 %add.i.1.i508, %224
  %or.i25.i.1.i515 = or i64 %xor.i23.i.1.i513, %xor1.i24.i.1.i514
  %xor2.i26.i.1.i516 = xor i64 %or.i25.i.1.i515, %add3.i.1.i510
  %shr.i30.i.1.i517 = or i64 %xor2.i26.i.1.i516, %xor2.i.i.1.i512
  %or29.i.1.i518 = lshr i64 %shr.i30.i.1.i517, 63
  %226 = load i64, i64* %arrayidx.i.2.i305, align 16, !tbaa !3
  %add.i.2.i520 = add i64 %or29.i.1.i518, %226
  %add3.i.2.i522 = add i64 %add.i.2.i520, %226
  store i64 %add3.i.2.i522, i64* %arrayidx5.i.2.i202, align 16, !tbaa !3
  %227 = xor i64 %add.i.2.i520, -9223372036854775808
  %xor2.i.i.2.i524 = and i64 %227, %226
  %xor.i23.i.2.i525 = xor i64 %add3.i.2.i522, %add.i.2.i520
  %xor1.i24.i.2.i526 = xor i64 %add.i.2.i520, %226
  %or.i25.i.2.i527 = or i64 %xor.i23.i.2.i525, %xor1.i24.i.2.i526
  %xor2.i26.i.2.i528 = xor i64 %or.i25.i.2.i527, %add3.i.2.i522
  %shr.i30.i.2.i529 = or i64 %xor2.i26.i.2.i528, %xor2.i.i.2.i524
  %or29.i.2.i530 = lshr i64 %shr.i30.i.2.i529, 63
  %228 = load i64, i64* %arrayidx.i.3.i317, align 8, !tbaa !3
  %add.i.3.i532 = add i64 %or29.i.2.i530, %228
  %add3.i.3.i534 = add i64 %add.i.3.i532, %228
  store i64 %add3.i.3.i534, i64* %arrayidx5.i.3.i214, align 8, !tbaa !3
  %229 = xor i64 %add.i.3.i532, -9223372036854775808
  %xor2.i.i.3.i536 = and i64 %229, %228
  %xor.i23.i.3.i537 = xor i64 %add3.i.3.i534, %add.i.3.i532
  %xor1.i24.i.3.i538 = xor i64 %add.i.3.i532, %228
  %or.i25.i.3.i539 = or i64 %xor.i23.i.3.i537, %xor1.i24.i.3.i538
  %xor2.i26.i.3.i540 = xor i64 %or.i25.i.3.i539, %add3.i.3.i534
  %shr.i30.i.3.i541 = or i64 %xor2.i26.i.3.i540, %xor2.i.i.3.i536
  %or29.i.3.i542 = lshr i64 %shr.i30.i.3.i541, 63
  %230 = load i64, i64* %arrayidx.i.4.i329, align 16, !tbaa !3
  %add.i.4.i544 = add i64 %or29.i.3.i542, %230
  %add3.i.4.i546 = add i64 %add.i.4.i544, %230
  store i64 %add3.i.4.i546, i64* %arrayidx5.i.4.i226, align 16, !tbaa !3
  %231 = xor i64 %add.i.4.i544, -9223372036854775808
  %xor2.i.i.4.i548 = and i64 %231, %230
  %xor.i23.i.4.i549 = xor i64 %add3.i.4.i546, %add.i.4.i544
  %xor1.i24.i.4.i550 = xor i64 %add.i.4.i544, %230
  %or.i25.i.4.i551 = or i64 %xor.i23.i.4.i549, %xor1.i24.i.4.i550
  %xor2.i26.i.4.i552 = xor i64 %or.i25.i.4.i551, %add3.i.4.i546
  %shr.i30.i.4.i553 = or i64 %xor2.i26.i.4.i552, %xor2.i.i.4.i548
  %or29.i.4.i554 = lshr i64 %shr.i30.i.4.i553, 63
  %232 = load i64, i64* %arrayidx.i.5.i341, align 8, !tbaa !3
  %add.i.5.i556 = add i64 %or29.i.4.i554, %232
  %add3.i.5.i558 = add i64 %add.i.5.i556, %232
  store i64 %add3.i.5.i558, i64* %arrayidx5.i.5.i238, align 8, !tbaa !3
  %233 = xor i64 %add.i.5.i556, -9223372036854775808
  %xor2.i.i.5.i560 = and i64 %233, %232
  %xor.i23.i.5.i561 = xor i64 %add3.i.5.i558, %add.i.5.i556
  %xor1.i24.i.5.i562 = xor i64 %add.i.5.i556, %232
  %or.i25.i.5.i563 = or i64 %xor.i23.i.5.i561, %xor1.i24.i.5.i562
  %xor2.i26.i.5.i564 = xor i64 %or.i25.i.5.i563, %add3.i.5.i558
  %shr.i30.i.5.i565 = or i64 %xor2.i26.i.5.i564, %xor2.i.i.5.i560
  %or29.i.5.i566 = lshr i64 %shr.i30.i.5.i565, 63
  %234 = load i64, i64* %arrayidx.i.6.i353, align 16, !tbaa !3
  %add.i.6.i568 = add i64 %or29.i.5.i566, %234
  %add3.i.6.i570 = add i64 %add.i.6.i568, %234
  store i64 %add3.i.6.i570, i64* %arrayidx5.i.6.i250, align 16, !tbaa !3
  %235 = xor i64 %add.i.6.i568, -9223372036854775808
  %xor2.i.i.6.i572 = and i64 %235, %234
  %xor.i23.i.6.i573 = xor i64 %add3.i.6.i570, %add.i.6.i568
  %xor1.i24.i.6.i574 = xor i64 %add.i.6.i568, %234
  %or.i25.i.6.i575 = or i64 %xor.i23.i.6.i573, %xor1.i24.i.6.i574
  %xor2.i26.i.6.i576 = xor i64 %or.i25.i.6.i575, %add3.i.6.i570
  %shr.i30.i.6.i577 = or i64 %xor2.i26.i.6.i576, %xor2.i.i.6.i572
  %or29.i.6.i578 = lshr i64 %shr.i30.i.6.i577, 63
  %236 = load i64, i64* %arrayidx.i.7.i365, align 8, !tbaa !3
  %add.i.7.i580 = add i64 %or29.i.6.i578, %236
  %add3.i.7.i582 = add i64 %add.i.7.i580, %236
  store i64 %add3.i.7.i582, i64* %arrayidx5.i.7.i262, align 8, !tbaa !3
  %237 = xor i64 %add.i.7.i580, -9223372036854775808
  %xor2.i.i.7.i584 = and i64 %237, %236
  %xor.i23.i.7.i585 = xor i64 %add3.i.7.i582, %add.i.7.i580
  %xor1.i24.i.7.i586 = xor i64 %add.i.7.i580, %236
  %or.i25.i.7.i587 = or i64 %xor.i23.i.7.i585, %xor1.i24.i.7.i586
  %xor2.i26.i.7.i588 = xor i64 %or.i25.i.7.i587, %add3.i.7.i582
  %shr.i30.i.7.i589 = or i64 %xor2.i26.i.7.i588, %xor2.i.i.7.i584
  %or29.i.7.i590 = lshr i64 %shr.i30.i.7.i589, 63
  %238 = load i64, i64* %arrayidx.i.8.i377, align 16, !tbaa !3
  %add.i.8.i592 = add i64 %or29.i.7.i590, %238
  %add3.i.8.i594 = add i64 %add.i.8.i592, %238
  store i64 %add3.i.8.i594, i64* %arrayidx5.i.8.i274, align 16, !tbaa !3
  %239 = xor i64 %add.i.8.i592, -9223372036854775808
  %xor2.i.i.8.i596 = and i64 %239, %238
  %xor.i23.i.8.i597 = xor i64 %add3.i.8.i594, %add.i.8.i592
  %xor1.i24.i.8.i598 = xor i64 %add.i.8.i592, %238
  %or.i25.i.8.i599 = or i64 %xor.i23.i.8.i597, %xor1.i24.i.8.i598
  %xor2.i26.i.8.i600 = xor i64 %or.i25.i.8.i599, %add3.i.8.i594
  %shr.i30.i.8.i601 = or i64 %xor2.i26.i.8.i600, %xor2.i.i.8.i596
  %or29.i.8.i602 = lshr i64 %shr.i30.i.8.i601, 63
  %240 = load i64, i64* %arrayidx.i.9.i389, align 8, !tbaa !3
  %factor1146 = shl i64 %240, 1
  %add3.i.9.i606 = or i64 %or29.i.8.i602, %factor1146
  store i64 %add3.i.9.i606, i64* %arrayidx5.i.9.i286, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i77, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i80) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %56, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i83, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i83) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %56) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  %arraydecay66 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay9, [10 x i64]* nonnull %arraydecay66)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xTPLe(%struct.point_proj* nocapture readonly %P, %struct.point_proj* %Q, [10 x i64]* %A24minus, [10 x i64]* %A24plus, i32 %e) local_unnamed_addr #4 {
entry:
  %arrayidx.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %0 = load i64, i64* %arrayidx.i, align 8, !tbaa !3
  %arrayidx2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  store i64 %0, i64* %arrayidx2.i, align 8, !tbaa !3
  %arrayidx.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 1
  %1 = load i64, i64* %arrayidx.i.1, align 8, !tbaa !3
  %arrayidx2.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 1
  store i64 %1, i64* %arrayidx2.i.1, align 8, !tbaa !3
  %arrayidx.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 2
  %2 = load i64, i64* %arrayidx.i.2, align 8, !tbaa !3
  %arrayidx2.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 2
  store i64 %2, i64* %arrayidx2.i.2, align 8, !tbaa !3
  %arrayidx.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 3
  %3 = load i64, i64* %arrayidx.i.3, align 8, !tbaa !3
  %arrayidx2.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 3
  store i64 %3, i64* %arrayidx2.i.3, align 8, !tbaa !3
  %arrayidx.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 4
  %4 = load i64, i64* %arrayidx.i.4, align 8, !tbaa !3
  %arrayidx2.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 4
  store i64 %4, i64* %arrayidx2.i.4, align 8, !tbaa !3
  %arrayidx.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 5
  %5 = load i64, i64* %arrayidx.i.5, align 8, !tbaa !3
  %arrayidx2.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 5
  store i64 %5, i64* %arrayidx2.i.5, align 8, !tbaa !3
  %arrayidx.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 6
  %6 = load i64, i64* %arrayidx.i.6, align 8, !tbaa !3
  %arrayidx2.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 6
  store i64 %6, i64* %arrayidx2.i.6, align 8, !tbaa !3
  %arrayidx.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 7
  %7 = load i64, i64* %arrayidx.i.7, align 8, !tbaa !3
  %arrayidx2.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 7
  store i64 %7, i64* %arrayidx2.i.7, align 8, !tbaa !3
  %arrayidx.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 8
  %8 = load i64, i64* %arrayidx.i.8, align 8, !tbaa !3
  %arrayidx2.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 8
  store i64 %8, i64* %arrayidx2.i.8, align 8, !tbaa !3
  %arrayidx.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 9
  %9 = load i64, i64* %arrayidx.i.9, align 8, !tbaa !3
  %arrayidx2.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 9
  store i64 %9, i64* %arrayidx2.i.9, align 8, !tbaa !3
  %arrayidx.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 10
  %10 = load i64, i64* %arrayidx.i.10, align 8, !tbaa !3
  %arrayidx2.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 10
  store i64 %10, i64* %arrayidx2.i.10, align 8, !tbaa !3
  %arrayidx.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 11
  %11 = load i64, i64* %arrayidx.i.11, align 8, !tbaa !3
  %arrayidx2.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 11
  store i64 %11, i64* %arrayidx2.i.11, align 8, !tbaa !3
  %arrayidx.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 12
  %12 = load i64, i64* %arrayidx.i.12, align 8, !tbaa !3
  %arrayidx2.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 12
  store i64 %12, i64* %arrayidx2.i.12, align 8, !tbaa !3
  %arrayidx.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 13
  %13 = load i64, i64* %arrayidx.i.13, align 8, !tbaa !3
  %arrayidx2.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 13
  store i64 %13, i64* %arrayidx2.i.13, align 8, !tbaa !3
  %arrayidx.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 14
  %14 = load i64, i64* %arrayidx.i.14, align 8, !tbaa !3
  %arrayidx2.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 14
  store i64 %14, i64* %arrayidx2.i.14, align 8, !tbaa !3
  %arrayidx.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 15
  %15 = load i64, i64* %arrayidx.i.15, align 8, !tbaa !3
  %arrayidx2.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 15
  store i64 %15, i64* %arrayidx2.i.15, align 8, !tbaa !3
  %arrayidx.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 16
  %16 = load i64, i64* %arrayidx.i.16, align 8, !tbaa !3
  %arrayidx2.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 16
  store i64 %16, i64* %arrayidx2.i.16, align 8, !tbaa !3
  %arrayidx.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 17
  %17 = load i64, i64* %arrayidx.i.17, align 8, !tbaa !3
  %arrayidx2.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 17
  store i64 %17, i64* %arrayidx2.i.17, align 8, !tbaa !3
  %arrayidx.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 18
  %18 = load i64, i64* %arrayidx.i.18, align 8, !tbaa !3
  %arrayidx2.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 18
  store i64 %18, i64* %arrayidx2.i.18, align 8, !tbaa !3
  %arrayidx.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 19
  %19 = load i64, i64* %arrayidx.i.19, align 8, !tbaa !3
  %arrayidx2.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 19
  store i64 %19, i64* %arrayidx2.i.19, align 8, !tbaa !3
  %arrayidx.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 20
  %20 = load i64, i64* %arrayidx.i.20, align 8, !tbaa !3
  %arrayidx2.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 20
  store i64 %20, i64* %arrayidx2.i.20, align 8, !tbaa !3
  %arrayidx.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 21
  %21 = load i64, i64* %arrayidx.i.21, align 8, !tbaa !3
  %arrayidx2.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 21
  store i64 %21, i64* %arrayidx2.i.21, align 8, !tbaa !3
  %arrayidx.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 22
  %22 = load i64, i64* %arrayidx.i.22, align 8, !tbaa !3
  %arrayidx2.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 22
  store i64 %22, i64* %arrayidx2.i.22, align 8, !tbaa !3
  %arrayidx.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 23
  %23 = load i64, i64* %arrayidx.i.23, align 8, !tbaa !3
  %arrayidx2.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 23
  store i64 %23, i64* %arrayidx2.i.23, align 8, !tbaa !3
  %arrayidx.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 24
  %24 = load i64, i64* %arrayidx.i.24, align 8, !tbaa !3
  %arrayidx2.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 24
  store i64 %24, i64* %arrayidx2.i.24, align 8, !tbaa !3
  %arrayidx.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 25
  %25 = load i64, i64* %arrayidx.i.25, align 8, !tbaa !3
  %arrayidx2.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 25
  store i64 %25, i64* %arrayidx2.i.25, align 8, !tbaa !3
  %arrayidx.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 26
  %26 = load i64, i64* %arrayidx.i.26, align 8, !tbaa !3
  %arrayidx2.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 26
  store i64 %26, i64* %arrayidx2.i.26, align 8, !tbaa !3
  %arrayidx.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 27
  %27 = load i64, i64* %arrayidx.i.27, align 8, !tbaa !3
  %arrayidx2.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 27
  store i64 %27, i64* %arrayidx2.i.27, align 8, !tbaa !3
  %arrayidx.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 28
  %28 = load i64, i64* %arrayidx.i.28, align 8, !tbaa !3
  %arrayidx2.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 28
  store i64 %28, i64* %arrayidx2.i.28, align 8, !tbaa !3
  %arrayidx.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 29
  %29 = load i64, i64* %arrayidx.i.29, align 8, !tbaa !3
  %arrayidx2.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 29
  store i64 %29, i64* %arrayidx2.i.29, align 8, !tbaa !3
  %arrayidx.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 30
  %30 = load i64, i64* %arrayidx.i.30, align 8, !tbaa !3
  %arrayidx2.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 30
  store i64 %30, i64* %arrayidx2.i.30, align 8, !tbaa !3
  %arrayidx.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 31
  %31 = load i64, i64* %arrayidx.i.31, align 8, !tbaa !3
  %arrayidx2.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 31
  store i64 %31, i64* %arrayidx2.i.31, align 8, !tbaa !3
  %arrayidx.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 32
  %32 = load i64, i64* %arrayidx.i.32, align 8, !tbaa !3
  %arrayidx2.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 32
  store i64 %32, i64* %arrayidx2.i.32, align 8, !tbaa !3
  %arrayidx.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 33
  %33 = load i64, i64* %arrayidx.i.33, align 8, !tbaa !3
  %arrayidx2.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 33
  store i64 %33, i64* %arrayidx2.i.33, align 8, !tbaa !3
  %arrayidx.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 34
  %34 = load i64, i64* %arrayidx.i.34, align 8, !tbaa !3
  %arrayidx2.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 34
  store i64 %34, i64* %arrayidx2.i.34, align 8, !tbaa !3
  %arrayidx.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 35
  %35 = load i64, i64* %arrayidx.i.35, align 8, !tbaa !3
  %arrayidx2.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 35
  store i64 %35, i64* %arrayidx2.i.35, align 8, !tbaa !3
  %arrayidx.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 36
  %36 = load i64, i64* %arrayidx.i.36, align 8, !tbaa !3
  %arrayidx2.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 36
  store i64 %36, i64* %arrayidx2.i.36, align 8, !tbaa !3
  %arrayidx.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 37
  %37 = load i64, i64* %arrayidx.i.37, align 8, !tbaa !3
  %arrayidx2.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 37
  store i64 %37, i64* %arrayidx2.i.37, align 8, !tbaa !3
  %arrayidx.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 38
  %38 = load i64, i64* %arrayidx.i.38, align 8, !tbaa !3
  %arrayidx2.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 38
  store i64 %38, i64* %arrayidx2.i.38, align 8, !tbaa !3
  %arrayidx.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 39
  %39 = load i64, i64* %arrayidx.i.39, align 8, !tbaa !3
  %arrayidx2.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 39
  store i64 %39, i64* %arrayidx2.i.39, align 8, !tbaa !3
  %cmp5 = icmp sgt i32 %e, 0
  br i1 %cmp5, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body, %entry
  ret void

for.body:                                         ; preds = %entry, %for.body
  %i.06 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  tail call void @xTPL(%struct.point_proj* %Q, %struct.point_proj* %Q, [10 x i64]* %A24minus, [10 x i64]* %A24plus)
  %inc = add nuw nsw i32 %i.06, 1
  %exitcond = icmp eq i32 %inc, %e
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

; Function Attrs: nounwind ssp uwtable
define void @get_3_isog(%struct.point_proj* %P, [10 x i64]* %A24minus, [10 x i64]* %A24plus, [2 x [10 x i64]]* %coeff) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %t3 = alloca [2 x [10 x i64]], align 16
  %t4 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = bitcast [2 x [10 x i64]]* %t3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  %4 = bitcast [2 x [10 x i64]]* %t4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 0, i64 0
  tail call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 1, i64 0
  tail call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %5 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  %6 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %7 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i60 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i60) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay4.i, i64* %arraydecay4.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  %8 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i60, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  %arraydecay22.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  %arraydecay4.i63 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i63) #10
  %arraydecay10.i66 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i66) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay4.i63, i64* nonnull %arraydecay10.i66, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i63, i64* nonnull %arraydecay10.i66, i64* nonnull %arraydecay8.i60) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay4.i63, i64* nonnull %arraydecay4.i63, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i76 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i60, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i76) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  %arraydecay22.i78 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i66, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i78) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  %arraydecay19 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0
  %arraydecay4.i81 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay4.i81) #10
  %arraydecay10.i84 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay10.i84) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  %9 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %10 = load i64, i64* %arraydecay10.i84, align 16, !tbaa !3
  %add3.i.i1429 = add i64 %10, %9
  store i64 %add3.i.i1429, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i1430 = xor i64 %add3.i.i1429, %9
  %xor1.i24.i.i1431 = xor i64 %10, %9
  %or.i25.i.i1432 = or i64 %xor.i23.i.i1430, %xor1.i24.i.i1431
  %xor2.i26.i.i1433 = xor i64 %or.i25.i.i1432, %add3.i.i1429
  %or29.i.i1434 = lshr i64 %xor2.i26.i.i1433, 63
  %arrayidx.i.1.i1435 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 1
  %11 = load i64, i64* %arrayidx.i.1.i1435, align 8, !tbaa !3
  %add.i.1.i1436 = add i64 %or29.i.i1434, %11
  %arrayidx2.i.1.i1437 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 1
  %12 = load i64, i64* %arrayidx2.i.1.i1437, align 8, !tbaa !3
  %add3.i.1.i1438 = add i64 %add.i.1.i1436, %12
  %arrayidx5.i.1.i1439 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i1438, i64* %arrayidx5.i.1.i1439, align 8, !tbaa !3
  %13 = xor i64 %add.i.1.i1436, -9223372036854775808
  %xor2.i.i.1.i1440 = and i64 %13, %11
  %xor.i23.i.1.i1441 = xor i64 %add3.i.1.i1438, %add.i.1.i1436
  %xor1.i24.i.1.i1442 = xor i64 %add.i.1.i1436, %12
  %or.i25.i.1.i1443 = or i64 %xor.i23.i.1.i1441, %xor1.i24.i.1.i1442
  %xor2.i26.i.1.i1444 = xor i64 %or.i25.i.1.i1443, %add3.i.1.i1438
  %shr.i30.i.1.i1445 = or i64 %xor2.i26.i.1.i1444, %xor2.i.i.1.i1440
  %or29.i.1.i1446 = lshr i64 %shr.i30.i.1.i1445, 63
  %arrayidx.i.2.i1447 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 2
  %14 = load i64, i64* %arrayidx.i.2.i1447, align 16, !tbaa !3
  %add.i.2.i1448 = add i64 %or29.i.1.i1446, %14
  %arrayidx2.i.2.i1449 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 2
  %15 = load i64, i64* %arrayidx2.i.2.i1449, align 16, !tbaa !3
  %add3.i.2.i1450 = add i64 %add.i.2.i1448, %15
  %arrayidx5.i.2.i1451 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i1450, i64* %arrayidx5.i.2.i1451, align 16, !tbaa !3
  %16 = xor i64 %add.i.2.i1448, -9223372036854775808
  %xor2.i.i.2.i1452 = and i64 %16, %14
  %xor.i23.i.2.i1453 = xor i64 %add3.i.2.i1450, %add.i.2.i1448
  %xor1.i24.i.2.i1454 = xor i64 %add.i.2.i1448, %15
  %or.i25.i.2.i1455 = or i64 %xor.i23.i.2.i1453, %xor1.i24.i.2.i1454
  %xor2.i26.i.2.i1456 = xor i64 %or.i25.i.2.i1455, %add3.i.2.i1450
  %shr.i30.i.2.i1457 = or i64 %xor2.i26.i.2.i1456, %xor2.i.i.2.i1452
  %or29.i.2.i1458 = lshr i64 %shr.i30.i.2.i1457, 63
  %arrayidx.i.3.i1459 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 3
  %17 = load i64, i64* %arrayidx.i.3.i1459, align 8, !tbaa !3
  %add.i.3.i1460 = add i64 %or29.i.2.i1458, %17
  %arrayidx2.i.3.i1461 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 3
  %18 = load i64, i64* %arrayidx2.i.3.i1461, align 8, !tbaa !3
  %add3.i.3.i1462 = add i64 %add.i.3.i1460, %18
  %arrayidx5.i.3.i1463 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i1462, i64* %arrayidx5.i.3.i1463, align 8, !tbaa !3
  %19 = xor i64 %add.i.3.i1460, -9223372036854775808
  %xor2.i.i.3.i1464 = and i64 %19, %17
  %xor.i23.i.3.i1465 = xor i64 %add3.i.3.i1462, %add.i.3.i1460
  %xor1.i24.i.3.i1466 = xor i64 %add.i.3.i1460, %18
  %or.i25.i.3.i1467 = or i64 %xor.i23.i.3.i1465, %xor1.i24.i.3.i1466
  %xor2.i26.i.3.i1468 = xor i64 %or.i25.i.3.i1467, %add3.i.3.i1462
  %shr.i30.i.3.i1469 = or i64 %xor2.i26.i.3.i1468, %xor2.i.i.3.i1464
  %or29.i.3.i1470 = lshr i64 %shr.i30.i.3.i1469, 63
  %arrayidx.i.4.i1471 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 4
  %20 = load i64, i64* %arrayidx.i.4.i1471, align 16, !tbaa !3
  %add.i.4.i1472 = add i64 %or29.i.3.i1470, %20
  %arrayidx2.i.4.i1473 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 4
  %21 = load i64, i64* %arrayidx2.i.4.i1473, align 16, !tbaa !3
  %add3.i.4.i1474 = add i64 %add.i.4.i1472, %21
  %arrayidx5.i.4.i1475 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i1474, i64* %arrayidx5.i.4.i1475, align 16, !tbaa !3
  %22 = xor i64 %add.i.4.i1472, -9223372036854775808
  %xor2.i.i.4.i1476 = and i64 %22, %20
  %xor.i23.i.4.i1477 = xor i64 %add3.i.4.i1474, %add.i.4.i1472
  %xor1.i24.i.4.i1478 = xor i64 %add.i.4.i1472, %21
  %or.i25.i.4.i1479 = or i64 %xor.i23.i.4.i1477, %xor1.i24.i.4.i1478
  %xor2.i26.i.4.i1480 = xor i64 %or.i25.i.4.i1479, %add3.i.4.i1474
  %shr.i30.i.4.i1481 = or i64 %xor2.i26.i.4.i1480, %xor2.i.i.4.i1476
  %or29.i.4.i1482 = lshr i64 %shr.i30.i.4.i1481, 63
  %arrayidx.i.5.i1483 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 5
  %23 = load i64, i64* %arrayidx.i.5.i1483, align 8, !tbaa !3
  %add.i.5.i1484 = add i64 %or29.i.4.i1482, %23
  %arrayidx2.i.5.i1485 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 5
  %24 = load i64, i64* %arrayidx2.i.5.i1485, align 8, !tbaa !3
  %add3.i.5.i1486 = add i64 %add.i.5.i1484, %24
  %arrayidx5.i.5.i1487 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i1486, i64* %arrayidx5.i.5.i1487, align 8, !tbaa !3
  %25 = xor i64 %add.i.5.i1484, -9223372036854775808
  %xor2.i.i.5.i1488 = and i64 %25, %23
  %xor.i23.i.5.i1489 = xor i64 %add3.i.5.i1486, %add.i.5.i1484
  %xor1.i24.i.5.i1490 = xor i64 %add.i.5.i1484, %24
  %or.i25.i.5.i1491 = or i64 %xor.i23.i.5.i1489, %xor1.i24.i.5.i1490
  %xor2.i26.i.5.i1492 = xor i64 %or.i25.i.5.i1491, %add3.i.5.i1486
  %shr.i30.i.5.i1493 = or i64 %xor2.i26.i.5.i1492, %xor2.i.i.5.i1488
  %or29.i.5.i1494 = lshr i64 %shr.i30.i.5.i1493, 63
  %arrayidx.i.6.i1495 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 6
  %26 = load i64, i64* %arrayidx.i.6.i1495, align 16, !tbaa !3
  %add.i.6.i1496 = add i64 %or29.i.5.i1494, %26
  %arrayidx2.i.6.i1497 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 6
  %27 = load i64, i64* %arrayidx2.i.6.i1497, align 16, !tbaa !3
  %add3.i.6.i1498 = add i64 %add.i.6.i1496, %27
  %arrayidx5.i.6.i1499 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i1498, i64* %arrayidx5.i.6.i1499, align 16, !tbaa !3
  %28 = xor i64 %add.i.6.i1496, -9223372036854775808
  %xor2.i.i.6.i1500 = and i64 %28, %26
  %xor.i23.i.6.i1501 = xor i64 %add3.i.6.i1498, %add.i.6.i1496
  %xor1.i24.i.6.i1502 = xor i64 %add.i.6.i1496, %27
  %or.i25.i.6.i1503 = or i64 %xor.i23.i.6.i1501, %xor1.i24.i.6.i1502
  %xor2.i26.i.6.i1504 = xor i64 %or.i25.i.6.i1503, %add3.i.6.i1498
  %shr.i30.i.6.i1505 = or i64 %xor2.i26.i.6.i1504, %xor2.i.i.6.i1500
  %or29.i.6.i1506 = lshr i64 %shr.i30.i.6.i1505, 63
  %arrayidx.i.7.i1507 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 7
  %29 = load i64, i64* %arrayidx.i.7.i1507, align 8, !tbaa !3
  %add.i.7.i1508 = add i64 %or29.i.6.i1506, %29
  %arrayidx2.i.7.i1509 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 7
  %30 = load i64, i64* %arrayidx2.i.7.i1509, align 8, !tbaa !3
  %add3.i.7.i1510 = add i64 %add.i.7.i1508, %30
  %arrayidx5.i.7.i1511 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i1510, i64* %arrayidx5.i.7.i1511, align 8, !tbaa !3
  %31 = xor i64 %add.i.7.i1508, -9223372036854775808
  %xor2.i.i.7.i1512 = and i64 %31, %29
  %xor.i23.i.7.i1513 = xor i64 %add3.i.7.i1510, %add.i.7.i1508
  %xor1.i24.i.7.i1514 = xor i64 %add.i.7.i1508, %30
  %or.i25.i.7.i1515 = or i64 %xor.i23.i.7.i1513, %xor1.i24.i.7.i1514
  %xor2.i26.i.7.i1516 = xor i64 %or.i25.i.7.i1515, %add3.i.7.i1510
  %shr.i30.i.7.i1517 = or i64 %xor2.i26.i.7.i1516, %xor2.i.i.7.i1512
  %or29.i.7.i1518 = lshr i64 %shr.i30.i.7.i1517, 63
  %arrayidx.i.8.i1519 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 8
  %32 = load i64, i64* %arrayidx.i.8.i1519, align 16, !tbaa !3
  %add.i.8.i1520 = add i64 %or29.i.7.i1518, %32
  %arrayidx2.i.8.i1521 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 8
  %33 = load i64, i64* %arrayidx2.i.8.i1521, align 16, !tbaa !3
  %add3.i.8.i1522 = add i64 %add.i.8.i1520, %33
  %arrayidx5.i.8.i1523 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i1522, i64* %arrayidx5.i.8.i1523, align 16, !tbaa !3
  %34 = xor i64 %add.i.8.i1520, -9223372036854775808
  %xor2.i.i.8.i1524 = and i64 %34, %32
  %xor.i23.i.8.i1525 = xor i64 %add3.i.8.i1522, %add.i.8.i1520
  %xor1.i24.i.8.i1526 = xor i64 %add.i.8.i1520, %33
  %or.i25.i.8.i1527 = or i64 %xor.i23.i.8.i1525, %xor1.i24.i.8.i1526
  %xor2.i26.i.8.i1528 = xor i64 %or.i25.i.8.i1527, %add3.i.8.i1522
  %shr.i30.i.8.i1529 = or i64 %xor2.i26.i.8.i1528, %xor2.i.i.8.i1524
  %or29.i.8.i1530 = lshr i64 %shr.i30.i.8.i1529, 63
  %arrayidx.i.9.i1531 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 9
  %35 = load i64, i64* %arrayidx.i.9.i1531, align 8, !tbaa !3
  %arrayidx2.i.9.i1533 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 9
  %36 = load i64, i64* %arrayidx2.i.9.i1533, align 8, !tbaa !3
  %add.i.9.i1532 = add i64 %36, %35
  %add3.i.9.i1534 = add i64 %add.i.9.i1532, %or29.i.8.i1530
  %arrayidx5.i.9.i1535 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i1534, i64* %arrayidx5.i.9.i1535, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i81, i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay8.i60) #10
  %37 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %add3.i.i1322 = shl i64 %37, 1
  store i64 %add3.i.i1322, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i1327 = lshr i64 %37, 63
  %38 = load i64, i64* %arrayidx.i.1.i1435, align 8, !tbaa !3
  %add.i.1.i1329 = add i64 %38, %or29.i.i1327
  %add3.i.1.i1331 = add i64 %add.i.1.i1329, %38
  %arrayidx5.i.1.i1332 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i1331, i64* %arrayidx5.i.1.i1332, align 8, !tbaa !3
  %39 = xor i64 %add.i.1.i1329, -9223372036854775808
  %xor2.i.i.1.i1333 = and i64 %39, %38
  %xor.i23.i.1.i1334 = xor i64 %add3.i.1.i1331, %add.i.1.i1329
  %xor1.i24.i.1.i1335 = xor i64 %add.i.1.i1329, %38
  %or.i25.i.1.i1336 = or i64 %xor.i23.i.1.i1334, %xor1.i24.i.1.i1335
  %xor2.i26.i.1.i1337 = xor i64 %or.i25.i.1.i1336, %add3.i.1.i1331
  %shr.i30.i.1.i1338 = or i64 %xor2.i26.i.1.i1337, %xor2.i.i.1.i1333
  %or29.i.1.i1339 = lshr i64 %shr.i30.i.1.i1338, 63
  %40 = load i64, i64* %arrayidx.i.2.i1447, align 16, !tbaa !3
  %add.i.2.i1341 = add i64 %or29.i.1.i1339, %40
  %add3.i.2.i1343 = add i64 %add.i.2.i1341, %40
  %arrayidx5.i.2.i1344 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i1343, i64* %arrayidx5.i.2.i1344, align 16, !tbaa !3
  %41 = xor i64 %add.i.2.i1341, -9223372036854775808
  %xor2.i.i.2.i1345 = and i64 %41, %40
  %xor.i23.i.2.i1346 = xor i64 %add3.i.2.i1343, %add.i.2.i1341
  %xor1.i24.i.2.i1347 = xor i64 %add.i.2.i1341, %40
  %or.i25.i.2.i1348 = or i64 %xor.i23.i.2.i1346, %xor1.i24.i.2.i1347
  %xor2.i26.i.2.i1349 = xor i64 %or.i25.i.2.i1348, %add3.i.2.i1343
  %shr.i30.i.2.i1350 = or i64 %xor2.i26.i.2.i1349, %xor2.i.i.2.i1345
  %or29.i.2.i1351 = lshr i64 %shr.i30.i.2.i1350, 63
  %42 = load i64, i64* %arrayidx.i.3.i1459, align 8, !tbaa !3
  %add.i.3.i1353 = add i64 %or29.i.2.i1351, %42
  %add3.i.3.i1355 = add i64 %add.i.3.i1353, %42
  %arrayidx5.i.3.i1356 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i1355, i64* %arrayidx5.i.3.i1356, align 8, !tbaa !3
  %43 = xor i64 %add.i.3.i1353, -9223372036854775808
  %xor2.i.i.3.i1357 = and i64 %43, %42
  %xor.i23.i.3.i1358 = xor i64 %add3.i.3.i1355, %add.i.3.i1353
  %xor1.i24.i.3.i1359 = xor i64 %add.i.3.i1353, %42
  %or.i25.i.3.i1360 = or i64 %xor.i23.i.3.i1358, %xor1.i24.i.3.i1359
  %xor2.i26.i.3.i1361 = xor i64 %or.i25.i.3.i1360, %add3.i.3.i1355
  %shr.i30.i.3.i1362 = or i64 %xor2.i26.i.3.i1361, %xor2.i.i.3.i1357
  %or29.i.3.i1363 = lshr i64 %shr.i30.i.3.i1362, 63
  %44 = load i64, i64* %arrayidx.i.4.i1471, align 16, !tbaa !3
  %add.i.4.i1365 = add i64 %or29.i.3.i1363, %44
  %add3.i.4.i1367 = add i64 %add.i.4.i1365, %44
  %arrayidx5.i.4.i1368 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i1367, i64* %arrayidx5.i.4.i1368, align 16, !tbaa !3
  %45 = xor i64 %add.i.4.i1365, -9223372036854775808
  %xor2.i.i.4.i1369 = and i64 %45, %44
  %xor.i23.i.4.i1370 = xor i64 %add3.i.4.i1367, %add.i.4.i1365
  %xor1.i24.i.4.i1371 = xor i64 %add.i.4.i1365, %44
  %or.i25.i.4.i1372 = or i64 %xor.i23.i.4.i1370, %xor1.i24.i.4.i1371
  %xor2.i26.i.4.i1373 = xor i64 %or.i25.i.4.i1372, %add3.i.4.i1367
  %shr.i30.i.4.i1374 = or i64 %xor2.i26.i.4.i1373, %xor2.i.i.4.i1369
  %or29.i.4.i1375 = lshr i64 %shr.i30.i.4.i1374, 63
  %46 = load i64, i64* %arrayidx.i.5.i1483, align 8, !tbaa !3
  %add.i.5.i1377 = add i64 %or29.i.4.i1375, %46
  %add3.i.5.i1379 = add i64 %add.i.5.i1377, %46
  %arrayidx5.i.5.i1380 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i1379, i64* %arrayidx5.i.5.i1380, align 8, !tbaa !3
  %47 = xor i64 %add.i.5.i1377, -9223372036854775808
  %xor2.i.i.5.i1381 = and i64 %47, %46
  %xor.i23.i.5.i1382 = xor i64 %add3.i.5.i1379, %add.i.5.i1377
  %xor1.i24.i.5.i1383 = xor i64 %add.i.5.i1377, %46
  %or.i25.i.5.i1384 = or i64 %xor.i23.i.5.i1382, %xor1.i24.i.5.i1383
  %xor2.i26.i.5.i1385 = xor i64 %or.i25.i.5.i1384, %add3.i.5.i1379
  %shr.i30.i.5.i1386 = or i64 %xor2.i26.i.5.i1385, %xor2.i.i.5.i1381
  %or29.i.5.i1387 = lshr i64 %shr.i30.i.5.i1386, 63
  %48 = load i64, i64* %arrayidx.i.6.i1495, align 16, !tbaa !3
  %add.i.6.i1389 = add i64 %or29.i.5.i1387, %48
  %add3.i.6.i1391 = add i64 %add.i.6.i1389, %48
  %arrayidx5.i.6.i1392 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i1391, i64* %arrayidx5.i.6.i1392, align 16, !tbaa !3
  %49 = xor i64 %add.i.6.i1389, -9223372036854775808
  %xor2.i.i.6.i1393 = and i64 %49, %48
  %xor.i23.i.6.i1394 = xor i64 %add3.i.6.i1391, %add.i.6.i1389
  %xor1.i24.i.6.i1395 = xor i64 %add.i.6.i1389, %48
  %or.i25.i.6.i1396 = or i64 %xor.i23.i.6.i1394, %xor1.i24.i.6.i1395
  %xor2.i26.i.6.i1397 = xor i64 %or.i25.i.6.i1396, %add3.i.6.i1391
  %shr.i30.i.6.i1398 = or i64 %xor2.i26.i.6.i1397, %xor2.i.i.6.i1393
  %or29.i.6.i1399 = lshr i64 %shr.i30.i.6.i1398, 63
  %50 = load i64, i64* %arrayidx.i.7.i1507, align 8, !tbaa !3
  %add.i.7.i1401 = add i64 %or29.i.6.i1399, %50
  %add3.i.7.i1403 = add i64 %add.i.7.i1401, %50
  %arrayidx5.i.7.i1404 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i1403, i64* %arrayidx5.i.7.i1404, align 8, !tbaa !3
  %51 = xor i64 %add.i.7.i1401, -9223372036854775808
  %xor2.i.i.7.i1405 = and i64 %51, %50
  %xor.i23.i.7.i1406 = xor i64 %add3.i.7.i1403, %add.i.7.i1401
  %xor1.i24.i.7.i1407 = xor i64 %add.i.7.i1401, %50
  %or.i25.i.7.i1408 = or i64 %xor.i23.i.7.i1406, %xor1.i24.i.7.i1407
  %xor2.i26.i.7.i1409 = xor i64 %or.i25.i.7.i1408, %add3.i.7.i1403
  %shr.i30.i.7.i1410 = or i64 %xor2.i26.i.7.i1409, %xor2.i.i.7.i1405
  %or29.i.7.i1411 = lshr i64 %shr.i30.i.7.i1410, 63
  %52 = load i64, i64* %arrayidx.i.8.i1519, align 16, !tbaa !3
  %add.i.8.i1413 = add i64 %or29.i.7.i1411, %52
  %add3.i.8.i1415 = add i64 %add.i.8.i1413, %52
  %arrayidx5.i.8.i1416 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i1415, i64* %arrayidx5.i.8.i1416, align 16, !tbaa !3
  %53 = xor i64 %add.i.8.i1413, -9223372036854775808
  %xor2.i.i.8.i1417 = and i64 %53, %52
  %xor.i23.i.8.i1418 = xor i64 %add3.i.8.i1415, %add.i.8.i1413
  %xor1.i24.i.8.i1419 = xor i64 %add.i.8.i1413, %52
  %or.i25.i.8.i1420 = or i64 %xor.i23.i.8.i1418, %xor1.i24.i.8.i1419
  %xor2.i26.i.8.i1421 = xor i64 %or.i25.i.8.i1420, %add3.i.8.i1415
  %shr.i30.i.8.i1422 = or i64 %xor2.i26.i.8.i1421, %xor2.i.i.8.i1417
  %or29.i.8.i1423 = lshr i64 %shr.i30.i.8.i1422, 63
  %54 = load i64, i64* %arrayidx.i.9.i1531, align 8, !tbaa !3
  %factor = shl i64 %54, 1
  %add3.i.9.i1427 = or i64 %or29.i.8.i1423, %factor
  %arrayidx5.i.9.i1428 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i1427, i64* %arrayidx5.i.9.i1428, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i60, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i81) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i84) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  %arraydecay24 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  %arraydecay4.i99 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  call void @fpsub610(i64* nonnull %arraydecay4.i81, i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay4.i99) #10
  %arraydecay10.i102 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  call void @fpsub610(i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay10.i102) #10
  call void @fpsub610(i64* nonnull %arraydecay4.i81, i64* nonnull %arraydecay17.i76, i64* nonnull %arraydecay4.i81) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i84, i64* nonnull %arraydecay22.i78, i64* nonnull %arraydecay10.i84) #10
  %arraydecay30 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0
  %arraydecay4.i111 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 0
  %55 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %56 = load i64, i64* %arraydecay4.i81, align 16, !tbaa !3
  %add3.i.i115 = add i64 %56, %55
  store i64 %add3.i.i115, i64* %arraydecay4.i111, align 16, !tbaa !3
  %xor.i23.i.i116 = xor i64 %add3.i.i115, %55
  %xor1.i24.i.i117 = xor i64 %56, %55
  %or.i25.i.i118 = or i64 %xor.i23.i.i116, %xor1.i24.i.i117
  %xor2.i26.i.i119 = xor i64 %or.i25.i.i118, %add3.i.i115
  %or29.i.i120 = lshr i64 %xor2.i26.i.i119, 63
  %arrayidx.i.1.i121 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %57 = load i64, i64* %arrayidx.i.1.i121, align 8, !tbaa !3
  %add.i.1.i122 = add i64 %or29.i.i120, %57
  %58 = load i64, i64* %arrayidx.i.1.i1435, align 8, !tbaa !3
  %add3.i.1.i124 = add i64 %add.i.1.i122, %58
  %arrayidx5.i.1.i125 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 1
  store i64 %add3.i.1.i124, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %59 = xor i64 %add.i.1.i122, -9223372036854775808
  %xor2.i.i.1.i126 = and i64 %59, %57
  %xor.i23.i.1.i127 = xor i64 %add3.i.1.i124, %add.i.1.i122
  %xor1.i24.i.1.i128 = xor i64 %add.i.1.i122, %58
  %or.i25.i.1.i129 = or i64 %xor.i23.i.1.i127, %xor1.i24.i.1.i128
  %xor2.i26.i.1.i130 = xor i64 %or.i25.i.1.i129, %add3.i.1.i124
  %shr.i30.i.1.i131 = or i64 %xor2.i26.i.1.i130, %xor2.i.i.1.i126
  %or29.i.1.i132 = lshr i64 %shr.i30.i.1.i131, 63
  %arrayidx.i.2.i133 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %60 = load i64, i64* %arrayidx.i.2.i133, align 16, !tbaa !3
  %add.i.2.i134 = add i64 %or29.i.1.i132, %60
  %61 = load i64, i64* %arrayidx.i.2.i1447, align 16, !tbaa !3
  %add3.i.2.i136 = add i64 %add.i.2.i134, %61
  %arrayidx5.i.2.i137 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 2
  store i64 %add3.i.2.i136, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %62 = xor i64 %add.i.2.i134, -9223372036854775808
  %xor2.i.i.2.i138 = and i64 %62, %60
  %xor.i23.i.2.i139 = xor i64 %add3.i.2.i136, %add.i.2.i134
  %xor1.i24.i.2.i140 = xor i64 %add.i.2.i134, %61
  %or.i25.i.2.i141 = or i64 %xor.i23.i.2.i139, %xor1.i24.i.2.i140
  %xor2.i26.i.2.i142 = xor i64 %or.i25.i.2.i141, %add3.i.2.i136
  %shr.i30.i.2.i143 = or i64 %xor2.i26.i.2.i142, %xor2.i.i.2.i138
  %or29.i.2.i144 = lshr i64 %shr.i30.i.2.i143, 63
  %arrayidx.i.3.i145 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %63 = load i64, i64* %arrayidx.i.3.i145, align 8, !tbaa !3
  %add.i.3.i146 = add i64 %or29.i.2.i144, %63
  %64 = load i64, i64* %arrayidx.i.3.i1459, align 8, !tbaa !3
  %add3.i.3.i148 = add i64 %add.i.3.i146, %64
  %arrayidx5.i.3.i149 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 3
  store i64 %add3.i.3.i148, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %65 = xor i64 %add.i.3.i146, -9223372036854775808
  %xor2.i.i.3.i150 = and i64 %65, %63
  %xor.i23.i.3.i151 = xor i64 %add3.i.3.i148, %add.i.3.i146
  %xor1.i24.i.3.i152 = xor i64 %add.i.3.i146, %64
  %or.i25.i.3.i153 = or i64 %xor.i23.i.3.i151, %xor1.i24.i.3.i152
  %xor2.i26.i.3.i154 = xor i64 %or.i25.i.3.i153, %add3.i.3.i148
  %shr.i30.i.3.i155 = or i64 %xor2.i26.i.3.i154, %xor2.i.i.3.i150
  %or29.i.3.i156 = lshr i64 %shr.i30.i.3.i155, 63
  %arrayidx.i.4.i157 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %66 = load i64, i64* %arrayidx.i.4.i157, align 16, !tbaa !3
  %add.i.4.i158 = add i64 %or29.i.3.i156, %66
  %67 = load i64, i64* %arrayidx.i.4.i1471, align 16, !tbaa !3
  %add3.i.4.i160 = add i64 %add.i.4.i158, %67
  %arrayidx5.i.4.i161 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 4
  store i64 %add3.i.4.i160, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %68 = xor i64 %add.i.4.i158, -9223372036854775808
  %xor2.i.i.4.i162 = and i64 %68, %66
  %xor.i23.i.4.i163 = xor i64 %add3.i.4.i160, %add.i.4.i158
  %xor1.i24.i.4.i164 = xor i64 %add.i.4.i158, %67
  %or.i25.i.4.i165 = or i64 %xor.i23.i.4.i163, %xor1.i24.i.4.i164
  %xor2.i26.i.4.i166 = xor i64 %or.i25.i.4.i165, %add3.i.4.i160
  %shr.i30.i.4.i167 = or i64 %xor2.i26.i.4.i166, %xor2.i.i.4.i162
  %or29.i.4.i168 = lshr i64 %shr.i30.i.4.i167, 63
  %arrayidx.i.5.i169 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %69 = load i64, i64* %arrayidx.i.5.i169, align 8, !tbaa !3
  %add.i.5.i170 = add i64 %or29.i.4.i168, %69
  %70 = load i64, i64* %arrayidx.i.5.i1483, align 8, !tbaa !3
  %add3.i.5.i172 = add i64 %add.i.5.i170, %70
  %arrayidx5.i.5.i173 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 5
  store i64 %add3.i.5.i172, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %71 = xor i64 %add.i.5.i170, -9223372036854775808
  %xor2.i.i.5.i174 = and i64 %71, %69
  %xor.i23.i.5.i175 = xor i64 %add3.i.5.i172, %add.i.5.i170
  %xor1.i24.i.5.i176 = xor i64 %add.i.5.i170, %70
  %or.i25.i.5.i177 = or i64 %xor.i23.i.5.i175, %xor1.i24.i.5.i176
  %xor2.i26.i.5.i178 = xor i64 %or.i25.i.5.i177, %add3.i.5.i172
  %shr.i30.i.5.i179 = or i64 %xor2.i26.i.5.i178, %xor2.i.i.5.i174
  %or29.i.5.i180 = lshr i64 %shr.i30.i.5.i179, 63
  %arrayidx.i.6.i181 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %72 = load i64, i64* %arrayidx.i.6.i181, align 16, !tbaa !3
  %add.i.6.i182 = add i64 %or29.i.5.i180, %72
  %73 = load i64, i64* %arrayidx.i.6.i1495, align 16, !tbaa !3
  %add3.i.6.i184 = add i64 %add.i.6.i182, %73
  %arrayidx5.i.6.i185 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 6
  store i64 %add3.i.6.i184, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %74 = xor i64 %add.i.6.i182, -9223372036854775808
  %xor2.i.i.6.i186 = and i64 %74, %72
  %xor.i23.i.6.i187 = xor i64 %add3.i.6.i184, %add.i.6.i182
  %xor1.i24.i.6.i188 = xor i64 %add.i.6.i182, %73
  %or.i25.i.6.i189 = or i64 %xor.i23.i.6.i187, %xor1.i24.i.6.i188
  %xor2.i26.i.6.i190 = xor i64 %or.i25.i.6.i189, %add3.i.6.i184
  %shr.i30.i.6.i191 = or i64 %xor2.i26.i.6.i190, %xor2.i.i.6.i186
  %or29.i.6.i192 = lshr i64 %shr.i30.i.6.i191, 63
  %arrayidx.i.7.i193 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %75 = load i64, i64* %arrayidx.i.7.i193, align 8, !tbaa !3
  %add.i.7.i194 = add i64 %or29.i.6.i192, %75
  %76 = load i64, i64* %arrayidx.i.7.i1507, align 8, !tbaa !3
  %add3.i.7.i196 = add i64 %add.i.7.i194, %76
  %arrayidx5.i.7.i197 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 7
  store i64 %add3.i.7.i196, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %77 = xor i64 %add.i.7.i194, -9223372036854775808
  %xor2.i.i.7.i198 = and i64 %77, %75
  %xor.i23.i.7.i199 = xor i64 %add3.i.7.i196, %add.i.7.i194
  %xor1.i24.i.7.i200 = xor i64 %add.i.7.i194, %76
  %or.i25.i.7.i201 = or i64 %xor.i23.i.7.i199, %xor1.i24.i.7.i200
  %xor2.i26.i.7.i202 = xor i64 %or.i25.i.7.i201, %add3.i.7.i196
  %shr.i30.i.7.i203 = or i64 %xor2.i26.i.7.i202, %xor2.i.i.7.i198
  %or29.i.7.i204 = lshr i64 %shr.i30.i.7.i203, 63
  %arrayidx.i.8.i205 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %78 = load i64, i64* %arrayidx.i.8.i205, align 16, !tbaa !3
  %add.i.8.i206 = add i64 %or29.i.7.i204, %78
  %79 = load i64, i64* %arrayidx.i.8.i1519, align 16, !tbaa !3
  %add3.i.8.i208 = add i64 %add.i.8.i206, %79
  %arrayidx5.i.8.i209 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 8
  store i64 %add3.i.8.i208, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %80 = xor i64 %add.i.8.i206, -9223372036854775808
  %xor2.i.i.8.i210 = and i64 %80, %78
  %xor.i23.i.8.i211 = xor i64 %add3.i.8.i208, %add.i.8.i206
  %xor1.i24.i.8.i212 = xor i64 %add.i.8.i206, %79
  %or.i25.i.8.i213 = or i64 %xor.i23.i.8.i211, %xor1.i24.i.8.i212
  %xor2.i26.i.8.i214 = xor i64 %or.i25.i.8.i213, %add3.i.8.i208
  %shr.i30.i.8.i215 = or i64 %xor2.i26.i.8.i214, %xor2.i.i.8.i210
  %or29.i.8.i216 = lshr i64 %shr.i30.i.8.i215, 63
  %arrayidx.i.9.i217 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %81 = load i64, i64* %arrayidx.i.9.i217, align 8, !tbaa !3
  %82 = load i64, i64* %arrayidx.i.9.i1531, align 8, !tbaa !3
  %add.i.9.i218 = add i64 %82, %81
  %add3.i.9.i220 = add i64 %add.i.9.i218, %or29.i.8.i216
  %arrayidx5.i.9.i221 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 9
  store i64 %add3.i.9.i220, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %arraydecay10.i114 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 0
  %83 = load i64, i64* %arraydecay22.i, align 16, !tbaa !3
  %84 = load i64, i64* %arraydecay10.i84, align 16, !tbaa !3
  %add3.i.i = add i64 %84, %83
  store i64 %add3.i.i, i64* %arraydecay10.i114, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %83
  %xor1.i24.i.i = xor i64 %84, %83
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %85 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %85
  %86 = load i64, i64* %arrayidx2.i.1.i1437, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %86
  %arrayidx5.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %87 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %87, %85
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %86
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %88 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %88
  %89 = load i64, i64* %arrayidx2.i.2.i1449, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %89
  %arrayidx5.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %90 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %90, %88
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %89
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %91 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %91
  %92 = load i64, i64* %arrayidx2.i.3.i1461, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %92
  %arrayidx5.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %93 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %93, %91
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %92
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %94 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %94
  %95 = load i64, i64* %arrayidx2.i.4.i1473, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %95
  %arrayidx5.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %96 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %96, %94
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %95
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %97 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %97
  %98 = load i64, i64* %arrayidx2.i.5.i1485, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %98
  %arrayidx5.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %99 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %99, %97
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %98
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %100 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %100
  %101 = load i64, i64* %arrayidx2.i.6.i1497, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %101
  %arrayidx5.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %102 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %102, %100
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %101
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %103 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %103
  %104 = load i64, i64* %arrayidx2.i.7.i1509, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %104
  %arrayidx5.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %105 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %105, %103
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %104
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %106 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %106
  %107 = load i64, i64* %arrayidx2.i.8.i1521, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %107
  %arrayidx5.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %108 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %108, %106
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %107
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %109 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %110 = load i64, i64* %arrayidx2.i.9.i1533, align 8, !tbaa !3
  %add.i.9.i = add i64 %110, %109
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %add3.i.i335 = shl i64 %add3.i.i115, 1
  store i64 %add3.i.i335, i64* %arraydecay4.i111, align 16, !tbaa !3
  %or29.i.i340 = lshr i64 %add3.i.i115, 63
  %add.i.1.i342 = add i64 %add3.i.1.i124, %or29.i.i340
  %add3.i.1.i344 = add i64 %add.i.1.i342, %add3.i.1.i124
  store i64 %add3.i.1.i344, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %111 = xor i64 %add.i.1.i342, -9223372036854775808
  %xor2.i.i.1.i346 = and i64 %111, %add3.i.1.i124
  %xor.i23.i.1.i347 = xor i64 %add3.i.1.i344, %add.i.1.i342
  %xor1.i24.i.1.i348 = xor i64 %add.i.1.i342, %add3.i.1.i124
  %or.i25.i.1.i349 = or i64 %xor.i23.i.1.i347, %xor1.i24.i.1.i348
  %xor2.i26.i.1.i350 = xor i64 %or.i25.i.1.i349, %add3.i.1.i344
  %shr.i30.i.1.i351 = or i64 %xor2.i26.i.1.i350, %xor2.i.i.1.i346
  %or29.i.1.i352 = lshr i64 %shr.i30.i.1.i351, 63
  %add.i.2.i354 = add i64 %add3.i.2.i136, %or29.i.1.i352
  %add3.i.2.i356 = add i64 %add.i.2.i354, %add3.i.2.i136
  store i64 %add3.i.2.i356, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %112 = xor i64 %add.i.2.i354, -9223372036854775808
  %xor2.i.i.2.i358 = and i64 %112, %add3.i.2.i136
  %xor.i23.i.2.i359 = xor i64 %add3.i.2.i356, %add.i.2.i354
  %xor1.i24.i.2.i360 = xor i64 %add.i.2.i354, %add3.i.2.i136
  %or.i25.i.2.i361 = or i64 %xor.i23.i.2.i359, %xor1.i24.i.2.i360
  %xor2.i26.i.2.i362 = xor i64 %or.i25.i.2.i361, %add3.i.2.i356
  %shr.i30.i.2.i363 = or i64 %xor2.i26.i.2.i362, %xor2.i.i.2.i358
  %or29.i.2.i364 = lshr i64 %shr.i30.i.2.i363, 63
  %add.i.3.i366 = add i64 %add3.i.3.i148, %or29.i.2.i364
  %add3.i.3.i368 = add i64 %add.i.3.i366, %add3.i.3.i148
  store i64 %add3.i.3.i368, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %113 = xor i64 %add.i.3.i366, -9223372036854775808
  %xor2.i.i.3.i370 = and i64 %113, %add3.i.3.i148
  %xor.i23.i.3.i371 = xor i64 %add3.i.3.i368, %add.i.3.i366
  %xor1.i24.i.3.i372 = xor i64 %add.i.3.i366, %add3.i.3.i148
  %or.i25.i.3.i373 = or i64 %xor.i23.i.3.i371, %xor1.i24.i.3.i372
  %xor2.i26.i.3.i374 = xor i64 %or.i25.i.3.i373, %add3.i.3.i368
  %shr.i30.i.3.i375 = or i64 %xor2.i26.i.3.i374, %xor2.i.i.3.i370
  %or29.i.3.i376 = lshr i64 %shr.i30.i.3.i375, 63
  %add.i.4.i378 = add i64 %add3.i.4.i160, %or29.i.3.i376
  %add3.i.4.i380 = add i64 %add.i.4.i378, %add3.i.4.i160
  store i64 %add3.i.4.i380, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %114 = xor i64 %add.i.4.i378, -9223372036854775808
  %xor2.i.i.4.i382 = and i64 %114, %add3.i.4.i160
  %xor.i23.i.4.i383 = xor i64 %add3.i.4.i380, %add.i.4.i378
  %xor1.i24.i.4.i384 = xor i64 %add.i.4.i378, %add3.i.4.i160
  %or.i25.i.4.i385 = or i64 %xor.i23.i.4.i383, %xor1.i24.i.4.i384
  %xor2.i26.i.4.i386 = xor i64 %or.i25.i.4.i385, %add3.i.4.i380
  %shr.i30.i.4.i387 = or i64 %xor2.i26.i.4.i386, %xor2.i.i.4.i382
  %or29.i.4.i388 = lshr i64 %shr.i30.i.4.i387, 63
  %add.i.5.i390 = add i64 %add3.i.5.i172, %or29.i.4.i388
  %add3.i.5.i392 = add i64 %add.i.5.i390, %add3.i.5.i172
  store i64 %add3.i.5.i392, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %115 = xor i64 %add.i.5.i390, -9223372036854775808
  %xor2.i.i.5.i394 = and i64 %115, %add3.i.5.i172
  %xor.i23.i.5.i395 = xor i64 %add3.i.5.i392, %add.i.5.i390
  %xor1.i24.i.5.i396 = xor i64 %add.i.5.i390, %add3.i.5.i172
  %or.i25.i.5.i397 = or i64 %xor.i23.i.5.i395, %xor1.i24.i.5.i396
  %xor2.i26.i.5.i398 = xor i64 %or.i25.i.5.i397, %add3.i.5.i392
  %shr.i30.i.5.i399 = or i64 %xor2.i26.i.5.i398, %xor2.i.i.5.i394
  %or29.i.5.i400 = lshr i64 %shr.i30.i.5.i399, 63
  %add.i.6.i402 = add i64 %add3.i.6.i184, %or29.i.5.i400
  %add3.i.6.i404 = add i64 %add.i.6.i402, %add3.i.6.i184
  store i64 %add3.i.6.i404, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %116 = xor i64 %add.i.6.i402, -9223372036854775808
  %xor2.i.i.6.i406 = and i64 %116, %add3.i.6.i184
  %xor.i23.i.6.i407 = xor i64 %add3.i.6.i404, %add.i.6.i402
  %xor1.i24.i.6.i408 = xor i64 %add.i.6.i402, %add3.i.6.i184
  %or.i25.i.6.i409 = or i64 %xor.i23.i.6.i407, %xor1.i24.i.6.i408
  %xor2.i26.i.6.i410 = xor i64 %or.i25.i.6.i409, %add3.i.6.i404
  %shr.i30.i.6.i411 = or i64 %xor2.i26.i.6.i410, %xor2.i.i.6.i406
  %or29.i.6.i412 = lshr i64 %shr.i30.i.6.i411, 63
  %add.i.7.i414 = add i64 %add3.i.7.i196, %or29.i.6.i412
  %add3.i.7.i416 = add i64 %add.i.7.i414, %add3.i.7.i196
  store i64 %add3.i.7.i416, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %117 = xor i64 %add.i.7.i414, -9223372036854775808
  %xor2.i.i.7.i418 = and i64 %117, %add3.i.7.i196
  %xor.i23.i.7.i419 = xor i64 %add3.i.7.i416, %add.i.7.i414
  %xor1.i24.i.7.i420 = xor i64 %add.i.7.i414, %add3.i.7.i196
  %or.i25.i.7.i421 = or i64 %xor.i23.i.7.i419, %xor1.i24.i.7.i420
  %xor2.i26.i.7.i422 = xor i64 %or.i25.i.7.i421, %add3.i.7.i416
  %shr.i30.i.7.i423 = or i64 %xor2.i26.i.7.i422, %xor2.i.i.7.i418
  %or29.i.7.i424 = lshr i64 %shr.i30.i.7.i423, 63
  %add.i.8.i426 = add i64 %add3.i.8.i208, %or29.i.7.i424
  %add3.i.8.i428 = add i64 %add.i.8.i426, %add3.i.8.i208
  store i64 %add3.i.8.i428, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %118 = xor i64 %add.i.8.i426, -9223372036854775808
  %xor2.i.i.8.i430 = and i64 %118, %add3.i.8.i208
  %xor.i23.i.8.i431 = xor i64 %add3.i.8.i428, %add.i.8.i426
  %xor1.i24.i.8.i432 = xor i64 %add.i.8.i426, %add3.i.8.i208
  %or.i25.i.8.i433 = or i64 %xor.i23.i.8.i431, %xor1.i24.i.8.i432
  %xor2.i26.i.8.i434 = xor i64 %or.i25.i.8.i433, %add3.i.8.i428
  %shr.i30.i.8.i435 = or i64 %xor2.i26.i.8.i434, %xor2.i.i.8.i430
  %or29.i.8.i436 = lshr i64 %shr.i30.i.8.i435, 63
  %factor1536 = shl i64 %add3.i.9.i220, 1
  %add3.i.9.i440 = or i64 %factor1536, %or29.i.8.i436
  store i64 %add3.i.9.i440, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %add3.i.i228 = shl i64 %add3.i.i, 1
  store i64 %add3.i.i228, i64* %arraydecay10.i114, align 16, !tbaa !3
  %or29.i.i233 = lshr i64 %add3.i.i, 63
  %add.i.1.i235 = add i64 %add3.i.1.i, %or29.i.i233
  %add3.i.1.i237 = add i64 %add.i.1.i235, %add3.i.1.i
  store i64 %add3.i.1.i237, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %119 = xor i64 %add.i.1.i235, -9223372036854775808
  %xor2.i.i.1.i239 = and i64 %119, %add3.i.1.i
  %xor.i23.i.1.i240 = xor i64 %add3.i.1.i237, %add.i.1.i235
  %xor1.i24.i.1.i241 = xor i64 %add.i.1.i235, %add3.i.1.i
  %or.i25.i.1.i242 = or i64 %xor.i23.i.1.i240, %xor1.i24.i.1.i241
  %xor2.i26.i.1.i243 = xor i64 %or.i25.i.1.i242, %add3.i.1.i237
  %shr.i30.i.1.i244 = or i64 %xor2.i26.i.1.i243, %xor2.i.i.1.i239
  %or29.i.1.i245 = lshr i64 %shr.i30.i.1.i244, 63
  %add.i.2.i247 = add i64 %add3.i.2.i, %or29.i.1.i245
  %add3.i.2.i249 = add i64 %add.i.2.i247, %add3.i.2.i
  store i64 %add3.i.2.i249, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %120 = xor i64 %add.i.2.i247, -9223372036854775808
  %xor2.i.i.2.i251 = and i64 %120, %add3.i.2.i
  %xor.i23.i.2.i252 = xor i64 %add3.i.2.i249, %add.i.2.i247
  %xor1.i24.i.2.i253 = xor i64 %add.i.2.i247, %add3.i.2.i
  %or.i25.i.2.i254 = or i64 %xor.i23.i.2.i252, %xor1.i24.i.2.i253
  %xor2.i26.i.2.i255 = xor i64 %or.i25.i.2.i254, %add3.i.2.i249
  %shr.i30.i.2.i256 = or i64 %xor2.i26.i.2.i255, %xor2.i.i.2.i251
  %or29.i.2.i257 = lshr i64 %shr.i30.i.2.i256, 63
  %add.i.3.i259 = add i64 %add3.i.3.i, %or29.i.2.i257
  %add3.i.3.i261 = add i64 %add.i.3.i259, %add3.i.3.i
  store i64 %add3.i.3.i261, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %121 = xor i64 %add.i.3.i259, -9223372036854775808
  %xor2.i.i.3.i263 = and i64 %121, %add3.i.3.i
  %xor.i23.i.3.i264 = xor i64 %add3.i.3.i261, %add.i.3.i259
  %xor1.i24.i.3.i265 = xor i64 %add.i.3.i259, %add3.i.3.i
  %or.i25.i.3.i266 = or i64 %xor.i23.i.3.i264, %xor1.i24.i.3.i265
  %xor2.i26.i.3.i267 = xor i64 %or.i25.i.3.i266, %add3.i.3.i261
  %shr.i30.i.3.i268 = or i64 %xor2.i26.i.3.i267, %xor2.i.i.3.i263
  %or29.i.3.i269 = lshr i64 %shr.i30.i.3.i268, 63
  %add.i.4.i271 = add i64 %add3.i.4.i, %or29.i.3.i269
  %add3.i.4.i273 = add i64 %add.i.4.i271, %add3.i.4.i
  store i64 %add3.i.4.i273, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %122 = xor i64 %add.i.4.i271, -9223372036854775808
  %xor2.i.i.4.i275 = and i64 %122, %add3.i.4.i
  %xor.i23.i.4.i276 = xor i64 %add3.i.4.i273, %add.i.4.i271
  %xor1.i24.i.4.i277 = xor i64 %add.i.4.i271, %add3.i.4.i
  %or.i25.i.4.i278 = or i64 %xor.i23.i.4.i276, %xor1.i24.i.4.i277
  %xor2.i26.i.4.i279 = xor i64 %or.i25.i.4.i278, %add3.i.4.i273
  %shr.i30.i.4.i280 = or i64 %xor2.i26.i.4.i279, %xor2.i.i.4.i275
  %or29.i.4.i281 = lshr i64 %shr.i30.i.4.i280, 63
  %add.i.5.i283 = add i64 %add3.i.5.i, %or29.i.4.i281
  %add3.i.5.i285 = add i64 %add.i.5.i283, %add3.i.5.i
  store i64 %add3.i.5.i285, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %123 = xor i64 %add.i.5.i283, -9223372036854775808
  %xor2.i.i.5.i287 = and i64 %123, %add3.i.5.i
  %xor.i23.i.5.i288 = xor i64 %add3.i.5.i285, %add.i.5.i283
  %xor1.i24.i.5.i289 = xor i64 %add.i.5.i283, %add3.i.5.i
  %or.i25.i.5.i290 = or i64 %xor.i23.i.5.i288, %xor1.i24.i.5.i289
  %xor2.i26.i.5.i291 = xor i64 %or.i25.i.5.i290, %add3.i.5.i285
  %shr.i30.i.5.i292 = or i64 %xor2.i26.i.5.i291, %xor2.i.i.5.i287
  %or29.i.5.i293 = lshr i64 %shr.i30.i.5.i292, 63
  %add.i.6.i295 = add i64 %add3.i.6.i, %or29.i.5.i293
  %add3.i.6.i297 = add i64 %add.i.6.i295, %add3.i.6.i
  store i64 %add3.i.6.i297, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %124 = xor i64 %add.i.6.i295, -9223372036854775808
  %xor2.i.i.6.i299 = and i64 %124, %add3.i.6.i
  %xor.i23.i.6.i300 = xor i64 %add3.i.6.i297, %add.i.6.i295
  %xor1.i24.i.6.i301 = xor i64 %add.i.6.i295, %add3.i.6.i
  %or.i25.i.6.i302 = or i64 %xor.i23.i.6.i300, %xor1.i24.i.6.i301
  %xor2.i26.i.6.i303 = xor i64 %or.i25.i.6.i302, %add3.i.6.i297
  %shr.i30.i.6.i304 = or i64 %xor2.i26.i.6.i303, %xor2.i.i.6.i299
  %or29.i.6.i305 = lshr i64 %shr.i30.i.6.i304, 63
  %add.i.7.i307 = add i64 %add3.i.7.i, %or29.i.6.i305
  %add3.i.7.i309 = add i64 %add.i.7.i307, %add3.i.7.i
  store i64 %add3.i.7.i309, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %125 = xor i64 %add.i.7.i307, -9223372036854775808
  %xor2.i.i.7.i311 = and i64 %125, %add3.i.7.i
  %xor.i23.i.7.i312 = xor i64 %add3.i.7.i309, %add.i.7.i307
  %xor1.i24.i.7.i313 = xor i64 %add.i.7.i307, %add3.i.7.i
  %or.i25.i.7.i314 = or i64 %xor.i23.i.7.i312, %xor1.i24.i.7.i313
  %xor2.i26.i.7.i315 = xor i64 %or.i25.i.7.i314, %add3.i.7.i309
  %shr.i30.i.7.i316 = or i64 %xor2.i26.i.7.i315, %xor2.i.i.7.i311
  %or29.i.7.i317 = lshr i64 %shr.i30.i.7.i316, 63
  %add.i.8.i319 = add i64 %add3.i.8.i, %or29.i.7.i317
  %add3.i.8.i321 = add i64 %add.i.8.i319, %add3.i.8.i
  store i64 %add3.i.8.i321, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %126 = xor i64 %add.i.8.i319, -9223372036854775808
  %xor2.i.i.8.i323 = and i64 %126, %add3.i.8.i
  %xor.i23.i.8.i324 = xor i64 %add3.i.8.i321, %add.i.8.i319
  %xor1.i24.i.8.i325 = xor i64 %add.i.8.i319, %add3.i.8.i
  %or.i25.i.8.i326 = or i64 %xor.i23.i.8.i324, %xor1.i24.i.8.i325
  %xor2.i26.i.8.i327 = xor i64 %or.i25.i.8.i326, %add3.i.8.i321
  %shr.i30.i.8.i328 = or i64 %xor2.i26.i.8.i327, %xor2.i.i.8.i323
  %or29.i.8.i329 = lshr i64 %shr.i30.i.8.i328, 63
  %factor1537 = shl i64 %add3.i.9.i, 1
  %add3.i.9.i333 = or i64 %factor1537, %or29.i.8.i329
  store i64 %add3.i.9.i333, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %127 = load i64, i64* %arraydecay17.i76, align 16, !tbaa !3
  %add3.i.i555 = add i64 %127, %add3.i.i335
  store i64 %add3.i.i555, i64* %arraydecay4.i111, align 16, !tbaa !3
  %xor.i23.i.i556 = xor i64 %add3.i.i555, %127
  %xor1.i24.i.i557 = xor i64 %127, %add3.i.i335
  %or.i25.i.i558 = or i64 %xor.i23.i.i556, %xor1.i24.i.i557
  %xor2.i26.i.i559 = xor i64 %or.i25.i.i558, %add3.i.i555
  %or29.i.i560 = lshr i64 %xor2.i26.i.i559, 63
  %arrayidx.i.1.i561 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %128 = load i64, i64* %arrayidx.i.1.i561, align 8, !tbaa !3
  %add.i.1.i562 = add i64 %or29.i.i560, %128
  %add3.i.1.i564 = add i64 %add.i.1.i562, %add3.i.1.i344
  store i64 %add3.i.1.i564, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %129 = xor i64 %add.i.1.i562, -9223372036854775808
  %xor2.i.i.1.i566 = and i64 %129, %128
  %xor.i23.i.1.i567 = xor i64 %add3.i.1.i564, %add.i.1.i562
  %xor1.i24.i.1.i568 = xor i64 %add.i.1.i562, %add3.i.1.i344
  %or.i25.i.1.i569 = or i64 %xor.i23.i.1.i567, %xor1.i24.i.1.i568
  %xor2.i26.i.1.i570 = xor i64 %or.i25.i.1.i569, %add3.i.1.i564
  %shr.i30.i.1.i571 = or i64 %xor2.i26.i.1.i570, %xor2.i.i.1.i566
  %or29.i.1.i572 = lshr i64 %shr.i30.i.1.i571, 63
  %arrayidx.i.2.i573 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %130 = load i64, i64* %arrayidx.i.2.i573, align 16, !tbaa !3
  %add.i.2.i574 = add i64 %or29.i.1.i572, %130
  %add3.i.2.i576 = add i64 %add.i.2.i574, %add3.i.2.i356
  store i64 %add3.i.2.i576, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %131 = xor i64 %add.i.2.i574, -9223372036854775808
  %xor2.i.i.2.i578 = and i64 %131, %130
  %xor.i23.i.2.i579 = xor i64 %add3.i.2.i576, %add.i.2.i574
  %xor1.i24.i.2.i580 = xor i64 %add.i.2.i574, %add3.i.2.i356
  %or.i25.i.2.i581 = or i64 %xor.i23.i.2.i579, %xor1.i24.i.2.i580
  %xor2.i26.i.2.i582 = xor i64 %or.i25.i.2.i581, %add3.i.2.i576
  %shr.i30.i.2.i583 = or i64 %xor2.i26.i.2.i582, %xor2.i.i.2.i578
  %or29.i.2.i584 = lshr i64 %shr.i30.i.2.i583, 63
  %arrayidx.i.3.i585 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %132 = load i64, i64* %arrayidx.i.3.i585, align 8, !tbaa !3
  %add.i.3.i586 = add i64 %or29.i.2.i584, %132
  %add3.i.3.i588 = add i64 %add.i.3.i586, %add3.i.3.i368
  store i64 %add3.i.3.i588, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %133 = xor i64 %add.i.3.i586, -9223372036854775808
  %xor2.i.i.3.i590 = and i64 %133, %132
  %xor.i23.i.3.i591 = xor i64 %add3.i.3.i588, %add.i.3.i586
  %xor1.i24.i.3.i592 = xor i64 %add.i.3.i586, %add3.i.3.i368
  %or.i25.i.3.i593 = or i64 %xor.i23.i.3.i591, %xor1.i24.i.3.i592
  %xor2.i26.i.3.i594 = xor i64 %or.i25.i.3.i593, %add3.i.3.i588
  %shr.i30.i.3.i595 = or i64 %xor2.i26.i.3.i594, %xor2.i.i.3.i590
  %or29.i.3.i596 = lshr i64 %shr.i30.i.3.i595, 63
  %arrayidx.i.4.i597 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %134 = load i64, i64* %arrayidx.i.4.i597, align 16, !tbaa !3
  %add.i.4.i598 = add i64 %or29.i.3.i596, %134
  %add3.i.4.i600 = add i64 %add.i.4.i598, %add3.i.4.i380
  store i64 %add3.i.4.i600, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %135 = xor i64 %add.i.4.i598, -9223372036854775808
  %xor2.i.i.4.i602 = and i64 %135, %134
  %xor.i23.i.4.i603 = xor i64 %add3.i.4.i600, %add.i.4.i598
  %xor1.i24.i.4.i604 = xor i64 %add.i.4.i598, %add3.i.4.i380
  %or.i25.i.4.i605 = or i64 %xor.i23.i.4.i603, %xor1.i24.i.4.i604
  %xor2.i26.i.4.i606 = xor i64 %or.i25.i.4.i605, %add3.i.4.i600
  %shr.i30.i.4.i607 = or i64 %xor2.i26.i.4.i606, %xor2.i.i.4.i602
  %or29.i.4.i608 = lshr i64 %shr.i30.i.4.i607, 63
  %arrayidx.i.5.i609 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %136 = load i64, i64* %arrayidx.i.5.i609, align 8, !tbaa !3
  %add.i.5.i610 = add i64 %or29.i.4.i608, %136
  %add3.i.5.i612 = add i64 %add.i.5.i610, %add3.i.5.i392
  store i64 %add3.i.5.i612, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %137 = xor i64 %add.i.5.i610, -9223372036854775808
  %xor2.i.i.5.i614 = and i64 %137, %136
  %xor.i23.i.5.i615 = xor i64 %add3.i.5.i612, %add.i.5.i610
  %xor1.i24.i.5.i616 = xor i64 %add.i.5.i610, %add3.i.5.i392
  %or.i25.i.5.i617 = or i64 %xor.i23.i.5.i615, %xor1.i24.i.5.i616
  %xor2.i26.i.5.i618 = xor i64 %or.i25.i.5.i617, %add3.i.5.i612
  %shr.i30.i.5.i619 = or i64 %xor2.i26.i.5.i618, %xor2.i.i.5.i614
  %or29.i.5.i620 = lshr i64 %shr.i30.i.5.i619, 63
  %arrayidx.i.6.i621 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %138 = load i64, i64* %arrayidx.i.6.i621, align 16, !tbaa !3
  %add.i.6.i622 = add i64 %or29.i.5.i620, %138
  %add3.i.6.i624 = add i64 %add.i.6.i622, %add3.i.6.i404
  store i64 %add3.i.6.i624, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %139 = xor i64 %add.i.6.i622, -9223372036854775808
  %xor2.i.i.6.i626 = and i64 %139, %138
  %xor.i23.i.6.i627 = xor i64 %add3.i.6.i624, %add.i.6.i622
  %xor1.i24.i.6.i628 = xor i64 %add.i.6.i622, %add3.i.6.i404
  %or.i25.i.6.i629 = or i64 %xor.i23.i.6.i627, %xor1.i24.i.6.i628
  %xor2.i26.i.6.i630 = xor i64 %or.i25.i.6.i629, %add3.i.6.i624
  %shr.i30.i.6.i631 = or i64 %xor2.i26.i.6.i630, %xor2.i.i.6.i626
  %or29.i.6.i632 = lshr i64 %shr.i30.i.6.i631, 63
  %arrayidx.i.7.i633 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %140 = load i64, i64* %arrayidx.i.7.i633, align 8, !tbaa !3
  %add.i.7.i634 = add i64 %or29.i.6.i632, %140
  %add3.i.7.i636 = add i64 %add.i.7.i634, %add3.i.7.i416
  store i64 %add3.i.7.i636, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %141 = xor i64 %add.i.7.i634, -9223372036854775808
  %xor2.i.i.7.i638 = and i64 %141, %140
  %xor.i23.i.7.i639 = xor i64 %add3.i.7.i636, %add.i.7.i634
  %xor1.i24.i.7.i640 = xor i64 %add.i.7.i634, %add3.i.7.i416
  %or.i25.i.7.i641 = or i64 %xor.i23.i.7.i639, %xor1.i24.i.7.i640
  %xor2.i26.i.7.i642 = xor i64 %or.i25.i.7.i641, %add3.i.7.i636
  %shr.i30.i.7.i643 = or i64 %xor2.i26.i.7.i642, %xor2.i.i.7.i638
  %or29.i.7.i644 = lshr i64 %shr.i30.i.7.i643, 63
  %arrayidx.i.8.i645 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %142 = load i64, i64* %arrayidx.i.8.i645, align 16, !tbaa !3
  %add.i.8.i646 = add i64 %or29.i.7.i644, %142
  %add3.i.8.i648 = add i64 %add.i.8.i646, %add3.i.8.i428
  store i64 %add3.i.8.i648, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %143 = xor i64 %add.i.8.i646, -9223372036854775808
  %xor2.i.i.8.i650 = and i64 %143, %142
  %xor.i23.i.8.i651 = xor i64 %add3.i.8.i648, %add.i.8.i646
  %xor1.i24.i.8.i652 = xor i64 %add.i.8.i646, %add3.i.8.i428
  %or.i25.i.8.i653 = or i64 %xor.i23.i.8.i651, %xor1.i24.i.8.i652
  %xor2.i26.i.8.i654 = xor i64 %or.i25.i.8.i653, %add3.i.8.i648
  %shr.i30.i.8.i655 = or i64 %xor2.i26.i.8.i654, %xor2.i.i.8.i650
  %or29.i.8.i656 = lshr i64 %shr.i30.i.8.i655, 63
  %arrayidx.i.9.i657 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %144 = load i64, i64* %arrayidx.i.9.i657, align 8, !tbaa !3
  %add.i.9.i658 = add i64 %144, %add3.i.9.i440
  %add3.i.9.i660 = add i64 %add.i.9.i658, %or29.i.8.i656
  store i64 %add3.i.9.i660, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %145 = load i64, i64* %arraydecay22.i78, align 16, !tbaa !3
  %add3.i.i448 = add i64 %145, %add3.i.i228
  store i64 %add3.i.i448, i64* %arraydecay10.i114, align 16, !tbaa !3
  %xor.i23.i.i449 = xor i64 %add3.i.i448, %145
  %xor1.i24.i.i450 = xor i64 %145, %add3.i.i228
  %or.i25.i.i451 = or i64 %xor.i23.i.i449, %xor1.i24.i.i450
  %xor2.i26.i.i452 = xor i64 %or.i25.i.i451, %add3.i.i448
  %or29.i.i453 = lshr i64 %xor2.i26.i.i452, 63
  %arrayidx.i.1.i454 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %146 = load i64, i64* %arrayidx.i.1.i454, align 8, !tbaa !3
  %add.i.1.i455 = add i64 %or29.i.i453, %146
  %add3.i.1.i457 = add i64 %add.i.1.i455, %add3.i.1.i237
  store i64 %add3.i.1.i457, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %147 = xor i64 %add.i.1.i455, -9223372036854775808
  %xor2.i.i.1.i459 = and i64 %147, %146
  %xor.i23.i.1.i460 = xor i64 %add3.i.1.i457, %add.i.1.i455
  %xor1.i24.i.1.i461 = xor i64 %add.i.1.i455, %add3.i.1.i237
  %or.i25.i.1.i462 = or i64 %xor.i23.i.1.i460, %xor1.i24.i.1.i461
  %xor2.i26.i.1.i463 = xor i64 %or.i25.i.1.i462, %add3.i.1.i457
  %shr.i30.i.1.i464 = or i64 %xor2.i26.i.1.i463, %xor2.i.i.1.i459
  %or29.i.1.i465 = lshr i64 %shr.i30.i.1.i464, 63
  %arrayidx.i.2.i466 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %148 = load i64, i64* %arrayidx.i.2.i466, align 16, !tbaa !3
  %add.i.2.i467 = add i64 %or29.i.1.i465, %148
  %add3.i.2.i469 = add i64 %add.i.2.i467, %add3.i.2.i249
  store i64 %add3.i.2.i469, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %149 = xor i64 %add.i.2.i467, -9223372036854775808
  %xor2.i.i.2.i471 = and i64 %149, %148
  %xor.i23.i.2.i472 = xor i64 %add3.i.2.i469, %add.i.2.i467
  %xor1.i24.i.2.i473 = xor i64 %add.i.2.i467, %add3.i.2.i249
  %or.i25.i.2.i474 = or i64 %xor.i23.i.2.i472, %xor1.i24.i.2.i473
  %xor2.i26.i.2.i475 = xor i64 %or.i25.i.2.i474, %add3.i.2.i469
  %shr.i30.i.2.i476 = or i64 %xor2.i26.i.2.i475, %xor2.i.i.2.i471
  %or29.i.2.i477 = lshr i64 %shr.i30.i.2.i476, 63
  %arrayidx.i.3.i478 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %150 = load i64, i64* %arrayidx.i.3.i478, align 8, !tbaa !3
  %add.i.3.i479 = add i64 %or29.i.2.i477, %150
  %add3.i.3.i481 = add i64 %add.i.3.i479, %add3.i.3.i261
  store i64 %add3.i.3.i481, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %151 = xor i64 %add.i.3.i479, -9223372036854775808
  %xor2.i.i.3.i483 = and i64 %151, %150
  %xor.i23.i.3.i484 = xor i64 %add3.i.3.i481, %add.i.3.i479
  %xor1.i24.i.3.i485 = xor i64 %add.i.3.i479, %add3.i.3.i261
  %or.i25.i.3.i486 = or i64 %xor.i23.i.3.i484, %xor1.i24.i.3.i485
  %xor2.i26.i.3.i487 = xor i64 %or.i25.i.3.i486, %add3.i.3.i481
  %shr.i30.i.3.i488 = or i64 %xor2.i26.i.3.i487, %xor2.i.i.3.i483
  %or29.i.3.i489 = lshr i64 %shr.i30.i.3.i488, 63
  %arrayidx.i.4.i490 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %152 = load i64, i64* %arrayidx.i.4.i490, align 16, !tbaa !3
  %add.i.4.i491 = add i64 %or29.i.3.i489, %152
  %add3.i.4.i493 = add i64 %add.i.4.i491, %add3.i.4.i273
  store i64 %add3.i.4.i493, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %153 = xor i64 %add.i.4.i491, -9223372036854775808
  %xor2.i.i.4.i495 = and i64 %153, %152
  %xor.i23.i.4.i496 = xor i64 %add3.i.4.i493, %add.i.4.i491
  %xor1.i24.i.4.i497 = xor i64 %add.i.4.i491, %add3.i.4.i273
  %or.i25.i.4.i498 = or i64 %xor.i23.i.4.i496, %xor1.i24.i.4.i497
  %xor2.i26.i.4.i499 = xor i64 %or.i25.i.4.i498, %add3.i.4.i493
  %shr.i30.i.4.i500 = or i64 %xor2.i26.i.4.i499, %xor2.i.i.4.i495
  %or29.i.4.i501 = lshr i64 %shr.i30.i.4.i500, 63
  %arrayidx.i.5.i502 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %154 = load i64, i64* %arrayidx.i.5.i502, align 8, !tbaa !3
  %add.i.5.i503 = add i64 %or29.i.4.i501, %154
  %add3.i.5.i505 = add i64 %add.i.5.i503, %add3.i.5.i285
  store i64 %add3.i.5.i505, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %155 = xor i64 %add.i.5.i503, -9223372036854775808
  %xor2.i.i.5.i507 = and i64 %155, %154
  %xor.i23.i.5.i508 = xor i64 %add3.i.5.i505, %add.i.5.i503
  %xor1.i24.i.5.i509 = xor i64 %add.i.5.i503, %add3.i.5.i285
  %or.i25.i.5.i510 = or i64 %xor.i23.i.5.i508, %xor1.i24.i.5.i509
  %xor2.i26.i.5.i511 = xor i64 %or.i25.i.5.i510, %add3.i.5.i505
  %shr.i30.i.5.i512 = or i64 %xor2.i26.i.5.i511, %xor2.i.i.5.i507
  %or29.i.5.i513 = lshr i64 %shr.i30.i.5.i512, 63
  %arrayidx.i.6.i514 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %156 = load i64, i64* %arrayidx.i.6.i514, align 16, !tbaa !3
  %add.i.6.i515 = add i64 %or29.i.5.i513, %156
  %add3.i.6.i517 = add i64 %add.i.6.i515, %add3.i.6.i297
  store i64 %add3.i.6.i517, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %157 = xor i64 %add.i.6.i515, -9223372036854775808
  %xor2.i.i.6.i519 = and i64 %157, %156
  %xor.i23.i.6.i520 = xor i64 %add3.i.6.i517, %add.i.6.i515
  %xor1.i24.i.6.i521 = xor i64 %add.i.6.i515, %add3.i.6.i297
  %or.i25.i.6.i522 = or i64 %xor.i23.i.6.i520, %xor1.i24.i.6.i521
  %xor2.i26.i.6.i523 = xor i64 %or.i25.i.6.i522, %add3.i.6.i517
  %shr.i30.i.6.i524 = or i64 %xor2.i26.i.6.i523, %xor2.i.i.6.i519
  %or29.i.6.i525 = lshr i64 %shr.i30.i.6.i524, 63
  %arrayidx.i.7.i526 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %158 = load i64, i64* %arrayidx.i.7.i526, align 8, !tbaa !3
  %add.i.7.i527 = add i64 %or29.i.6.i525, %158
  %add3.i.7.i529 = add i64 %add.i.7.i527, %add3.i.7.i309
  store i64 %add3.i.7.i529, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %159 = xor i64 %add.i.7.i527, -9223372036854775808
  %xor2.i.i.7.i531 = and i64 %159, %158
  %xor.i23.i.7.i532 = xor i64 %add3.i.7.i529, %add.i.7.i527
  %xor1.i24.i.7.i533 = xor i64 %add.i.7.i527, %add3.i.7.i309
  %or.i25.i.7.i534 = or i64 %xor.i23.i.7.i532, %xor1.i24.i.7.i533
  %xor2.i26.i.7.i535 = xor i64 %or.i25.i.7.i534, %add3.i.7.i529
  %shr.i30.i.7.i536 = or i64 %xor2.i26.i.7.i535, %xor2.i.i.7.i531
  %or29.i.7.i537 = lshr i64 %shr.i30.i.7.i536, 63
  %arrayidx.i.8.i538 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %160 = load i64, i64* %arrayidx.i.8.i538, align 16, !tbaa !3
  %add.i.8.i539 = add i64 %or29.i.7.i537, %160
  %add3.i.8.i541 = add i64 %add.i.8.i539, %add3.i.8.i321
  store i64 %add3.i.8.i541, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %161 = xor i64 %add.i.8.i539, -9223372036854775808
  %xor2.i.i.8.i543 = and i64 %161, %160
  %xor.i23.i.8.i544 = xor i64 %add3.i.8.i541, %add.i.8.i539
  %xor1.i24.i.8.i545 = xor i64 %add.i.8.i539, %add3.i.8.i321
  %or.i25.i.8.i546 = or i64 %xor.i23.i.8.i544, %xor1.i24.i.8.i545
  %xor2.i26.i.8.i547 = xor i64 %or.i25.i.8.i546, %add3.i.8.i541
  %shr.i30.i.8.i548 = or i64 %xor2.i26.i.8.i547, %xor2.i.i.8.i543
  %or29.i.8.i549 = lshr i64 %shr.i30.i.8.i548, 63
  %arrayidx.i.9.i550 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %162 = load i64, i64* %arrayidx.i.9.i550, align 8, !tbaa !3
  %add.i.9.i551 = add i64 %162, %add3.i.9.i333
  %add3.i.9.i553 = add i64 %add.i.9.i551, %or29.i.8.i549
  store i64 %add3.i.9.i553, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay24, [10 x i64]* nonnull %arraydecay30, [10 x i64]* %A24minus)
  %163 = load i64, i64* %arraydecay17.i76, align 16, !tbaa !3
  %164 = load i64, i64* %arraydecay4.i99, align 16, !tbaa !3
  %add3.i.i775 = add i64 %164, %163
  store i64 %add3.i.i775, i64* %arraydecay4.i111, align 16, !tbaa !3
  %xor.i23.i.i776 = xor i64 %add3.i.i775, %163
  %xor1.i24.i.i777 = xor i64 %164, %163
  %or.i25.i.i778 = or i64 %xor.i23.i.i776, %xor1.i24.i.i777
  %xor2.i26.i.i779 = xor i64 %or.i25.i.i778, %add3.i.i775
  %or29.i.i780 = lshr i64 %xor2.i26.i.i779, 63
  %165 = load i64, i64* %arrayidx.i.1.i561, align 8, !tbaa !3
  %add.i.1.i782 = add i64 %or29.i.i780, %165
  %arrayidx2.i.1.i783 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 1
  %166 = load i64, i64* %arrayidx2.i.1.i783, align 8, !tbaa !3
  %add3.i.1.i784 = add i64 %add.i.1.i782, %166
  store i64 %add3.i.1.i784, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %167 = xor i64 %add.i.1.i782, -9223372036854775808
  %xor2.i.i.1.i786 = and i64 %167, %165
  %xor.i23.i.1.i787 = xor i64 %add3.i.1.i784, %add.i.1.i782
  %xor1.i24.i.1.i788 = xor i64 %add.i.1.i782, %166
  %or.i25.i.1.i789 = or i64 %xor.i23.i.1.i787, %xor1.i24.i.1.i788
  %xor2.i26.i.1.i790 = xor i64 %or.i25.i.1.i789, %add3.i.1.i784
  %shr.i30.i.1.i791 = or i64 %xor2.i26.i.1.i790, %xor2.i.i.1.i786
  %or29.i.1.i792 = lshr i64 %shr.i30.i.1.i791, 63
  %168 = load i64, i64* %arrayidx.i.2.i573, align 16, !tbaa !3
  %add.i.2.i794 = add i64 %or29.i.1.i792, %168
  %arrayidx2.i.2.i795 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 2
  %169 = load i64, i64* %arrayidx2.i.2.i795, align 16, !tbaa !3
  %add3.i.2.i796 = add i64 %add.i.2.i794, %169
  store i64 %add3.i.2.i796, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %170 = xor i64 %add.i.2.i794, -9223372036854775808
  %xor2.i.i.2.i798 = and i64 %170, %168
  %xor.i23.i.2.i799 = xor i64 %add3.i.2.i796, %add.i.2.i794
  %xor1.i24.i.2.i800 = xor i64 %add.i.2.i794, %169
  %or.i25.i.2.i801 = or i64 %xor.i23.i.2.i799, %xor1.i24.i.2.i800
  %xor2.i26.i.2.i802 = xor i64 %or.i25.i.2.i801, %add3.i.2.i796
  %shr.i30.i.2.i803 = or i64 %xor2.i26.i.2.i802, %xor2.i.i.2.i798
  %or29.i.2.i804 = lshr i64 %shr.i30.i.2.i803, 63
  %171 = load i64, i64* %arrayidx.i.3.i585, align 8, !tbaa !3
  %add.i.3.i806 = add i64 %or29.i.2.i804, %171
  %arrayidx2.i.3.i807 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 3
  %172 = load i64, i64* %arrayidx2.i.3.i807, align 8, !tbaa !3
  %add3.i.3.i808 = add i64 %add.i.3.i806, %172
  store i64 %add3.i.3.i808, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %173 = xor i64 %add.i.3.i806, -9223372036854775808
  %xor2.i.i.3.i810 = and i64 %173, %171
  %xor.i23.i.3.i811 = xor i64 %add3.i.3.i808, %add.i.3.i806
  %xor1.i24.i.3.i812 = xor i64 %add.i.3.i806, %172
  %or.i25.i.3.i813 = or i64 %xor.i23.i.3.i811, %xor1.i24.i.3.i812
  %xor2.i26.i.3.i814 = xor i64 %or.i25.i.3.i813, %add3.i.3.i808
  %shr.i30.i.3.i815 = or i64 %xor2.i26.i.3.i814, %xor2.i.i.3.i810
  %or29.i.3.i816 = lshr i64 %shr.i30.i.3.i815, 63
  %174 = load i64, i64* %arrayidx.i.4.i597, align 16, !tbaa !3
  %add.i.4.i818 = add i64 %or29.i.3.i816, %174
  %arrayidx2.i.4.i819 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 4
  %175 = load i64, i64* %arrayidx2.i.4.i819, align 16, !tbaa !3
  %add3.i.4.i820 = add i64 %add.i.4.i818, %175
  store i64 %add3.i.4.i820, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %176 = xor i64 %add.i.4.i818, -9223372036854775808
  %xor2.i.i.4.i822 = and i64 %176, %174
  %xor.i23.i.4.i823 = xor i64 %add3.i.4.i820, %add.i.4.i818
  %xor1.i24.i.4.i824 = xor i64 %add.i.4.i818, %175
  %or.i25.i.4.i825 = or i64 %xor.i23.i.4.i823, %xor1.i24.i.4.i824
  %xor2.i26.i.4.i826 = xor i64 %or.i25.i.4.i825, %add3.i.4.i820
  %shr.i30.i.4.i827 = or i64 %xor2.i26.i.4.i826, %xor2.i.i.4.i822
  %or29.i.4.i828 = lshr i64 %shr.i30.i.4.i827, 63
  %177 = load i64, i64* %arrayidx.i.5.i609, align 8, !tbaa !3
  %add.i.5.i830 = add i64 %or29.i.4.i828, %177
  %arrayidx2.i.5.i831 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 5
  %178 = load i64, i64* %arrayidx2.i.5.i831, align 8, !tbaa !3
  %add3.i.5.i832 = add i64 %add.i.5.i830, %178
  store i64 %add3.i.5.i832, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %179 = xor i64 %add.i.5.i830, -9223372036854775808
  %xor2.i.i.5.i834 = and i64 %179, %177
  %xor.i23.i.5.i835 = xor i64 %add3.i.5.i832, %add.i.5.i830
  %xor1.i24.i.5.i836 = xor i64 %add.i.5.i830, %178
  %or.i25.i.5.i837 = or i64 %xor.i23.i.5.i835, %xor1.i24.i.5.i836
  %xor2.i26.i.5.i838 = xor i64 %or.i25.i.5.i837, %add3.i.5.i832
  %shr.i30.i.5.i839 = or i64 %xor2.i26.i.5.i838, %xor2.i.i.5.i834
  %or29.i.5.i840 = lshr i64 %shr.i30.i.5.i839, 63
  %180 = load i64, i64* %arrayidx.i.6.i621, align 16, !tbaa !3
  %add.i.6.i842 = add i64 %or29.i.5.i840, %180
  %arrayidx2.i.6.i843 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 6
  %181 = load i64, i64* %arrayidx2.i.6.i843, align 16, !tbaa !3
  %add3.i.6.i844 = add i64 %add.i.6.i842, %181
  store i64 %add3.i.6.i844, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %182 = xor i64 %add.i.6.i842, -9223372036854775808
  %xor2.i.i.6.i846 = and i64 %182, %180
  %xor.i23.i.6.i847 = xor i64 %add3.i.6.i844, %add.i.6.i842
  %xor1.i24.i.6.i848 = xor i64 %add.i.6.i842, %181
  %or.i25.i.6.i849 = or i64 %xor.i23.i.6.i847, %xor1.i24.i.6.i848
  %xor2.i26.i.6.i850 = xor i64 %or.i25.i.6.i849, %add3.i.6.i844
  %shr.i30.i.6.i851 = or i64 %xor2.i26.i.6.i850, %xor2.i.i.6.i846
  %or29.i.6.i852 = lshr i64 %shr.i30.i.6.i851, 63
  %183 = load i64, i64* %arrayidx.i.7.i633, align 8, !tbaa !3
  %add.i.7.i854 = add i64 %or29.i.6.i852, %183
  %arrayidx2.i.7.i855 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 7
  %184 = load i64, i64* %arrayidx2.i.7.i855, align 8, !tbaa !3
  %add3.i.7.i856 = add i64 %add.i.7.i854, %184
  store i64 %add3.i.7.i856, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %185 = xor i64 %add.i.7.i854, -9223372036854775808
  %xor2.i.i.7.i858 = and i64 %185, %183
  %xor.i23.i.7.i859 = xor i64 %add3.i.7.i856, %add.i.7.i854
  %xor1.i24.i.7.i860 = xor i64 %add.i.7.i854, %184
  %or.i25.i.7.i861 = or i64 %xor.i23.i.7.i859, %xor1.i24.i.7.i860
  %xor2.i26.i.7.i862 = xor i64 %or.i25.i.7.i861, %add3.i.7.i856
  %shr.i30.i.7.i863 = or i64 %xor2.i26.i.7.i862, %xor2.i.i.7.i858
  %or29.i.7.i864 = lshr i64 %shr.i30.i.7.i863, 63
  %186 = load i64, i64* %arrayidx.i.8.i645, align 16, !tbaa !3
  %add.i.8.i866 = add i64 %or29.i.7.i864, %186
  %arrayidx2.i.8.i867 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 8
  %187 = load i64, i64* %arrayidx2.i.8.i867, align 16, !tbaa !3
  %add3.i.8.i868 = add i64 %add.i.8.i866, %187
  store i64 %add3.i.8.i868, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %188 = xor i64 %add.i.8.i866, -9223372036854775808
  %xor2.i.i.8.i870 = and i64 %188, %186
  %xor.i23.i.8.i871 = xor i64 %add3.i.8.i868, %add.i.8.i866
  %xor1.i24.i.8.i872 = xor i64 %add.i.8.i866, %187
  %or.i25.i.8.i873 = or i64 %xor.i23.i.8.i871, %xor1.i24.i.8.i872
  %xor2.i26.i.8.i874 = xor i64 %or.i25.i.8.i873, %add3.i.8.i868
  %shr.i30.i.8.i875 = or i64 %xor2.i26.i.8.i874, %xor2.i.i.8.i870
  %or29.i.8.i876 = lshr i64 %shr.i30.i.8.i875, 63
  %189 = load i64, i64* %arrayidx.i.9.i657, align 8, !tbaa !3
  %arrayidx2.i.9.i879 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 9
  %190 = load i64, i64* %arrayidx2.i.9.i879, align 8, !tbaa !3
  %add.i.9.i878 = add i64 %190, %189
  %add3.i.9.i880 = add i64 %add.i.9.i878, %or29.i.8.i876
  store i64 %add3.i.9.i880, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %191 = load i64, i64* %arraydecay22.i78, align 16, !tbaa !3
  %192 = load i64, i64* %arraydecay10.i102, align 16, !tbaa !3
  %add3.i.i668 = add i64 %192, %191
  store i64 %add3.i.i668, i64* %arraydecay10.i114, align 16, !tbaa !3
  %xor.i23.i.i669 = xor i64 %add3.i.i668, %191
  %xor1.i24.i.i670 = xor i64 %192, %191
  %or.i25.i.i671 = or i64 %xor.i23.i.i669, %xor1.i24.i.i670
  %xor2.i26.i.i672 = xor i64 %or.i25.i.i671, %add3.i.i668
  %or29.i.i673 = lshr i64 %xor2.i26.i.i672, 63
  %193 = load i64, i64* %arrayidx.i.1.i454, align 8, !tbaa !3
  %add.i.1.i675 = add i64 %or29.i.i673, %193
  %arrayidx2.i.1.i676 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 1
  %194 = load i64, i64* %arrayidx2.i.1.i676, align 8, !tbaa !3
  %add3.i.1.i677 = add i64 %add.i.1.i675, %194
  store i64 %add3.i.1.i677, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %195 = xor i64 %add.i.1.i675, -9223372036854775808
  %xor2.i.i.1.i679 = and i64 %195, %193
  %xor.i23.i.1.i680 = xor i64 %add3.i.1.i677, %add.i.1.i675
  %xor1.i24.i.1.i681 = xor i64 %add.i.1.i675, %194
  %or.i25.i.1.i682 = or i64 %xor.i23.i.1.i680, %xor1.i24.i.1.i681
  %xor2.i26.i.1.i683 = xor i64 %or.i25.i.1.i682, %add3.i.1.i677
  %shr.i30.i.1.i684 = or i64 %xor2.i26.i.1.i683, %xor2.i.i.1.i679
  %or29.i.1.i685 = lshr i64 %shr.i30.i.1.i684, 63
  %196 = load i64, i64* %arrayidx.i.2.i466, align 16, !tbaa !3
  %add.i.2.i687 = add i64 %or29.i.1.i685, %196
  %arrayidx2.i.2.i688 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 2
  %197 = load i64, i64* %arrayidx2.i.2.i688, align 16, !tbaa !3
  %add3.i.2.i689 = add i64 %add.i.2.i687, %197
  store i64 %add3.i.2.i689, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %198 = xor i64 %add.i.2.i687, -9223372036854775808
  %xor2.i.i.2.i691 = and i64 %198, %196
  %xor.i23.i.2.i692 = xor i64 %add3.i.2.i689, %add.i.2.i687
  %xor1.i24.i.2.i693 = xor i64 %add.i.2.i687, %197
  %or.i25.i.2.i694 = or i64 %xor.i23.i.2.i692, %xor1.i24.i.2.i693
  %xor2.i26.i.2.i695 = xor i64 %or.i25.i.2.i694, %add3.i.2.i689
  %shr.i30.i.2.i696 = or i64 %xor2.i26.i.2.i695, %xor2.i.i.2.i691
  %or29.i.2.i697 = lshr i64 %shr.i30.i.2.i696, 63
  %199 = load i64, i64* %arrayidx.i.3.i478, align 8, !tbaa !3
  %add.i.3.i699 = add i64 %or29.i.2.i697, %199
  %arrayidx2.i.3.i700 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 3
  %200 = load i64, i64* %arrayidx2.i.3.i700, align 8, !tbaa !3
  %add3.i.3.i701 = add i64 %add.i.3.i699, %200
  store i64 %add3.i.3.i701, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %201 = xor i64 %add.i.3.i699, -9223372036854775808
  %xor2.i.i.3.i703 = and i64 %201, %199
  %xor.i23.i.3.i704 = xor i64 %add3.i.3.i701, %add.i.3.i699
  %xor1.i24.i.3.i705 = xor i64 %add.i.3.i699, %200
  %or.i25.i.3.i706 = or i64 %xor.i23.i.3.i704, %xor1.i24.i.3.i705
  %xor2.i26.i.3.i707 = xor i64 %or.i25.i.3.i706, %add3.i.3.i701
  %shr.i30.i.3.i708 = or i64 %xor2.i26.i.3.i707, %xor2.i.i.3.i703
  %or29.i.3.i709 = lshr i64 %shr.i30.i.3.i708, 63
  %202 = load i64, i64* %arrayidx.i.4.i490, align 16, !tbaa !3
  %add.i.4.i711 = add i64 %or29.i.3.i709, %202
  %arrayidx2.i.4.i712 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 4
  %203 = load i64, i64* %arrayidx2.i.4.i712, align 16, !tbaa !3
  %add3.i.4.i713 = add i64 %add.i.4.i711, %203
  store i64 %add3.i.4.i713, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %204 = xor i64 %add.i.4.i711, -9223372036854775808
  %xor2.i.i.4.i715 = and i64 %204, %202
  %xor.i23.i.4.i716 = xor i64 %add3.i.4.i713, %add.i.4.i711
  %xor1.i24.i.4.i717 = xor i64 %add.i.4.i711, %203
  %or.i25.i.4.i718 = or i64 %xor.i23.i.4.i716, %xor1.i24.i.4.i717
  %xor2.i26.i.4.i719 = xor i64 %or.i25.i.4.i718, %add3.i.4.i713
  %shr.i30.i.4.i720 = or i64 %xor2.i26.i.4.i719, %xor2.i.i.4.i715
  %or29.i.4.i721 = lshr i64 %shr.i30.i.4.i720, 63
  %205 = load i64, i64* %arrayidx.i.5.i502, align 8, !tbaa !3
  %add.i.5.i723 = add i64 %or29.i.4.i721, %205
  %arrayidx2.i.5.i724 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 5
  %206 = load i64, i64* %arrayidx2.i.5.i724, align 8, !tbaa !3
  %add3.i.5.i725 = add i64 %add.i.5.i723, %206
  store i64 %add3.i.5.i725, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %207 = xor i64 %add.i.5.i723, -9223372036854775808
  %xor2.i.i.5.i727 = and i64 %207, %205
  %xor.i23.i.5.i728 = xor i64 %add3.i.5.i725, %add.i.5.i723
  %xor1.i24.i.5.i729 = xor i64 %add.i.5.i723, %206
  %or.i25.i.5.i730 = or i64 %xor.i23.i.5.i728, %xor1.i24.i.5.i729
  %xor2.i26.i.5.i731 = xor i64 %or.i25.i.5.i730, %add3.i.5.i725
  %shr.i30.i.5.i732 = or i64 %xor2.i26.i.5.i731, %xor2.i.i.5.i727
  %or29.i.5.i733 = lshr i64 %shr.i30.i.5.i732, 63
  %208 = load i64, i64* %arrayidx.i.6.i514, align 16, !tbaa !3
  %add.i.6.i735 = add i64 %or29.i.5.i733, %208
  %arrayidx2.i.6.i736 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 6
  %209 = load i64, i64* %arrayidx2.i.6.i736, align 16, !tbaa !3
  %add3.i.6.i737 = add i64 %add.i.6.i735, %209
  store i64 %add3.i.6.i737, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %210 = xor i64 %add.i.6.i735, -9223372036854775808
  %xor2.i.i.6.i739 = and i64 %210, %208
  %xor.i23.i.6.i740 = xor i64 %add3.i.6.i737, %add.i.6.i735
  %xor1.i24.i.6.i741 = xor i64 %add.i.6.i735, %209
  %or.i25.i.6.i742 = or i64 %xor.i23.i.6.i740, %xor1.i24.i.6.i741
  %xor2.i26.i.6.i743 = xor i64 %or.i25.i.6.i742, %add3.i.6.i737
  %shr.i30.i.6.i744 = or i64 %xor2.i26.i.6.i743, %xor2.i.i.6.i739
  %or29.i.6.i745 = lshr i64 %shr.i30.i.6.i744, 63
  %211 = load i64, i64* %arrayidx.i.7.i526, align 8, !tbaa !3
  %add.i.7.i747 = add i64 %or29.i.6.i745, %211
  %arrayidx2.i.7.i748 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 7
  %212 = load i64, i64* %arrayidx2.i.7.i748, align 8, !tbaa !3
  %add3.i.7.i749 = add i64 %add.i.7.i747, %212
  store i64 %add3.i.7.i749, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %213 = xor i64 %add.i.7.i747, -9223372036854775808
  %xor2.i.i.7.i751 = and i64 %213, %211
  %xor.i23.i.7.i752 = xor i64 %add3.i.7.i749, %add.i.7.i747
  %xor1.i24.i.7.i753 = xor i64 %add.i.7.i747, %212
  %or.i25.i.7.i754 = or i64 %xor.i23.i.7.i752, %xor1.i24.i.7.i753
  %xor2.i26.i.7.i755 = xor i64 %or.i25.i.7.i754, %add3.i.7.i749
  %shr.i30.i.7.i756 = or i64 %xor2.i26.i.7.i755, %xor2.i.i.7.i751
  %or29.i.7.i757 = lshr i64 %shr.i30.i.7.i756, 63
  %214 = load i64, i64* %arrayidx.i.8.i538, align 16, !tbaa !3
  %add.i.8.i759 = add i64 %or29.i.7.i757, %214
  %arrayidx2.i.8.i760 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 8
  %215 = load i64, i64* %arrayidx2.i.8.i760, align 16, !tbaa !3
  %add3.i.8.i761 = add i64 %add.i.8.i759, %215
  store i64 %add3.i.8.i761, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %216 = xor i64 %add.i.8.i759, -9223372036854775808
  %xor2.i.i.8.i763 = and i64 %216, %214
  %xor.i23.i.8.i764 = xor i64 %add3.i.8.i761, %add.i.8.i759
  %xor1.i24.i.8.i765 = xor i64 %add.i.8.i759, %215
  %or.i25.i.8.i766 = or i64 %xor.i23.i.8.i764, %xor1.i24.i.8.i765
  %xor2.i26.i.8.i767 = xor i64 %or.i25.i.8.i766, %add3.i.8.i761
  %shr.i30.i.8.i768 = or i64 %xor2.i26.i.8.i767, %xor2.i.i.8.i763
  %or29.i.8.i769 = lshr i64 %shr.i30.i.8.i768, 63
  %217 = load i64, i64* %arrayidx.i.9.i550, align 8, !tbaa !3
  %arrayidx2.i.9.i772 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 9
  %218 = load i64, i64* %arrayidx2.i.9.i772, align 8, !tbaa !3
  %add.i.9.i771 = add i64 %218, %217
  %add3.i.9.i773 = add i64 %add.i.9.i771, %or29.i.8.i769
  store i64 %add3.i.9.i773, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %add3.i.i995 = shl i64 %add3.i.i775, 1
  store i64 %add3.i.i995, i64* %arraydecay4.i111, align 16, !tbaa !3
  %or29.i.i1000 = lshr i64 %add3.i.i775, 63
  %add.i.1.i1002 = add i64 %add3.i.1.i784, %or29.i.i1000
  %add3.i.1.i1004 = add i64 %add.i.1.i1002, %add3.i.1.i784
  store i64 %add3.i.1.i1004, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %219 = xor i64 %add.i.1.i1002, -9223372036854775808
  %xor2.i.i.1.i1006 = and i64 %219, %add3.i.1.i784
  %xor.i23.i.1.i1007 = xor i64 %add3.i.1.i1004, %add.i.1.i1002
  %xor1.i24.i.1.i1008 = xor i64 %add.i.1.i1002, %add3.i.1.i784
  %or.i25.i.1.i1009 = or i64 %xor.i23.i.1.i1007, %xor1.i24.i.1.i1008
  %xor2.i26.i.1.i1010 = xor i64 %or.i25.i.1.i1009, %add3.i.1.i1004
  %shr.i30.i.1.i1011 = or i64 %xor2.i26.i.1.i1010, %xor2.i.i.1.i1006
  %or29.i.1.i1012 = lshr i64 %shr.i30.i.1.i1011, 63
  %add.i.2.i1014 = add i64 %add3.i.2.i796, %or29.i.1.i1012
  %add3.i.2.i1016 = add i64 %add.i.2.i1014, %add3.i.2.i796
  store i64 %add3.i.2.i1016, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %220 = xor i64 %add.i.2.i1014, -9223372036854775808
  %xor2.i.i.2.i1018 = and i64 %220, %add3.i.2.i796
  %xor.i23.i.2.i1019 = xor i64 %add3.i.2.i1016, %add.i.2.i1014
  %xor1.i24.i.2.i1020 = xor i64 %add.i.2.i1014, %add3.i.2.i796
  %or.i25.i.2.i1021 = or i64 %xor.i23.i.2.i1019, %xor1.i24.i.2.i1020
  %xor2.i26.i.2.i1022 = xor i64 %or.i25.i.2.i1021, %add3.i.2.i1016
  %shr.i30.i.2.i1023 = or i64 %xor2.i26.i.2.i1022, %xor2.i.i.2.i1018
  %or29.i.2.i1024 = lshr i64 %shr.i30.i.2.i1023, 63
  %add.i.3.i1026 = add i64 %add3.i.3.i808, %or29.i.2.i1024
  %add3.i.3.i1028 = add i64 %add.i.3.i1026, %add3.i.3.i808
  store i64 %add3.i.3.i1028, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %221 = xor i64 %add.i.3.i1026, -9223372036854775808
  %xor2.i.i.3.i1030 = and i64 %221, %add3.i.3.i808
  %xor.i23.i.3.i1031 = xor i64 %add3.i.3.i1028, %add.i.3.i1026
  %xor1.i24.i.3.i1032 = xor i64 %add.i.3.i1026, %add3.i.3.i808
  %or.i25.i.3.i1033 = or i64 %xor.i23.i.3.i1031, %xor1.i24.i.3.i1032
  %xor2.i26.i.3.i1034 = xor i64 %or.i25.i.3.i1033, %add3.i.3.i1028
  %shr.i30.i.3.i1035 = or i64 %xor2.i26.i.3.i1034, %xor2.i.i.3.i1030
  %or29.i.3.i1036 = lshr i64 %shr.i30.i.3.i1035, 63
  %add.i.4.i1038 = add i64 %add3.i.4.i820, %or29.i.3.i1036
  %add3.i.4.i1040 = add i64 %add.i.4.i1038, %add3.i.4.i820
  store i64 %add3.i.4.i1040, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %222 = xor i64 %add.i.4.i1038, -9223372036854775808
  %xor2.i.i.4.i1042 = and i64 %222, %add3.i.4.i820
  %xor.i23.i.4.i1043 = xor i64 %add3.i.4.i1040, %add.i.4.i1038
  %xor1.i24.i.4.i1044 = xor i64 %add.i.4.i1038, %add3.i.4.i820
  %or.i25.i.4.i1045 = or i64 %xor.i23.i.4.i1043, %xor1.i24.i.4.i1044
  %xor2.i26.i.4.i1046 = xor i64 %or.i25.i.4.i1045, %add3.i.4.i1040
  %shr.i30.i.4.i1047 = or i64 %xor2.i26.i.4.i1046, %xor2.i.i.4.i1042
  %or29.i.4.i1048 = lshr i64 %shr.i30.i.4.i1047, 63
  %add.i.5.i1050 = add i64 %add3.i.5.i832, %or29.i.4.i1048
  %add3.i.5.i1052 = add i64 %add.i.5.i1050, %add3.i.5.i832
  store i64 %add3.i.5.i1052, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %223 = xor i64 %add.i.5.i1050, -9223372036854775808
  %xor2.i.i.5.i1054 = and i64 %223, %add3.i.5.i832
  %xor.i23.i.5.i1055 = xor i64 %add3.i.5.i1052, %add.i.5.i1050
  %xor1.i24.i.5.i1056 = xor i64 %add.i.5.i1050, %add3.i.5.i832
  %or.i25.i.5.i1057 = or i64 %xor.i23.i.5.i1055, %xor1.i24.i.5.i1056
  %xor2.i26.i.5.i1058 = xor i64 %or.i25.i.5.i1057, %add3.i.5.i1052
  %shr.i30.i.5.i1059 = or i64 %xor2.i26.i.5.i1058, %xor2.i.i.5.i1054
  %or29.i.5.i1060 = lshr i64 %shr.i30.i.5.i1059, 63
  %add.i.6.i1062 = add i64 %add3.i.6.i844, %or29.i.5.i1060
  %add3.i.6.i1064 = add i64 %add.i.6.i1062, %add3.i.6.i844
  store i64 %add3.i.6.i1064, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %224 = xor i64 %add.i.6.i1062, -9223372036854775808
  %xor2.i.i.6.i1066 = and i64 %224, %add3.i.6.i844
  %xor.i23.i.6.i1067 = xor i64 %add3.i.6.i1064, %add.i.6.i1062
  %xor1.i24.i.6.i1068 = xor i64 %add.i.6.i1062, %add3.i.6.i844
  %or.i25.i.6.i1069 = or i64 %xor.i23.i.6.i1067, %xor1.i24.i.6.i1068
  %xor2.i26.i.6.i1070 = xor i64 %or.i25.i.6.i1069, %add3.i.6.i1064
  %shr.i30.i.6.i1071 = or i64 %xor2.i26.i.6.i1070, %xor2.i.i.6.i1066
  %or29.i.6.i1072 = lshr i64 %shr.i30.i.6.i1071, 63
  %add.i.7.i1074 = add i64 %add3.i.7.i856, %or29.i.6.i1072
  %add3.i.7.i1076 = add i64 %add.i.7.i1074, %add3.i.7.i856
  store i64 %add3.i.7.i1076, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %225 = xor i64 %add.i.7.i1074, -9223372036854775808
  %xor2.i.i.7.i1078 = and i64 %225, %add3.i.7.i856
  %xor.i23.i.7.i1079 = xor i64 %add3.i.7.i1076, %add.i.7.i1074
  %xor1.i24.i.7.i1080 = xor i64 %add.i.7.i1074, %add3.i.7.i856
  %or.i25.i.7.i1081 = or i64 %xor.i23.i.7.i1079, %xor1.i24.i.7.i1080
  %xor2.i26.i.7.i1082 = xor i64 %or.i25.i.7.i1081, %add3.i.7.i1076
  %shr.i30.i.7.i1083 = or i64 %xor2.i26.i.7.i1082, %xor2.i.i.7.i1078
  %or29.i.7.i1084 = lshr i64 %shr.i30.i.7.i1083, 63
  %add.i.8.i1086 = add i64 %add3.i.8.i868, %or29.i.7.i1084
  %add3.i.8.i1088 = add i64 %add.i.8.i1086, %add3.i.8.i868
  store i64 %add3.i.8.i1088, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %226 = xor i64 %add.i.8.i1086, -9223372036854775808
  %xor2.i.i.8.i1090 = and i64 %226, %add3.i.8.i868
  %xor.i23.i.8.i1091 = xor i64 %add3.i.8.i1088, %add.i.8.i1086
  %xor1.i24.i.8.i1092 = xor i64 %add.i.8.i1086, %add3.i.8.i868
  %or.i25.i.8.i1093 = or i64 %xor.i23.i.8.i1091, %xor1.i24.i.8.i1092
  %xor2.i26.i.8.i1094 = xor i64 %or.i25.i.8.i1093, %add3.i.8.i1088
  %shr.i30.i.8.i1095 = or i64 %xor2.i26.i.8.i1094, %xor2.i.i.8.i1090
  %or29.i.8.i1096 = lshr i64 %shr.i30.i.8.i1095, 63
  %factor1538 = shl i64 %add3.i.9.i880, 1
  %add3.i.9.i1100 = or i64 %factor1538, %or29.i.8.i1096
  store i64 %add3.i.9.i1100, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %add3.i.i888 = shl i64 %add3.i.i668, 1
  store i64 %add3.i.i888, i64* %arraydecay10.i114, align 16, !tbaa !3
  %or29.i.i893 = lshr i64 %add3.i.i668, 63
  %add.i.1.i895 = add i64 %add3.i.1.i677, %or29.i.i893
  %add3.i.1.i897 = add i64 %add.i.1.i895, %add3.i.1.i677
  store i64 %add3.i.1.i897, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %227 = xor i64 %add.i.1.i895, -9223372036854775808
  %xor2.i.i.1.i899 = and i64 %227, %add3.i.1.i677
  %xor.i23.i.1.i900 = xor i64 %add3.i.1.i897, %add.i.1.i895
  %xor1.i24.i.1.i901 = xor i64 %add.i.1.i895, %add3.i.1.i677
  %or.i25.i.1.i902 = or i64 %xor.i23.i.1.i900, %xor1.i24.i.1.i901
  %xor2.i26.i.1.i903 = xor i64 %or.i25.i.1.i902, %add3.i.1.i897
  %shr.i30.i.1.i904 = or i64 %xor2.i26.i.1.i903, %xor2.i.i.1.i899
  %or29.i.1.i905 = lshr i64 %shr.i30.i.1.i904, 63
  %add.i.2.i907 = add i64 %add3.i.2.i689, %or29.i.1.i905
  %add3.i.2.i909 = add i64 %add.i.2.i907, %add3.i.2.i689
  store i64 %add3.i.2.i909, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %228 = xor i64 %add.i.2.i907, -9223372036854775808
  %xor2.i.i.2.i911 = and i64 %228, %add3.i.2.i689
  %xor.i23.i.2.i912 = xor i64 %add3.i.2.i909, %add.i.2.i907
  %xor1.i24.i.2.i913 = xor i64 %add.i.2.i907, %add3.i.2.i689
  %or.i25.i.2.i914 = or i64 %xor.i23.i.2.i912, %xor1.i24.i.2.i913
  %xor2.i26.i.2.i915 = xor i64 %or.i25.i.2.i914, %add3.i.2.i909
  %shr.i30.i.2.i916 = or i64 %xor2.i26.i.2.i915, %xor2.i.i.2.i911
  %or29.i.2.i917 = lshr i64 %shr.i30.i.2.i916, 63
  %add.i.3.i919 = add i64 %add3.i.3.i701, %or29.i.2.i917
  %add3.i.3.i921 = add i64 %add.i.3.i919, %add3.i.3.i701
  store i64 %add3.i.3.i921, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %229 = xor i64 %add.i.3.i919, -9223372036854775808
  %xor2.i.i.3.i923 = and i64 %229, %add3.i.3.i701
  %xor.i23.i.3.i924 = xor i64 %add3.i.3.i921, %add.i.3.i919
  %xor1.i24.i.3.i925 = xor i64 %add.i.3.i919, %add3.i.3.i701
  %or.i25.i.3.i926 = or i64 %xor.i23.i.3.i924, %xor1.i24.i.3.i925
  %xor2.i26.i.3.i927 = xor i64 %or.i25.i.3.i926, %add3.i.3.i921
  %shr.i30.i.3.i928 = or i64 %xor2.i26.i.3.i927, %xor2.i.i.3.i923
  %or29.i.3.i929 = lshr i64 %shr.i30.i.3.i928, 63
  %add.i.4.i931 = add i64 %add3.i.4.i713, %or29.i.3.i929
  %add3.i.4.i933 = add i64 %add.i.4.i931, %add3.i.4.i713
  store i64 %add3.i.4.i933, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %230 = xor i64 %add.i.4.i931, -9223372036854775808
  %xor2.i.i.4.i935 = and i64 %230, %add3.i.4.i713
  %xor.i23.i.4.i936 = xor i64 %add3.i.4.i933, %add.i.4.i931
  %xor1.i24.i.4.i937 = xor i64 %add.i.4.i931, %add3.i.4.i713
  %or.i25.i.4.i938 = or i64 %xor.i23.i.4.i936, %xor1.i24.i.4.i937
  %xor2.i26.i.4.i939 = xor i64 %or.i25.i.4.i938, %add3.i.4.i933
  %shr.i30.i.4.i940 = or i64 %xor2.i26.i.4.i939, %xor2.i.i.4.i935
  %or29.i.4.i941 = lshr i64 %shr.i30.i.4.i940, 63
  %add.i.5.i943 = add i64 %add3.i.5.i725, %or29.i.4.i941
  %add3.i.5.i945 = add i64 %add.i.5.i943, %add3.i.5.i725
  store i64 %add3.i.5.i945, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %231 = xor i64 %add.i.5.i943, -9223372036854775808
  %xor2.i.i.5.i947 = and i64 %231, %add3.i.5.i725
  %xor.i23.i.5.i948 = xor i64 %add3.i.5.i945, %add.i.5.i943
  %xor1.i24.i.5.i949 = xor i64 %add.i.5.i943, %add3.i.5.i725
  %or.i25.i.5.i950 = or i64 %xor.i23.i.5.i948, %xor1.i24.i.5.i949
  %xor2.i26.i.5.i951 = xor i64 %or.i25.i.5.i950, %add3.i.5.i945
  %shr.i30.i.5.i952 = or i64 %xor2.i26.i.5.i951, %xor2.i.i.5.i947
  %or29.i.5.i953 = lshr i64 %shr.i30.i.5.i952, 63
  %add.i.6.i955 = add i64 %add3.i.6.i737, %or29.i.5.i953
  %add3.i.6.i957 = add i64 %add.i.6.i955, %add3.i.6.i737
  store i64 %add3.i.6.i957, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %232 = xor i64 %add.i.6.i955, -9223372036854775808
  %xor2.i.i.6.i959 = and i64 %232, %add3.i.6.i737
  %xor.i23.i.6.i960 = xor i64 %add3.i.6.i957, %add.i.6.i955
  %xor1.i24.i.6.i961 = xor i64 %add.i.6.i955, %add3.i.6.i737
  %or.i25.i.6.i962 = or i64 %xor.i23.i.6.i960, %xor1.i24.i.6.i961
  %xor2.i26.i.6.i963 = xor i64 %or.i25.i.6.i962, %add3.i.6.i957
  %shr.i30.i.6.i964 = or i64 %xor2.i26.i.6.i963, %xor2.i.i.6.i959
  %or29.i.6.i965 = lshr i64 %shr.i30.i.6.i964, 63
  %add.i.7.i967 = add i64 %add3.i.7.i749, %or29.i.6.i965
  %add3.i.7.i969 = add i64 %add.i.7.i967, %add3.i.7.i749
  store i64 %add3.i.7.i969, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %233 = xor i64 %add.i.7.i967, -9223372036854775808
  %xor2.i.i.7.i971 = and i64 %233, %add3.i.7.i749
  %xor.i23.i.7.i972 = xor i64 %add3.i.7.i969, %add.i.7.i967
  %xor1.i24.i.7.i973 = xor i64 %add.i.7.i967, %add3.i.7.i749
  %or.i25.i.7.i974 = or i64 %xor.i23.i.7.i972, %xor1.i24.i.7.i973
  %xor2.i26.i.7.i975 = xor i64 %or.i25.i.7.i974, %add3.i.7.i969
  %shr.i30.i.7.i976 = or i64 %xor2.i26.i.7.i975, %xor2.i.i.7.i971
  %or29.i.7.i977 = lshr i64 %shr.i30.i.7.i976, 63
  %add.i.8.i979 = add i64 %add3.i.8.i761, %or29.i.7.i977
  %add3.i.8.i981 = add i64 %add.i.8.i979, %add3.i.8.i761
  store i64 %add3.i.8.i981, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %234 = xor i64 %add.i.8.i979, -9223372036854775808
  %xor2.i.i.8.i983 = and i64 %234, %add3.i.8.i761
  %xor.i23.i.8.i984 = xor i64 %add3.i.8.i981, %add.i.8.i979
  %xor1.i24.i.8.i985 = xor i64 %add.i.8.i979, %add3.i.8.i761
  %or.i25.i.8.i986 = or i64 %xor.i23.i.8.i984, %xor1.i24.i.8.i985
  %xor2.i26.i.8.i987 = xor i64 %or.i25.i.8.i986, %add3.i.8.i981
  %shr.i30.i.8.i988 = or i64 %xor2.i26.i.8.i987, %xor2.i.i.8.i983
  %or29.i.8.i989 = lshr i64 %shr.i30.i.8.i988, 63
  %factor1539 = shl i64 %add3.i.9.i773, 1
  %add3.i.9.i993 = or i64 %factor1539, %or29.i.8.i989
  store i64 %add3.i.9.i993, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %235 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %add3.i.i1215 = add i64 %235, %add3.i.i995
  store i64 %add3.i.i1215, i64* %arraydecay4.i111, align 16, !tbaa !3
  %xor.i23.i.i1216 = xor i64 %add3.i.i1215, %235
  %xor1.i24.i.i1217 = xor i64 %235, %add3.i.i995
  %or.i25.i.i1218 = or i64 %xor.i23.i.i1216, %xor1.i24.i.i1217
  %xor2.i26.i.i1219 = xor i64 %or.i25.i.i1218, %add3.i.i1215
  %or29.i.i1220 = lshr i64 %xor2.i26.i.i1219, 63
  %236 = load i64, i64* %arrayidx.i.1.i121, align 8, !tbaa !3
  %add.i.1.i1222 = add i64 %or29.i.i1220, %236
  %add3.i.1.i1224 = add i64 %add.i.1.i1222, %add3.i.1.i1004
  store i64 %add3.i.1.i1224, i64* %arrayidx5.i.1.i125, align 8, !tbaa !3
  %237 = xor i64 %add.i.1.i1222, -9223372036854775808
  %xor2.i.i.1.i1226 = and i64 %237, %236
  %xor.i23.i.1.i1227 = xor i64 %add3.i.1.i1224, %add.i.1.i1222
  %xor1.i24.i.1.i1228 = xor i64 %add.i.1.i1222, %add3.i.1.i1004
  %or.i25.i.1.i1229 = or i64 %xor.i23.i.1.i1227, %xor1.i24.i.1.i1228
  %xor2.i26.i.1.i1230 = xor i64 %or.i25.i.1.i1229, %add3.i.1.i1224
  %shr.i30.i.1.i1231 = or i64 %xor2.i26.i.1.i1230, %xor2.i.i.1.i1226
  %or29.i.1.i1232 = lshr i64 %shr.i30.i.1.i1231, 63
  %238 = load i64, i64* %arrayidx.i.2.i133, align 16, !tbaa !3
  %add.i.2.i1234 = add i64 %or29.i.1.i1232, %238
  %add3.i.2.i1236 = add i64 %add.i.2.i1234, %add3.i.2.i1016
  store i64 %add3.i.2.i1236, i64* %arrayidx5.i.2.i137, align 16, !tbaa !3
  %239 = xor i64 %add.i.2.i1234, -9223372036854775808
  %xor2.i.i.2.i1238 = and i64 %239, %238
  %xor.i23.i.2.i1239 = xor i64 %add3.i.2.i1236, %add.i.2.i1234
  %xor1.i24.i.2.i1240 = xor i64 %add.i.2.i1234, %add3.i.2.i1016
  %or.i25.i.2.i1241 = or i64 %xor.i23.i.2.i1239, %xor1.i24.i.2.i1240
  %xor2.i26.i.2.i1242 = xor i64 %or.i25.i.2.i1241, %add3.i.2.i1236
  %shr.i30.i.2.i1243 = or i64 %xor2.i26.i.2.i1242, %xor2.i.i.2.i1238
  %or29.i.2.i1244 = lshr i64 %shr.i30.i.2.i1243, 63
  %240 = load i64, i64* %arrayidx.i.3.i145, align 8, !tbaa !3
  %add.i.3.i1246 = add i64 %or29.i.2.i1244, %240
  %add3.i.3.i1248 = add i64 %add.i.3.i1246, %add3.i.3.i1028
  store i64 %add3.i.3.i1248, i64* %arrayidx5.i.3.i149, align 8, !tbaa !3
  %241 = xor i64 %add.i.3.i1246, -9223372036854775808
  %xor2.i.i.3.i1250 = and i64 %241, %240
  %xor.i23.i.3.i1251 = xor i64 %add3.i.3.i1248, %add.i.3.i1246
  %xor1.i24.i.3.i1252 = xor i64 %add.i.3.i1246, %add3.i.3.i1028
  %or.i25.i.3.i1253 = or i64 %xor.i23.i.3.i1251, %xor1.i24.i.3.i1252
  %xor2.i26.i.3.i1254 = xor i64 %or.i25.i.3.i1253, %add3.i.3.i1248
  %shr.i30.i.3.i1255 = or i64 %xor2.i26.i.3.i1254, %xor2.i.i.3.i1250
  %or29.i.3.i1256 = lshr i64 %shr.i30.i.3.i1255, 63
  %242 = load i64, i64* %arrayidx.i.4.i157, align 16, !tbaa !3
  %add.i.4.i1258 = add i64 %or29.i.3.i1256, %242
  %add3.i.4.i1260 = add i64 %add.i.4.i1258, %add3.i.4.i1040
  store i64 %add3.i.4.i1260, i64* %arrayidx5.i.4.i161, align 16, !tbaa !3
  %243 = xor i64 %add.i.4.i1258, -9223372036854775808
  %xor2.i.i.4.i1262 = and i64 %243, %242
  %xor.i23.i.4.i1263 = xor i64 %add3.i.4.i1260, %add.i.4.i1258
  %xor1.i24.i.4.i1264 = xor i64 %add.i.4.i1258, %add3.i.4.i1040
  %or.i25.i.4.i1265 = or i64 %xor.i23.i.4.i1263, %xor1.i24.i.4.i1264
  %xor2.i26.i.4.i1266 = xor i64 %or.i25.i.4.i1265, %add3.i.4.i1260
  %shr.i30.i.4.i1267 = or i64 %xor2.i26.i.4.i1266, %xor2.i.i.4.i1262
  %or29.i.4.i1268 = lshr i64 %shr.i30.i.4.i1267, 63
  %244 = load i64, i64* %arrayidx.i.5.i169, align 8, !tbaa !3
  %add.i.5.i1270 = add i64 %or29.i.4.i1268, %244
  %add3.i.5.i1272 = add i64 %add.i.5.i1270, %add3.i.5.i1052
  store i64 %add3.i.5.i1272, i64* %arrayidx5.i.5.i173, align 8, !tbaa !3
  %245 = xor i64 %add.i.5.i1270, -9223372036854775808
  %xor2.i.i.5.i1274 = and i64 %245, %244
  %xor.i23.i.5.i1275 = xor i64 %add3.i.5.i1272, %add.i.5.i1270
  %xor1.i24.i.5.i1276 = xor i64 %add.i.5.i1270, %add3.i.5.i1052
  %or.i25.i.5.i1277 = or i64 %xor.i23.i.5.i1275, %xor1.i24.i.5.i1276
  %xor2.i26.i.5.i1278 = xor i64 %or.i25.i.5.i1277, %add3.i.5.i1272
  %shr.i30.i.5.i1279 = or i64 %xor2.i26.i.5.i1278, %xor2.i.i.5.i1274
  %or29.i.5.i1280 = lshr i64 %shr.i30.i.5.i1279, 63
  %246 = load i64, i64* %arrayidx.i.6.i181, align 16, !tbaa !3
  %add.i.6.i1282 = add i64 %or29.i.5.i1280, %246
  %add3.i.6.i1284 = add i64 %add.i.6.i1282, %add3.i.6.i1064
  store i64 %add3.i.6.i1284, i64* %arrayidx5.i.6.i185, align 16, !tbaa !3
  %247 = xor i64 %add.i.6.i1282, -9223372036854775808
  %xor2.i.i.6.i1286 = and i64 %247, %246
  %xor.i23.i.6.i1287 = xor i64 %add3.i.6.i1284, %add.i.6.i1282
  %xor1.i24.i.6.i1288 = xor i64 %add.i.6.i1282, %add3.i.6.i1064
  %or.i25.i.6.i1289 = or i64 %xor.i23.i.6.i1287, %xor1.i24.i.6.i1288
  %xor2.i26.i.6.i1290 = xor i64 %or.i25.i.6.i1289, %add3.i.6.i1284
  %shr.i30.i.6.i1291 = or i64 %xor2.i26.i.6.i1290, %xor2.i.i.6.i1286
  %or29.i.6.i1292 = lshr i64 %shr.i30.i.6.i1291, 63
  %248 = load i64, i64* %arrayidx.i.7.i193, align 8, !tbaa !3
  %add.i.7.i1294 = add i64 %or29.i.6.i1292, %248
  %add3.i.7.i1296 = add i64 %add.i.7.i1294, %add3.i.7.i1076
  store i64 %add3.i.7.i1296, i64* %arrayidx5.i.7.i197, align 8, !tbaa !3
  %249 = xor i64 %add.i.7.i1294, -9223372036854775808
  %xor2.i.i.7.i1298 = and i64 %249, %248
  %xor.i23.i.7.i1299 = xor i64 %add3.i.7.i1296, %add.i.7.i1294
  %xor1.i24.i.7.i1300 = xor i64 %add.i.7.i1294, %add3.i.7.i1076
  %or.i25.i.7.i1301 = or i64 %xor.i23.i.7.i1299, %xor1.i24.i.7.i1300
  %xor2.i26.i.7.i1302 = xor i64 %or.i25.i.7.i1301, %add3.i.7.i1296
  %shr.i30.i.7.i1303 = or i64 %xor2.i26.i.7.i1302, %xor2.i.i.7.i1298
  %or29.i.7.i1304 = lshr i64 %shr.i30.i.7.i1303, 63
  %250 = load i64, i64* %arrayidx.i.8.i205, align 16, !tbaa !3
  %add.i.8.i1306 = add i64 %or29.i.7.i1304, %250
  %add3.i.8.i1308 = add i64 %add.i.8.i1306, %add3.i.8.i1088
  store i64 %add3.i.8.i1308, i64* %arrayidx5.i.8.i209, align 16, !tbaa !3
  %251 = xor i64 %add.i.8.i1306, -9223372036854775808
  %xor2.i.i.8.i1310 = and i64 %251, %250
  %xor.i23.i.8.i1311 = xor i64 %add3.i.8.i1308, %add.i.8.i1306
  %xor1.i24.i.8.i1312 = xor i64 %add.i.8.i1306, %add3.i.8.i1088
  %or.i25.i.8.i1313 = or i64 %xor.i23.i.8.i1311, %xor1.i24.i.8.i1312
  %xor2.i26.i.8.i1314 = xor i64 %or.i25.i.8.i1313, %add3.i.8.i1308
  %shr.i30.i.8.i1315 = or i64 %xor2.i26.i.8.i1314, %xor2.i.i.8.i1310
  %or29.i.8.i1316 = lshr i64 %shr.i30.i.8.i1315, 63
  %252 = load i64, i64* %arrayidx.i.9.i217, align 8, !tbaa !3
  %add.i.9.i1318 = add i64 %252, %add3.i.9.i1100
  %add3.i.9.i1320 = add i64 %add.i.9.i1318, %or29.i.8.i1316
  store i64 %add3.i.9.i1320, i64* %arrayidx5.i.9.i221, align 8, !tbaa !3
  %253 = load i64, i64* %arraydecay22.i, align 16, !tbaa !3
  %add3.i.i1108 = add i64 %253, %add3.i.i888
  store i64 %add3.i.i1108, i64* %arraydecay10.i114, align 16, !tbaa !3
  %xor.i23.i.i1109 = xor i64 %add3.i.i1108, %253
  %xor1.i24.i.i1110 = xor i64 %253, %add3.i.i888
  %or.i25.i.i1111 = or i64 %xor.i23.i.i1109, %xor1.i24.i.i1110
  %xor2.i26.i.i1112 = xor i64 %or.i25.i.i1111, %add3.i.i1108
  %or29.i.i1113 = lshr i64 %xor2.i26.i.i1112, 63
  %254 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i1115 = add i64 %or29.i.i1113, %254
  %add3.i.1.i1117 = add i64 %add.i.1.i1115, %add3.i.1.i897
  store i64 %add3.i.1.i1117, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %255 = xor i64 %add.i.1.i1115, -9223372036854775808
  %xor2.i.i.1.i1119 = and i64 %255, %254
  %xor.i23.i.1.i1120 = xor i64 %add3.i.1.i1117, %add.i.1.i1115
  %xor1.i24.i.1.i1121 = xor i64 %add.i.1.i1115, %add3.i.1.i897
  %or.i25.i.1.i1122 = or i64 %xor.i23.i.1.i1120, %xor1.i24.i.1.i1121
  %xor2.i26.i.1.i1123 = xor i64 %or.i25.i.1.i1122, %add3.i.1.i1117
  %shr.i30.i.1.i1124 = or i64 %xor2.i26.i.1.i1123, %xor2.i.i.1.i1119
  %or29.i.1.i1125 = lshr i64 %shr.i30.i.1.i1124, 63
  %256 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i1127 = add i64 %or29.i.1.i1125, %256
  %add3.i.2.i1129 = add i64 %add.i.2.i1127, %add3.i.2.i909
  store i64 %add3.i.2.i1129, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %257 = xor i64 %add.i.2.i1127, -9223372036854775808
  %xor2.i.i.2.i1131 = and i64 %257, %256
  %xor.i23.i.2.i1132 = xor i64 %add3.i.2.i1129, %add.i.2.i1127
  %xor1.i24.i.2.i1133 = xor i64 %add.i.2.i1127, %add3.i.2.i909
  %or.i25.i.2.i1134 = or i64 %xor.i23.i.2.i1132, %xor1.i24.i.2.i1133
  %xor2.i26.i.2.i1135 = xor i64 %or.i25.i.2.i1134, %add3.i.2.i1129
  %shr.i30.i.2.i1136 = or i64 %xor2.i26.i.2.i1135, %xor2.i.i.2.i1131
  %or29.i.2.i1137 = lshr i64 %shr.i30.i.2.i1136, 63
  %258 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i1139 = add i64 %or29.i.2.i1137, %258
  %add3.i.3.i1141 = add i64 %add.i.3.i1139, %add3.i.3.i921
  store i64 %add3.i.3.i1141, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %259 = xor i64 %add.i.3.i1139, -9223372036854775808
  %xor2.i.i.3.i1143 = and i64 %259, %258
  %xor.i23.i.3.i1144 = xor i64 %add3.i.3.i1141, %add.i.3.i1139
  %xor1.i24.i.3.i1145 = xor i64 %add.i.3.i1139, %add3.i.3.i921
  %or.i25.i.3.i1146 = or i64 %xor.i23.i.3.i1144, %xor1.i24.i.3.i1145
  %xor2.i26.i.3.i1147 = xor i64 %or.i25.i.3.i1146, %add3.i.3.i1141
  %shr.i30.i.3.i1148 = or i64 %xor2.i26.i.3.i1147, %xor2.i.i.3.i1143
  %or29.i.3.i1149 = lshr i64 %shr.i30.i.3.i1148, 63
  %260 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i1151 = add i64 %or29.i.3.i1149, %260
  %add3.i.4.i1153 = add i64 %add.i.4.i1151, %add3.i.4.i933
  store i64 %add3.i.4.i1153, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %261 = xor i64 %add.i.4.i1151, -9223372036854775808
  %xor2.i.i.4.i1155 = and i64 %261, %260
  %xor.i23.i.4.i1156 = xor i64 %add3.i.4.i1153, %add.i.4.i1151
  %xor1.i24.i.4.i1157 = xor i64 %add.i.4.i1151, %add3.i.4.i933
  %or.i25.i.4.i1158 = or i64 %xor.i23.i.4.i1156, %xor1.i24.i.4.i1157
  %xor2.i26.i.4.i1159 = xor i64 %or.i25.i.4.i1158, %add3.i.4.i1153
  %shr.i30.i.4.i1160 = or i64 %xor2.i26.i.4.i1159, %xor2.i.i.4.i1155
  %or29.i.4.i1161 = lshr i64 %shr.i30.i.4.i1160, 63
  %262 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i1163 = add i64 %or29.i.4.i1161, %262
  %add3.i.5.i1165 = add i64 %add.i.5.i1163, %add3.i.5.i945
  store i64 %add3.i.5.i1165, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %263 = xor i64 %add.i.5.i1163, -9223372036854775808
  %xor2.i.i.5.i1167 = and i64 %263, %262
  %xor.i23.i.5.i1168 = xor i64 %add3.i.5.i1165, %add.i.5.i1163
  %xor1.i24.i.5.i1169 = xor i64 %add.i.5.i1163, %add3.i.5.i945
  %or.i25.i.5.i1170 = or i64 %xor.i23.i.5.i1168, %xor1.i24.i.5.i1169
  %xor2.i26.i.5.i1171 = xor i64 %or.i25.i.5.i1170, %add3.i.5.i1165
  %shr.i30.i.5.i1172 = or i64 %xor2.i26.i.5.i1171, %xor2.i.i.5.i1167
  %or29.i.5.i1173 = lshr i64 %shr.i30.i.5.i1172, 63
  %264 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i1175 = add i64 %or29.i.5.i1173, %264
  %add3.i.6.i1177 = add i64 %add.i.6.i1175, %add3.i.6.i957
  store i64 %add3.i.6.i1177, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %265 = xor i64 %add.i.6.i1175, -9223372036854775808
  %xor2.i.i.6.i1179 = and i64 %265, %264
  %xor.i23.i.6.i1180 = xor i64 %add3.i.6.i1177, %add.i.6.i1175
  %xor1.i24.i.6.i1181 = xor i64 %add.i.6.i1175, %add3.i.6.i957
  %or.i25.i.6.i1182 = or i64 %xor.i23.i.6.i1180, %xor1.i24.i.6.i1181
  %xor2.i26.i.6.i1183 = xor i64 %or.i25.i.6.i1182, %add3.i.6.i1177
  %shr.i30.i.6.i1184 = or i64 %xor2.i26.i.6.i1183, %xor2.i.i.6.i1179
  %or29.i.6.i1185 = lshr i64 %shr.i30.i.6.i1184, 63
  %266 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i1187 = add i64 %or29.i.6.i1185, %266
  %add3.i.7.i1189 = add i64 %add.i.7.i1187, %add3.i.7.i969
  store i64 %add3.i.7.i1189, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %267 = xor i64 %add.i.7.i1187, -9223372036854775808
  %xor2.i.i.7.i1191 = and i64 %267, %266
  %xor.i23.i.7.i1192 = xor i64 %add3.i.7.i1189, %add.i.7.i1187
  %xor1.i24.i.7.i1193 = xor i64 %add.i.7.i1187, %add3.i.7.i969
  %or.i25.i.7.i1194 = or i64 %xor.i23.i.7.i1192, %xor1.i24.i.7.i1193
  %xor2.i26.i.7.i1195 = xor i64 %or.i25.i.7.i1194, %add3.i.7.i1189
  %shr.i30.i.7.i1196 = or i64 %xor2.i26.i.7.i1195, %xor2.i.i.7.i1191
  %or29.i.7.i1197 = lshr i64 %shr.i30.i.7.i1196, 63
  %268 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i1199 = add i64 %or29.i.7.i1197, %268
  %add3.i.8.i1201 = add i64 %add.i.8.i1199, %add3.i.8.i981
  store i64 %add3.i.8.i1201, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %269 = xor i64 %add.i.8.i1199, -9223372036854775808
  %xor2.i.i.8.i1203 = and i64 %269, %268
  %xor.i23.i.8.i1204 = xor i64 %add3.i.8.i1201, %add.i.8.i1199
  %xor1.i24.i.8.i1205 = xor i64 %add.i.8.i1199, %add3.i.8.i981
  %or.i25.i.8.i1206 = or i64 %xor.i23.i.8.i1204, %xor1.i24.i.8.i1205
  %xor2.i26.i.8.i1207 = xor i64 %or.i25.i.8.i1206, %add3.i.8.i1201
  %shr.i30.i.8.i1208 = or i64 %xor2.i26.i.8.i1207, %xor2.i.i.8.i1203
  %or29.i.8.i1209 = lshr i64 %shr.i30.i.8.i1208, 63
  %270 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %add.i.9.i1211 = add i64 %270, %add3.i.9.i993
  %add3.i.9.i1213 = add i64 %add.i.9.i1211, %or29.i.8.i1209
  store i64 %add3.i.9.i1213, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay19, [10 x i64]* nonnull %arraydecay30, [10 x i64]* %A24plus)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @eval_3_isog(%struct.point_proj* %Q, [2 x [10 x i64]]* %coeff) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0
  %arraydecay1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i45 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i45) #10
  %arraydecay10.i48 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i48) #10
  %arraydecay8 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %arraydecay8, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay2)
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %coeff, i64 1, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay12, [10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay7)
  %arraydecay17 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  %arraydecay4.i51 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  %3 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %4 = load i64, i64* %arraydecay4.i45, align 16, !tbaa !3
  %add3.i.i55 = add i64 %4, %3
  store i64 %add3.i.i55, i64* %arraydecay4.i51, align 16, !tbaa !3
  %xor.i23.i.i56 = xor i64 %add3.i.i55, %3
  %xor1.i24.i.i57 = xor i64 %4, %3
  %or.i25.i.i58 = or i64 %xor.i23.i.i56, %xor1.i24.i.i57
  %xor2.i26.i.i59 = xor i64 %or.i25.i.i58, %add3.i.i55
  %or29.i.i60 = lshr i64 %xor2.i26.i.i59, 63
  %arrayidx.i.1.i61 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %5 = load i64, i64* %arrayidx.i.1.i61, align 8, !tbaa !3
  %add.i.1.i62 = add i64 %or29.i.i60, %5
  %arrayidx2.i.1.i63 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %6 = load i64, i64* %arrayidx2.i.1.i63, align 8, !tbaa !3
  %add3.i.1.i64 = add i64 %add.i.1.i62, %6
  %arrayidx5.i.1.i65 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 1
  store i64 %add3.i.1.i64, i64* %arrayidx5.i.1.i65, align 8, !tbaa !3
  %7 = xor i64 %add.i.1.i62, -9223372036854775808
  %xor2.i.i.1.i66 = and i64 %7, %5
  %xor.i23.i.1.i67 = xor i64 %add3.i.1.i64, %add.i.1.i62
  %xor1.i24.i.1.i68 = xor i64 %add.i.1.i62, %6
  %or.i25.i.1.i69 = or i64 %xor.i23.i.1.i67, %xor1.i24.i.1.i68
  %xor2.i26.i.1.i70 = xor i64 %or.i25.i.1.i69, %add3.i.1.i64
  %shr.i30.i.1.i71 = or i64 %xor2.i26.i.1.i70, %xor2.i.i.1.i66
  %or29.i.1.i72 = lshr i64 %shr.i30.i.1.i71, 63
  %arrayidx.i.2.i73 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %8 = load i64, i64* %arrayidx.i.2.i73, align 16, !tbaa !3
  %add.i.2.i74 = add i64 %or29.i.1.i72, %8
  %arrayidx2.i.2.i75 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %9 = load i64, i64* %arrayidx2.i.2.i75, align 16, !tbaa !3
  %add3.i.2.i76 = add i64 %add.i.2.i74, %9
  %arrayidx5.i.2.i77 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 2
  store i64 %add3.i.2.i76, i64* %arrayidx5.i.2.i77, align 16, !tbaa !3
  %10 = xor i64 %add.i.2.i74, -9223372036854775808
  %xor2.i.i.2.i78 = and i64 %10, %8
  %xor.i23.i.2.i79 = xor i64 %add3.i.2.i76, %add.i.2.i74
  %xor1.i24.i.2.i80 = xor i64 %add.i.2.i74, %9
  %or.i25.i.2.i81 = or i64 %xor.i23.i.2.i79, %xor1.i24.i.2.i80
  %xor2.i26.i.2.i82 = xor i64 %or.i25.i.2.i81, %add3.i.2.i76
  %shr.i30.i.2.i83 = or i64 %xor2.i26.i.2.i82, %xor2.i.i.2.i78
  %or29.i.2.i84 = lshr i64 %shr.i30.i.2.i83, 63
  %arrayidx.i.3.i85 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %11 = load i64, i64* %arrayidx.i.3.i85, align 8, !tbaa !3
  %add.i.3.i86 = add i64 %or29.i.2.i84, %11
  %arrayidx2.i.3.i87 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %12 = load i64, i64* %arrayidx2.i.3.i87, align 8, !tbaa !3
  %add3.i.3.i88 = add i64 %add.i.3.i86, %12
  %arrayidx5.i.3.i89 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 3
  store i64 %add3.i.3.i88, i64* %arrayidx5.i.3.i89, align 8, !tbaa !3
  %13 = xor i64 %add.i.3.i86, -9223372036854775808
  %xor2.i.i.3.i90 = and i64 %13, %11
  %xor.i23.i.3.i91 = xor i64 %add3.i.3.i88, %add.i.3.i86
  %xor1.i24.i.3.i92 = xor i64 %add.i.3.i86, %12
  %or.i25.i.3.i93 = or i64 %xor.i23.i.3.i91, %xor1.i24.i.3.i92
  %xor2.i26.i.3.i94 = xor i64 %or.i25.i.3.i93, %add3.i.3.i88
  %shr.i30.i.3.i95 = or i64 %xor2.i26.i.3.i94, %xor2.i.i.3.i90
  %or29.i.3.i96 = lshr i64 %shr.i30.i.3.i95, 63
  %arrayidx.i.4.i97 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %14 = load i64, i64* %arrayidx.i.4.i97, align 16, !tbaa !3
  %add.i.4.i98 = add i64 %or29.i.3.i96, %14
  %arrayidx2.i.4.i99 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %15 = load i64, i64* %arrayidx2.i.4.i99, align 16, !tbaa !3
  %add3.i.4.i100 = add i64 %add.i.4.i98, %15
  %arrayidx5.i.4.i101 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 4
  store i64 %add3.i.4.i100, i64* %arrayidx5.i.4.i101, align 16, !tbaa !3
  %16 = xor i64 %add.i.4.i98, -9223372036854775808
  %xor2.i.i.4.i102 = and i64 %16, %14
  %xor.i23.i.4.i103 = xor i64 %add3.i.4.i100, %add.i.4.i98
  %xor1.i24.i.4.i104 = xor i64 %add.i.4.i98, %15
  %or.i25.i.4.i105 = or i64 %xor.i23.i.4.i103, %xor1.i24.i.4.i104
  %xor2.i26.i.4.i106 = xor i64 %or.i25.i.4.i105, %add3.i.4.i100
  %shr.i30.i.4.i107 = or i64 %xor2.i26.i.4.i106, %xor2.i.i.4.i102
  %or29.i.4.i108 = lshr i64 %shr.i30.i.4.i107, 63
  %arrayidx.i.5.i109 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %17 = load i64, i64* %arrayidx.i.5.i109, align 8, !tbaa !3
  %add.i.5.i110 = add i64 %or29.i.4.i108, %17
  %arrayidx2.i.5.i111 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %18 = load i64, i64* %arrayidx2.i.5.i111, align 8, !tbaa !3
  %add3.i.5.i112 = add i64 %add.i.5.i110, %18
  %arrayidx5.i.5.i113 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 5
  store i64 %add3.i.5.i112, i64* %arrayidx5.i.5.i113, align 8, !tbaa !3
  %19 = xor i64 %add.i.5.i110, -9223372036854775808
  %xor2.i.i.5.i114 = and i64 %19, %17
  %xor.i23.i.5.i115 = xor i64 %add3.i.5.i112, %add.i.5.i110
  %xor1.i24.i.5.i116 = xor i64 %add.i.5.i110, %18
  %or.i25.i.5.i117 = or i64 %xor.i23.i.5.i115, %xor1.i24.i.5.i116
  %xor2.i26.i.5.i118 = xor i64 %or.i25.i.5.i117, %add3.i.5.i112
  %shr.i30.i.5.i119 = or i64 %xor2.i26.i.5.i118, %xor2.i.i.5.i114
  %or29.i.5.i120 = lshr i64 %shr.i30.i.5.i119, 63
  %arrayidx.i.6.i121 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %20 = load i64, i64* %arrayidx.i.6.i121, align 16, !tbaa !3
  %add.i.6.i122 = add i64 %or29.i.5.i120, %20
  %arrayidx2.i.6.i123 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %21 = load i64, i64* %arrayidx2.i.6.i123, align 16, !tbaa !3
  %add3.i.6.i124 = add i64 %add.i.6.i122, %21
  %arrayidx5.i.6.i125 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 6
  store i64 %add3.i.6.i124, i64* %arrayidx5.i.6.i125, align 16, !tbaa !3
  %22 = xor i64 %add.i.6.i122, -9223372036854775808
  %xor2.i.i.6.i126 = and i64 %22, %20
  %xor.i23.i.6.i127 = xor i64 %add3.i.6.i124, %add.i.6.i122
  %xor1.i24.i.6.i128 = xor i64 %add.i.6.i122, %21
  %or.i25.i.6.i129 = or i64 %xor.i23.i.6.i127, %xor1.i24.i.6.i128
  %xor2.i26.i.6.i130 = xor i64 %or.i25.i.6.i129, %add3.i.6.i124
  %shr.i30.i.6.i131 = or i64 %xor2.i26.i.6.i130, %xor2.i.i.6.i126
  %or29.i.6.i132 = lshr i64 %shr.i30.i.6.i131, 63
  %arrayidx.i.7.i133 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %23 = load i64, i64* %arrayidx.i.7.i133, align 8, !tbaa !3
  %add.i.7.i134 = add i64 %or29.i.6.i132, %23
  %arrayidx2.i.7.i135 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %24 = load i64, i64* %arrayidx2.i.7.i135, align 8, !tbaa !3
  %add3.i.7.i136 = add i64 %add.i.7.i134, %24
  %arrayidx5.i.7.i137 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 7
  store i64 %add3.i.7.i136, i64* %arrayidx5.i.7.i137, align 8, !tbaa !3
  %25 = xor i64 %add.i.7.i134, -9223372036854775808
  %xor2.i.i.7.i138 = and i64 %25, %23
  %xor.i23.i.7.i139 = xor i64 %add3.i.7.i136, %add.i.7.i134
  %xor1.i24.i.7.i140 = xor i64 %add.i.7.i134, %24
  %or.i25.i.7.i141 = or i64 %xor.i23.i.7.i139, %xor1.i24.i.7.i140
  %xor2.i26.i.7.i142 = xor i64 %or.i25.i.7.i141, %add3.i.7.i136
  %shr.i30.i.7.i143 = or i64 %xor2.i26.i.7.i142, %xor2.i.i.7.i138
  %or29.i.7.i144 = lshr i64 %shr.i30.i.7.i143, 63
  %arrayidx.i.8.i145 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %26 = load i64, i64* %arrayidx.i.8.i145, align 16, !tbaa !3
  %add.i.8.i146 = add i64 %or29.i.7.i144, %26
  %arrayidx2.i.8.i147 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %27 = load i64, i64* %arrayidx2.i.8.i147, align 16, !tbaa !3
  %add3.i.8.i148 = add i64 %add.i.8.i146, %27
  %arrayidx5.i.8.i149 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 8
  store i64 %add3.i.8.i148, i64* %arrayidx5.i.8.i149, align 16, !tbaa !3
  %28 = xor i64 %add.i.8.i146, -9223372036854775808
  %xor2.i.i.8.i150 = and i64 %28, %26
  %xor.i23.i.8.i151 = xor i64 %add3.i.8.i148, %add.i.8.i146
  %xor1.i24.i.8.i152 = xor i64 %add.i.8.i146, %27
  %or.i25.i.8.i153 = or i64 %xor.i23.i.8.i151, %xor1.i24.i.8.i152
  %xor2.i26.i.8.i154 = xor i64 %or.i25.i.8.i153, %add3.i.8.i148
  %shr.i30.i.8.i155 = or i64 %xor2.i26.i.8.i154, %xor2.i.i.8.i150
  %or29.i.8.i156 = lshr i64 %shr.i30.i.8.i155, 63
  %arrayidx.i.9.i157 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %29 = load i64, i64* %arrayidx.i.9.i157, align 8, !tbaa !3
  %arrayidx2.i.9.i159 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %30 = load i64, i64* %arrayidx2.i.9.i159, align 8, !tbaa !3
  %add.i.9.i158 = add i64 %30, %29
  %add3.i.9.i160 = add i64 %add.i.9.i158, %or29.i.8.i156
  %arrayidx5.i.9.i161 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 9
  store i64 %add3.i.9.i160, i64* %arrayidx5.i.9.i161, align 8, !tbaa !3
  %arraydecay10.i54 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  %31 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %32 = load i64, i64* %arraydecay10.i48, align 16, !tbaa !3
  %add3.i.i = add i64 %32, %31
  store i64 %add3.i.i, i64* %arraydecay10.i54, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %31
  %xor1.i24.i.i = xor i64 %32, %31
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %33 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %33
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %34 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %34
  %arrayidx5.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %35 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %35, %33
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %34
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %36 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %36
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %37 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %37
  %arrayidx5.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %38 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %38, %36
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %37
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %39 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %39
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %40 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %40
  %arrayidx5.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %41 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %41, %39
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %40
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %42 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %42
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %43 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %43
  %arrayidx5.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %44 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %44, %42
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %43
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %45 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %45
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %46 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %46
  %arrayidx5.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %47 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %47, %45
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %46
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %48 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %48
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %49 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %49
  %arrayidx5.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %50 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %50, %48
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %49
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %51 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %51
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %52 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %52
  %arrayidx5.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %53 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %53, %51
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %52
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %54 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %54
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %55 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %55
  %arrayidx5.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %56 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %56, %54
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %55
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %57 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %58 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %58, %57
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i45, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i48, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  %59 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %59) #10
  %60 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %60) #10
  %61 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %61) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  %62 = load i64, i64* %arraydecay4.i51, align 16, !tbaa !3
  %63 = load i64, i64* %arraydecay10.i54, align 16, !tbaa !3
  %add3.i.i183 = add i64 %63, %62
  store i64 %add3.i.i183, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i184 = xor i64 %add3.i.i183, %62
  %xor1.i24.i.i185 = xor i64 %63, %62
  %or.i25.i.i186 = or i64 %xor.i23.i.i184, %xor1.i24.i.i185
  %xor2.i26.i.i187 = xor i64 %or.i25.i.i186, %add3.i.i183
  %or29.i.i188 = lshr i64 %xor2.i26.i.i187, 63
  %64 = load i64, i64* %arrayidx5.i.1.i65, align 8, !tbaa !3
  %add.i.1.i190 = add i64 %or29.i.i188, %64
  %65 = load i64, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %add3.i.1.i192 = add i64 %add.i.1.i190, %65
  %arrayidx5.i.1.i193 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i192, i64* %arrayidx5.i.1.i193, align 8, !tbaa !3
  %66 = xor i64 %add.i.1.i190, -9223372036854775808
  %xor2.i.i.1.i194 = and i64 %66, %64
  %xor.i23.i.1.i195 = xor i64 %add3.i.1.i192, %add.i.1.i190
  %xor1.i24.i.1.i196 = xor i64 %add.i.1.i190, %65
  %or.i25.i.1.i197 = or i64 %xor.i23.i.1.i195, %xor1.i24.i.1.i196
  %xor2.i26.i.1.i198 = xor i64 %or.i25.i.1.i197, %add3.i.1.i192
  %shr.i30.i.1.i199 = or i64 %xor2.i26.i.1.i198, %xor2.i.i.1.i194
  %or29.i.1.i200 = lshr i64 %shr.i30.i.1.i199, 63
  %67 = load i64, i64* %arrayidx5.i.2.i77, align 16, !tbaa !3
  %add.i.2.i202 = add i64 %or29.i.1.i200, %67
  %68 = load i64, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %add3.i.2.i204 = add i64 %add.i.2.i202, %68
  %arrayidx5.i.2.i205 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i204, i64* %arrayidx5.i.2.i205, align 16, !tbaa !3
  %69 = xor i64 %add.i.2.i202, -9223372036854775808
  %xor2.i.i.2.i206 = and i64 %69, %67
  %xor.i23.i.2.i207 = xor i64 %add3.i.2.i204, %add.i.2.i202
  %xor1.i24.i.2.i208 = xor i64 %add.i.2.i202, %68
  %or.i25.i.2.i209 = or i64 %xor.i23.i.2.i207, %xor1.i24.i.2.i208
  %xor2.i26.i.2.i210 = xor i64 %or.i25.i.2.i209, %add3.i.2.i204
  %shr.i30.i.2.i211 = or i64 %xor2.i26.i.2.i210, %xor2.i.i.2.i206
  %or29.i.2.i212 = lshr i64 %shr.i30.i.2.i211, 63
  %70 = load i64, i64* %arrayidx5.i.3.i89, align 8, !tbaa !3
  %add.i.3.i214 = add i64 %or29.i.2.i212, %70
  %71 = load i64, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %add3.i.3.i216 = add i64 %add.i.3.i214, %71
  %arrayidx5.i.3.i217 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i216, i64* %arrayidx5.i.3.i217, align 8, !tbaa !3
  %72 = xor i64 %add.i.3.i214, -9223372036854775808
  %xor2.i.i.3.i218 = and i64 %72, %70
  %xor.i23.i.3.i219 = xor i64 %add3.i.3.i216, %add.i.3.i214
  %xor1.i24.i.3.i220 = xor i64 %add.i.3.i214, %71
  %or.i25.i.3.i221 = or i64 %xor.i23.i.3.i219, %xor1.i24.i.3.i220
  %xor2.i26.i.3.i222 = xor i64 %or.i25.i.3.i221, %add3.i.3.i216
  %shr.i30.i.3.i223 = or i64 %xor2.i26.i.3.i222, %xor2.i.i.3.i218
  %or29.i.3.i224 = lshr i64 %shr.i30.i.3.i223, 63
  %73 = load i64, i64* %arrayidx5.i.4.i101, align 16, !tbaa !3
  %add.i.4.i226 = add i64 %or29.i.3.i224, %73
  %74 = load i64, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %add3.i.4.i228 = add i64 %add.i.4.i226, %74
  %arrayidx5.i.4.i229 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i228, i64* %arrayidx5.i.4.i229, align 16, !tbaa !3
  %75 = xor i64 %add.i.4.i226, -9223372036854775808
  %xor2.i.i.4.i230 = and i64 %75, %73
  %xor.i23.i.4.i231 = xor i64 %add3.i.4.i228, %add.i.4.i226
  %xor1.i24.i.4.i232 = xor i64 %add.i.4.i226, %74
  %or.i25.i.4.i233 = or i64 %xor.i23.i.4.i231, %xor1.i24.i.4.i232
  %xor2.i26.i.4.i234 = xor i64 %or.i25.i.4.i233, %add3.i.4.i228
  %shr.i30.i.4.i235 = or i64 %xor2.i26.i.4.i234, %xor2.i.i.4.i230
  %or29.i.4.i236 = lshr i64 %shr.i30.i.4.i235, 63
  %76 = load i64, i64* %arrayidx5.i.5.i113, align 8, !tbaa !3
  %add.i.5.i238 = add i64 %or29.i.4.i236, %76
  %77 = load i64, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %add3.i.5.i240 = add i64 %add.i.5.i238, %77
  %arrayidx5.i.5.i241 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i240, i64* %arrayidx5.i.5.i241, align 8, !tbaa !3
  %78 = xor i64 %add.i.5.i238, -9223372036854775808
  %xor2.i.i.5.i242 = and i64 %78, %76
  %xor.i23.i.5.i243 = xor i64 %add3.i.5.i240, %add.i.5.i238
  %xor1.i24.i.5.i244 = xor i64 %add.i.5.i238, %77
  %or.i25.i.5.i245 = or i64 %xor.i23.i.5.i243, %xor1.i24.i.5.i244
  %xor2.i26.i.5.i246 = xor i64 %or.i25.i.5.i245, %add3.i.5.i240
  %shr.i30.i.5.i247 = or i64 %xor2.i26.i.5.i246, %xor2.i.i.5.i242
  %or29.i.5.i248 = lshr i64 %shr.i30.i.5.i247, 63
  %79 = load i64, i64* %arrayidx5.i.6.i125, align 16, !tbaa !3
  %add.i.6.i250 = add i64 %or29.i.5.i248, %79
  %80 = load i64, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %add3.i.6.i252 = add i64 %add.i.6.i250, %80
  %arrayidx5.i.6.i253 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i252, i64* %arrayidx5.i.6.i253, align 16, !tbaa !3
  %81 = xor i64 %add.i.6.i250, -9223372036854775808
  %xor2.i.i.6.i254 = and i64 %81, %79
  %xor.i23.i.6.i255 = xor i64 %add3.i.6.i252, %add.i.6.i250
  %xor1.i24.i.6.i256 = xor i64 %add.i.6.i250, %80
  %or.i25.i.6.i257 = or i64 %xor.i23.i.6.i255, %xor1.i24.i.6.i256
  %xor2.i26.i.6.i258 = xor i64 %or.i25.i.6.i257, %add3.i.6.i252
  %shr.i30.i.6.i259 = or i64 %xor2.i26.i.6.i258, %xor2.i.i.6.i254
  %or29.i.6.i260 = lshr i64 %shr.i30.i.6.i259, 63
  %82 = load i64, i64* %arrayidx5.i.7.i137, align 8, !tbaa !3
  %add.i.7.i262 = add i64 %or29.i.6.i260, %82
  %83 = load i64, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %add3.i.7.i264 = add i64 %add.i.7.i262, %83
  %arrayidx5.i.7.i265 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i264, i64* %arrayidx5.i.7.i265, align 8, !tbaa !3
  %84 = xor i64 %add.i.7.i262, -9223372036854775808
  %xor2.i.i.7.i266 = and i64 %84, %82
  %xor.i23.i.7.i267 = xor i64 %add3.i.7.i264, %add.i.7.i262
  %xor1.i24.i.7.i268 = xor i64 %add.i.7.i262, %83
  %or.i25.i.7.i269 = or i64 %xor.i23.i.7.i267, %xor1.i24.i.7.i268
  %xor2.i26.i.7.i270 = xor i64 %or.i25.i.7.i269, %add3.i.7.i264
  %shr.i30.i.7.i271 = or i64 %xor2.i26.i.7.i270, %xor2.i.i.7.i266
  %or29.i.7.i272 = lshr i64 %shr.i30.i.7.i271, 63
  %85 = load i64, i64* %arrayidx5.i.8.i149, align 16, !tbaa !3
  %add.i.8.i274 = add i64 %or29.i.7.i272, %85
  %86 = load i64, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %add3.i.8.i276 = add i64 %add.i.8.i274, %86
  %arrayidx5.i.8.i277 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i276, i64* %arrayidx5.i.8.i277, align 16, !tbaa !3
  %87 = xor i64 %add.i.8.i274, -9223372036854775808
  %xor2.i.i.8.i278 = and i64 %87, %85
  %xor.i23.i.8.i279 = xor i64 %add3.i.8.i276, %add.i.8.i274
  %xor1.i24.i.8.i280 = xor i64 %add.i.8.i274, %86
  %or.i25.i.8.i281 = or i64 %xor.i23.i.8.i279, %xor1.i24.i.8.i280
  %xor2.i26.i.8.i282 = xor i64 %or.i25.i.8.i281, %add3.i.8.i276
  %shr.i30.i.8.i283 = or i64 %xor2.i26.i.8.i282, %xor2.i.i.8.i278
  %or29.i.8.i284 = lshr i64 %shr.i30.i.8.i283, 63
  %88 = load i64, i64* %arrayidx5.i.9.i161, align 8, !tbaa !3
  %89 = load i64, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %add.i.9.i286 = add i64 %89, %88
  %add3.i.9.i288 = add i64 %add.i.9.i286, %or29.i.8.i284
  %arrayidx5.i.9.i289 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i288, i64* %arrayidx5.i.9.i289, align 8, !tbaa !3
  %arraydecay8.i170 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i51, i64* nonnull %arraydecay10.i54, i64* nonnull %arraydecay8.i170) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  %90 = load i64, i64* %arraydecay4.i51, align 16, !tbaa !3
  %add3.i.i290 = shl i64 %90, 1
  store i64 %add3.i.i290, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i295 = lshr i64 %90, 63
  %91 = load i64, i64* %arrayidx5.i.1.i65, align 8, !tbaa !3
  %add.i.1.i297 = add i64 %91, %or29.i.i295
  %add3.i.1.i299 = add i64 %add.i.1.i297, %91
  %arrayidx5.i.1.i300 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i299, i64* %arrayidx5.i.1.i300, align 8, !tbaa !3
  %92 = xor i64 %add.i.1.i297, -9223372036854775808
  %xor2.i.i.1.i301 = and i64 %92, %91
  %xor.i23.i.1.i302 = xor i64 %add3.i.1.i299, %add.i.1.i297
  %xor1.i24.i.1.i303 = xor i64 %add.i.1.i297, %91
  %or.i25.i.1.i304 = or i64 %xor.i23.i.1.i302, %xor1.i24.i.1.i303
  %xor2.i26.i.1.i305 = xor i64 %or.i25.i.1.i304, %add3.i.1.i299
  %shr.i30.i.1.i306 = or i64 %xor2.i26.i.1.i305, %xor2.i.i.1.i301
  %or29.i.1.i307 = lshr i64 %shr.i30.i.1.i306, 63
  %93 = load i64, i64* %arrayidx5.i.2.i77, align 16, !tbaa !3
  %add.i.2.i309 = add i64 %or29.i.1.i307, %93
  %add3.i.2.i311 = add i64 %add.i.2.i309, %93
  %arrayidx5.i.2.i312 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i311, i64* %arrayidx5.i.2.i312, align 16, !tbaa !3
  %94 = xor i64 %add.i.2.i309, -9223372036854775808
  %xor2.i.i.2.i313 = and i64 %94, %93
  %xor.i23.i.2.i314 = xor i64 %add3.i.2.i311, %add.i.2.i309
  %xor1.i24.i.2.i315 = xor i64 %add.i.2.i309, %93
  %or.i25.i.2.i316 = or i64 %xor.i23.i.2.i314, %xor1.i24.i.2.i315
  %xor2.i26.i.2.i317 = xor i64 %or.i25.i.2.i316, %add3.i.2.i311
  %shr.i30.i.2.i318 = or i64 %xor2.i26.i.2.i317, %xor2.i.i.2.i313
  %or29.i.2.i319 = lshr i64 %shr.i30.i.2.i318, 63
  %95 = load i64, i64* %arrayidx5.i.3.i89, align 8, !tbaa !3
  %add.i.3.i321 = add i64 %or29.i.2.i319, %95
  %add3.i.3.i323 = add i64 %add.i.3.i321, %95
  %arrayidx5.i.3.i324 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i323, i64* %arrayidx5.i.3.i324, align 8, !tbaa !3
  %96 = xor i64 %add.i.3.i321, -9223372036854775808
  %xor2.i.i.3.i325 = and i64 %96, %95
  %xor.i23.i.3.i326 = xor i64 %add3.i.3.i323, %add.i.3.i321
  %xor1.i24.i.3.i327 = xor i64 %add.i.3.i321, %95
  %or.i25.i.3.i328 = or i64 %xor.i23.i.3.i326, %xor1.i24.i.3.i327
  %xor2.i26.i.3.i329 = xor i64 %or.i25.i.3.i328, %add3.i.3.i323
  %shr.i30.i.3.i330 = or i64 %xor2.i26.i.3.i329, %xor2.i.i.3.i325
  %or29.i.3.i331 = lshr i64 %shr.i30.i.3.i330, 63
  %97 = load i64, i64* %arrayidx5.i.4.i101, align 16, !tbaa !3
  %add.i.4.i333 = add i64 %or29.i.3.i331, %97
  %add3.i.4.i335 = add i64 %add.i.4.i333, %97
  %arrayidx5.i.4.i336 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i335, i64* %arrayidx5.i.4.i336, align 16, !tbaa !3
  %98 = xor i64 %add.i.4.i333, -9223372036854775808
  %xor2.i.i.4.i337 = and i64 %98, %97
  %xor.i23.i.4.i338 = xor i64 %add3.i.4.i335, %add.i.4.i333
  %xor1.i24.i.4.i339 = xor i64 %add.i.4.i333, %97
  %or.i25.i.4.i340 = or i64 %xor.i23.i.4.i338, %xor1.i24.i.4.i339
  %xor2.i26.i.4.i341 = xor i64 %or.i25.i.4.i340, %add3.i.4.i335
  %shr.i30.i.4.i342 = or i64 %xor2.i26.i.4.i341, %xor2.i.i.4.i337
  %or29.i.4.i343 = lshr i64 %shr.i30.i.4.i342, 63
  %99 = load i64, i64* %arrayidx5.i.5.i113, align 8, !tbaa !3
  %add.i.5.i345 = add i64 %or29.i.4.i343, %99
  %add3.i.5.i347 = add i64 %add.i.5.i345, %99
  %arrayidx5.i.5.i348 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i347, i64* %arrayidx5.i.5.i348, align 8, !tbaa !3
  %100 = xor i64 %add.i.5.i345, -9223372036854775808
  %xor2.i.i.5.i349 = and i64 %100, %99
  %xor.i23.i.5.i350 = xor i64 %add3.i.5.i347, %add.i.5.i345
  %xor1.i24.i.5.i351 = xor i64 %add.i.5.i345, %99
  %or.i25.i.5.i352 = or i64 %xor.i23.i.5.i350, %xor1.i24.i.5.i351
  %xor2.i26.i.5.i353 = xor i64 %or.i25.i.5.i352, %add3.i.5.i347
  %shr.i30.i.5.i354 = or i64 %xor2.i26.i.5.i353, %xor2.i.i.5.i349
  %or29.i.5.i355 = lshr i64 %shr.i30.i.5.i354, 63
  %101 = load i64, i64* %arrayidx5.i.6.i125, align 16, !tbaa !3
  %add.i.6.i357 = add i64 %or29.i.5.i355, %101
  %add3.i.6.i359 = add i64 %add.i.6.i357, %101
  %arrayidx5.i.6.i360 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i359, i64* %arrayidx5.i.6.i360, align 16, !tbaa !3
  %102 = xor i64 %add.i.6.i357, -9223372036854775808
  %xor2.i.i.6.i361 = and i64 %102, %101
  %xor.i23.i.6.i362 = xor i64 %add3.i.6.i359, %add.i.6.i357
  %xor1.i24.i.6.i363 = xor i64 %add.i.6.i357, %101
  %or.i25.i.6.i364 = or i64 %xor.i23.i.6.i362, %xor1.i24.i.6.i363
  %xor2.i26.i.6.i365 = xor i64 %or.i25.i.6.i364, %add3.i.6.i359
  %shr.i30.i.6.i366 = or i64 %xor2.i26.i.6.i365, %xor2.i.i.6.i361
  %or29.i.6.i367 = lshr i64 %shr.i30.i.6.i366, 63
  %103 = load i64, i64* %arrayidx5.i.7.i137, align 8, !tbaa !3
  %add.i.7.i369 = add i64 %or29.i.6.i367, %103
  %add3.i.7.i371 = add i64 %add.i.7.i369, %103
  %arrayidx5.i.7.i372 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i371, i64* %arrayidx5.i.7.i372, align 8, !tbaa !3
  %104 = xor i64 %add.i.7.i369, -9223372036854775808
  %xor2.i.i.7.i373 = and i64 %104, %103
  %xor.i23.i.7.i374 = xor i64 %add3.i.7.i371, %add.i.7.i369
  %xor1.i24.i.7.i375 = xor i64 %add.i.7.i369, %103
  %or.i25.i.7.i376 = or i64 %xor.i23.i.7.i374, %xor1.i24.i.7.i375
  %xor2.i26.i.7.i377 = xor i64 %or.i25.i.7.i376, %add3.i.7.i371
  %shr.i30.i.7.i378 = or i64 %xor2.i26.i.7.i377, %xor2.i.i.7.i373
  %or29.i.7.i379 = lshr i64 %shr.i30.i.7.i378, 63
  %105 = load i64, i64* %arrayidx5.i.8.i149, align 16, !tbaa !3
  %add.i.8.i381 = add i64 %or29.i.7.i379, %105
  %add3.i.8.i383 = add i64 %add.i.8.i381, %105
  %arrayidx5.i.8.i384 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i383, i64* %arrayidx5.i.8.i384, align 16, !tbaa !3
  %106 = xor i64 %add.i.8.i381, -9223372036854775808
  %xor2.i.i.8.i385 = and i64 %106, %105
  %xor.i23.i.8.i386 = xor i64 %add3.i.8.i383, %add.i.8.i381
  %xor1.i24.i.8.i387 = xor i64 %add.i.8.i381, %105
  %or.i25.i.8.i388 = or i64 %xor.i23.i.8.i386, %xor1.i24.i.8.i387
  %xor2.i26.i.8.i389 = xor i64 %or.i25.i.8.i388, %add3.i.8.i383
  %shr.i30.i.8.i390 = or i64 %xor2.i26.i.8.i389, %xor2.i.i.8.i385
  %or29.i.8.i391 = lshr i64 %shr.i30.i.8.i390, 63
  %107 = load i64, i64* %arrayidx5.i.9.i161, align 8, !tbaa !3
  %factor = shl i64 %107, 1
  %add3.i.9.i395 = or i64 %or29.i.8.i391, %factor
  %arrayidx5.i.9.i396 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i395, i64* %arrayidx5.i.9.i396, align 8, !tbaa !3
  %108 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %108, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i170, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i51) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %108, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i54, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i54) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %61) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %60) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %59) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %59) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %60) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %61) #10
  %109 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %110 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i397 = add i64 %110, %109
  store i64 %add3.i.i397, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i398 = xor i64 %add3.i.i397, %109
  %xor1.i24.i.i399 = xor i64 %110, %109
  %or.i25.i.i400 = or i64 %xor.i23.i.i398, %xor1.i24.i.i399
  %xor2.i26.i.i401 = xor i64 %or.i25.i.i400, %add3.i.i397
  %or29.i.i402 = lshr i64 %xor2.i26.i.i401, 63
  %111 = load i64, i64* %arrayidx.i.1.i61, align 8, !tbaa !3
  %add.i.1.i404 = add i64 %or29.i.i402, %111
  %112 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add3.i.1.i406 = add i64 %add.i.1.i404, %112
  store i64 %add3.i.1.i406, i64* %arrayidx5.i.1.i193, align 8, !tbaa !3
  %113 = xor i64 %add.i.1.i404, -9223372036854775808
  %xor2.i.i.1.i408 = and i64 %113, %111
  %xor.i23.i.1.i409 = xor i64 %add3.i.1.i406, %add.i.1.i404
  %xor1.i24.i.1.i410 = xor i64 %add.i.1.i404, %112
  %or.i25.i.1.i411 = or i64 %xor.i23.i.1.i409, %xor1.i24.i.1.i410
  %xor2.i26.i.1.i412 = xor i64 %or.i25.i.1.i411, %add3.i.1.i406
  %shr.i30.i.1.i413 = or i64 %xor2.i26.i.1.i412, %xor2.i.i.1.i408
  %or29.i.1.i414 = lshr i64 %shr.i30.i.1.i413, 63
  %114 = load i64, i64* %arrayidx.i.2.i73, align 16, !tbaa !3
  %add.i.2.i416 = add i64 %or29.i.1.i414, %114
  %115 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add3.i.2.i418 = add i64 %add.i.2.i416, %115
  store i64 %add3.i.2.i418, i64* %arrayidx5.i.2.i205, align 16, !tbaa !3
  %116 = xor i64 %add.i.2.i416, -9223372036854775808
  %xor2.i.i.2.i420 = and i64 %116, %114
  %xor.i23.i.2.i421 = xor i64 %add3.i.2.i418, %add.i.2.i416
  %xor1.i24.i.2.i422 = xor i64 %add.i.2.i416, %115
  %or.i25.i.2.i423 = or i64 %xor.i23.i.2.i421, %xor1.i24.i.2.i422
  %xor2.i26.i.2.i424 = xor i64 %or.i25.i.2.i423, %add3.i.2.i418
  %shr.i30.i.2.i425 = or i64 %xor2.i26.i.2.i424, %xor2.i.i.2.i420
  %or29.i.2.i426 = lshr i64 %shr.i30.i.2.i425, 63
  %117 = load i64, i64* %arrayidx.i.3.i85, align 8, !tbaa !3
  %add.i.3.i428 = add i64 %or29.i.2.i426, %117
  %118 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add3.i.3.i430 = add i64 %add.i.3.i428, %118
  store i64 %add3.i.3.i430, i64* %arrayidx5.i.3.i217, align 8, !tbaa !3
  %119 = xor i64 %add.i.3.i428, -9223372036854775808
  %xor2.i.i.3.i432 = and i64 %119, %117
  %xor.i23.i.3.i433 = xor i64 %add3.i.3.i430, %add.i.3.i428
  %xor1.i24.i.3.i434 = xor i64 %add.i.3.i428, %118
  %or.i25.i.3.i435 = or i64 %xor.i23.i.3.i433, %xor1.i24.i.3.i434
  %xor2.i26.i.3.i436 = xor i64 %or.i25.i.3.i435, %add3.i.3.i430
  %shr.i30.i.3.i437 = or i64 %xor2.i26.i.3.i436, %xor2.i.i.3.i432
  %or29.i.3.i438 = lshr i64 %shr.i30.i.3.i437, 63
  %120 = load i64, i64* %arrayidx.i.4.i97, align 16, !tbaa !3
  %add.i.4.i440 = add i64 %or29.i.3.i438, %120
  %121 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add3.i.4.i442 = add i64 %add.i.4.i440, %121
  store i64 %add3.i.4.i442, i64* %arrayidx5.i.4.i229, align 16, !tbaa !3
  %122 = xor i64 %add.i.4.i440, -9223372036854775808
  %xor2.i.i.4.i444 = and i64 %122, %120
  %xor.i23.i.4.i445 = xor i64 %add3.i.4.i442, %add.i.4.i440
  %xor1.i24.i.4.i446 = xor i64 %add.i.4.i440, %121
  %or.i25.i.4.i447 = or i64 %xor.i23.i.4.i445, %xor1.i24.i.4.i446
  %xor2.i26.i.4.i448 = xor i64 %or.i25.i.4.i447, %add3.i.4.i442
  %shr.i30.i.4.i449 = or i64 %xor2.i26.i.4.i448, %xor2.i.i.4.i444
  %or29.i.4.i450 = lshr i64 %shr.i30.i.4.i449, 63
  %123 = load i64, i64* %arrayidx.i.5.i109, align 8, !tbaa !3
  %add.i.5.i452 = add i64 %or29.i.4.i450, %123
  %124 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add3.i.5.i454 = add i64 %add.i.5.i452, %124
  store i64 %add3.i.5.i454, i64* %arrayidx5.i.5.i241, align 8, !tbaa !3
  %125 = xor i64 %add.i.5.i452, -9223372036854775808
  %xor2.i.i.5.i456 = and i64 %125, %123
  %xor.i23.i.5.i457 = xor i64 %add3.i.5.i454, %add.i.5.i452
  %xor1.i24.i.5.i458 = xor i64 %add.i.5.i452, %124
  %or.i25.i.5.i459 = or i64 %xor.i23.i.5.i457, %xor1.i24.i.5.i458
  %xor2.i26.i.5.i460 = xor i64 %or.i25.i.5.i459, %add3.i.5.i454
  %shr.i30.i.5.i461 = or i64 %xor2.i26.i.5.i460, %xor2.i.i.5.i456
  %or29.i.5.i462 = lshr i64 %shr.i30.i.5.i461, 63
  %126 = load i64, i64* %arrayidx.i.6.i121, align 16, !tbaa !3
  %add.i.6.i464 = add i64 %or29.i.5.i462, %126
  %127 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add3.i.6.i466 = add i64 %add.i.6.i464, %127
  store i64 %add3.i.6.i466, i64* %arrayidx5.i.6.i253, align 16, !tbaa !3
  %128 = xor i64 %add.i.6.i464, -9223372036854775808
  %xor2.i.i.6.i468 = and i64 %128, %126
  %xor.i23.i.6.i469 = xor i64 %add3.i.6.i466, %add.i.6.i464
  %xor1.i24.i.6.i470 = xor i64 %add.i.6.i464, %127
  %or.i25.i.6.i471 = or i64 %xor.i23.i.6.i469, %xor1.i24.i.6.i470
  %xor2.i26.i.6.i472 = xor i64 %or.i25.i.6.i471, %add3.i.6.i466
  %shr.i30.i.6.i473 = or i64 %xor2.i26.i.6.i472, %xor2.i.i.6.i468
  %or29.i.6.i474 = lshr i64 %shr.i30.i.6.i473, 63
  %129 = load i64, i64* %arrayidx.i.7.i133, align 8, !tbaa !3
  %add.i.7.i476 = add i64 %or29.i.6.i474, %129
  %130 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add3.i.7.i478 = add i64 %add.i.7.i476, %130
  store i64 %add3.i.7.i478, i64* %arrayidx5.i.7.i265, align 8, !tbaa !3
  %131 = xor i64 %add.i.7.i476, -9223372036854775808
  %xor2.i.i.7.i480 = and i64 %131, %129
  %xor.i23.i.7.i481 = xor i64 %add3.i.7.i478, %add.i.7.i476
  %xor1.i24.i.7.i482 = xor i64 %add.i.7.i476, %130
  %or.i25.i.7.i483 = or i64 %xor.i23.i.7.i481, %xor1.i24.i.7.i482
  %xor2.i26.i.7.i484 = xor i64 %or.i25.i.7.i483, %add3.i.7.i478
  %shr.i30.i.7.i485 = or i64 %xor2.i26.i.7.i484, %xor2.i.i.7.i480
  %or29.i.7.i486 = lshr i64 %shr.i30.i.7.i485, 63
  %132 = load i64, i64* %arrayidx.i.8.i145, align 16, !tbaa !3
  %add.i.8.i488 = add i64 %or29.i.7.i486, %132
  %133 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add3.i.8.i490 = add i64 %add.i.8.i488, %133
  store i64 %add3.i.8.i490, i64* %arrayidx5.i.8.i277, align 16, !tbaa !3
  %134 = xor i64 %add.i.8.i488, -9223372036854775808
  %xor2.i.i.8.i492 = and i64 %134, %132
  %xor.i23.i.8.i493 = xor i64 %add3.i.8.i490, %add.i.8.i488
  %xor1.i24.i.8.i494 = xor i64 %add.i.8.i488, %133
  %or.i25.i.8.i495 = or i64 %xor.i23.i.8.i493, %xor1.i24.i.8.i494
  %xor2.i26.i.8.i496 = xor i64 %or.i25.i.8.i495, %add3.i.8.i490
  %shr.i30.i.8.i497 = or i64 %xor2.i26.i.8.i496, %xor2.i.i.8.i492
  %or29.i.8.i498 = lshr i64 %shr.i30.i.8.i497, 63
  %135 = load i64, i64* %arrayidx.i.9.i157, align 8, !tbaa !3
  %136 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %add.i.9.i500 = add i64 %136, %135
  %add3.i.9.i502 = add i64 %add.i.9.i500, %or29.i.8.i498
  store i64 %add3.i.9.i502, i64* %arrayidx5.i.9.i289, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i170) #10
  %137 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i504 = shl i64 %137, 1
  store i64 %add3.i.i504, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i509 = lshr i64 %137, 63
  %138 = load i64, i64* %arrayidx.i.1.i61, align 8, !tbaa !3
  %add.i.1.i511 = add i64 %138, %or29.i.i509
  %add3.i.1.i513 = add i64 %add.i.1.i511, %138
  store i64 %add3.i.1.i513, i64* %arrayidx5.i.1.i300, align 8, !tbaa !3
  %139 = xor i64 %add.i.1.i511, -9223372036854775808
  %xor2.i.i.1.i515 = and i64 %139, %138
  %xor.i23.i.1.i516 = xor i64 %add3.i.1.i513, %add.i.1.i511
  %xor1.i24.i.1.i517 = xor i64 %add.i.1.i511, %138
  %or.i25.i.1.i518 = or i64 %xor.i23.i.1.i516, %xor1.i24.i.1.i517
  %xor2.i26.i.1.i519 = xor i64 %or.i25.i.1.i518, %add3.i.1.i513
  %shr.i30.i.1.i520 = or i64 %xor2.i26.i.1.i519, %xor2.i.i.1.i515
  %or29.i.1.i521 = lshr i64 %shr.i30.i.1.i520, 63
  %140 = load i64, i64* %arrayidx.i.2.i73, align 16, !tbaa !3
  %add.i.2.i523 = add i64 %or29.i.1.i521, %140
  %add3.i.2.i525 = add i64 %add.i.2.i523, %140
  store i64 %add3.i.2.i525, i64* %arrayidx5.i.2.i312, align 16, !tbaa !3
  %141 = xor i64 %add.i.2.i523, -9223372036854775808
  %xor2.i.i.2.i527 = and i64 %141, %140
  %xor.i23.i.2.i528 = xor i64 %add3.i.2.i525, %add.i.2.i523
  %xor1.i24.i.2.i529 = xor i64 %add.i.2.i523, %140
  %or.i25.i.2.i530 = or i64 %xor.i23.i.2.i528, %xor1.i24.i.2.i529
  %xor2.i26.i.2.i531 = xor i64 %or.i25.i.2.i530, %add3.i.2.i525
  %shr.i30.i.2.i532 = or i64 %xor2.i26.i.2.i531, %xor2.i.i.2.i527
  %or29.i.2.i533 = lshr i64 %shr.i30.i.2.i532, 63
  %142 = load i64, i64* %arrayidx.i.3.i85, align 8, !tbaa !3
  %add.i.3.i535 = add i64 %or29.i.2.i533, %142
  %add3.i.3.i537 = add i64 %add.i.3.i535, %142
  store i64 %add3.i.3.i537, i64* %arrayidx5.i.3.i324, align 8, !tbaa !3
  %143 = xor i64 %add.i.3.i535, -9223372036854775808
  %xor2.i.i.3.i539 = and i64 %143, %142
  %xor.i23.i.3.i540 = xor i64 %add3.i.3.i537, %add.i.3.i535
  %xor1.i24.i.3.i541 = xor i64 %add.i.3.i535, %142
  %or.i25.i.3.i542 = or i64 %xor.i23.i.3.i540, %xor1.i24.i.3.i541
  %xor2.i26.i.3.i543 = xor i64 %or.i25.i.3.i542, %add3.i.3.i537
  %shr.i30.i.3.i544 = or i64 %xor2.i26.i.3.i543, %xor2.i.i.3.i539
  %or29.i.3.i545 = lshr i64 %shr.i30.i.3.i544, 63
  %144 = load i64, i64* %arrayidx.i.4.i97, align 16, !tbaa !3
  %add.i.4.i547 = add i64 %or29.i.3.i545, %144
  %add3.i.4.i549 = add i64 %add.i.4.i547, %144
  store i64 %add3.i.4.i549, i64* %arrayidx5.i.4.i336, align 16, !tbaa !3
  %145 = xor i64 %add.i.4.i547, -9223372036854775808
  %xor2.i.i.4.i551 = and i64 %145, %144
  %xor.i23.i.4.i552 = xor i64 %add3.i.4.i549, %add.i.4.i547
  %xor1.i24.i.4.i553 = xor i64 %add.i.4.i547, %144
  %or.i25.i.4.i554 = or i64 %xor.i23.i.4.i552, %xor1.i24.i.4.i553
  %xor2.i26.i.4.i555 = xor i64 %or.i25.i.4.i554, %add3.i.4.i549
  %shr.i30.i.4.i556 = or i64 %xor2.i26.i.4.i555, %xor2.i.i.4.i551
  %or29.i.4.i557 = lshr i64 %shr.i30.i.4.i556, 63
  %146 = load i64, i64* %arrayidx.i.5.i109, align 8, !tbaa !3
  %add.i.5.i559 = add i64 %or29.i.4.i557, %146
  %add3.i.5.i561 = add i64 %add.i.5.i559, %146
  store i64 %add3.i.5.i561, i64* %arrayidx5.i.5.i348, align 8, !tbaa !3
  %147 = xor i64 %add.i.5.i559, -9223372036854775808
  %xor2.i.i.5.i563 = and i64 %147, %146
  %xor.i23.i.5.i564 = xor i64 %add3.i.5.i561, %add.i.5.i559
  %xor1.i24.i.5.i565 = xor i64 %add.i.5.i559, %146
  %or.i25.i.5.i566 = or i64 %xor.i23.i.5.i564, %xor1.i24.i.5.i565
  %xor2.i26.i.5.i567 = xor i64 %or.i25.i.5.i566, %add3.i.5.i561
  %shr.i30.i.5.i568 = or i64 %xor2.i26.i.5.i567, %xor2.i.i.5.i563
  %or29.i.5.i569 = lshr i64 %shr.i30.i.5.i568, 63
  %148 = load i64, i64* %arrayidx.i.6.i121, align 16, !tbaa !3
  %add.i.6.i571 = add i64 %or29.i.5.i569, %148
  %add3.i.6.i573 = add i64 %add.i.6.i571, %148
  store i64 %add3.i.6.i573, i64* %arrayidx5.i.6.i360, align 16, !tbaa !3
  %149 = xor i64 %add.i.6.i571, -9223372036854775808
  %xor2.i.i.6.i575 = and i64 %149, %148
  %xor.i23.i.6.i576 = xor i64 %add3.i.6.i573, %add.i.6.i571
  %xor1.i24.i.6.i577 = xor i64 %add.i.6.i571, %148
  %or.i25.i.6.i578 = or i64 %xor.i23.i.6.i576, %xor1.i24.i.6.i577
  %xor2.i26.i.6.i579 = xor i64 %or.i25.i.6.i578, %add3.i.6.i573
  %shr.i30.i.6.i580 = or i64 %xor2.i26.i.6.i579, %xor2.i.i.6.i575
  %or29.i.6.i581 = lshr i64 %shr.i30.i.6.i580, 63
  %150 = load i64, i64* %arrayidx.i.7.i133, align 8, !tbaa !3
  %add.i.7.i583 = add i64 %or29.i.6.i581, %150
  %add3.i.7.i585 = add i64 %add.i.7.i583, %150
  store i64 %add3.i.7.i585, i64* %arrayidx5.i.7.i372, align 8, !tbaa !3
  %151 = xor i64 %add.i.7.i583, -9223372036854775808
  %xor2.i.i.7.i587 = and i64 %151, %150
  %xor.i23.i.7.i588 = xor i64 %add3.i.7.i585, %add.i.7.i583
  %xor1.i24.i.7.i589 = xor i64 %add.i.7.i583, %150
  %or.i25.i.7.i590 = or i64 %xor.i23.i.7.i588, %xor1.i24.i.7.i589
  %xor2.i26.i.7.i591 = xor i64 %or.i25.i.7.i590, %add3.i.7.i585
  %shr.i30.i.7.i592 = or i64 %xor2.i26.i.7.i591, %xor2.i.i.7.i587
  %or29.i.7.i593 = lshr i64 %shr.i30.i.7.i592, 63
  %152 = load i64, i64* %arrayidx.i.8.i145, align 16, !tbaa !3
  %add.i.8.i595 = add i64 %or29.i.7.i593, %152
  %add3.i.8.i597 = add i64 %add.i.8.i595, %152
  store i64 %add3.i.8.i597, i64* %arrayidx5.i.8.i384, align 16, !tbaa !3
  %153 = xor i64 %add.i.8.i595, -9223372036854775808
  %xor2.i.i.8.i599 = and i64 %153, %152
  %xor.i23.i.8.i600 = xor i64 %add3.i.8.i597, %add.i.8.i595
  %xor1.i24.i.8.i601 = xor i64 %add.i.8.i595, %152
  %or.i25.i.8.i602 = or i64 %xor.i23.i.8.i600, %xor1.i24.i.8.i601
  %xor2.i26.i.8.i603 = xor i64 %or.i25.i.8.i602, %add3.i.8.i597
  %shr.i30.i.8.i604 = or i64 %xor2.i26.i.8.i603, %xor2.i.i.8.i599
  %or29.i.8.i605 = lshr i64 %shr.i30.i.8.i604, 63
  %154 = load i64, i64* %arrayidx.i.9.i157, align 8, !tbaa !3
  %factor611 = shl i64 %154, 1
  %add3.i.9.i609 = or i64 %or29.i.8.i605, %factor611
  store i64 %add3.i.9.i609, i64* %arrayidx5.i.9.i396, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %108, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i170, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %108, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %108) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %61) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %60) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %59) #10
  call void @fp2mul610_mont([10 x i64]* %arraydecay, [10 x i64]* nonnull %arraydecay17, [10 x i64]* %arraydecay)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay1)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @inv_3_way([10 x i64]* %z1, [10 x i64]* %z2, [10 x i64]* %z3) local_unnamed_addr #4 {
entry:
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %z1, [10 x i64]* %z2, [10 x i64]* nonnull %arraydecay)
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %z3, [10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2)
  call void @fp2inv610_mont([10 x i64]* nonnull %arraydecay2)
  %arraydecay5 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %z3, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay5)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2, [10 x i64]* %z3)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay5, [10 x i64]* %z2, [10 x i64]* nonnull %arraydecay)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay5, [10 x i64]* %z1, [10 x i64]* %z2)
  %3 = bitcast [2 x [10 x i64]]* %t0 to <4 x i64>*
  %4 = load <4 x i64>, <4 x i64>* %3, align 16, !tbaa !3
  %5 = bitcast [10 x i64]* %z1 to <4 x i64>*
  store <4 x i64> %4, <4 x i64>* %5, align 8, !tbaa !3
  %arrayidx.4.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %arrayidx2.4.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %z1, i64 0, i64 4
  %6 = bitcast i64* %arrayidx.4.i.i to <4 x i64>*
  %7 = load <4 x i64>, <4 x i64>* %6, align 16, !tbaa !3
  %8 = bitcast i64* %arrayidx2.4.i.i to <4 x i64>*
  store <4 x i64> %7, <4 x i64>* %8, align 8, !tbaa !3
  %arrayidx.8.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %arrayidx2.8.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %z1, i64 0, i64 8
  %9 = bitcast i64* %arrayidx.8.i.i to <4 x i64>*
  %10 = load <4 x i64>, <4 x i64>* %9, align 16, !tbaa !3
  %11 = bitcast i64* %arrayidx2.8.i.i to <4 x i64>*
  store <4 x i64> %10, <4 x i64>* %11, align 8, !tbaa !3
  %arrayidx.2.i11.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %arrayidx2.2.i12.i = getelementptr inbounds [10 x i64], [10 x i64]* %z1, i64 1, i64 2
  %12 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %13 = load <4 x i64>, <4 x i64>* %12, align 16, !tbaa !3
  %14 = bitcast i64* %arrayidx2.2.i12.i to <4 x i64>*
  store <4 x i64> %13, <4 x i64>* %14, align 8, !tbaa !3
  %arrayidx.6.i19.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %arrayidx2.6.i20.i = getelementptr inbounds [10 x i64], [10 x i64]* %z1, i64 1, i64 6
  %15 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %16 = load <4 x i64>, <4 x i64>* %15, align 16, !tbaa !3
  %17 = bitcast i64* %arrayidx2.6.i20.i to <4 x i64>*
  store <4 x i64> %16, <4 x i64>* %17, align 8, !tbaa !3
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @get_A([10 x i64]* %xP, [10 x i64]* %xQ, [10 x i64]* %xR, [10 x i64]* %A) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %one = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %one to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 1
  %4 = bitcast [10 x i64]* %3 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 80, i1 false)
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay, align 16, !tbaa !3
  %arrayidx2.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 0, i64 1
  %arrayidx2.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 0, i64 4
  %5 = bitcast i64* %arrayidx2.1.i to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %5, i8 0, i64 24, i1 false)
  %6 = bitcast i64* %arrayidx2.4.i to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %6, align 16, !tbaa !3
  %arrayidx2.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i, align 16, !tbaa !3
  %arrayidx2.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i, align 8, !tbaa !3
  %arraydecay1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay.i33 = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 0
  %arraydecay2.i34 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 0, i64 0
  %arraydecay4.i35 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @fpadd610(i64* %arraydecay.i33, i64* %arraydecay2.i34, i64* nonnull %arraydecay4.i35) #10
  %arraydecay6.i36 = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 0
  %arraydecay8.i37 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 1, i64 0
  %arraydecay10.i38 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay6.i36, i64* nonnull %arraydecay8.i37, i64* nonnull %arraydecay10.i38) #10
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %xP, [10 x i64]* %xQ, [10 x i64]* nonnull %arraydecay2)
  call void @fp2mul610_mont([10 x i64]* %xR, [10 x i64]* nonnull %arraydecay1, [10 x i64]* %A)
  %arraydecay.i39 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  %arraydecay2.i40 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 0
  call void @fpadd610(i64* nonnull %arraydecay.i39, i64* %arraydecay2.i40, i64* %arraydecay2.i40) #10
  %arraydecay6.i42 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  %arraydecay8.i43 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay6.i42, i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay8.i43) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* %xR, [10 x i64]* nonnull %arraydecay2)
  call void @fpsub610(i64* %arraydecay2.i40, i64* nonnull %arraydecay, i64* %arraydecay2.i40) #10
  %arraydecay8.i49 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %one, i64 0, i64 1, i64 0
  call void @fpsub610(i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay8.i49, i64* nonnull %arraydecay8.i43) #10
  call void @fpadd610(i64* nonnull %arraydecay.i39, i64* nonnull %arraydecay.i39, i64* nonnull %arraydecay.i39) #10
  call void @fpadd610(i64* nonnull %arraydecay6.i42, i64* nonnull %arraydecay6.i42, i64* nonnull %arraydecay6.i42) #10
  %arraydecay2.i58 = getelementptr inbounds [10 x i64], [10 x i64]* %xR, i64 0, i64 0
  call void @fpadd610(i64* nonnull %arraydecay4.i35, i64* %arraydecay2.i58, i64* nonnull %arraydecay4.i35) #10
  %arraydecay8.i61 = getelementptr inbounds [10 x i64], [10 x i64]* %xR, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay10.i38, i64* nonnull %arraydecay8.i61, i64* nonnull %arraydecay10.i38) #10
  call void @fpadd610(i64* nonnull %arraydecay.i39, i64* nonnull %arraydecay.i39, i64* nonnull %arraydecay.i39) #10
  call void @fpadd610(i64* nonnull %arraydecay6.i42, i64* nonnull %arraydecay6.i42, i64* nonnull %arraydecay6.i42) #10
  %7 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %7) #10
  %8 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %8) #10
  %9 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %9) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay2.i40, i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i71 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay2.i40, i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay8.i71) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay2.i40, i64* %arraydecay2.i40, i64* nonnull %arraydecay13.i) #10
  %10 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i71, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay2.i40) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay8.i43) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %7) #10
  call void @fp2inv610_mont([10 x i64]* nonnull %arraydecay2)
  call void @fp2mul610_mont([10 x i64]* %A, [10 x i64]* nonnull %arraydecay2, [10 x i64]* %A)
  call void @fpsub610(i64* %arraydecay2.i40, i64* nonnull %arraydecay4.i35, i64* %arraydecay2.i40) #10
  call void @fpsub610(i64* nonnull %arraydecay8.i43, i64* nonnull %arraydecay10.i38, i64* nonnull %arraydecay8.i43) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @j_inv([10 x i64]* %A, [10 x i64]* %C, [10 x i64]* %jinv) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  %3 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  %4 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay.i = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 0
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i = getelementptr inbounds [10 x i64], [10 x i64]* %jinv, i64 0, i64 0
  %5 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  %arraydecay22.i = getelementptr inbounds [10 x i64], [10 x i64]* %jinv, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay.i43 = getelementptr inbounds [10 x i64], [10 x i64]* %C, i64 0, i64 0
  %arraydecay2.i44 = getelementptr inbounds [10 x i64], [10 x i64]* %C, i64 1, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i43, i64* nonnull %arraydecay2.i44, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* %arraydecay.i43, i64* nonnull %arraydecay2.i44, i64* nonnull %arraydecay8.i) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i43, i64* %arraydecay.i43, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i48 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i48) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  %arraydecay22.i50 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i44, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i50) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  %arraydecay3 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call void @fpadd610(i64* nonnull %arraydecay17.i48, i64* nonnull %arraydecay17.i48, i64* nonnull %arraydecay4.i) #10
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay10.i) #10
  call void @fpsub610(i64* %arraydecay17.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpsub610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @fpsub610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay17.i48, i64* nonnull %arraydecay4.i) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay10.i) #10
  call void @fpsub610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay17.i48, i64* %arraydecay17.i) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %6 = load i64, i64* %arraydecay17.i48, align 16, !tbaa !3
  %7 = load i64, i64* %arraydecay22.i50, align 16, !tbaa !3
  %add3.i.i = add i64 %7, %6
  store i64 %add3.i.i, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %6
  %xor1.i24.i.i = xor i64 %7, %6
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %8 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %8
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %9 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %9
  %arrayidx5.i.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %10 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %10, %8
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %9
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %11 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %11
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %12 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %12
  %arrayidx5.i.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %13 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %13, %11
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %12
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %14 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %14
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %15 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %15
  %arrayidx5.i.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %16 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %16, %14
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %15
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %17 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %17
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %18 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %18
  %arrayidx5.i.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %19 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %19, %17
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %18
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %20 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %20
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %21 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %21
  %arrayidx5.i.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %22 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %22, %20
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %21
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %23 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %23
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %24 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %24
  %arrayidx5.i.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %25 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %25, %23
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %24
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %26 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %26
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %27 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %27
  %arrayidx5.i.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %28 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %28, %26
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %27
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %29 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %29
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %30 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %30
  %arrayidx5.i.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %31 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %31, %29
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %30
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %32 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %33 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %33, %32
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay17.i48, i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay8.i) #10
  %34 = load i64, i64* %arraydecay17.i48, align 16, !tbaa !3
  %add3.i.i120 = shl i64 %34, 1
  store i64 %add3.i.i120, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i125 = lshr i64 %34, 63
  %35 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i127 = add i64 %35, %or29.i.i125
  %add3.i.1.i129 = add i64 %add.i.1.i127, %35
  %arrayidx5.i.1.i130 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i129, i64* %arrayidx5.i.1.i130, align 8, !tbaa !3
  %36 = xor i64 %add.i.1.i127, -9223372036854775808
  %xor2.i.i.1.i131 = and i64 %36, %35
  %xor.i23.i.1.i132 = xor i64 %add3.i.1.i129, %add.i.1.i127
  %xor1.i24.i.1.i133 = xor i64 %add.i.1.i127, %35
  %or.i25.i.1.i134 = or i64 %xor.i23.i.1.i132, %xor1.i24.i.1.i133
  %xor2.i26.i.1.i135 = xor i64 %or.i25.i.1.i134, %add3.i.1.i129
  %shr.i30.i.1.i136 = or i64 %xor2.i26.i.1.i135, %xor2.i.i.1.i131
  %or29.i.1.i137 = lshr i64 %shr.i30.i.1.i136, 63
  %37 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i139 = add i64 %or29.i.1.i137, %37
  %add3.i.2.i141 = add i64 %add.i.2.i139, %37
  %arrayidx5.i.2.i142 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i141, i64* %arrayidx5.i.2.i142, align 16, !tbaa !3
  %38 = xor i64 %add.i.2.i139, -9223372036854775808
  %xor2.i.i.2.i143 = and i64 %38, %37
  %xor.i23.i.2.i144 = xor i64 %add3.i.2.i141, %add.i.2.i139
  %xor1.i24.i.2.i145 = xor i64 %add.i.2.i139, %37
  %or.i25.i.2.i146 = or i64 %xor.i23.i.2.i144, %xor1.i24.i.2.i145
  %xor2.i26.i.2.i147 = xor i64 %or.i25.i.2.i146, %add3.i.2.i141
  %shr.i30.i.2.i148 = or i64 %xor2.i26.i.2.i147, %xor2.i.i.2.i143
  %or29.i.2.i149 = lshr i64 %shr.i30.i.2.i148, 63
  %39 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i151 = add i64 %or29.i.2.i149, %39
  %add3.i.3.i153 = add i64 %add.i.3.i151, %39
  %arrayidx5.i.3.i154 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i153, i64* %arrayidx5.i.3.i154, align 8, !tbaa !3
  %40 = xor i64 %add.i.3.i151, -9223372036854775808
  %xor2.i.i.3.i155 = and i64 %40, %39
  %xor.i23.i.3.i156 = xor i64 %add3.i.3.i153, %add.i.3.i151
  %xor1.i24.i.3.i157 = xor i64 %add.i.3.i151, %39
  %or.i25.i.3.i158 = or i64 %xor.i23.i.3.i156, %xor1.i24.i.3.i157
  %xor2.i26.i.3.i159 = xor i64 %or.i25.i.3.i158, %add3.i.3.i153
  %shr.i30.i.3.i160 = or i64 %xor2.i26.i.3.i159, %xor2.i.i.3.i155
  %or29.i.3.i161 = lshr i64 %shr.i30.i.3.i160, 63
  %41 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i163 = add i64 %or29.i.3.i161, %41
  %add3.i.4.i165 = add i64 %add.i.4.i163, %41
  %arrayidx5.i.4.i166 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i165, i64* %arrayidx5.i.4.i166, align 16, !tbaa !3
  %42 = xor i64 %add.i.4.i163, -9223372036854775808
  %xor2.i.i.4.i167 = and i64 %42, %41
  %xor.i23.i.4.i168 = xor i64 %add3.i.4.i165, %add.i.4.i163
  %xor1.i24.i.4.i169 = xor i64 %add.i.4.i163, %41
  %or.i25.i.4.i170 = or i64 %xor.i23.i.4.i168, %xor1.i24.i.4.i169
  %xor2.i26.i.4.i171 = xor i64 %or.i25.i.4.i170, %add3.i.4.i165
  %shr.i30.i.4.i172 = or i64 %xor2.i26.i.4.i171, %xor2.i.i.4.i167
  %or29.i.4.i173 = lshr i64 %shr.i30.i.4.i172, 63
  %43 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i175 = add i64 %or29.i.4.i173, %43
  %add3.i.5.i177 = add i64 %add.i.5.i175, %43
  %arrayidx5.i.5.i178 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i177, i64* %arrayidx5.i.5.i178, align 8, !tbaa !3
  %44 = xor i64 %add.i.5.i175, -9223372036854775808
  %xor2.i.i.5.i179 = and i64 %44, %43
  %xor.i23.i.5.i180 = xor i64 %add3.i.5.i177, %add.i.5.i175
  %xor1.i24.i.5.i181 = xor i64 %add.i.5.i175, %43
  %or.i25.i.5.i182 = or i64 %xor.i23.i.5.i180, %xor1.i24.i.5.i181
  %xor2.i26.i.5.i183 = xor i64 %or.i25.i.5.i182, %add3.i.5.i177
  %shr.i30.i.5.i184 = or i64 %xor2.i26.i.5.i183, %xor2.i.i.5.i179
  %or29.i.5.i185 = lshr i64 %shr.i30.i.5.i184, 63
  %45 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i187 = add i64 %or29.i.5.i185, %45
  %add3.i.6.i189 = add i64 %add.i.6.i187, %45
  %arrayidx5.i.6.i190 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i189, i64* %arrayidx5.i.6.i190, align 16, !tbaa !3
  %46 = xor i64 %add.i.6.i187, -9223372036854775808
  %xor2.i.i.6.i191 = and i64 %46, %45
  %xor.i23.i.6.i192 = xor i64 %add3.i.6.i189, %add.i.6.i187
  %xor1.i24.i.6.i193 = xor i64 %add.i.6.i187, %45
  %or.i25.i.6.i194 = or i64 %xor.i23.i.6.i192, %xor1.i24.i.6.i193
  %xor2.i26.i.6.i195 = xor i64 %or.i25.i.6.i194, %add3.i.6.i189
  %shr.i30.i.6.i196 = or i64 %xor2.i26.i.6.i195, %xor2.i.i.6.i191
  %or29.i.6.i197 = lshr i64 %shr.i30.i.6.i196, 63
  %47 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i199 = add i64 %or29.i.6.i197, %47
  %add3.i.7.i201 = add i64 %add.i.7.i199, %47
  %arrayidx5.i.7.i202 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i201, i64* %arrayidx5.i.7.i202, align 8, !tbaa !3
  %48 = xor i64 %add.i.7.i199, -9223372036854775808
  %xor2.i.i.7.i203 = and i64 %48, %47
  %xor.i23.i.7.i204 = xor i64 %add3.i.7.i201, %add.i.7.i199
  %xor1.i24.i.7.i205 = xor i64 %add.i.7.i199, %47
  %or.i25.i.7.i206 = or i64 %xor.i23.i.7.i204, %xor1.i24.i.7.i205
  %xor2.i26.i.7.i207 = xor i64 %or.i25.i.7.i206, %add3.i.7.i201
  %shr.i30.i.7.i208 = or i64 %xor2.i26.i.7.i207, %xor2.i.i.7.i203
  %or29.i.7.i209 = lshr i64 %shr.i30.i.7.i208, 63
  %49 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i211 = add i64 %or29.i.7.i209, %49
  %add3.i.8.i213 = add i64 %add.i.8.i211, %49
  %arrayidx5.i.8.i214 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i213, i64* %arrayidx5.i.8.i214, align 16, !tbaa !3
  %50 = xor i64 %add.i.8.i211, -9223372036854775808
  %xor2.i.i.8.i215 = and i64 %50, %49
  %xor.i23.i.8.i216 = xor i64 %add3.i.8.i213, %add.i.8.i211
  %xor1.i24.i.8.i217 = xor i64 %add.i.8.i211, %49
  %or.i25.i.8.i218 = or i64 %xor.i23.i.8.i216, %xor1.i24.i.8.i217
  %xor2.i26.i.8.i219 = xor i64 %or.i25.i.8.i218, %add3.i.8.i213
  %shr.i30.i.8.i220 = or i64 %xor2.i26.i.8.i219, %xor2.i.i.8.i215
  %or29.i.8.i221 = lshr i64 %shr.i30.i.8.i220, 63
  %51 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor = shl i64 %51, 1
  %add3.i.9.i225 = or i64 %or29.i.8.i221, %factor
  %arrayidx5.i.9.i226 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i225, i64* %arrayidx5.i.9.i226, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i48) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i50, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i50) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @fp2mul610_mont([10 x i64]* %jinv, [10 x i64]* nonnull %arraydecay, [10 x i64]* %jinv)
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %2) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %52 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %53 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i227 = add i64 %53, %52
  store i64 %add3.i.i227, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i228 = xor i64 %add3.i.i227, %52
  %xor1.i24.i.i229 = xor i64 %53, %52
  %or.i25.i.i230 = or i64 %xor.i23.i.i228, %xor1.i24.i.i229
  %xor2.i26.i.i231 = xor i64 %or.i25.i.i230, %add3.i.i227
  %or29.i.i232 = lshr i64 %xor2.i26.i.i231, 63
  %arrayidx.i.1.i233 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %54 = load i64, i64* %arrayidx.i.1.i233, align 8, !tbaa !3
  %add.i.1.i234 = add i64 %or29.i.i232, %54
  %arrayidx2.i.1.i235 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %55 = load i64, i64* %arrayidx2.i.1.i235, align 8, !tbaa !3
  %add3.i.1.i236 = add i64 %add.i.1.i234, %55
  store i64 %add3.i.1.i236, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %56 = xor i64 %add.i.1.i234, -9223372036854775808
  %xor2.i.i.1.i238 = and i64 %56, %54
  %xor.i23.i.1.i239 = xor i64 %add3.i.1.i236, %add.i.1.i234
  %xor1.i24.i.1.i240 = xor i64 %add.i.1.i234, %55
  %or.i25.i.1.i241 = or i64 %xor.i23.i.1.i239, %xor1.i24.i.1.i240
  %xor2.i26.i.1.i242 = xor i64 %or.i25.i.1.i241, %add3.i.1.i236
  %shr.i30.i.1.i243 = or i64 %xor2.i26.i.1.i242, %xor2.i.i.1.i238
  %or29.i.1.i244 = lshr i64 %shr.i30.i.1.i243, 63
  %arrayidx.i.2.i245 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %57 = load i64, i64* %arrayidx.i.2.i245, align 16, !tbaa !3
  %add.i.2.i246 = add i64 %or29.i.1.i244, %57
  %arrayidx2.i.2.i247 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %58 = load i64, i64* %arrayidx2.i.2.i247, align 16, !tbaa !3
  %add3.i.2.i248 = add i64 %add.i.2.i246, %58
  store i64 %add3.i.2.i248, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %59 = xor i64 %add.i.2.i246, -9223372036854775808
  %xor2.i.i.2.i250 = and i64 %59, %57
  %xor.i23.i.2.i251 = xor i64 %add3.i.2.i248, %add.i.2.i246
  %xor1.i24.i.2.i252 = xor i64 %add.i.2.i246, %58
  %or.i25.i.2.i253 = or i64 %xor.i23.i.2.i251, %xor1.i24.i.2.i252
  %xor2.i26.i.2.i254 = xor i64 %or.i25.i.2.i253, %add3.i.2.i248
  %shr.i30.i.2.i255 = or i64 %xor2.i26.i.2.i254, %xor2.i.i.2.i250
  %or29.i.2.i256 = lshr i64 %shr.i30.i.2.i255, 63
  %arrayidx.i.3.i257 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %60 = load i64, i64* %arrayidx.i.3.i257, align 8, !tbaa !3
  %add.i.3.i258 = add i64 %or29.i.2.i256, %60
  %arrayidx2.i.3.i259 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %61 = load i64, i64* %arrayidx2.i.3.i259, align 8, !tbaa !3
  %add3.i.3.i260 = add i64 %add.i.3.i258, %61
  store i64 %add3.i.3.i260, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %62 = xor i64 %add.i.3.i258, -9223372036854775808
  %xor2.i.i.3.i262 = and i64 %62, %60
  %xor.i23.i.3.i263 = xor i64 %add3.i.3.i260, %add.i.3.i258
  %xor1.i24.i.3.i264 = xor i64 %add.i.3.i258, %61
  %or.i25.i.3.i265 = or i64 %xor.i23.i.3.i263, %xor1.i24.i.3.i264
  %xor2.i26.i.3.i266 = xor i64 %or.i25.i.3.i265, %add3.i.3.i260
  %shr.i30.i.3.i267 = or i64 %xor2.i26.i.3.i266, %xor2.i.i.3.i262
  %or29.i.3.i268 = lshr i64 %shr.i30.i.3.i267, 63
  %arrayidx.i.4.i269 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %63 = load i64, i64* %arrayidx.i.4.i269, align 16, !tbaa !3
  %add.i.4.i270 = add i64 %or29.i.3.i268, %63
  %arrayidx2.i.4.i271 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %64 = load i64, i64* %arrayidx2.i.4.i271, align 16, !tbaa !3
  %add3.i.4.i272 = add i64 %add.i.4.i270, %64
  store i64 %add3.i.4.i272, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %65 = xor i64 %add.i.4.i270, -9223372036854775808
  %xor2.i.i.4.i274 = and i64 %65, %63
  %xor.i23.i.4.i275 = xor i64 %add3.i.4.i272, %add.i.4.i270
  %xor1.i24.i.4.i276 = xor i64 %add.i.4.i270, %64
  %or.i25.i.4.i277 = or i64 %xor.i23.i.4.i275, %xor1.i24.i.4.i276
  %xor2.i26.i.4.i278 = xor i64 %or.i25.i.4.i277, %add3.i.4.i272
  %shr.i30.i.4.i279 = or i64 %xor2.i26.i.4.i278, %xor2.i.i.4.i274
  %or29.i.4.i280 = lshr i64 %shr.i30.i.4.i279, 63
  %arrayidx.i.5.i281 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %66 = load i64, i64* %arrayidx.i.5.i281, align 8, !tbaa !3
  %add.i.5.i282 = add i64 %or29.i.4.i280, %66
  %arrayidx2.i.5.i283 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %67 = load i64, i64* %arrayidx2.i.5.i283, align 8, !tbaa !3
  %add3.i.5.i284 = add i64 %add.i.5.i282, %67
  store i64 %add3.i.5.i284, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %68 = xor i64 %add.i.5.i282, -9223372036854775808
  %xor2.i.i.5.i286 = and i64 %68, %66
  %xor.i23.i.5.i287 = xor i64 %add3.i.5.i284, %add.i.5.i282
  %xor1.i24.i.5.i288 = xor i64 %add.i.5.i282, %67
  %or.i25.i.5.i289 = or i64 %xor.i23.i.5.i287, %xor1.i24.i.5.i288
  %xor2.i26.i.5.i290 = xor i64 %or.i25.i.5.i289, %add3.i.5.i284
  %shr.i30.i.5.i291 = or i64 %xor2.i26.i.5.i290, %xor2.i.i.5.i286
  %or29.i.5.i292 = lshr i64 %shr.i30.i.5.i291, 63
  %arrayidx.i.6.i293 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %69 = load i64, i64* %arrayidx.i.6.i293, align 16, !tbaa !3
  %add.i.6.i294 = add i64 %or29.i.5.i292, %69
  %arrayidx2.i.6.i295 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %70 = load i64, i64* %arrayidx2.i.6.i295, align 16, !tbaa !3
  %add3.i.6.i296 = add i64 %add.i.6.i294, %70
  store i64 %add3.i.6.i296, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %71 = xor i64 %add.i.6.i294, -9223372036854775808
  %xor2.i.i.6.i298 = and i64 %71, %69
  %xor.i23.i.6.i299 = xor i64 %add3.i.6.i296, %add.i.6.i294
  %xor1.i24.i.6.i300 = xor i64 %add.i.6.i294, %70
  %or.i25.i.6.i301 = or i64 %xor.i23.i.6.i299, %xor1.i24.i.6.i300
  %xor2.i26.i.6.i302 = xor i64 %or.i25.i.6.i301, %add3.i.6.i296
  %shr.i30.i.6.i303 = or i64 %xor2.i26.i.6.i302, %xor2.i.i.6.i298
  %or29.i.6.i304 = lshr i64 %shr.i30.i.6.i303, 63
  %arrayidx.i.7.i305 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %72 = load i64, i64* %arrayidx.i.7.i305, align 8, !tbaa !3
  %add.i.7.i306 = add i64 %or29.i.6.i304, %72
  %arrayidx2.i.7.i307 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %73 = load i64, i64* %arrayidx2.i.7.i307, align 8, !tbaa !3
  %add3.i.7.i308 = add i64 %add.i.7.i306, %73
  store i64 %add3.i.7.i308, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %74 = xor i64 %add.i.7.i306, -9223372036854775808
  %xor2.i.i.7.i310 = and i64 %74, %72
  %xor.i23.i.7.i311 = xor i64 %add3.i.7.i308, %add.i.7.i306
  %xor1.i24.i.7.i312 = xor i64 %add.i.7.i306, %73
  %or.i25.i.7.i313 = or i64 %xor.i23.i.7.i311, %xor1.i24.i.7.i312
  %xor2.i26.i.7.i314 = xor i64 %or.i25.i.7.i313, %add3.i.7.i308
  %shr.i30.i.7.i315 = or i64 %xor2.i26.i.7.i314, %xor2.i.i.7.i310
  %or29.i.7.i316 = lshr i64 %shr.i30.i.7.i315, 63
  %arrayidx.i.8.i317 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %75 = load i64, i64* %arrayidx.i.8.i317, align 16, !tbaa !3
  %add.i.8.i318 = add i64 %or29.i.7.i316, %75
  %arrayidx2.i.8.i319 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %76 = load i64, i64* %arrayidx2.i.8.i319, align 16, !tbaa !3
  %add3.i.8.i320 = add i64 %add.i.8.i318, %76
  store i64 %add3.i.8.i320, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %77 = xor i64 %add.i.8.i318, -9223372036854775808
  %xor2.i.i.8.i322 = and i64 %77, %75
  %xor.i23.i.8.i323 = xor i64 %add3.i.8.i320, %add.i.8.i318
  %xor1.i24.i.8.i324 = xor i64 %add.i.8.i318, %76
  %or.i25.i.8.i325 = or i64 %xor.i23.i.8.i323, %xor1.i24.i.8.i324
  %xor2.i26.i.8.i326 = xor i64 %or.i25.i.8.i325, %add3.i.8.i320
  %shr.i30.i.8.i327 = or i64 %xor2.i26.i.8.i326, %xor2.i.i.8.i322
  %or29.i.8.i328 = lshr i64 %shr.i30.i.8.i327, 63
  %arrayidx.i.9.i329 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %78 = load i64, i64* %arrayidx.i.9.i329, align 8, !tbaa !3
  %arrayidx2.i.9.i331 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %79 = load i64, i64* %arrayidx2.i.9.i331, align 8, !tbaa !3
  %add.i.9.i330 = add i64 %79, %78
  %add3.i.9.i332 = add i64 %add.i.9.i330, %or29.i.8.i328
  store i64 %add3.i.9.i332, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i) #10
  %80 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i334 = shl i64 %80, 1
  store i64 %add3.i.i334, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i339 = lshr i64 %80, 63
  %81 = load i64, i64* %arrayidx.i.1.i233, align 8, !tbaa !3
  %add.i.1.i341 = add i64 %81, %or29.i.i339
  %add3.i.1.i343 = add i64 %add.i.1.i341, %81
  store i64 %add3.i.1.i343, i64* %arrayidx5.i.1.i130, align 8, !tbaa !3
  %82 = xor i64 %add.i.1.i341, -9223372036854775808
  %xor2.i.i.1.i345 = and i64 %82, %81
  %xor.i23.i.1.i346 = xor i64 %add3.i.1.i343, %add.i.1.i341
  %xor1.i24.i.1.i347 = xor i64 %add.i.1.i341, %81
  %or.i25.i.1.i348 = or i64 %xor.i23.i.1.i346, %xor1.i24.i.1.i347
  %xor2.i26.i.1.i349 = xor i64 %or.i25.i.1.i348, %add3.i.1.i343
  %shr.i30.i.1.i350 = or i64 %xor2.i26.i.1.i349, %xor2.i.i.1.i345
  %or29.i.1.i351 = lshr i64 %shr.i30.i.1.i350, 63
  %83 = load i64, i64* %arrayidx.i.2.i245, align 16, !tbaa !3
  %add.i.2.i353 = add i64 %or29.i.1.i351, %83
  %add3.i.2.i355 = add i64 %add.i.2.i353, %83
  store i64 %add3.i.2.i355, i64* %arrayidx5.i.2.i142, align 16, !tbaa !3
  %84 = xor i64 %add.i.2.i353, -9223372036854775808
  %xor2.i.i.2.i357 = and i64 %84, %83
  %xor.i23.i.2.i358 = xor i64 %add3.i.2.i355, %add.i.2.i353
  %xor1.i24.i.2.i359 = xor i64 %add.i.2.i353, %83
  %or.i25.i.2.i360 = or i64 %xor.i23.i.2.i358, %xor1.i24.i.2.i359
  %xor2.i26.i.2.i361 = xor i64 %or.i25.i.2.i360, %add3.i.2.i355
  %shr.i30.i.2.i362 = or i64 %xor2.i26.i.2.i361, %xor2.i.i.2.i357
  %or29.i.2.i363 = lshr i64 %shr.i30.i.2.i362, 63
  %85 = load i64, i64* %arrayidx.i.3.i257, align 8, !tbaa !3
  %add.i.3.i365 = add i64 %or29.i.2.i363, %85
  %add3.i.3.i367 = add i64 %add.i.3.i365, %85
  store i64 %add3.i.3.i367, i64* %arrayidx5.i.3.i154, align 8, !tbaa !3
  %86 = xor i64 %add.i.3.i365, -9223372036854775808
  %xor2.i.i.3.i369 = and i64 %86, %85
  %xor.i23.i.3.i370 = xor i64 %add3.i.3.i367, %add.i.3.i365
  %xor1.i24.i.3.i371 = xor i64 %add.i.3.i365, %85
  %or.i25.i.3.i372 = or i64 %xor.i23.i.3.i370, %xor1.i24.i.3.i371
  %xor2.i26.i.3.i373 = xor i64 %or.i25.i.3.i372, %add3.i.3.i367
  %shr.i30.i.3.i374 = or i64 %xor2.i26.i.3.i373, %xor2.i.i.3.i369
  %or29.i.3.i375 = lshr i64 %shr.i30.i.3.i374, 63
  %87 = load i64, i64* %arrayidx.i.4.i269, align 16, !tbaa !3
  %add.i.4.i377 = add i64 %or29.i.3.i375, %87
  %add3.i.4.i379 = add i64 %add.i.4.i377, %87
  store i64 %add3.i.4.i379, i64* %arrayidx5.i.4.i166, align 16, !tbaa !3
  %88 = xor i64 %add.i.4.i377, -9223372036854775808
  %xor2.i.i.4.i381 = and i64 %88, %87
  %xor.i23.i.4.i382 = xor i64 %add3.i.4.i379, %add.i.4.i377
  %xor1.i24.i.4.i383 = xor i64 %add.i.4.i377, %87
  %or.i25.i.4.i384 = or i64 %xor.i23.i.4.i382, %xor1.i24.i.4.i383
  %xor2.i26.i.4.i385 = xor i64 %or.i25.i.4.i384, %add3.i.4.i379
  %shr.i30.i.4.i386 = or i64 %xor2.i26.i.4.i385, %xor2.i.i.4.i381
  %or29.i.4.i387 = lshr i64 %shr.i30.i.4.i386, 63
  %89 = load i64, i64* %arrayidx.i.5.i281, align 8, !tbaa !3
  %add.i.5.i389 = add i64 %or29.i.4.i387, %89
  %add3.i.5.i391 = add i64 %add.i.5.i389, %89
  store i64 %add3.i.5.i391, i64* %arrayidx5.i.5.i178, align 8, !tbaa !3
  %90 = xor i64 %add.i.5.i389, -9223372036854775808
  %xor2.i.i.5.i393 = and i64 %90, %89
  %xor.i23.i.5.i394 = xor i64 %add3.i.5.i391, %add.i.5.i389
  %xor1.i24.i.5.i395 = xor i64 %add.i.5.i389, %89
  %or.i25.i.5.i396 = or i64 %xor.i23.i.5.i394, %xor1.i24.i.5.i395
  %xor2.i26.i.5.i397 = xor i64 %or.i25.i.5.i396, %add3.i.5.i391
  %shr.i30.i.5.i398 = or i64 %xor2.i26.i.5.i397, %xor2.i.i.5.i393
  %or29.i.5.i399 = lshr i64 %shr.i30.i.5.i398, 63
  %91 = load i64, i64* %arrayidx.i.6.i293, align 16, !tbaa !3
  %add.i.6.i401 = add i64 %or29.i.5.i399, %91
  %add3.i.6.i403 = add i64 %add.i.6.i401, %91
  store i64 %add3.i.6.i403, i64* %arrayidx5.i.6.i190, align 16, !tbaa !3
  %92 = xor i64 %add.i.6.i401, -9223372036854775808
  %xor2.i.i.6.i405 = and i64 %92, %91
  %xor.i23.i.6.i406 = xor i64 %add3.i.6.i403, %add.i.6.i401
  %xor1.i24.i.6.i407 = xor i64 %add.i.6.i401, %91
  %or.i25.i.6.i408 = or i64 %xor.i23.i.6.i406, %xor1.i24.i.6.i407
  %xor2.i26.i.6.i409 = xor i64 %or.i25.i.6.i408, %add3.i.6.i403
  %shr.i30.i.6.i410 = or i64 %xor2.i26.i.6.i409, %xor2.i.i.6.i405
  %or29.i.6.i411 = lshr i64 %shr.i30.i.6.i410, 63
  %93 = load i64, i64* %arrayidx.i.7.i305, align 8, !tbaa !3
  %add.i.7.i413 = add i64 %or29.i.6.i411, %93
  %add3.i.7.i415 = add i64 %add.i.7.i413, %93
  store i64 %add3.i.7.i415, i64* %arrayidx5.i.7.i202, align 8, !tbaa !3
  %94 = xor i64 %add.i.7.i413, -9223372036854775808
  %xor2.i.i.7.i417 = and i64 %94, %93
  %xor.i23.i.7.i418 = xor i64 %add3.i.7.i415, %add.i.7.i413
  %xor1.i24.i.7.i419 = xor i64 %add.i.7.i413, %93
  %or.i25.i.7.i420 = or i64 %xor.i23.i.7.i418, %xor1.i24.i.7.i419
  %xor2.i26.i.7.i421 = xor i64 %or.i25.i.7.i420, %add3.i.7.i415
  %shr.i30.i.7.i422 = or i64 %xor2.i26.i.7.i421, %xor2.i.i.7.i417
  %or29.i.7.i423 = lshr i64 %shr.i30.i.7.i422, 63
  %95 = load i64, i64* %arrayidx.i.8.i317, align 16, !tbaa !3
  %add.i.8.i425 = add i64 %or29.i.7.i423, %95
  %add3.i.8.i427 = add i64 %add.i.8.i425, %95
  store i64 %add3.i.8.i427, i64* %arrayidx5.i.8.i214, align 16, !tbaa !3
  %96 = xor i64 %add.i.8.i425, -9223372036854775808
  %xor2.i.i.8.i429 = and i64 %96, %95
  %xor.i23.i.8.i430 = xor i64 %add3.i.8.i427, %add.i.8.i425
  %xor1.i24.i.8.i431 = xor i64 %add.i.8.i425, %95
  %or.i25.i.8.i432 = or i64 %xor.i23.i.8.i430, %xor1.i24.i.8.i431
  %xor2.i26.i.8.i433 = xor i64 %or.i25.i.8.i432, %add3.i.8.i427
  %shr.i30.i.8.i434 = or i64 %xor2.i26.i.8.i433, %xor2.i.i.8.i429
  %or29.i.8.i435 = lshr i64 %shr.i30.i.8.i434, 63
  %97 = load i64, i64* %arrayidx.i.9.i329, align 8, !tbaa !3
  %factor441 = shl i64 %97, 1
  %add3.i.9.i439 = or i64 %or29.i.8.i435, %factor441
  store i64 %add3.i.9.i439, i64* %arrayidx5.i.9.i226, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i48) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i50) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %2) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay3, [10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay3)
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  call void @fp2inv610_mont([10 x i64]* %jinv)
  call void @fp2mul610_mont([10 x i64]* %jinv, [10 x i64]* nonnull %arraydecay3, [10 x i64]* %jinv)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xDBLADD(%struct.point_proj* %P, %struct.point_proj* %Q, [10 x i64]* %XPQ, [10 x i64]* %ZPQ, [10 x i64]* %A24) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t0 = alloca [2 x [10 x i64]], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %arraydecay = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0
  %arraydecay1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay1, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i) #10
  %arraydecay6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %arraydecay4.i114 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i114) #10
  %arraydecay10.i117 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i117) #10
  %3 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  %4 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %5 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  %6 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %7 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i300 = add i64 %7, %6
  store i64 %add3.i.i300, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i301 = xor i64 %add3.i.i300, %6
  %xor1.i24.i.i302 = xor i64 %7, %6
  %or.i25.i.i303 = or i64 %xor.i23.i.i301, %xor1.i24.i.i302
  %xor2.i26.i.i304 = xor i64 %or.i25.i.i303, %add3.i.i300
  %or29.i.i305 = lshr i64 %xor2.i26.i.i304, 63
  %arrayidx.i.1.i306 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 1
  %8 = load i64, i64* %arrayidx.i.1.i306, align 8, !tbaa !3
  %add.i.1.i307 = add i64 %or29.i.i305, %8
  %arrayidx2.i.1.i308 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 1
  %9 = load i64, i64* %arrayidx2.i.1.i308, align 8, !tbaa !3
  %add3.i.1.i309 = add i64 %add.i.1.i307, %9
  %arrayidx5.i.1.i310 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i309, i64* %arrayidx5.i.1.i310, align 8, !tbaa !3
  %10 = xor i64 %add.i.1.i307, -9223372036854775808
  %xor2.i.i.1.i311 = and i64 %10, %8
  %xor.i23.i.1.i312 = xor i64 %add3.i.1.i309, %add.i.1.i307
  %xor1.i24.i.1.i313 = xor i64 %add.i.1.i307, %9
  %or.i25.i.1.i314 = or i64 %xor.i23.i.1.i312, %xor1.i24.i.1.i313
  %xor2.i26.i.1.i315 = xor i64 %or.i25.i.1.i314, %add3.i.1.i309
  %shr.i30.i.1.i316 = or i64 %xor2.i26.i.1.i315, %xor2.i.i.1.i311
  %or29.i.1.i317 = lshr i64 %shr.i30.i.1.i316, 63
  %arrayidx.i.2.i318 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 2
  %11 = load i64, i64* %arrayidx.i.2.i318, align 16, !tbaa !3
  %add.i.2.i319 = add i64 %or29.i.1.i317, %11
  %arrayidx2.i.2.i320 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 2
  %12 = load i64, i64* %arrayidx2.i.2.i320, align 16, !tbaa !3
  %add3.i.2.i321 = add i64 %add.i.2.i319, %12
  %arrayidx5.i.2.i322 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i321, i64* %arrayidx5.i.2.i322, align 16, !tbaa !3
  %13 = xor i64 %add.i.2.i319, -9223372036854775808
  %xor2.i.i.2.i323 = and i64 %13, %11
  %xor.i23.i.2.i324 = xor i64 %add3.i.2.i321, %add.i.2.i319
  %xor1.i24.i.2.i325 = xor i64 %add.i.2.i319, %12
  %or.i25.i.2.i326 = or i64 %xor.i23.i.2.i324, %xor1.i24.i.2.i325
  %xor2.i26.i.2.i327 = xor i64 %or.i25.i.2.i326, %add3.i.2.i321
  %shr.i30.i.2.i328 = or i64 %xor2.i26.i.2.i327, %xor2.i.i.2.i323
  %or29.i.2.i329 = lshr i64 %shr.i30.i.2.i328, 63
  %arrayidx.i.3.i330 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 3
  %14 = load i64, i64* %arrayidx.i.3.i330, align 8, !tbaa !3
  %add.i.3.i331 = add i64 %or29.i.2.i329, %14
  %arrayidx2.i.3.i332 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 3
  %15 = load i64, i64* %arrayidx2.i.3.i332, align 8, !tbaa !3
  %add3.i.3.i333 = add i64 %add.i.3.i331, %15
  %arrayidx5.i.3.i334 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i333, i64* %arrayidx5.i.3.i334, align 8, !tbaa !3
  %16 = xor i64 %add.i.3.i331, -9223372036854775808
  %xor2.i.i.3.i335 = and i64 %16, %14
  %xor.i23.i.3.i336 = xor i64 %add3.i.3.i333, %add.i.3.i331
  %xor1.i24.i.3.i337 = xor i64 %add.i.3.i331, %15
  %or.i25.i.3.i338 = or i64 %xor.i23.i.3.i336, %xor1.i24.i.3.i337
  %xor2.i26.i.3.i339 = xor i64 %or.i25.i.3.i338, %add3.i.3.i333
  %shr.i30.i.3.i340 = or i64 %xor2.i26.i.3.i339, %xor2.i.i.3.i335
  %or29.i.3.i341 = lshr i64 %shr.i30.i.3.i340, 63
  %arrayidx.i.4.i342 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 4
  %17 = load i64, i64* %arrayidx.i.4.i342, align 16, !tbaa !3
  %add.i.4.i343 = add i64 %or29.i.3.i341, %17
  %arrayidx2.i.4.i344 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 4
  %18 = load i64, i64* %arrayidx2.i.4.i344, align 16, !tbaa !3
  %add3.i.4.i345 = add i64 %add.i.4.i343, %18
  %arrayidx5.i.4.i346 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i345, i64* %arrayidx5.i.4.i346, align 16, !tbaa !3
  %19 = xor i64 %add.i.4.i343, -9223372036854775808
  %xor2.i.i.4.i347 = and i64 %19, %17
  %xor.i23.i.4.i348 = xor i64 %add3.i.4.i345, %add.i.4.i343
  %xor1.i24.i.4.i349 = xor i64 %add.i.4.i343, %18
  %or.i25.i.4.i350 = or i64 %xor.i23.i.4.i348, %xor1.i24.i.4.i349
  %xor2.i26.i.4.i351 = xor i64 %or.i25.i.4.i350, %add3.i.4.i345
  %shr.i30.i.4.i352 = or i64 %xor2.i26.i.4.i351, %xor2.i.i.4.i347
  %or29.i.4.i353 = lshr i64 %shr.i30.i.4.i352, 63
  %arrayidx.i.5.i354 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 5
  %20 = load i64, i64* %arrayidx.i.5.i354, align 8, !tbaa !3
  %add.i.5.i355 = add i64 %or29.i.4.i353, %20
  %arrayidx2.i.5.i356 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 5
  %21 = load i64, i64* %arrayidx2.i.5.i356, align 8, !tbaa !3
  %add3.i.5.i357 = add i64 %add.i.5.i355, %21
  %arrayidx5.i.5.i358 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i357, i64* %arrayidx5.i.5.i358, align 8, !tbaa !3
  %22 = xor i64 %add.i.5.i355, -9223372036854775808
  %xor2.i.i.5.i359 = and i64 %22, %20
  %xor.i23.i.5.i360 = xor i64 %add3.i.5.i357, %add.i.5.i355
  %xor1.i24.i.5.i361 = xor i64 %add.i.5.i355, %21
  %or.i25.i.5.i362 = or i64 %xor.i23.i.5.i360, %xor1.i24.i.5.i361
  %xor2.i26.i.5.i363 = xor i64 %or.i25.i.5.i362, %add3.i.5.i357
  %shr.i30.i.5.i364 = or i64 %xor2.i26.i.5.i363, %xor2.i.i.5.i359
  %or29.i.5.i365 = lshr i64 %shr.i30.i.5.i364, 63
  %arrayidx.i.6.i366 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 6
  %23 = load i64, i64* %arrayidx.i.6.i366, align 16, !tbaa !3
  %add.i.6.i367 = add i64 %or29.i.5.i365, %23
  %arrayidx2.i.6.i368 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 6
  %24 = load i64, i64* %arrayidx2.i.6.i368, align 16, !tbaa !3
  %add3.i.6.i369 = add i64 %add.i.6.i367, %24
  %arrayidx5.i.6.i370 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i369, i64* %arrayidx5.i.6.i370, align 16, !tbaa !3
  %25 = xor i64 %add.i.6.i367, -9223372036854775808
  %xor2.i.i.6.i371 = and i64 %25, %23
  %xor.i23.i.6.i372 = xor i64 %add3.i.6.i369, %add.i.6.i367
  %xor1.i24.i.6.i373 = xor i64 %add.i.6.i367, %24
  %or.i25.i.6.i374 = or i64 %xor.i23.i.6.i372, %xor1.i24.i.6.i373
  %xor2.i26.i.6.i375 = xor i64 %or.i25.i.6.i374, %add3.i.6.i369
  %shr.i30.i.6.i376 = or i64 %xor2.i26.i.6.i375, %xor2.i.i.6.i371
  %or29.i.6.i377 = lshr i64 %shr.i30.i.6.i376, 63
  %arrayidx.i.7.i378 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 7
  %26 = load i64, i64* %arrayidx.i.7.i378, align 8, !tbaa !3
  %add.i.7.i379 = add i64 %or29.i.6.i377, %26
  %arrayidx2.i.7.i380 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 7
  %27 = load i64, i64* %arrayidx2.i.7.i380, align 8, !tbaa !3
  %add3.i.7.i381 = add i64 %add.i.7.i379, %27
  %arrayidx5.i.7.i382 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i381, i64* %arrayidx5.i.7.i382, align 8, !tbaa !3
  %28 = xor i64 %add.i.7.i379, -9223372036854775808
  %xor2.i.i.7.i383 = and i64 %28, %26
  %xor.i23.i.7.i384 = xor i64 %add3.i.7.i381, %add.i.7.i379
  %xor1.i24.i.7.i385 = xor i64 %add.i.7.i379, %27
  %or.i25.i.7.i386 = or i64 %xor.i23.i.7.i384, %xor1.i24.i.7.i385
  %xor2.i26.i.7.i387 = xor i64 %or.i25.i.7.i386, %add3.i.7.i381
  %shr.i30.i.7.i388 = or i64 %xor2.i26.i.7.i387, %xor2.i.i.7.i383
  %or29.i.7.i389 = lshr i64 %shr.i30.i.7.i388, 63
  %arrayidx.i.8.i390 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 8
  %29 = load i64, i64* %arrayidx.i.8.i390, align 16, !tbaa !3
  %add.i.8.i391 = add i64 %or29.i.7.i389, %29
  %arrayidx2.i.8.i392 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 8
  %30 = load i64, i64* %arrayidx2.i.8.i392, align 16, !tbaa !3
  %add3.i.8.i393 = add i64 %add.i.8.i391, %30
  %arrayidx5.i.8.i394 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i393, i64* %arrayidx5.i.8.i394, align 16, !tbaa !3
  %31 = xor i64 %add.i.8.i391, -9223372036854775808
  %xor2.i.i.8.i395 = and i64 %31, %29
  %xor.i23.i.8.i396 = xor i64 %add3.i.8.i393, %add.i.8.i391
  %xor1.i24.i.8.i397 = xor i64 %add.i.8.i391, %30
  %or.i25.i.8.i398 = or i64 %xor.i23.i.8.i396, %xor1.i24.i.8.i397
  %xor2.i26.i.8.i399 = xor i64 %or.i25.i.8.i398, %add3.i.8.i393
  %shr.i30.i.8.i400 = or i64 %xor2.i26.i.8.i399, %xor2.i.i.8.i395
  %or29.i.8.i401 = lshr i64 %shr.i30.i.8.i400, 63
  %arrayidx.i.9.i402 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 0, i64 9
  %32 = load i64, i64* %arrayidx.i.9.i402, align 8, !tbaa !3
  %arrayidx2.i.9.i404 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t0, i64 0, i64 1, i64 9
  %33 = load i64, i64* %arrayidx2.i.9.i404, align 8, !tbaa !3
  %add.i.9.i403 = add i64 %33, %32
  %add3.i.9.i405 = add i64 %add.i.9.i403, %or29.i.8.i401
  %arrayidx5.i.9.i406 = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i405, i64* %arrayidx5.i.9.i406, align 8, !tbaa !3
  %arraydecay8.i120 = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i120) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  %34 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i407 = shl i64 %34, 1
  store i64 %add3.i.i407, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i412 = lshr i64 %34, 63
  %35 = load i64, i64* %arrayidx.i.1.i306, align 8, !tbaa !3
  %add.i.1.i414 = add i64 %35, %or29.i.i412
  %add3.i.1.i416 = add i64 %add.i.1.i414, %35
  %arrayidx5.i.1.i417 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i416, i64* %arrayidx5.i.1.i417, align 8, !tbaa !3
  %36 = xor i64 %add.i.1.i414, -9223372036854775808
  %xor2.i.i.1.i418 = and i64 %36, %35
  %xor.i23.i.1.i419 = xor i64 %add3.i.1.i416, %add.i.1.i414
  %xor1.i24.i.1.i420 = xor i64 %add.i.1.i414, %35
  %or.i25.i.1.i421 = or i64 %xor.i23.i.1.i419, %xor1.i24.i.1.i420
  %xor2.i26.i.1.i422 = xor i64 %or.i25.i.1.i421, %add3.i.1.i416
  %shr.i30.i.1.i423 = or i64 %xor2.i26.i.1.i422, %xor2.i.i.1.i418
  %or29.i.1.i424 = lshr i64 %shr.i30.i.1.i423, 63
  %37 = load i64, i64* %arrayidx.i.2.i318, align 16, !tbaa !3
  %add.i.2.i426 = add i64 %or29.i.1.i424, %37
  %add3.i.2.i428 = add i64 %add.i.2.i426, %37
  %arrayidx5.i.2.i429 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i428, i64* %arrayidx5.i.2.i429, align 16, !tbaa !3
  %38 = xor i64 %add.i.2.i426, -9223372036854775808
  %xor2.i.i.2.i430 = and i64 %38, %37
  %xor.i23.i.2.i431 = xor i64 %add3.i.2.i428, %add.i.2.i426
  %xor1.i24.i.2.i432 = xor i64 %add.i.2.i426, %37
  %or.i25.i.2.i433 = or i64 %xor.i23.i.2.i431, %xor1.i24.i.2.i432
  %xor2.i26.i.2.i434 = xor i64 %or.i25.i.2.i433, %add3.i.2.i428
  %shr.i30.i.2.i435 = or i64 %xor2.i26.i.2.i434, %xor2.i.i.2.i430
  %or29.i.2.i436 = lshr i64 %shr.i30.i.2.i435, 63
  %39 = load i64, i64* %arrayidx.i.3.i330, align 8, !tbaa !3
  %add.i.3.i438 = add i64 %or29.i.2.i436, %39
  %add3.i.3.i440 = add i64 %add.i.3.i438, %39
  %arrayidx5.i.3.i441 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i440, i64* %arrayidx5.i.3.i441, align 8, !tbaa !3
  %40 = xor i64 %add.i.3.i438, -9223372036854775808
  %xor2.i.i.3.i442 = and i64 %40, %39
  %xor.i23.i.3.i443 = xor i64 %add3.i.3.i440, %add.i.3.i438
  %xor1.i24.i.3.i444 = xor i64 %add.i.3.i438, %39
  %or.i25.i.3.i445 = or i64 %xor.i23.i.3.i443, %xor1.i24.i.3.i444
  %xor2.i26.i.3.i446 = xor i64 %or.i25.i.3.i445, %add3.i.3.i440
  %shr.i30.i.3.i447 = or i64 %xor2.i26.i.3.i446, %xor2.i.i.3.i442
  %or29.i.3.i448 = lshr i64 %shr.i30.i.3.i447, 63
  %41 = load i64, i64* %arrayidx.i.4.i342, align 16, !tbaa !3
  %add.i.4.i450 = add i64 %or29.i.3.i448, %41
  %add3.i.4.i452 = add i64 %add.i.4.i450, %41
  %arrayidx5.i.4.i453 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i452, i64* %arrayidx5.i.4.i453, align 16, !tbaa !3
  %42 = xor i64 %add.i.4.i450, -9223372036854775808
  %xor2.i.i.4.i454 = and i64 %42, %41
  %xor.i23.i.4.i455 = xor i64 %add3.i.4.i452, %add.i.4.i450
  %xor1.i24.i.4.i456 = xor i64 %add.i.4.i450, %41
  %or.i25.i.4.i457 = or i64 %xor.i23.i.4.i455, %xor1.i24.i.4.i456
  %xor2.i26.i.4.i458 = xor i64 %or.i25.i.4.i457, %add3.i.4.i452
  %shr.i30.i.4.i459 = or i64 %xor2.i26.i.4.i458, %xor2.i.i.4.i454
  %or29.i.4.i460 = lshr i64 %shr.i30.i.4.i459, 63
  %43 = load i64, i64* %arrayidx.i.5.i354, align 8, !tbaa !3
  %add.i.5.i462 = add i64 %or29.i.4.i460, %43
  %add3.i.5.i464 = add i64 %add.i.5.i462, %43
  %arrayidx5.i.5.i465 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i464, i64* %arrayidx5.i.5.i465, align 8, !tbaa !3
  %44 = xor i64 %add.i.5.i462, -9223372036854775808
  %xor2.i.i.5.i466 = and i64 %44, %43
  %xor.i23.i.5.i467 = xor i64 %add3.i.5.i464, %add.i.5.i462
  %xor1.i24.i.5.i468 = xor i64 %add.i.5.i462, %43
  %or.i25.i.5.i469 = or i64 %xor.i23.i.5.i467, %xor1.i24.i.5.i468
  %xor2.i26.i.5.i470 = xor i64 %or.i25.i.5.i469, %add3.i.5.i464
  %shr.i30.i.5.i471 = or i64 %xor2.i26.i.5.i470, %xor2.i.i.5.i466
  %or29.i.5.i472 = lshr i64 %shr.i30.i.5.i471, 63
  %45 = load i64, i64* %arrayidx.i.6.i366, align 16, !tbaa !3
  %add.i.6.i474 = add i64 %or29.i.5.i472, %45
  %add3.i.6.i476 = add i64 %add.i.6.i474, %45
  %arrayidx5.i.6.i477 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i476, i64* %arrayidx5.i.6.i477, align 16, !tbaa !3
  %46 = xor i64 %add.i.6.i474, -9223372036854775808
  %xor2.i.i.6.i478 = and i64 %46, %45
  %xor.i23.i.6.i479 = xor i64 %add3.i.6.i476, %add.i.6.i474
  %xor1.i24.i.6.i480 = xor i64 %add.i.6.i474, %45
  %or.i25.i.6.i481 = or i64 %xor.i23.i.6.i479, %xor1.i24.i.6.i480
  %xor2.i26.i.6.i482 = xor i64 %or.i25.i.6.i481, %add3.i.6.i476
  %shr.i30.i.6.i483 = or i64 %xor2.i26.i.6.i482, %xor2.i.i.6.i478
  %or29.i.6.i484 = lshr i64 %shr.i30.i.6.i483, 63
  %47 = load i64, i64* %arrayidx.i.7.i378, align 8, !tbaa !3
  %add.i.7.i486 = add i64 %or29.i.6.i484, %47
  %add3.i.7.i488 = add i64 %add.i.7.i486, %47
  %arrayidx5.i.7.i489 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i488, i64* %arrayidx5.i.7.i489, align 8, !tbaa !3
  %48 = xor i64 %add.i.7.i486, -9223372036854775808
  %xor2.i.i.7.i490 = and i64 %48, %47
  %xor.i23.i.7.i491 = xor i64 %add3.i.7.i488, %add.i.7.i486
  %xor1.i24.i.7.i492 = xor i64 %add.i.7.i486, %47
  %or.i25.i.7.i493 = or i64 %xor.i23.i.7.i491, %xor1.i24.i.7.i492
  %xor2.i26.i.7.i494 = xor i64 %or.i25.i.7.i493, %add3.i.7.i488
  %shr.i30.i.7.i495 = or i64 %xor2.i26.i.7.i494, %xor2.i.i.7.i490
  %or29.i.7.i496 = lshr i64 %shr.i30.i.7.i495, 63
  %49 = load i64, i64* %arrayidx.i.8.i390, align 16, !tbaa !3
  %add.i.8.i498 = add i64 %or29.i.7.i496, %49
  %add3.i.8.i500 = add i64 %add.i.8.i498, %49
  %arrayidx5.i.8.i501 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i500, i64* %arrayidx5.i.8.i501, align 16, !tbaa !3
  %50 = xor i64 %add.i.8.i498, -9223372036854775808
  %xor2.i.i.8.i502 = and i64 %50, %49
  %xor.i23.i.8.i503 = xor i64 %add3.i.8.i500, %add.i.8.i498
  %xor1.i24.i.8.i504 = xor i64 %add.i.8.i498, %49
  %or.i25.i.8.i505 = or i64 %xor.i23.i.8.i503, %xor1.i24.i.8.i504
  %xor2.i26.i.8.i506 = xor i64 %or.i25.i.8.i505, %add3.i.8.i500
  %shr.i30.i.8.i507 = or i64 %xor2.i26.i.8.i506, %xor2.i.i.8.i502
  %or29.i.8.i508 = lshr i64 %shr.i30.i.8.i507, 63
  %51 = load i64, i64* %arrayidx.i.9.i402, align 8, !tbaa !3
  %factor = shl i64 %51, 1
  %add3.i.9.i512 = or i64 %or29.i.8.i508, %factor
  %arrayidx5.i.9.i513 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i512, i64* %arrayidx5.i.9.i513, align 8, !tbaa !3
  %52 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i120, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay6.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  %arraydecay12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0
  %arraydecay14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0
  %arraydecay15 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  %arraydecay.i121 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i122 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay14, i64 0, i64 0
  %arraydecay4.i123 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  call void @mp_sub610_p2(i64* %arraydecay.i121, i64* nonnull %arraydecay2.i122, i64* nonnull %arraydecay4.i123) #10
  %arraydecay6.i124 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 0
  %arraydecay8.i125 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 1, i64 0
  %arraydecay10.i126 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay8.i125, i64* nonnull %arraydecay10.i126) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i121, i64* nonnull %arraydecay2.i122, i64* %arraydecay.i121) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay8.i125, i64* nonnull %arraydecay6.i124) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay15, [10 x i64]* nonnull %arraydecay2)
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  %53 = load i64, i64* %arraydecay4.i114, align 16, !tbaa !3
  %54 = load i64, i64* %arraydecay10.i117, align 16, !tbaa !3
  %add3.i.i514 = add i64 %54, %53
  store i64 %add3.i.i514, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i515 = xor i64 %add3.i.i514, %53
  %xor1.i24.i.i516 = xor i64 %54, %53
  %or.i25.i.i517 = or i64 %xor.i23.i.i515, %xor1.i24.i.i516
  %xor2.i26.i.i518 = xor i64 %or.i25.i.i517, %add3.i.i514
  %or29.i.i519 = lshr i64 %xor2.i26.i.i518, 63
  %arrayidx.i.1.i520 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %55 = load i64, i64* %arrayidx.i.1.i520, align 8, !tbaa !3
  %add.i.1.i521 = add i64 %or29.i.i519, %55
  %arrayidx2.i.1.i522 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %56 = load i64, i64* %arrayidx2.i.1.i522, align 8, !tbaa !3
  %add3.i.1.i523 = add i64 %add.i.1.i521, %56
  store i64 %add3.i.1.i523, i64* %arrayidx5.i.1.i310, align 8, !tbaa !3
  %57 = xor i64 %add.i.1.i521, -9223372036854775808
  %xor2.i.i.1.i525 = and i64 %57, %55
  %xor.i23.i.1.i526 = xor i64 %add3.i.1.i523, %add.i.1.i521
  %xor1.i24.i.1.i527 = xor i64 %add.i.1.i521, %56
  %or.i25.i.1.i528 = or i64 %xor.i23.i.1.i526, %xor1.i24.i.1.i527
  %xor2.i26.i.1.i529 = xor i64 %or.i25.i.1.i528, %add3.i.1.i523
  %shr.i30.i.1.i530 = or i64 %xor2.i26.i.1.i529, %xor2.i.i.1.i525
  %or29.i.1.i531 = lshr i64 %shr.i30.i.1.i530, 63
  %arrayidx.i.2.i532 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %58 = load i64, i64* %arrayidx.i.2.i532, align 16, !tbaa !3
  %add.i.2.i533 = add i64 %or29.i.1.i531, %58
  %arrayidx2.i.2.i534 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %59 = load i64, i64* %arrayidx2.i.2.i534, align 16, !tbaa !3
  %add3.i.2.i535 = add i64 %add.i.2.i533, %59
  store i64 %add3.i.2.i535, i64* %arrayidx5.i.2.i322, align 16, !tbaa !3
  %60 = xor i64 %add.i.2.i533, -9223372036854775808
  %xor2.i.i.2.i537 = and i64 %60, %58
  %xor.i23.i.2.i538 = xor i64 %add3.i.2.i535, %add.i.2.i533
  %xor1.i24.i.2.i539 = xor i64 %add.i.2.i533, %59
  %or.i25.i.2.i540 = or i64 %xor.i23.i.2.i538, %xor1.i24.i.2.i539
  %xor2.i26.i.2.i541 = xor i64 %or.i25.i.2.i540, %add3.i.2.i535
  %shr.i30.i.2.i542 = or i64 %xor2.i26.i.2.i541, %xor2.i.i.2.i537
  %or29.i.2.i543 = lshr i64 %shr.i30.i.2.i542, 63
  %arrayidx.i.3.i544 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %61 = load i64, i64* %arrayidx.i.3.i544, align 8, !tbaa !3
  %add.i.3.i545 = add i64 %or29.i.2.i543, %61
  %arrayidx2.i.3.i546 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %62 = load i64, i64* %arrayidx2.i.3.i546, align 8, !tbaa !3
  %add3.i.3.i547 = add i64 %add.i.3.i545, %62
  store i64 %add3.i.3.i547, i64* %arrayidx5.i.3.i334, align 8, !tbaa !3
  %63 = xor i64 %add.i.3.i545, -9223372036854775808
  %xor2.i.i.3.i549 = and i64 %63, %61
  %xor.i23.i.3.i550 = xor i64 %add3.i.3.i547, %add.i.3.i545
  %xor1.i24.i.3.i551 = xor i64 %add.i.3.i545, %62
  %or.i25.i.3.i552 = or i64 %xor.i23.i.3.i550, %xor1.i24.i.3.i551
  %xor2.i26.i.3.i553 = xor i64 %or.i25.i.3.i552, %add3.i.3.i547
  %shr.i30.i.3.i554 = or i64 %xor2.i26.i.3.i553, %xor2.i.i.3.i549
  %or29.i.3.i555 = lshr i64 %shr.i30.i.3.i554, 63
  %arrayidx.i.4.i556 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %64 = load i64, i64* %arrayidx.i.4.i556, align 16, !tbaa !3
  %add.i.4.i557 = add i64 %or29.i.3.i555, %64
  %arrayidx2.i.4.i558 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %65 = load i64, i64* %arrayidx2.i.4.i558, align 16, !tbaa !3
  %add3.i.4.i559 = add i64 %add.i.4.i557, %65
  store i64 %add3.i.4.i559, i64* %arrayidx5.i.4.i346, align 16, !tbaa !3
  %66 = xor i64 %add.i.4.i557, -9223372036854775808
  %xor2.i.i.4.i561 = and i64 %66, %64
  %xor.i23.i.4.i562 = xor i64 %add3.i.4.i559, %add.i.4.i557
  %xor1.i24.i.4.i563 = xor i64 %add.i.4.i557, %65
  %or.i25.i.4.i564 = or i64 %xor.i23.i.4.i562, %xor1.i24.i.4.i563
  %xor2.i26.i.4.i565 = xor i64 %or.i25.i.4.i564, %add3.i.4.i559
  %shr.i30.i.4.i566 = or i64 %xor2.i26.i.4.i565, %xor2.i.i.4.i561
  %or29.i.4.i567 = lshr i64 %shr.i30.i.4.i566, 63
  %arrayidx.i.5.i568 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %67 = load i64, i64* %arrayidx.i.5.i568, align 8, !tbaa !3
  %add.i.5.i569 = add i64 %or29.i.4.i567, %67
  %arrayidx2.i.5.i570 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %68 = load i64, i64* %arrayidx2.i.5.i570, align 8, !tbaa !3
  %add3.i.5.i571 = add i64 %add.i.5.i569, %68
  store i64 %add3.i.5.i571, i64* %arrayidx5.i.5.i358, align 8, !tbaa !3
  %69 = xor i64 %add.i.5.i569, -9223372036854775808
  %xor2.i.i.5.i573 = and i64 %69, %67
  %xor.i23.i.5.i574 = xor i64 %add3.i.5.i571, %add.i.5.i569
  %xor1.i24.i.5.i575 = xor i64 %add.i.5.i569, %68
  %or.i25.i.5.i576 = or i64 %xor.i23.i.5.i574, %xor1.i24.i.5.i575
  %xor2.i26.i.5.i577 = xor i64 %or.i25.i.5.i576, %add3.i.5.i571
  %shr.i30.i.5.i578 = or i64 %xor2.i26.i.5.i577, %xor2.i.i.5.i573
  %or29.i.5.i579 = lshr i64 %shr.i30.i.5.i578, 63
  %arrayidx.i.6.i580 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %70 = load i64, i64* %arrayidx.i.6.i580, align 16, !tbaa !3
  %add.i.6.i581 = add i64 %or29.i.5.i579, %70
  %arrayidx2.i.6.i582 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %71 = load i64, i64* %arrayidx2.i.6.i582, align 16, !tbaa !3
  %add3.i.6.i583 = add i64 %add.i.6.i581, %71
  store i64 %add3.i.6.i583, i64* %arrayidx5.i.6.i370, align 16, !tbaa !3
  %72 = xor i64 %add.i.6.i581, -9223372036854775808
  %xor2.i.i.6.i585 = and i64 %72, %70
  %xor.i23.i.6.i586 = xor i64 %add3.i.6.i583, %add.i.6.i581
  %xor1.i24.i.6.i587 = xor i64 %add.i.6.i581, %71
  %or.i25.i.6.i588 = or i64 %xor.i23.i.6.i586, %xor1.i24.i.6.i587
  %xor2.i26.i.6.i589 = xor i64 %or.i25.i.6.i588, %add3.i.6.i583
  %shr.i30.i.6.i590 = or i64 %xor2.i26.i.6.i589, %xor2.i.i.6.i585
  %or29.i.6.i591 = lshr i64 %shr.i30.i.6.i590, 63
  %arrayidx.i.7.i592 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %73 = load i64, i64* %arrayidx.i.7.i592, align 8, !tbaa !3
  %add.i.7.i593 = add i64 %or29.i.6.i591, %73
  %arrayidx2.i.7.i594 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %74 = load i64, i64* %arrayidx2.i.7.i594, align 8, !tbaa !3
  %add3.i.7.i595 = add i64 %add.i.7.i593, %74
  store i64 %add3.i.7.i595, i64* %arrayidx5.i.7.i382, align 8, !tbaa !3
  %75 = xor i64 %add.i.7.i593, -9223372036854775808
  %xor2.i.i.7.i597 = and i64 %75, %73
  %xor.i23.i.7.i598 = xor i64 %add3.i.7.i595, %add.i.7.i593
  %xor1.i24.i.7.i599 = xor i64 %add.i.7.i593, %74
  %or.i25.i.7.i600 = or i64 %xor.i23.i.7.i598, %xor1.i24.i.7.i599
  %xor2.i26.i.7.i601 = xor i64 %or.i25.i.7.i600, %add3.i.7.i595
  %shr.i30.i.7.i602 = or i64 %xor2.i26.i.7.i601, %xor2.i.i.7.i597
  %or29.i.7.i603 = lshr i64 %shr.i30.i.7.i602, 63
  %arrayidx.i.8.i604 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %76 = load i64, i64* %arrayidx.i.8.i604, align 16, !tbaa !3
  %add.i.8.i605 = add i64 %or29.i.7.i603, %76
  %arrayidx2.i.8.i606 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %77 = load i64, i64* %arrayidx2.i.8.i606, align 16, !tbaa !3
  %add3.i.8.i607 = add i64 %add.i.8.i605, %77
  store i64 %add3.i.8.i607, i64* %arrayidx5.i.8.i394, align 16, !tbaa !3
  %78 = xor i64 %add.i.8.i605, -9223372036854775808
  %xor2.i.i.8.i609 = and i64 %78, %76
  %xor.i23.i.8.i610 = xor i64 %add3.i.8.i607, %add.i.8.i605
  %xor1.i24.i.8.i611 = xor i64 %add.i.8.i605, %77
  %or.i25.i.8.i612 = or i64 %xor.i23.i.8.i610, %xor1.i24.i.8.i611
  %xor2.i26.i.8.i613 = xor i64 %or.i25.i.8.i612, %add3.i.8.i607
  %shr.i30.i.8.i614 = or i64 %xor2.i26.i.8.i613, %xor2.i.i.8.i609
  %or29.i.8.i615 = lshr i64 %shr.i30.i.8.i614, 63
  %arrayidx.i.9.i616 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %79 = load i64, i64* %arrayidx.i.9.i616, align 8, !tbaa !3
  %arrayidx2.i.9.i618 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %80 = load i64, i64* %arrayidx2.i.9.i618, align 8, !tbaa !3
  %add.i.9.i617 = add i64 %80, %79
  %add3.i.9.i619 = add i64 %add.i.9.i617, %or29.i.8.i615
  store i64 %add3.i.9.i619, i64* %arrayidx5.i.9.i406, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i114, i64* nonnull %arraydecay10.i117, i64* nonnull %arraydecay8.i120) #10
  %81 = load i64, i64* %arraydecay4.i114, align 16, !tbaa !3
  %add3.i.i621 = shl i64 %81, 1
  store i64 %add3.i.i621, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i626 = lshr i64 %81, 63
  %82 = load i64, i64* %arrayidx.i.1.i520, align 8, !tbaa !3
  %add.i.1.i628 = add i64 %82, %or29.i.i626
  %add3.i.1.i630 = add i64 %add.i.1.i628, %82
  store i64 %add3.i.1.i630, i64* %arrayidx5.i.1.i417, align 8, !tbaa !3
  %83 = xor i64 %add.i.1.i628, -9223372036854775808
  %xor2.i.i.1.i632 = and i64 %83, %82
  %xor.i23.i.1.i633 = xor i64 %add3.i.1.i630, %add.i.1.i628
  %xor1.i24.i.1.i634 = xor i64 %add.i.1.i628, %82
  %or.i25.i.1.i635 = or i64 %xor.i23.i.1.i633, %xor1.i24.i.1.i634
  %xor2.i26.i.1.i636 = xor i64 %or.i25.i.1.i635, %add3.i.1.i630
  %shr.i30.i.1.i637 = or i64 %xor2.i26.i.1.i636, %xor2.i.i.1.i632
  %or29.i.1.i638 = lshr i64 %shr.i30.i.1.i637, 63
  %84 = load i64, i64* %arrayidx.i.2.i532, align 16, !tbaa !3
  %add.i.2.i640 = add i64 %or29.i.1.i638, %84
  %add3.i.2.i642 = add i64 %add.i.2.i640, %84
  store i64 %add3.i.2.i642, i64* %arrayidx5.i.2.i429, align 16, !tbaa !3
  %85 = xor i64 %add.i.2.i640, -9223372036854775808
  %xor2.i.i.2.i644 = and i64 %85, %84
  %xor.i23.i.2.i645 = xor i64 %add3.i.2.i642, %add.i.2.i640
  %xor1.i24.i.2.i646 = xor i64 %add.i.2.i640, %84
  %or.i25.i.2.i647 = or i64 %xor.i23.i.2.i645, %xor1.i24.i.2.i646
  %xor2.i26.i.2.i648 = xor i64 %or.i25.i.2.i647, %add3.i.2.i642
  %shr.i30.i.2.i649 = or i64 %xor2.i26.i.2.i648, %xor2.i.i.2.i644
  %or29.i.2.i650 = lshr i64 %shr.i30.i.2.i649, 63
  %86 = load i64, i64* %arrayidx.i.3.i544, align 8, !tbaa !3
  %add.i.3.i652 = add i64 %or29.i.2.i650, %86
  %add3.i.3.i654 = add i64 %add.i.3.i652, %86
  store i64 %add3.i.3.i654, i64* %arrayidx5.i.3.i441, align 8, !tbaa !3
  %87 = xor i64 %add.i.3.i652, -9223372036854775808
  %xor2.i.i.3.i656 = and i64 %87, %86
  %xor.i23.i.3.i657 = xor i64 %add3.i.3.i654, %add.i.3.i652
  %xor1.i24.i.3.i658 = xor i64 %add.i.3.i652, %86
  %or.i25.i.3.i659 = or i64 %xor.i23.i.3.i657, %xor1.i24.i.3.i658
  %xor2.i26.i.3.i660 = xor i64 %or.i25.i.3.i659, %add3.i.3.i654
  %shr.i30.i.3.i661 = or i64 %xor2.i26.i.3.i660, %xor2.i.i.3.i656
  %or29.i.3.i662 = lshr i64 %shr.i30.i.3.i661, 63
  %88 = load i64, i64* %arrayidx.i.4.i556, align 16, !tbaa !3
  %add.i.4.i664 = add i64 %or29.i.3.i662, %88
  %add3.i.4.i666 = add i64 %add.i.4.i664, %88
  store i64 %add3.i.4.i666, i64* %arrayidx5.i.4.i453, align 16, !tbaa !3
  %89 = xor i64 %add.i.4.i664, -9223372036854775808
  %xor2.i.i.4.i668 = and i64 %89, %88
  %xor.i23.i.4.i669 = xor i64 %add3.i.4.i666, %add.i.4.i664
  %xor1.i24.i.4.i670 = xor i64 %add.i.4.i664, %88
  %or.i25.i.4.i671 = or i64 %xor.i23.i.4.i669, %xor1.i24.i.4.i670
  %xor2.i26.i.4.i672 = xor i64 %or.i25.i.4.i671, %add3.i.4.i666
  %shr.i30.i.4.i673 = or i64 %xor2.i26.i.4.i672, %xor2.i.i.4.i668
  %or29.i.4.i674 = lshr i64 %shr.i30.i.4.i673, 63
  %90 = load i64, i64* %arrayidx.i.5.i568, align 8, !tbaa !3
  %add.i.5.i676 = add i64 %or29.i.4.i674, %90
  %add3.i.5.i678 = add i64 %add.i.5.i676, %90
  store i64 %add3.i.5.i678, i64* %arrayidx5.i.5.i465, align 8, !tbaa !3
  %91 = xor i64 %add.i.5.i676, -9223372036854775808
  %xor2.i.i.5.i680 = and i64 %91, %90
  %xor.i23.i.5.i681 = xor i64 %add3.i.5.i678, %add.i.5.i676
  %xor1.i24.i.5.i682 = xor i64 %add.i.5.i676, %90
  %or.i25.i.5.i683 = or i64 %xor.i23.i.5.i681, %xor1.i24.i.5.i682
  %xor2.i26.i.5.i684 = xor i64 %or.i25.i.5.i683, %add3.i.5.i678
  %shr.i30.i.5.i685 = or i64 %xor2.i26.i.5.i684, %xor2.i.i.5.i680
  %or29.i.5.i686 = lshr i64 %shr.i30.i.5.i685, 63
  %92 = load i64, i64* %arrayidx.i.6.i580, align 16, !tbaa !3
  %add.i.6.i688 = add i64 %or29.i.5.i686, %92
  %add3.i.6.i690 = add i64 %add.i.6.i688, %92
  store i64 %add3.i.6.i690, i64* %arrayidx5.i.6.i477, align 16, !tbaa !3
  %93 = xor i64 %add.i.6.i688, -9223372036854775808
  %xor2.i.i.6.i692 = and i64 %93, %92
  %xor.i23.i.6.i693 = xor i64 %add3.i.6.i690, %add.i.6.i688
  %xor1.i24.i.6.i694 = xor i64 %add.i.6.i688, %92
  %or.i25.i.6.i695 = or i64 %xor.i23.i.6.i693, %xor1.i24.i.6.i694
  %xor2.i26.i.6.i696 = xor i64 %or.i25.i.6.i695, %add3.i.6.i690
  %shr.i30.i.6.i697 = or i64 %xor2.i26.i.6.i696, %xor2.i.i.6.i692
  %or29.i.6.i698 = lshr i64 %shr.i30.i.6.i697, 63
  %94 = load i64, i64* %arrayidx.i.7.i592, align 8, !tbaa !3
  %add.i.7.i700 = add i64 %or29.i.6.i698, %94
  %add3.i.7.i702 = add i64 %add.i.7.i700, %94
  store i64 %add3.i.7.i702, i64* %arrayidx5.i.7.i489, align 8, !tbaa !3
  %95 = xor i64 %add.i.7.i700, -9223372036854775808
  %xor2.i.i.7.i704 = and i64 %95, %94
  %xor.i23.i.7.i705 = xor i64 %add3.i.7.i702, %add.i.7.i700
  %xor1.i24.i.7.i706 = xor i64 %add.i.7.i700, %94
  %or.i25.i.7.i707 = or i64 %xor.i23.i.7.i705, %xor1.i24.i.7.i706
  %xor2.i26.i.7.i708 = xor i64 %or.i25.i.7.i707, %add3.i.7.i702
  %shr.i30.i.7.i709 = or i64 %xor2.i26.i.7.i708, %xor2.i.i.7.i704
  %or29.i.7.i710 = lshr i64 %shr.i30.i.7.i709, 63
  %96 = load i64, i64* %arrayidx.i.8.i604, align 16, !tbaa !3
  %add.i.8.i712 = add i64 %or29.i.7.i710, %96
  %add3.i.8.i714 = add i64 %add.i.8.i712, %96
  store i64 %add3.i.8.i714, i64* %arrayidx5.i.8.i501, align 16, !tbaa !3
  %97 = xor i64 %add.i.8.i712, -9223372036854775808
  %xor2.i.i.8.i716 = and i64 %97, %96
  %xor.i23.i.8.i717 = xor i64 %add3.i.8.i714, %add.i.8.i712
  %xor1.i24.i.8.i718 = xor i64 %add.i.8.i712, %96
  %or.i25.i.8.i719 = or i64 %xor.i23.i.8.i717, %xor1.i24.i.8.i718
  %xor2.i26.i.8.i720 = xor i64 %or.i25.i.8.i719, %add3.i.8.i714
  %shr.i30.i.8.i721 = or i64 %xor2.i26.i.8.i720, %xor2.i.i.8.i716
  %or29.i.8.i722 = lshr i64 %shr.i30.i.8.i721, 63
  %98 = load i64, i64* %arrayidx.i.9.i616, align 8, !tbaa !3
  %factor728 = shl i64 %98, 1
  %add3.i.9.i726 = or i64 %or29.i.8.i722, %factor728
  store i64 %add3.i.9.i726, i64* %arrayidx5.i.9.i513, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i120, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay2.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i117, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay8.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* %arraydecay12, [10 x i64]* nonnull %arraydecay7)
  call void @mp_sub610_p2(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay4.i123) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i126) #10
  call void @fp2mul610_mont([10 x i64]* %arraydecay, [10 x i64]* nonnull %arraydecay1, [10 x i64]* %arraydecay)
  call void @fp2mul610_mont([10 x i64]* %A24, [10 x i64]* nonnull %arraydecay15, [10 x i64]* %arraydecay12)
  call void @mp_sub610_p2(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i114, i64* nonnull %arraydecay2.i122) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i117, i64* nonnull %arraydecay8.i125) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i121, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i) #10
  %99 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %100 = load i64, i64* %arraydecay4.i114, align 16, !tbaa !3
  %add3.i.i169 = add i64 %100, %99
  store i64 %add3.i.i169, i64* %arraydecay.i121, align 8, !tbaa !3
  %xor.i23.i.i170 = xor i64 %add3.i.i169, %99
  %xor1.i24.i.i171 = xor i64 %100, %99
  %or.i25.i.i172 = or i64 %xor.i23.i.i170, %xor1.i24.i.i171
  %xor2.i26.i.i173 = xor i64 %or.i25.i.i172, %add3.i.i169
  %or29.i.i174 = lshr i64 %xor2.i26.i.i173, 63
  %101 = load i64, i64* %arrayidx.i.1.i306, align 8, !tbaa !3
  %add.i.1.i176 = add i64 %or29.i.i174, %101
  %102 = load i64, i64* %arrayidx.i.1.i520, align 8, !tbaa !3
  %add3.i.1.i178 = add i64 %add.i.1.i176, %102
  %arrayidx5.i.1.i179 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 1
  store i64 %add3.i.1.i178, i64* %arrayidx5.i.1.i179, align 8, !tbaa !3
  %103 = xor i64 %add.i.1.i176, -9223372036854775808
  %xor2.i.i.1.i180 = and i64 %103, %101
  %xor.i23.i.1.i181 = xor i64 %add3.i.1.i178, %add.i.1.i176
  %xor1.i24.i.1.i182 = xor i64 %add.i.1.i176, %102
  %or.i25.i.1.i183 = or i64 %xor.i23.i.1.i181, %xor1.i24.i.1.i182
  %xor2.i26.i.1.i184 = xor i64 %or.i25.i.1.i183, %add3.i.1.i178
  %shr.i30.i.1.i185 = or i64 %xor2.i26.i.1.i184, %xor2.i.i.1.i180
  %or29.i.1.i186 = lshr i64 %shr.i30.i.1.i185, 63
  %104 = load i64, i64* %arrayidx.i.2.i318, align 16, !tbaa !3
  %add.i.2.i188 = add i64 %or29.i.1.i186, %104
  %105 = load i64, i64* %arrayidx.i.2.i532, align 16, !tbaa !3
  %add3.i.2.i190 = add i64 %add.i.2.i188, %105
  %arrayidx5.i.2.i191 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 2
  store i64 %add3.i.2.i190, i64* %arrayidx5.i.2.i191, align 8, !tbaa !3
  %106 = xor i64 %add.i.2.i188, -9223372036854775808
  %xor2.i.i.2.i192 = and i64 %106, %104
  %xor.i23.i.2.i193 = xor i64 %add3.i.2.i190, %add.i.2.i188
  %xor1.i24.i.2.i194 = xor i64 %add.i.2.i188, %105
  %or.i25.i.2.i195 = or i64 %xor.i23.i.2.i193, %xor1.i24.i.2.i194
  %xor2.i26.i.2.i196 = xor i64 %or.i25.i.2.i195, %add3.i.2.i190
  %shr.i30.i.2.i197 = or i64 %xor2.i26.i.2.i196, %xor2.i.i.2.i192
  %or29.i.2.i198 = lshr i64 %shr.i30.i.2.i197, 63
  %107 = load i64, i64* %arrayidx.i.3.i330, align 8, !tbaa !3
  %add.i.3.i200 = add i64 %or29.i.2.i198, %107
  %108 = load i64, i64* %arrayidx.i.3.i544, align 8, !tbaa !3
  %add3.i.3.i202 = add i64 %add.i.3.i200, %108
  %arrayidx5.i.3.i203 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 3
  store i64 %add3.i.3.i202, i64* %arrayidx5.i.3.i203, align 8, !tbaa !3
  %109 = xor i64 %add.i.3.i200, -9223372036854775808
  %xor2.i.i.3.i204 = and i64 %109, %107
  %xor.i23.i.3.i205 = xor i64 %add3.i.3.i202, %add.i.3.i200
  %xor1.i24.i.3.i206 = xor i64 %add.i.3.i200, %108
  %or.i25.i.3.i207 = or i64 %xor.i23.i.3.i205, %xor1.i24.i.3.i206
  %xor2.i26.i.3.i208 = xor i64 %or.i25.i.3.i207, %add3.i.3.i202
  %shr.i30.i.3.i209 = or i64 %xor2.i26.i.3.i208, %xor2.i.i.3.i204
  %or29.i.3.i210 = lshr i64 %shr.i30.i.3.i209, 63
  %110 = load i64, i64* %arrayidx.i.4.i342, align 16, !tbaa !3
  %add.i.4.i212 = add i64 %or29.i.3.i210, %110
  %111 = load i64, i64* %arrayidx.i.4.i556, align 16, !tbaa !3
  %add3.i.4.i214 = add i64 %add.i.4.i212, %111
  %arrayidx5.i.4.i215 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 4
  store i64 %add3.i.4.i214, i64* %arrayidx5.i.4.i215, align 8, !tbaa !3
  %112 = xor i64 %add.i.4.i212, -9223372036854775808
  %xor2.i.i.4.i216 = and i64 %112, %110
  %xor.i23.i.4.i217 = xor i64 %add3.i.4.i214, %add.i.4.i212
  %xor1.i24.i.4.i218 = xor i64 %add.i.4.i212, %111
  %or.i25.i.4.i219 = or i64 %xor.i23.i.4.i217, %xor1.i24.i.4.i218
  %xor2.i26.i.4.i220 = xor i64 %or.i25.i.4.i219, %add3.i.4.i214
  %shr.i30.i.4.i221 = or i64 %xor2.i26.i.4.i220, %xor2.i.i.4.i216
  %or29.i.4.i222 = lshr i64 %shr.i30.i.4.i221, 63
  %113 = load i64, i64* %arrayidx.i.5.i354, align 8, !tbaa !3
  %add.i.5.i224 = add i64 %or29.i.4.i222, %113
  %114 = load i64, i64* %arrayidx.i.5.i568, align 8, !tbaa !3
  %add3.i.5.i226 = add i64 %add.i.5.i224, %114
  %arrayidx5.i.5.i227 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 5
  store i64 %add3.i.5.i226, i64* %arrayidx5.i.5.i227, align 8, !tbaa !3
  %115 = xor i64 %add.i.5.i224, -9223372036854775808
  %xor2.i.i.5.i228 = and i64 %115, %113
  %xor.i23.i.5.i229 = xor i64 %add3.i.5.i226, %add.i.5.i224
  %xor1.i24.i.5.i230 = xor i64 %add.i.5.i224, %114
  %or.i25.i.5.i231 = or i64 %xor.i23.i.5.i229, %xor1.i24.i.5.i230
  %xor2.i26.i.5.i232 = xor i64 %or.i25.i.5.i231, %add3.i.5.i226
  %shr.i30.i.5.i233 = or i64 %xor2.i26.i.5.i232, %xor2.i.i.5.i228
  %or29.i.5.i234 = lshr i64 %shr.i30.i.5.i233, 63
  %116 = load i64, i64* %arrayidx.i.6.i366, align 16, !tbaa !3
  %add.i.6.i236 = add i64 %or29.i.5.i234, %116
  %117 = load i64, i64* %arrayidx.i.6.i580, align 16, !tbaa !3
  %add3.i.6.i238 = add i64 %add.i.6.i236, %117
  %arrayidx5.i.6.i239 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 6
  store i64 %add3.i.6.i238, i64* %arrayidx5.i.6.i239, align 8, !tbaa !3
  %118 = xor i64 %add.i.6.i236, -9223372036854775808
  %xor2.i.i.6.i240 = and i64 %118, %116
  %xor.i23.i.6.i241 = xor i64 %add3.i.6.i238, %add.i.6.i236
  %xor1.i24.i.6.i242 = xor i64 %add.i.6.i236, %117
  %or.i25.i.6.i243 = or i64 %xor.i23.i.6.i241, %xor1.i24.i.6.i242
  %xor2.i26.i.6.i244 = xor i64 %or.i25.i.6.i243, %add3.i.6.i238
  %shr.i30.i.6.i245 = or i64 %xor2.i26.i.6.i244, %xor2.i.i.6.i240
  %or29.i.6.i246 = lshr i64 %shr.i30.i.6.i245, 63
  %119 = load i64, i64* %arrayidx.i.7.i378, align 8, !tbaa !3
  %add.i.7.i248 = add i64 %or29.i.6.i246, %119
  %120 = load i64, i64* %arrayidx.i.7.i592, align 8, !tbaa !3
  %add3.i.7.i250 = add i64 %add.i.7.i248, %120
  %arrayidx5.i.7.i251 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 7
  store i64 %add3.i.7.i250, i64* %arrayidx5.i.7.i251, align 8, !tbaa !3
  %121 = xor i64 %add.i.7.i248, -9223372036854775808
  %xor2.i.i.7.i252 = and i64 %121, %119
  %xor.i23.i.7.i253 = xor i64 %add3.i.7.i250, %add.i.7.i248
  %xor1.i24.i.7.i254 = xor i64 %add.i.7.i248, %120
  %or.i25.i.7.i255 = or i64 %xor.i23.i.7.i253, %xor1.i24.i.7.i254
  %xor2.i26.i.7.i256 = xor i64 %or.i25.i.7.i255, %add3.i.7.i250
  %shr.i30.i.7.i257 = or i64 %xor2.i26.i.7.i256, %xor2.i.i.7.i252
  %or29.i.7.i258 = lshr i64 %shr.i30.i.7.i257, 63
  %122 = load i64, i64* %arrayidx.i.8.i390, align 16, !tbaa !3
  %add.i.8.i260 = add i64 %or29.i.7.i258, %122
  %123 = load i64, i64* %arrayidx.i.8.i604, align 16, !tbaa !3
  %add3.i.8.i262 = add i64 %add.i.8.i260, %123
  %arrayidx5.i.8.i263 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 8
  store i64 %add3.i.8.i262, i64* %arrayidx5.i.8.i263, align 8, !tbaa !3
  %124 = xor i64 %add.i.8.i260, -9223372036854775808
  %xor2.i.i.8.i264 = and i64 %124, %122
  %xor.i23.i.8.i265 = xor i64 %add3.i.8.i262, %add.i.8.i260
  %xor1.i24.i.8.i266 = xor i64 %add.i.8.i260, %123
  %or.i25.i.8.i267 = or i64 %xor.i23.i.8.i265, %xor1.i24.i.8.i266
  %xor2.i26.i.8.i268 = xor i64 %or.i25.i.8.i267, %add3.i.8.i262
  %shr.i30.i.8.i269 = or i64 %xor2.i26.i.8.i268, %xor2.i.i.8.i264
  %or29.i.8.i270 = lshr i64 %shr.i30.i.8.i269, 63
  %125 = load i64, i64* %arrayidx.i.9.i402, align 8, !tbaa !3
  %126 = load i64, i64* %arrayidx.i.9.i616, align 8, !tbaa !3
  %add.i.9.i272 = add i64 %126, %125
  %add3.i.9.i274 = add i64 %add.i.9.i272, %or29.i.8.i270
  %arrayidx5.i.9.i275 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 9
  store i64 %add3.i.9.i274, i64* %arrayidx5.i.9.i275, align 8, !tbaa !3
  %127 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %128 = load i64, i64* %arraydecay10.i117, align 16, !tbaa !3
  %add3.i.i = add i64 %128, %127
  store i64 %add3.i.i, i64* %arraydecay6.i124, align 8, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %127
  %xor1.i24.i.i = xor i64 %128, %127
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %129 = load i64, i64* %arrayidx2.i.1.i308, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %129
  %130 = load i64, i64* %arrayidx2.i.1.i522, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %130
  %arrayidx5.i.1.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %131 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %131, %129
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %130
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %132 = load i64, i64* %arrayidx2.i.2.i320, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %132
  %133 = load i64, i64* %arrayidx2.i.2.i534, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %133
  %arrayidx5.i.2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 8, !tbaa !3
  %134 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %134, %132
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %133
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %135 = load i64, i64* %arrayidx2.i.3.i332, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %135
  %136 = load i64, i64* %arrayidx2.i.3.i546, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %136
  %arrayidx5.i.3.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %137 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %137, %135
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %136
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %138 = load i64, i64* %arrayidx2.i.4.i344, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %138
  %139 = load i64, i64* %arrayidx2.i.4.i558, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %139
  %arrayidx5.i.4.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 8, !tbaa !3
  %140 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %140, %138
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %139
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %141 = load i64, i64* %arrayidx2.i.5.i356, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %141
  %142 = load i64, i64* %arrayidx2.i.5.i570, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %142
  %arrayidx5.i.5.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %143 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %143, %141
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %142
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %144 = load i64, i64* %arrayidx2.i.6.i368, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %144
  %145 = load i64, i64* %arrayidx2.i.6.i582, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %145
  %arrayidx5.i.6.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 8, !tbaa !3
  %146 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %146, %144
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %145
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %147 = load i64, i64* %arrayidx2.i.7.i380, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %147
  %148 = load i64, i64* %arrayidx2.i.7.i594, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %148
  %arrayidx5.i.7.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %149 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %149, %147
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %148
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %150 = load i64, i64* %arrayidx2.i.8.i392, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %150
  %151 = load i64, i64* %arrayidx2.i.8.i606, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %151
  %arrayidx5.i.8.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 8, !tbaa !3
  %152 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %152, %150
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %151
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %153 = load i64, i64* %arrayidx2.i.9.i404, align 8, !tbaa !3
  %154 = load i64, i64* %arrayidx2.i.9.i618, align 8, !tbaa !3
  %add.i.9.i = add i64 %154, %153
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay15, [10 x i64]* nonnull %arraydecay1)
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i122, i64* nonnull %arraydecay8.i125, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* nonnull %arraydecay2.i122, i64* nonnull %arraydecay8.i125, i64* nonnull %arraydecay8.i120) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay2.i122, i64* nonnull %arraydecay2.i122, i64* nonnull %arraydecay13.i) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i120, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay2.i122) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay8.i125, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay8.i125) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %3) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i121, i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* %arraydecay.i121, i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay8.i120) #10
  call fastcc void @mp_addfast(i64* %arraydecay.i121, i64* %arraydecay.i121, i64* nonnull %arraydecay13.i) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i120, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* %arraydecay.i121) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %52, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay6.i124, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay6.i124) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %52) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %3) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay14, [10 x i64]* %XPQ, [10 x i64]* nonnull %arraydecay14)
  call void @fp2mul610_mont([10 x i64]* %arraydecay12, [10 x i64]* %ZPQ, [10 x i64]* %arraydecay12)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xTPL_fast(%struct.point_proj* %P, %struct.point_proj* %Q, [10 x i64]* %A2) local_unnamed_addr #4 {
entry:
  %temp.i.i = alloca [20 x i64], align 16
  %t1.i = alloca [10 x i64], align 16
  %t2.i = alloca [10 x i64], align 16
  %t3.i = alloca [10 x i64], align 16
  %t1 = alloca [2 x [10 x i64]], align 16
  %t2 = alloca [2 x [10 x i64]], align 16
  %t3 = alloca [2 x [10 x i64]], align 16
  %t4 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [2 x [10 x i64]]* %t1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #10
  %1 = bitcast [2 x [10 x i64]]* %t2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #10
  %2 = bitcast [2 x [10 x i64]]* %t3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %3 = bitcast [2 x [10 x i64]]* %t4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %3) #10
  %arraydecay = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0
  %arraydecay1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0
  %4 = bitcast [10 x i64]* %t1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  %5 = bitcast [10 x i64]* %t2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  %6 = bitcast [10 x i64]* %t3.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %arraydecay.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %arraydecay2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 1, i64 0
  %arraydecay3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay3.i) #10
  %arraydecay8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t2.i, i64 0, i64 0
  call void @mp_sub610_p4(i64* %arraydecay.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay8.i) #10
  %arraydecay13.i = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 0
  call fastcc void @mp_addfast(i64* %arraydecay.i, i64* %arraydecay.i, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 0
  %7 = bitcast [20 x i64]* %temp.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  %arraydecay22.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 0
  %arraydecay3 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %arraydecay.i75 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay2, i64 0, i64 0
  %arraydecay2.i76 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 1, i64 1, i64 0
  call fastcc void @mp_addfast(i64* nonnull %arraydecay.i75, i64* nonnull %arraydecay2.i76, i64* nonnull %arraydecay3.i) #10
  call void @mp_sub610_p4(i64* nonnull %arraydecay.i75, i64* nonnull %arraydecay2.i76, i64* nonnull %arraydecay8.i) #10
  call fastcc void @mp_addfast(i64* nonnull %arraydecay.i75, i64* nonnull %arraydecay.i75, i64* nonnull %arraydecay13.i) #10
  %arraydecay17.i80 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i80) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  %arraydecay22.i82 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay2.i76, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i82) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 0
  call void @fpadd610(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay4.i) #10
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay10.i) #10
  %arraydecay11 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0
  %arraydecay4.i88 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 0
  call void @fpadd610(i64* %arraydecay.i, i64* nonnull %arraydecay.i75, i64* nonnull %arraydecay4.i88) #10
  %arraydecay10.i91 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 0
  call void @fpadd610(i64* nonnull %arraydecay2.i, i64* nonnull %arraydecay2.i76, i64* nonnull %arraydecay10.i91) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %8 = load i64, i64* %arraydecay4.i88, align 16, !tbaa !3
  %9 = load i64, i64* %arraydecay10.i91, align 16, !tbaa !3
  %add3.i.i = add i64 %9, %8
  store i64 %add3.i.i, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %8
  %xor1.i24.i.i = xor i64 %9, %8
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 1
  %10 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %10
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 1
  %11 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %11
  %arrayidx5.i.1.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %12 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %12, %10
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %11
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 2
  %13 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %13
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 2
  %14 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %14
  %arrayidx5.i.2.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %15 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %15, %13
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %14
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 3
  %16 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %16
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 3
  %17 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %17
  %arrayidx5.i.3.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %18 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %18, %16
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %17
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 4
  %19 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %19
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 4
  %20 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %20
  %arrayidx5.i.4.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %21 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %21, %19
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %20
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 5
  %22 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %22
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 5
  %23 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %23
  %arrayidx5.i.5.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %24 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %24, %22
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %23
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 6
  %25 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %25
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 6
  %26 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %26
  %arrayidx5.i.6.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %27 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %27, %25
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %26
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 7
  %28 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %28
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 7
  %29 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %29
  %arrayidx5.i.7.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %30 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %30, %28
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %29
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 8
  %31 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %31
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 8
  %32 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %32
  %arrayidx5.i.8.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %33 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %33, %31
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %32
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 0, i64 9
  %34 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t4, i64 0, i64 1, i64 9
  %35 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %35, %34
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [10 x i64], [10 x i64]* %t1.i, i64 0, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i88, i64* nonnull %arraydecay10.i91, i64* nonnull %arraydecay8.i) #10
  %36 = load i64, i64* %arraydecay4.i88, align 16, !tbaa !3
  %add3.i.i194 = shl i64 %36, 1
  store i64 %add3.i.i194, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i199 = lshr i64 %36, 63
  %37 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i201 = add i64 %37, %or29.i.i199
  %add3.i.1.i203 = add i64 %add.i.1.i201, %37
  %arrayidx5.i.1.i204 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 1
  store i64 %add3.i.1.i203, i64* %arrayidx5.i.1.i204, align 8, !tbaa !3
  %38 = xor i64 %add.i.1.i201, -9223372036854775808
  %xor2.i.i.1.i205 = and i64 %38, %37
  %xor.i23.i.1.i206 = xor i64 %add3.i.1.i203, %add.i.1.i201
  %xor1.i24.i.1.i207 = xor i64 %add.i.1.i201, %37
  %or.i25.i.1.i208 = or i64 %xor.i23.i.1.i206, %xor1.i24.i.1.i207
  %xor2.i26.i.1.i209 = xor i64 %or.i25.i.1.i208, %add3.i.1.i203
  %shr.i30.i.1.i210 = or i64 %xor2.i26.i.1.i209, %xor2.i.i.1.i205
  %or29.i.1.i211 = lshr i64 %shr.i30.i.1.i210, 63
  %39 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i213 = add i64 %or29.i.1.i211, %39
  %add3.i.2.i215 = add i64 %add.i.2.i213, %39
  %arrayidx5.i.2.i216 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 2
  store i64 %add3.i.2.i215, i64* %arrayidx5.i.2.i216, align 16, !tbaa !3
  %40 = xor i64 %add.i.2.i213, -9223372036854775808
  %xor2.i.i.2.i217 = and i64 %40, %39
  %xor.i23.i.2.i218 = xor i64 %add3.i.2.i215, %add.i.2.i213
  %xor1.i24.i.2.i219 = xor i64 %add.i.2.i213, %39
  %or.i25.i.2.i220 = or i64 %xor.i23.i.2.i218, %xor1.i24.i.2.i219
  %xor2.i26.i.2.i221 = xor i64 %or.i25.i.2.i220, %add3.i.2.i215
  %shr.i30.i.2.i222 = or i64 %xor2.i26.i.2.i221, %xor2.i.i.2.i217
  %or29.i.2.i223 = lshr i64 %shr.i30.i.2.i222, 63
  %41 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i225 = add i64 %or29.i.2.i223, %41
  %add3.i.3.i227 = add i64 %add.i.3.i225, %41
  %arrayidx5.i.3.i228 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 3
  store i64 %add3.i.3.i227, i64* %arrayidx5.i.3.i228, align 8, !tbaa !3
  %42 = xor i64 %add.i.3.i225, -9223372036854775808
  %xor2.i.i.3.i229 = and i64 %42, %41
  %xor.i23.i.3.i230 = xor i64 %add3.i.3.i227, %add.i.3.i225
  %xor1.i24.i.3.i231 = xor i64 %add.i.3.i225, %41
  %or.i25.i.3.i232 = or i64 %xor.i23.i.3.i230, %xor1.i24.i.3.i231
  %xor2.i26.i.3.i233 = xor i64 %or.i25.i.3.i232, %add3.i.3.i227
  %shr.i30.i.3.i234 = or i64 %xor2.i26.i.3.i233, %xor2.i.i.3.i229
  %or29.i.3.i235 = lshr i64 %shr.i30.i.3.i234, 63
  %43 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i237 = add i64 %or29.i.3.i235, %43
  %add3.i.4.i239 = add i64 %add.i.4.i237, %43
  %arrayidx5.i.4.i240 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 4
  store i64 %add3.i.4.i239, i64* %arrayidx5.i.4.i240, align 16, !tbaa !3
  %44 = xor i64 %add.i.4.i237, -9223372036854775808
  %xor2.i.i.4.i241 = and i64 %44, %43
  %xor.i23.i.4.i242 = xor i64 %add3.i.4.i239, %add.i.4.i237
  %xor1.i24.i.4.i243 = xor i64 %add.i.4.i237, %43
  %or.i25.i.4.i244 = or i64 %xor.i23.i.4.i242, %xor1.i24.i.4.i243
  %xor2.i26.i.4.i245 = xor i64 %or.i25.i.4.i244, %add3.i.4.i239
  %shr.i30.i.4.i246 = or i64 %xor2.i26.i.4.i245, %xor2.i.i.4.i241
  %or29.i.4.i247 = lshr i64 %shr.i30.i.4.i246, 63
  %45 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i249 = add i64 %or29.i.4.i247, %45
  %add3.i.5.i251 = add i64 %add.i.5.i249, %45
  %arrayidx5.i.5.i252 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 5
  store i64 %add3.i.5.i251, i64* %arrayidx5.i.5.i252, align 8, !tbaa !3
  %46 = xor i64 %add.i.5.i249, -9223372036854775808
  %xor2.i.i.5.i253 = and i64 %46, %45
  %xor.i23.i.5.i254 = xor i64 %add3.i.5.i251, %add.i.5.i249
  %xor1.i24.i.5.i255 = xor i64 %add.i.5.i249, %45
  %or.i25.i.5.i256 = or i64 %xor.i23.i.5.i254, %xor1.i24.i.5.i255
  %xor2.i26.i.5.i257 = xor i64 %or.i25.i.5.i256, %add3.i.5.i251
  %shr.i30.i.5.i258 = or i64 %xor2.i26.i.5.i257, %xor2.i.i.5.i253
  %or29.i.5.i259 = lshr i64 %shr.i30.i.5.i258, 63
  %47 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i261 = add i64 %or29.i.5.i259, %47
  %add3.i.6.i263 = add i64 %add.i.6.i261, %47
  %arrayidx5.i.6.i264 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 6
  store i64 %add3.i.6.i263, i64* %arrayidx5.i.6.i264, align 16, !tbaa !3
  %48 = xor i64 %add.i.6.i261, -9223372036854775808
  %xor2.i.i.6.i265 = and i64 %48, %47
  %xor.i23.i.6.i266 = xor i64 %add3.i.6.i263, %add.i.6.i261
  %xor1.i24.i.6.i267 = xor i64 %add.i.6.i261, %47
  %or.i25.i.6.i268 = or i64 %xor.i23.i.6.i266, %xor1.i24.i.6.i267
  %xor2.i26.i.6.i269 = xor i64 %or.i25.i.6.i268, %add3.i.6.i263
  %shr.i30.i.6.i270 = or i64 %xor2.i26.i.6.i269, %xor2.i.i.6.i265
  %or29.i.6.i271 = lshr i64 %shr.i30.i.6.i270, 63
  %49 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i273 = add i64 %or29.i.6.i271, %49
  %add3.i.7.i275 = add i64 %add.i.7.i273, %49
  %arrayidx5.i.7.i276 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 7
  store i64 %add3.i.7.i275, i64* %arrayidx5.i.7.i276, align 8, !tbaa !3
  %50 = xor i64 %add.i.7.i273, -9223372036854775808
  %xor2.i.i.7.i277 = and i64 %50, %49
  %xor.i23.i.7.i278 = xor i64 %add3.i.7.i275, %add.i.7.i273
  %xor1.i24.i.7.i279 = xor i64 %add.i.7.i273, %49
  %or.i25.i.7.i280 = or i64 %xor.i23.i.7.i278, %xor1.i24.i.7.i279
  %xor2.i26.i.7.i281 = xor i64 %or.i25.i.7.i280, %add3.i.7.i275
  %shr.i30.i.7.i282 = or i64 %xor2.i26.i.7.i281, %xor2.i.i.7.i277
  %or29.i.7.i283 = lshr i64 %shr.i30.i.7.i282, 63
  %51 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i285 = add i64 %or29.i.7.i283, %51
  %add3.i.8.i287 = add i64 %add.i.8.i285, %51
  %arrayidx5.i.8.i288 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 8
  store i64 %add3.i.8.i287, i64* %arrayidx5.i.8.i288, align 16, !tbaa !3
  %52 = xor i64 %add.i.8.i285, -9223372036854775808
  %xor2.i.i.8.i289 = and i64 %52, %51
  %xor.i23.i.8.i290 = xor i64 %add3.i.8.i287, %add.i.8.i285
  %xor1.i24.i.8.i291 = xor i64 %add.i.8.i285, %51
  %or.i25.i.8.i292 = or i64 %xor.i23.i.8.i290, %xor1.i24.i.8.i291
  %xor2.i26.i.8.i293 = xor i64 %or.i25.i.8.i292, %add3.i.8.i287
  %shr.i30.i.8.i294 = or i64 %xor2.i26.i.8.i293, %xor2.i.i.8.i289
  %or29.i.8.i295 = lshr i64 %shr.i30.i.8.i294, 63
  %53 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor = shl i64 %53, 1
  %add3.i.9.i299 = or i64 %or29.i.8.i295, %factor
  %arrayidx5.i.9.i300 = getelementptr inbounds [10 x i64], [10 x i64]* %t3.i, i64 0, i64 9
  store i64 %add3.i.9.i299, i64* %arrayidx5.i.9.i300, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i88) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i91, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i91) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @fpsub610(i64* nonnull %arraydecay4.i88, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i88) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i91, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i91) #10
  call void @fp2mul610_mont([10 x i64]* %A2, [10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay11)
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i88, i64* nonnull %arraydecay4.i88) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i91, i64* nonnull %arraydecay10.i91) #10
  call void @fpsub610(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay4.i) #10
  call void @fpsub610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %54 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %55 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i301 = add i64 %55, %54
  store i64 %add3.i.i301, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i302 = xor i64 %add3.i.i301, %54
  %xor1.i24.i.i303 = xor i64 %55, %54
  %or.i25.i.i304 = or i64 %xor.i23.i.i302, %xor1.i24.i.i303
  %xor2.i26.i.i305 = xor i64 %or.i25.i.i304, %add3.i.i301
  %or29.i.i306 = lshr i64 %xor2.i26.i.i305, 63
  %arrayidx.i.1.i307 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 1
  %56 = load i64, i64* %arrayidx.i.1.i307, align 8, !tbaa !3
  %add.i.1.i308 = add i64 %or29.i.i306, %56
  %arrayidx2.i.1.i309 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 1
  %57 = load i64, i64* %arrayidx2.i.1.i309, align 8, !tbaa !3
  %add3.i.1.i310 = add i64 %add.i.1.i308, %57
  store i64 %add3.i.1.i310, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %58 = xor i64 %add.i.1.i308, -9223372036854775808
  %xor2.i.i.1.i312 = and i64 %58, %56
  %xor.i23.i.1.i313 = xor i64 %add3.i.1.i310, %add.i.1.i308
  %xor1.i24.i.1.i314 = xor i64 %add.i.1.i308, %57
  %or.i25.i.1.i315 = or i64 %xor.i23.i.1.i313, %xor1.i24.i.1.i314
  %xor2.i26.i.1.i316 = xor i64 %or.i25.i.1.i315, %add3.i.1.i310
  %shr.i30.i.1.i317 = or i64 %xor2.i26.i.1.i316, %xor2.i.i.1.i312
  %or29.i.1.i318 = lshr i64 %shr.i30.i.1.i317, 63
  %arrayidx.i.2.i319 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 2
  %59 = load i64, i64* %arrayidx.i.2.i319, align 16, !tbaa !3
  %add.i.2.i320 = add i64 %or29.i.1.i318, %59
  %arrayidx2.i.2.i321 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 2
  %60 = load i64, i64* %arrayidx2.i.2.i321, align 16, !tbaa !3
  %add3.i.2.i322 = add i64 %add.i.2.i320, %60
  store i64 %add3.i.2.i322, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %61 = xor i64 %add.i.2.i320, -9223372036854775808
  %xor2.i.i.2.i324 = and i64 %61, %59
  %xor.i23.i.2.i325 = xor i64 %add3.i.2.i322, %add.i.2.i320
  %xor1.i24.i.2.i326 = xor i64 %add.i.2.i320, %60
  %or.i25.i.2.i327 = or i64 %xor.i23.i.2.i325, %xor1.i24.i.2.i326
  %xor2.i26.i.2.i328 = xor i64 %or.i25.i.2.i327, %add3.i.2.i322
  %shr.i30.i.2.i329 = or i64 %xor2.i26.i.2.i328, %xor2.i.i.2.i324
  %or29.i.2.i330 = lshr i64 %shr.i30.i.2.i329, 63
  %arrayidx.i.3.i331 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 3
  %62 = load i64, i64* %arrayidx.i.3.i331, align 8, !tbaa !3
  %add.i.3.i332 = add i64 %or29.i.2.i330, %62
  %arrayidx2.i.3.i333 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 3
  %63 = load i64, i64* %arrayidx2.i.3.i333, align 8, !tbaa !3
  %add3.i.3.i334 = add i64 %add.i.3.i332, %63
  store i64 %add3.i.3.i334, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %64 = xor i64 %add.i.3.i332, -9223372036854775808
  %xor2.i.i.3.i336 = and i64 %64, %62
  %xor.i23.i.3.i337 = xor i64 %add3.i.3.i334, %add.i.3.i332
  %xor1.i24.i.3.i338 = xor i64 %add.i.3.i332, %63
  %or.i25.i.3.i339 = or i64 %xor.i23.i.3.i337, %xor1.i24.i.3.i338
  %xor2.i26.i.3.i340 = xor i64 %or.i25.i.3.i339, %add3.i.3.i334
  %shr.i30.i.3.i341 = or i64 %xor2.i26.i.3.i340, %xor2.i.i.3.i336
  %or29.i.3.i342 = lshr i64 %shr.i30.i.3.i341, 63
  %arrayidx.i.4.i343 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 4
  %65 = load i64, i64* %arrayidx.i.4.i343, align 16, !tbaa !3
  %add.i.4.i344 = add i64 %or29.i.3.i342, %65
  %arrayidx2.i.4.i345 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 4
  %66 = load i64, i64* %arrayidx2.i.4.i345, align 16, !tbaa !3
  %add3.i.4.i346 = add i64 %add.i.4.i344, %66
  store i64 %add3.i.4.i346, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %67 = xor i64 %add.i.4.i344, -9223372036854775808
  %xor2.i.i.4.i348 = and i64 %67, %65
  %xor.i23.i.4.i349 = xor i64 %add3.i.4.i346, %add.i.4.i344
  %xor1.i24.i.4.i350 = xor i64 %add.i.4.i344, %66
  %or.i25.i.4.i351 = or i64 %xor.i23.i.4.i349, %xor1.i24.i.4.i350
  %xor2.i26.i.4.i352 = xor i64 %or.i25.i.4.i351, %add3.i.4.i346
  %shr.i30.i.4.i353 = or i64 %xor2.i26.i.4.i352, %xor2.i.i.4.i348
  %or29.i.4.i354 = lshr i64 %shr.i30.i.4.i353, 63
  %arrayidx.i.5.i355 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 5
  %68 = load i64, i64* %arrayidx.i.5.i355, align 8, !tbaa !3
  %add.i.5.i356 = add i64 %or29.i.4.i354, %68
  %arrayidx2.i.5.i357 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 5
  %69 = load i64, i64* %arrayidx2.i.5.i357, align 8, !tbaa !3
  %add3.i.5.i358 = add i64 %add.i.5.i356, %69
  store i64 %add3.i.5.i358, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %70 = xor i64 %add.i.5.i356, -9223372036854775808
  %xor2.i.i.5.i360 = and i64 %70, %68
  %xor.i23.i.5.i361 = xor i64 %add3.i.5.i358, %add.i.5.i356
  %xor1.i24.i.5.i362 = xor i64 %add.i.5.i356, %69
  %or.i25.i.5.i363 = or i64 %xor.i23.i.5.i361, %xor1.i24.i.5.i362
  %xor2.i26.i.5.i364 = xor i64 %or.i25.i.5.i363, %add3.i.5.i358
  %shr.i30.i.5.i365 = or i64 %xor2.i26.i.5.i364, %xor2.i.i.5.i360
  %or29.i.5.i366 = lshr i64 %shr.i30.i.5.i365, 63
  %arrayidx.i.6.i367 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 6
  %71 = load i64, i64* %arrayidx.i.6.i367, align 16, !tbaa !3
  %add.i.6.i368 = add i64 %or29.i.5.i366, %71
  %arrayidx2.i.6.i369 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 6
  %72 = load i64, i64* %arrayidx2.i.6.i369, align 16, !tbaa !3
  %add3.i.6.i370 = add i64 %add.i.6.i368, %72
  store i64 %add3.i.6.i370, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %73 = xor i64 %add.i.6.i368, -9223372036854775808
  %xor2.i.i.6.i372 = and i64 %73, %71
  %xor.i23.i.6.i373 = xor i64 %add3.i.6.i370, %add.i.6.i368
  %xor1.i24.i.6.i374 = xor i64 %add.i.6.i368, %72
  %or.i25.i.6.i375 = or i64 %xor.i23.i.6.i373, %xor1.i24.i.6.i374
  %xor2.i26.i.6.i376 = xor i64 %or.i25.i.6.i375, %add3.i.6.i370
  %shr.i30.i.6.i377 = or i64 %xor2.i26.i.6.i376, %xor2.i.i.6.i372
  %or29.i.6.i378 = lshr i64 %shr.i30.i.6.i377, 63
  %arrayidx.i.7.i379 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 7
  %74 = load i64, i64* %arrayidx.i.7.i379, align 8, !tbaa !3
  %add.i.7.i380 = add i64 %or29.i.6.i378, %74
  %arrayidx2.i.7.i381 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 7
  %75 = load i64, i64* %arrayidx2.i.7.i381, align 8, !tbaa !3
  %add3.i.7.i382 = add i64 %add.i.7.i380, %75
  store i64 %add3.i.7.i382, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %76 = xor i64 %add.i.7.i380, -9223372036854775808
  %xor2.i.i.7.i384 = and i64 %76, %74
  %xor.i23.i.7.i385 = xor i64 %add3.i.7.i382, %add.i.7.i380
  %xor1.i24.i.7.i386 = xor i64 %add.i.7.i380, %75
  %or.i25.i.7.i387 = or i64 %xor.i23.i.7.i385, %xor1.i24.i.7.i386
  %xor2.i26.i.7.i388 = xor i64 %or.i25.i.7.i387, %add3.i.7.i382
  %shr.i30.i.7.i389 = or i64 %xor2.i26.i.7.i388, %xor2.i.i.7.i384
  %or29.i.7.i390 = lshr i64 %shr.i30.i.7.i389, 63
  %arrayidx.i.8.i391 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 8
  %77 = load i64, i64* %arrayidx.i.8.i391, align 16, !tbaa !3
  %add.i.8.i392 = add i64 %or29.i.7.i390, %77
  %arrayidx2.i.8.i393 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 8
  %78 = load i64, i64* %arrayidx2.i.8.i393, align 16, !tbaa !3
  %add3.i.8.i394 = add i64 %add.i.8.i392, %78
  store i64 %add3.i.8.i394, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %79 = xor i64 %add.i.8.i392, -9223372036854775808
  %xor2.i.i.8.i396 = and i64 %79, %77
  %xor.i23.i.8.i397 = xor i64 %add3.i.8.i394, %add.i.8.i392
  %xor1.i24.i.8.i398 = xor i64 %add.i.8.i392, %78
  %or.i25.i.8.i399 = or i64 %xor.i23.i.8.i397, %xor1.i24.i.8.i398
  %xor2.i26.i.8.i400 = xor i64 %or.i25.i.8.i399, %add3.i.8.i394
  %shr.i30.i.8.i401 = or i64 %xor2.i26.i.8.i400, %xor2.i.i.8.i396
  %or29.i.8.i402 = lshr i64 %shr.i30.i.8.i401, 63
  %arrayidx.i.9.i403 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 0, i64 9
  %80 = load i64, i64* %arrayidx.i.9.i403, align 8, !tbaa !3
  %arrayidx2.i.9.i405 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t3, i64 0, i64 1, i64 9
  %81 = load i64, i64* %arrayidx2.i.9.i405, align 8, !tbaa !3
  %add.i.9.i404 = add i64 %81, %80
  %add3.i.9.i406 = add i64 %add.i.9.i404, %or29.i.8.i402
  store i64 %add3.i.9.i406, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i) #10
  %82 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i408 = shl i64 %82, 1
  store i64 %add3.i.i408, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i413 = lshr i64 %82, 63
  %83 = load i64, i64* %arrayidx.i.1.i307, align 8, !tbaa !3
  %add.i.1.i415 = add i64 %83, %or29.i.i413
  %add3.i.1.i417 = add i64 %add.i.1.i415, %83
  store i64 %add3.i.1.i417, i64* %arrayidx5.i.1.i204, align 8, !tbaa !3
  %84 = xor i64 %add.i.1.i415, -9223372036854775808
  %xor2.i.i.1.i419 = and i64 %84, %83
  %xor.i23.i.1.i420 = xor i64 %add3.i.1.i417, %add.i.1.i415
  %xor1.i24.i.1.i421 = xor i64 %add.i.1.i415, %83
  %or.i25.i.1.i422 = or i64 %xor.i23.i.1.i420, %xor1.i24.i.1.i421
  %xor2.i26.i.1.i423 = xor i64 %or.i25.i.1.i422, %add3.i.1.i417
  %shr.i30.i.1.i424 = or i64 %xor2.i26.i.1.i423, %xor2.i.i.1.i419
  %or29.i.1.i425 = lshr i64 %shr.i30.i.1.i424, 63
  %85 = load i64, i64* %arrayidx.i.2.i319, align 16, !tbaa !3
  %add.i.2.i427 = add i64 %or29.i.1.i425, %85
  %add3.i.2.i429 = add i64 %add.i.2.i427, %85
  store i64 %add3.i.2.i429, i64* %arrayidx5.i.2.i216, align 16, !tbaa !3
  %86 = xor i64 %add.i.2.i427, -9223372036854775808
  %xor2.i.i.2.i431 = and i64 %86, %85
  %xor.i23.i.2.i432 = xor i64 %add3.i.2.i429, %add.i.2.i427
  %xor1.i24.i.2.i433 = xor i64 %add.i.2.i427, %85
  %or.i25.i.2.i434 = or i64 %xor.i23.i.2.i432, %xor1.i24.i.2.i433
  %xor2.i26.i.2.i435 = xor i64 %or.i25.i.2.i434, %add3.i.2.i429
  %shr.i30.i.2.i436 = or i64 %xor2.i26.i.2.i435, %xor2.i.i.2.i431
  %or29.i.2.i437 = lshr i64 %shr.i30.i.2.i436, 63
  %87 = load i64, i64* %arrayidx.i.3.i331, align 8, !tbaa !3
  %add.i.3.i439 = add i64 %or29.i.2.i437, %87
  %add3.i.3.i441 = add i64 %add.i.3.i439, %87
  store i64 %add3.i.3.i441, i64* %arrayidx5.i.3.i228, align 8, !tbaa !3
  %88 = xor i64 %add.i.3.i439, -9223372036854775808
  %xor2.i.i.3.i443 = and i64 %88, %87
  %xor.i23.i.3.i444 = xor i64 %add3.i.3.i441, %add.i.3.i439
  %xor1.i24.i.3.i445 = xor i64 %add.i.3.i439, %87
  %or.i25.i.3.i446 = or i64 %xor.i23.i.3.i444, %xor1.i24.i.3.i445
  %xor2.i26.i.3.i447 = xor i64 %or.i25.i.3.i446, %add3.i.3.i441
  %shr.i30.i.3.i448 = or i64 %xor2.i26.i.3.i447, %xor2.i.i.3.i443
  %or29.i.3.i449 = lshr i64 %shr.i30.i.3.i448, 63
  %89 = load i64, i64* %arrayidx.i.4.i343, align 16, !tbaa !3
  %add.i.4.i451 = add i64 %or29.i.3.i449, %89
  %add3.i.4.i453 = add i64 %add.i.4.i451, %89
  store i64 %add3.i.4.i453, i64* %arrayidx5.i.4.i240, align 16, !tbaa !3
  %90 = xor i64 %add.i.4.i451, -9223372036854775808
  %xor2.i.i.4.i455 = and i64 %90, %89
  %xor.i23.i.4.i456 = xor i64 %add3.i.4.i453, %add.i.4.i451
  %xor1.i24.i.4.i457 = xor i64 %add.i.4.i451, %89
  %or.i25.i.4.i458 = or i64 %xor.i23.i.4.i456, %xor1.i24.i.4.i457
  %xor2.i26.i.4.i459 = xor i64 %or.i25.i.4.i458, %add3.i.4.i453
  %shr.i30.i.4.i460 = or i64 %xor2.i26.i.4.i459, %xor2.i.i.4.i455
  %or29.i.4.i461 = lshr i64 %shr.i30.i.4.i460, 63
  %91 = load i64, i64* %arrayidx.i.5.i355, align 8, !tbaa !3
  %add.i.5.i463 = add i64 %or29.i.4.i461, %91
  %add3.i.5.i465 = add i64 %add.i.5.i463, %91
  store i64 %add3.i.5.i465, i64* %arrayidx5.i.5.i252, align 8, !tbaa !3
  %92 = xor i64 %add.i.5.i463, -9223372036854775808
  %xor2.i.i.5.i467 = and i64 %92, %91
  %xor.i23.i.5.i468 = xor i64 %add3.i.5.i465, %add.i.5.i463
  %xor1.i24.i.5.i469 = xor i64 %add.i.5.i463, %91
  %or.i25.i.5.i470 = or i64 %xor.i23.i.5.i468, %xor1.i24.i.5.i469
  %xor2.i26.i.5.i471 = xor i64 %or.i25.i.5.i470, %add3.i.5.i465
  %shr.i30.i.5.i472 = or i64 %xor2.i26.i.5.i471, %xor2.i.i.5.i467
  %or29.i.5.i473 = lshr i64 %shr.i30.i.5.i472, 63
  %93 = load i64, i64* %arrayidx.i.6.i367, align 16, !tbaa !3
  %add.i.6.i475 = add i64 %or29.i.5.i473, %93
  %add3.i.6.i477 = add i64 %add.i.6.i475, %93
  store i64 %add3.i.6.i477, i64* %arrayidx5.i.6.i264, align 16, !tbaa !3
  %94 = xor i64 %add.i.6.i475, -9223372036854775808
  %xor2.i.i.6.i479 = and i64 %94, %93
  %xor.i23.i.6.i480 = xor i64 %add3.i.6.i477, %add.i.6.i475
  %xor1.i24.i.6.i481 = xor i64 %add.i.6.i475, %93
  %or.i25.i.6.i482 = or i64 %xor.i23.i.6.i480, %xor1.i24.i.6.i481
  %xor2.i26.i.6.i483 = xor i64 %or.i25.i.6.i482, %add3.i.6.i477
  %shr.i30.i.6.i484 = or i64 %xor2.i26.i.6.i483, %xor2.i.i.6.i479
  %or29.i.6.i485 = lshr i64 %shr.i30.i.6.i484, 63
  %95 = load i64, i64* %arrayidx.i.7.i379, align 8, !tbaa !3
  %add.i.7.i487 = add i64 %or29.i.6.i485, %95
  %add3.i.7.i489 = add i64 %add.i.7.i487, %95
  store i64 %add3.i.7.i489, i64* %arrayidx5.i.7.i276, align 8, !tbaa !3
  %96 = xor i64 %add.i.7.i487, -9223372036854775808
  %xor2.i.i.7.i491 = and i64 %96, %95
  %xor.i23.i.7.i492 = xor i64 %add3.i.7.i489, %add.i.7.i487
  %xor1.i24.i.7.i493 = xor i64 %add.i.7.i487, %95
  %or.i25.i.7.i494 = or i64 %xor.i23.i.7.i492, %xor1.i24.i.7.i493
  %xor2.i26.i.7.i495 = xor i64 %or.i25.i.7.i494, %add3.i.7.i489
  %shr.i30.i.7.i496 = or i64 %xor2.i26.i.7.i495, %xor2.i.i.7.i491
  %or29.i.7.i497 = lshr i64 %shr.i30.i.7.i496, 63
  %97 = load i64, i64* %arrayidx.i.8.i391, align 16, !tbaa !3
  %add.i.8.i499 = add i64 %or29.i.7.i497, %97
  %add3.i.8.i501 = add i64 %add.i.8.i499, %97
  store i64 %add3.i.8.i501, i64* %arrayidx5.i.8.i288, align 16, !tbaa !3
  %98 = xor i64 %add.i.8.i499, -9223372036854775808
  %xor2.i.i.8.i503 = and i64 %98, %97
  %xor.i23.i.8.i504 = xor i64 %add3.i.8.i501, %add.i.8.i499
  %xor1.i24.i.8.i505 = xor i64 %add.i.8.i499, %97
  %or.i25.i.8.i506 = or i64 %xor.i23.i.8.i504, %xor1.i24.i.8.i505
  %xor2.i26.i.8.i507 = xor i64 %or.i25.i.8.i506, %add3.i.8.i501
  %shr.i30.i.8.i508 = or i64 %xor2.i26.i.8.i507, %xor2.i.i.8.i503
  %or29.i.8.i509 = lshr i64 %shr.i30.i.8.i508, 63
  %99 = load i64, i64* %arrayidx.i.9.i403, align 8, !tbaa !3
  %factor943 = shl i64 %99, 1
  %add3.i.9.i513 = or i64 %or29.i.8.i509, %factor943
  store i64 %add3.i.9.i513, i64* %arrayidx5.i.9.i300, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay4.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay10.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay1)
  call void @fpadd610(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i) #10
  call void @fpadd610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i) #10
  call void @fpadd610(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay17.i) #10
  call void @fpadd610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay22.i) #10
  call void @fpsub610(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay17.i) #10
  call void @fpsub610(i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %100 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %101 = load i64, i64* %arraydecay22.i, align 16, !tbaa !3
  %add3.i.i622 = add i64 %101, %100
  store i64 %add3.i.i622, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i623 = xor i64 %add3.i.i622, %100
  %xor1.i24.i.i624 = xor i64 %101, %100
  %or.i25.i.i625 = or i64 %xor.i23.i.i623, %xor1.i24.i.i624
  %xor2.i26.i.i626 = xor i64 %or.i25.i.i625, %add3.i.i622
  %or29.i.i627 = lshr i64 %xor2.i26.i.i626, 63
  %arrayidx.i.1.i628 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 1
  %102 = load i64, i64* %arrayidx.i.1.i628, align 8, !tbaa !3
  %add.i.1.i629 = add i64 %or29.i.i627, %102
  %arrayidx2.i.1.i630 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 1
  %103 = load i64, i64* %arrayidx2.i.1.i630, align 8, !tbaa !3
  %add3.i.1.i631 = add i64 %add.i.1.i629, %103
  store i64 %add3.i.1.i631, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %104 = xor i64 %add.i.1.i629, -9223372036854775808
  %xor2.i.i.1.i633 = and i64 %104, %102
  %xor.i23.i.1.i634 = xor i64 %add3.i.1.i631, %add.i.1.i629
  %xor1.i24.i.1.i635 = xor i64 %add.i.1.i629, %103
  %or.i25.i.1.i636 = or i64 %xor.i23.i.1.i634, %xor1.i24.i.1.i635
  %xor2.i26.i.1.i637 = xor i64 %or.i25.i.1.i636, %add3.i.1.i631
  %shr.i30.i.1.i638 = or i64 %xor2.i26.i.1.i637, %xor2.i.i.1.i633
  %or29.i.1.i639 = lshr i64 %shr.i30.i.1.i638, 63
  %arrayidx.i.2.i640 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 2
  %105 = load i64, i64* %arrayidx.i.2.i640, align 16, !tbaa !3
  %add.i.2.i641 = add i64 %or29.i.1.i639, %105
  %arrayidx2.i.2.i642 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 2
  %106 = load i64, i64* %arrayidx2.i.2.i642, align 16, !tbaa !3
  %add3.i.2.i643 = add i64 %add.i.2.i641, %106
  store i64 %add3.i.2.i643, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %107 = xor i64 %add.i.2.i641, -9223372036854775808
  %xor2.i.i.2.i645 = and i64 %107, %105
  %xor.i23.i.2.i646 = xor i64 %add3.i.2.i643, %add.i.2.i641
  %xor1.i24.i.2.i647 = xor i64 %add.i.2.i641, %106
  %or.i25.i.2.i648 = or i64 %xor.i23.i.2.i646, %xor1.i24.i.2.i647
  %xor2.i26.i.2.i649 = xor i64 %or.i25.i.2.i648, %add3.i.2.i643
  %shr.i30.i.2.i650 = or i64 %xor2.i26.i.2.i649, %xor2.i.i.2.i645
  %or29.i.2.i651 = lshr i64 %shr.i30.i.2.i650, 63
  %arrayidx.i.3.i652 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 3
  %108 = load i64, i64* %arrayidx.i.3.i652, align 8, !tbaa !3
  %add.i.3.i653 = add i64 %or29.i.2.i651, %108
  %arrayidx2.i.3.i654 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 3
  %109 = load i64, i64* %arrayidx2.i.3.i654, align 8, !tbaa !3
  %add3.i.3.i655 = add i64 %add.i.3.i653, %109
  store i64 %add3.i.3.i655, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %110 = xor i64 %add.i.3.i653, -9223372036854775808
  %xor2.i.i.3.i657 = and i64 %110, %108
  %xor.i23.i.3.i658 = xor i64 %add3.i.3.i655, %add.i.3.i653
  %xor1.i24.i.3.i659 = xor i64 %add.i.3.i653, %109
  %or.i25.i.3.i660 = or i64 %xor.i23.i.3.i658, %xor1.i24.i.3.i659
  %xor2.i26.i.3.i661 = xor i64 %or.i25.i.3.i660, %add3.i.3.i655
  %shr.i30.i.3.i662 = or i64 %xor2.i26.i.3.i661, %xor2.i.i.3.i657
  %or29.i.3.i663 = lshr i64 %shr.i30.i.3.i662, 63
  %arrayidx.i.4.i664 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 4
  %111 = load i64, i64* %arrayidx.i.4.i664, align 16, !tbaa !3
  %add.i.4.i665 = add i64 %or29.i.3.i663, %111
  %arrayidx2.i.4.i666 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 4
  %112 = load i64, i64* %arrayidx2.i.4.i666, align 16, !tbaa !3
  %add3.i.4.i667 = add i64 %add.i.4.i665, %112
  store i64 %add3.i.4.i667, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %113 = xor i64 %add.i.4.i665, -9223372036854775808
  %xor2.i.i.4.i669 = and i64 %113, %111
  %xor.i23.i.4.i670 = xor i64 %add3.i.4.i667, %add.i.4.i665
  %xor1.i24.i.4.i671 = xor i64 %add.i.4.i665, %112
  %or.i25.i.4.i672 = or i64 %xor.i23.i.4.i670, %xor1.i24.i.4.i671
  %xor2.i26.i.4.i673 = xor i64 %or.i25.i.4.i672, %add3.i.4.i667
  %shr.i30.i.4.i674 = or i64 %xor2.i26.i.4.i673, %xor2.i.i.4.i669
  %or29.i.4.i675 = lshr i64 %shr.i30.i.4.i674, 63
  %arrayidx.i.5.i676 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 5
  %114 = load i64, i64* %arrayidx.i.5.i676, align 8, !tbaa !3
  %add.i.5.i677 = add i64 %or29.i.4.i675, %114
  %arrayidx2.i.5.i678 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 5
  %115 = load i64, i64* %arrayidx2.i.5.i678, align 8, !tbaa !3
  %add3.i.5.i679 = add i64 %add.i.5.i677, %115
  store i64 %add3.i.5.i679, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %116 = xor i64 %add.i.5.i677, -9223372036854775808
  %xor2.i.i.5.i681 = and i64 %116, %114
  %xor.i23.i.5.i682 = xor i64 %add3.i.5.i679, %add.i.5.i677
  %xor1.i24.i.5.i683 = xor i64 %add.i.5.i677, %115
  %or.i25.i.5.i684 = or i64 %xor.i23.i.5.i682, %xor1.i24.i.5.i683
  %xor2.i26.i.5.i685 = xor i64 %or.i25.i.5.i684, %add3.i.5.i679
  %shr.i30.i.5.i686 = or i64 %xor2.i26.i.5.i685, %xor2.i.i.5.i681
  %or29.i.5.i687 = lshr i64 %shr.i30.i.5.i686, 63
  %arrayidx.i.6.i688 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 6
  %117 = load i64, i64* %arrayidx.i.6.i688, align 16, !tbaa !3
  %add.i.6.i689 = add i64 %or29.i.5.i687, %117
  %arrayidx2.i.6.i690 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 6
  %118 = load i64, i64* %arrayidx2.i.6.i690, align 16, !tbaa !3
  %add3.i.6.i691 = add i64 %add.i.6.i689, %118
  store i64 %add3.i.6.i691, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %119 = xor i64 %add.i.6.i689, -9223372036854775808
  %xor2.i.i.6.i693 = and i64 %119, %117
  %xor.i23.i.6.i694 = xor i64 %add3.i.6.i691, %add.i.6.i689
  %xor1.i24.i.6.i695 = xor i64 %add.i.6.i689, %118
  %or.i25.i.6.i696 = or i64 %xor.i23.i.6.i694, %xor1.i24.i.6.i695
  %xor2.i26.i.6.i697 = xor i64 %or.i25.i.6.i696, %add3.i.6.i691
  %shr.i30.i.6.i698 = or i64 %xor2.i26.i.6.i697, %xor2.i.i.6.i693
  %or29.i.6.i699 = lshr i64 %shr.i30.i.6.i698, 63
  %arrayidx.i.7.i700 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 7
  %120 = load i64, i64* %arrayidx.i.7.i700, align 8, !tbaa !3
  %add.i.7.i701 = add i64 %or29.i.6.i699, %120
  %arrayidx2.i.7.i702 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 7
  %121 = load i64, i64* %arrayidx2.i.7.i702, align 8, !tbaa !3
  %add3.i.7.i703 = add i64 %add.i.7.i701, %121
  store i64 %add3.i.7.i703, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %122 = xor i64 %add.i.7.i701, -9223372036854775808
  %xor2.i.i.7.i705 = and i64 %122, %120
  %xor.i23.i.7.i706 = xor i64 %add3.i.7.i703, %add.i.7.i701
  %xor1.i24.i.7.i707 = xor i64 %add.i.7.i701, %121
  %or.i25.i.7.i708 = or i64 %xor.i23.i.7.i706, %xor1.i24.i.7.i707
  %xor2.i26.i.7.i709 = xor i64 %or.i25.i.7.i708, %add3.i.7.i703
  %shr.i30.i.7.i710 = or i64 %xor2.i26.i.7.i709, %xor2.i.i.7.i705
  %or29.i.7.i711 = lshr i64 %shr.i30.i.7.i710, 63
  %arrayidx.i.8.i712 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 8
  %123 = load i64, i64* %arrayidx.i.8.i712, align 16, !tbaa !3
  %add.i.8.i713 = add i64 %or29.i.7.i711, %123
  %arrayidx2.i.8.i714 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 8
  %124 = load i64, i64* %arrayidx2.i.8.i714, align 16, !tbaa !3
  %add3.i.8.i715 = add i64 %add.i.8.i713, %124
  store i64 %add3.i.8.i715, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %125 = xor i64 %add.i.8.i713, -9223372036854775808
  %xor2.i.i.8.i717 = and i64 %125, %123
  %xor.i23.i.8.i718 = xor i64 %add3.i.8.i715, %add.i.8.i713
  %xor1.i24.i.8.i719 = xor i64 %add.i.8.i713, %124
  %or.i25.i.8.i720 = or i64 %xor.i23.i.8.i718, %xor1.i24.i.8.i719
  %xor2.i26.i.8.i721 = xor i64 %or.i25.i.8.i720, %add3.i.8.i715
  %shr.i30.i.8.i722 = or i64 %xor2.i26.i.8.i721, %xor2.i.i.8.i717
  %or29.i.8.i723 = lshr i64 %shr.i30.i.8.i722, 63
  %arrayidx.i.9.i724 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 0, i64 9
  %126 = load i64, i64* %arrayidx.i.9.i724, align 8, !tbaa !3
  %arrayidx2.i.9.i726 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t1, i64 0, i64 1, i64 9
  %127 = load i64, i64* %arrayidx2.i.9.i726, align 8, !tbaa !3
  %add.i.9.i725 = add i64 %127, %126
  %add3.i.9.i727 = add i64 %add.i.9.i725, %or29.i.8.i723
  store i64 %add3.i.9.i727, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay17.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay8.i) #10
  %128 = load i64, i64* %arraydecay17.i, align 16, !tbaa !3
  %add3.i.i836 = shl i64 %128, 1
  store i64 %add3.i.i836, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i841 = lshr i64 %128, 63
  %129 = load i64, i64* %arrayidx.i.1.i628, align 8, !tbaa !3
  %add.i.1.i843 = add i64 %129, %or29.i.i841
  %add3.i.1.i845 = add i64 %add.i.1.i843, %129
  store i64 %add3.i.1.i845, i64* %arrayidx5.i.1.i204, align 8, !tbaa !3
  %130 = xor i64 %add.i.1.i843, -9223372036854775808
  %xor2.i.i.1.i847 = and i64 %130, %129
  %xor.i23.i.1.i848 = xor i64 %add3.i.1.i845, %add.i.1.i843
  %xor1.i24.i.1.i849 = xor i64 %add.i.1.i843, %129
  %or.i25.i.1.i850 = or i64 %xor.i23.i.1.i848, %xor1.i24.i.1.i849
  %xor2.i26.i.1.i851 = xor i64 %or.i25.i.1.i850, %add3.i.1.i845
  %shr.i30.i.1.i852 = or i64 %xor2.i26.i.1.i851, %xor2.i.i.1.i847
  %or29.i.1.i853 = lshr i64 %shr.i30.i.1.i852, 63
  %131 = load i64, i64* %arrayidx.i.2.i640, align 16, !tbaa !3
  %add.i.2.i855 = add i64 %or29.i.1.i853, %131
  %add3.i.2.i857 = add i64 %add.i.2.i855, %131
  store i64 %add3.i.2.i857, i64* %arrayidx5.i.2.i216, align 16, !tbaa !3
  %132 = xor i64 %add.i.2.i855, -9223372036854775808
  %xor2.i.i.2.i859 = and i64 %132, %131
  %xor.i23.i.2.i860 = xor i64 %add3.i.2.i857, %add.i.2.i855
  %xor1.i24.i.2.i861 = xor i64 %add.i.2.i855, %131
  %or.i25.i.2.i862 = or i64 %xor.i23.i.2.i860, %xor1.i24.i.2.i861
  %xor2.i26.i.2.i863 = xor i64 %or.i25.i.2.i862, %add3.i.2.i857
  %shr.i30.i.2.i864 = or i64 %xor2.i26.i.2.i863, %xor2.i.i.2.i859
  %or29.i.2.i865 = lshr i64 %shr.i30.i.2.i864, 63
  %133 = load i64, i64* %arrayidx.i.3.i652, align 8, !tbaa !3
  %add.i.3.i867 = add i64 %or29.i.2.i865, %133
  %add3.i.3.i869 = add i64 %add.i.3.i867, %133
  store i64 %add3.i.3.i869, i64* %arrayidx5.i.3.i228, align 8, !tbaa !3
  %134 = xor i64 %add.i.3.i867, -9223372036854775808
  %xor2.i.i.3.i871 = and i64 %134, %133
  %xor.i23.i.3.i872 = xor i64 %add3.i.3.i869, %add.i.3.i867
  %xor1.i24.i.3.i873 = xor i64 %add.i.3.i867, %133
  %or.i25.i.3.i874 = or i64 %xor.i23.i.3.i872, %xor1.i24.i.3.i873
  %xor2.i26.i.3.i875 = xor i64 %or.i25.i.3.i874, %add3.i.3.i869
  %shr.i30.i.3.i876 = or i64 %xor2.i26.i.3.i875, %xor2.i.i.3.i871
  %or29.i.3.i877 = lshr i64 %shr.i30.i.3.i876, 63
  %135 = load i64, i64* %arrayidx.i.4.i664, align 16, !tbaa !3
  %add.i.4.i879 = add i64 %or29.i.3.i877, %135
  %add3.i.4.i881 = add i64 %add.i.4.i879, %135
  store i64 %add3.i.4.i881, i64* %arrayidx5.i.4.i240, align 16, !tbaa !3
  %136 = xor i64 %add.i.4.i879, -9223372036854775808
  %xor2.i.i.4.i883 = and i64 %136, %135
  %xor.i23.i.4.i884 = xor i64 %add3.i.4.i881, %add.i.4.i879
  %xor1.i24.i.4.i885 = xor i64 %add.i.4.i879, %135
  %or.i25.i.4.i886 = or i64 %xor.i23.i.4.i884, %xor1.i24.i.4.i885
  %xor2.i26.i.4.i887 = xor i64 %or.i25.i.4.i886, %add3.i.4.i881
  %shr.i30.i.4.i888 = or i64 %xor2.i26.i.4.i887, %xor2.i.i.4.i883
  %or29.i.4.i889 = lshr i64 %shr.i30.i.4.i888, 63
  %137 = load i64, i64* %arrayidx.i.5.i676, align 8, !tbaa !3
  %add.i.5.i891 = add i64 %or29.i.4.i889, %137
  %add3.i.5.i893 = add i64 %add.i.5.i891, %137
  store i64 %add3.i.5.i893, i64* %arrayidx5.i.5.i252, align 8, !tbaa !3
  %138 = xor i64 %add.i.5.i891, -9223372036854775808
  %xor2.i.i.5.i895 = and i64 %138, %137
  %xor.i23.i.5.i896 = xor i64 %add3.i.5.i893, %add.i.5.i891
  %xor1.i24.i.5.i897 = xor i64 %add.i.5.i891, %137
  %or.i25.i.5.i898 = or i64 %xor.i23.i.5.i896, %xor1.i24.i.5.i897
  %xor2.i26.i.5.i899 = xor i64 %or.i25.i.5.i898, %add3.i.5.i893
  %shr.i30.i.5.i900 = or i64 %xor2.i26.i.5.i899, %xor2.i.i.5.i895
  %or29.i.5.i901 = lshr i64 %shr.i30.i.5.i900, 63
  %139 = load i64, i64* %arrayidx.i.6.i688, align 16, !tbaa !3
  %add.i.6.i903 = add i64 %or29.i.5.i901, %139
  %add3.i.6.i905 = add i64 %add.i.6.i903, %139
  store i64 %add3.i.6.i905, i64* %arrayidx5.i.6.i264, align 16, !tbaa !3
  %140 = xor i64 %add.i.6.i903, -9223372036854775808
  %xor2.i.i.6.i907 = and i64 %140, %139
  %xor.i23.i.6.i908 = xor i64 %add3.i.6.i905, %add.i.6.i903
  %xor1.i24.i.6.i909 = xor i64 %add.i.6.i903, %139
  %or.i25.i.6.i910 = or i64 %xor.i23.i.6.i908, %xor1.i24.i.6.i909
  %xor2.i26.i.6.i911 = xor i64 %or.i25.i.6.i910, %add3.i.6.i905
  %shr.i30.i.6.i912 = or i64 %xor2.i26.i.6.i911, %xor2.i.i.6.i907
  %or29.i.6.i913 = lshr i64 %shr.i30.i.6.i912, 63
  %141 = load i64, i64* %arrayidx.i.7.i700, align 8, !tbaa !3
  %add.i.7.i915 = add i64 %or29.i.6.i913, %141
  %add3.i.7.i917 = add i64 %add.i.7.i915, %141
  store i64 %add3.i.7.i917, i64* %arrayidx5.i.7.i276, align 8, !tbaa !3
  %142 = xor i64 %add.i.7.i915, -9223372036854775808
  %xor2.i.i.7.i919 = and i64 %142, %141
  %xor.i23.i.7.i920 = xor i64 %add3.i.7.i917, %add.i.7.i915
  %xor1.i24.i.7.i921 = xor i64 %add.i.7.i915, %141
  %or.i25.i.7.i922 = or i64 %xor.i23.i.7.i920, %xor1.i24.i.7.i921
  %xor2.i26.i.7.i923 = xor i64 %or.i25.i.7.i922, %add3.i.7.i917
  %shr.i30.i.7.i924 = or i64 %xor2.i26.i.7.i923, %xor2.i.i.7.i919
  %or29.i.7.i925 = lshr i64 %shr.i30.i.7.i924, 63
  %143 = load i64, i64* %arrayidx.i.8.i712, align 16, !tbaa !3
  %add.i.8.i927 = add i64 %or29.i.7.i925, %143
  %add3.i.8.i929 = add i64 %add.i.8.i927, %143
  store i64 %add3.i.8.i929, i64* %arrayidx5.i.8.i288, align 16, !tbaa !3
  %144 = xor i64 %add.i.8.i927, -9223372036854775808
  %xor2.i.i.8.i931 = and i64 %144, %143
  %xor.i23.i.8.i932 = xor i64 %add3.i.8.i929, %add.i.8.i927
  %xor1.i24.i.8.i933 = xor i64 %add.i.8.i927, %143
  %or.i25.i.8.i934 = or i64 %xor.i23.i.8.i932, %xor1.i24.i.8.i933
  %xor2.i26.i.8.i935 = xor i64 %or.i25.i.8.i934, %add3.i.8.i929
  %shr.i30.i.8.i936 = or i64 %xor2.i26.i.8.i935, %xor2.i.i.8.i931
  %or29.i.8.i937 = lshr i64 %shr.i30.i.8.i936, 63
  %145 = load i64, i64* %arrayidx.i.9.i724, align 8, !tbaa !3
  %factor944 = shl i64 %145, 1
  %add3.i.9.i941 = or i64 %or29.i.8.i937, %factor944
  store i64 %add3.i.9.i941, i64* %arrayidx5.i.9.i300, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay3, [10 x i64]* nonnull %arraydecay11, [10 x i64]* nonnull %arraydecay3)
  call void @fpadd610(i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay17.i80) #10
  call void @fpadd610(i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay22.i82) #10
  call void @fpadd610(i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay17.i80) #10
  call void @fpadd610(i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay22.i82) #10
  call void @fpsub610(i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay17.i80) #10
  call void @fpsub610(i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay22.i82) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %4) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %6) #10
  %146 = load i64, i64* %arraydecay17.i80, align 16, !tbaa !3
  %147 = load i64, i64* %arraydecay22.i82, align 16, !tbaa !3
  %add3.i.i729 = add i64 %147, %146
  store i64 %add3.i.i729, i64* %arraydecay3.i, align 16, !tbaa !3
  %xor.i23.i.i730 = xor i64 %add3.i.i729, %146
  %xor1.i24.i.i731 = xor i64 %147, %146
  %or.i25.i.i732 = or i64 %xor.i23.i.i730, %xor1.i24.i.i731
  %xor2.i26.i.i733 = xor i64 %or.i25.i.i732, %add3.i.i729
  %or29.i.i734 = lshr i64 %xor2.i26.i.i733, 63
  %arrayidx.i.1.i735 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 1
  %148 = load i64, i64* %arrayidx.i.1.i735, align 8, !tbaa !3
  %add.i.1.i736 = add i64 %or29.i.i734, %148
  %arrayidx2.i.1.i737 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 1
  %149 = load i64, i64* %arrayidx2.i.1.i737, align 8, !tbaa !3
  %add3.i.1.i738 = add i64 %add.i.1.i736, %149
  store i64 %add3.i.1.i738, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %150 = xor i64 %add.i.1.i736, -9223372036854775808
  %xor2.i.i.1.i740 = and i64 %150, %148
  %xor.i23.i.1.i741 = xor i64 %add3.i.1.i738, %add.i.1.i736
  %xor1.i24.i.1.i742 = xor i64 %add.i.1.i736, %149
  %or.i25.i.1.i743 = or i64 %xor.i23.i.1.i741, %xor1.i24.i.1.i742
  %xor2.i26.i.1.i744 = xor i64 %or.i25.i.1.i743, %add3.i.1.i738
  %shr.i30.i.1.i745 = or i64 %xor2.i26.i.1.i744, %xor2.i.i.1.i740
  %or29.i.1.i746 = lshr i64 %shr.i30.i.1.i745, 63
  %arrayidx.i.2.i747 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 2
  %151 = load i64, i64* %arrayidx.i.2.i747, align 16, !tbaa !3
  %add.i.2.i748 = add i64 %or29.i.1.i746, %151
  %arrayidx2.i.2.i749 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 2
  %152 = load i64, i64* %arrayidx2.i.2.i749, align 16, !tbaa !3
  %add3.i.2.i750 = add i64 %add.i.2.i748, %152
  store i64 %add3.i.2.i750, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %153 = xor i64 %add.i.2.i748, -9223372036854775808
  %xor2.i.i.2.i752 = and i64 %153, %151
  %xor.i23.i.2.i753 = xor i64 %add3.i.2.i750, %add.i.2.i748
  %xor1.i24.i.2.i754 = xor i64 %add.i.2.i748, %152
  %or.i25.i.2.i755 = or i64 %xor.i23.i.2.i753, %xor1.i24.i.2.i754
  %xor2.i26.i.2.i756 = xor i64 %or.i25.i.2.i755, %add3.i.2.i750
  %shr.i30.i.2.i757 = or i64 %xor2.i26.i.2.i756, %xor2.i.i.2.i752
  %or29.i.2.i758 = lshr i64 %shr.i30.i.2.i757, 63
  %arrayidx.i.3.i759 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 3
  %154 = load i64, i64* %arrayidx.i.3.i759, align 8, !tbaa !3
  %add.i.3.i760 = add i64 %or29.i.2.i758, %154
  %arrayidx2.i.3.i761 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 3
  %155 = load i64, i64* %arrayidx2.i.3.i761, align 8, !tbaa !3
  %add3.i.3.i762 = add i64 %add.i.3.i760, %155
  store i64 %add3.i.3.i762, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %156 = xor i64 %add.i.3.i760, -9223372036854775808
  %xor2.i.i.3.i764 = and i64 %156, %154
  %xor.i23.i.3.i765 = xor i64 %add3.i.3.i762, %add.i.3.i760
  %xor1.i24.i.3.i766 = xor i64 %add.i.3.i760, %155
  %or.i25.i.3.i767 = or i64 %xor.i23.i.3.i765, %xor1.i24.i.3.i766
  %xor2.i26.i.3.i768 = xor i64 %or.i25.i.3.i767, %add3.i.3.i762
  %shr.i30.i.3.i769 = or i64 %xor2.i26.i.3.i768, %xor2.i.i.3.i764
  %or29.i.3.i770 = lshr i64 %shr.i30.i.3.i769, 63
  %arrayidx.i.4.i771 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 4
  %157 = load i64, i64* %arrayidx.i.4.i771, align 16, !tbaa !3
  %add.i.4.i772 = add i64 %or29.i.3.i770, %157
  %arrayidx2.i.4.i773 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 4
  %158 = load i64, i64* %arrayidx2.i.4.i773, align 16, !tbaa !3
  %add3.i.4.i774 = add i64 %add.i.4.i772, %158
  store i64 %add3.i.4.i774, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %159 = xor i64 %add.i.4.i772, -9223372036854775808
  %xor2.i.i.4.i776 = and i64 %159, %157
  %xor.i23.i.4.i777 = xor i64 %add3.i.4.i774, %add.i.4.i772
  %xor1.i24.i.4.i778 = xor i64 %add.i.4.i772, %158
  %or.i25.i.4.i779 = or i64 %xor.i23.i.4.i777, %xor1.i24.i.4.i778
  %xor2.i26.i.4.i780 = xor i64 %or.i25.i.4.i779, %add3.i.4.i774
  %shr.i30.i.4.i781 = or i64 %xor2.i26.i.4.i780, %xor2.i.i.4.i776
  %or29.i.4.i782 = lshr i64 %shr.i30.i.4.i781, 63
  %arrayidx.i.5.i783 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 5
  %160 = load i64, i64* %arrayidx.i.5.i783, align 8, !tbaa !3
  %add.i.5.i784 = add i64 %or29.i.4.i782, %160
  %arrayidx2.i.5.i785 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 5
  %161 = load i64, i64* %arrayidx2.i.5.i785, align 8, !tbaa !3
  %add3.i.5.i786 = add i64 %add.i.5.i784, %161
  store i64 %add3.i.5.i786, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %162 = xor i64 %add.i.5.i784, -9223372036854775808
  %xor2.i.i.5.i788 = and i64 %162, %160
  %xor.i23.i.5.i789 = xor i64 %add3.i.5.i786, %add.i.5.i784
  %xor1.i24.i.5.i790 = xor i64 %add.i.5.i784, %161
  %or.i25.i.5.i791 = or i64 %xor.i23.i.5.i789, %xor1.i24.i.5.i790
  %xor2.i26.i.5.i792 = xor i64 %or.i25.i.5.i791, %add3.i.5.i786
  %shr.i30.i.5.i793 = or i64 %xor2.i26.i.5.i792, %xor2.i.i.5.i788
  %or29.i.5.i794 = lshr i64 %shr.i30.i.5.i793, 63
  %arrayidx.i.6.i795 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 6
  %163 = load i64, i64* %arrayidx.i.6.i795, align 16, !tbaa !3
  %add.i.6.i796 = add i64 %or29.i.5.i794, %163
  %arrayidx2.i.6.i797 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 6
  %164 = load i64, i64* %arrayidx2.i.6.i797, align 16, !tbaa !3
  %add3.i.6.i798 = add i64 %add.i.6.i796, %164
  store i64 %add3.i.6.i798, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %165 = xor i64 %add.i.6.i796, -9223372036854775808
  %xor2.i.i.6.i800 = and i64 %165, %163
  %xor.i23.i.6.i801 = xor i64 %add3.i.6.i798, %add.i.6.i796
  %xor1.i24.i.6.i802 = xor i64 %add.i.6.i796, %164
  %or.i25.i.6.i803 = or i64 %xor.i23.i.6.i801, %xor1.i24.i.6.i802
  %xor2.i26.i.6.i804 = xor i64 %or.i25.i.6.i803, %add3.i.6.i798
  %shr.i30.i.6.i805 = or i64 %xor2.i26.i.6.i804, %xor2.i.i.6.i800
  %or29.i.6.i806 = lshr i64 %shr.i30.i.6.i805, 63
  %arrayidx.i.7.i807 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 7
  %166 = load i64, i64* %arrayidx.i.7.i807, align 8, !tbaa !3
  %add.i.7.i808 = add i64 %or29.i.6.i806, %166
  %arrayidx2.i.7.i809 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 7
  %167 = load i64, i64* %arrayidx2.i.7.i809, align 8, !tbaa !3
  %add3.i.7.i810 = add i64 %add.i.7.i808, %167
  store i64 %add3.i.7.i810, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %168 = xor i64 %add.i.7.i808, -9223372036854775808
  %xor2.i.i.7.i812 = and i64 %168, %166
  %xor.i23.i.7.i813 = xor i64 %add3.i.7.i810, %add.i.7.i808
  %xor1.i24.i.7.i814 = xor i64 %add.i.7.i808, %167
  %or.i25.i.7.i815 = or i64 %xor.i23.i.7.i813, %xor1.i24.i.7.i814
  %xor2.i26.i.7.i816 = xor i64 %or.i25.i.7.i815, %add3.i.7.i810
  %shr.i30.i.7.i817 = or i64 %xor2.i26.i.7.i816, %xor2.i.i.7.i812
  %or29.i.7.i818 = lshr i64 %shr.i30.i.7.i817, 63
  %arrayidx.i.8.i819 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 8
  %169 = load i64, i64* %arrayidx.i.8.i819, align 16, !tbaa !3
  %add.i.8.i820 = add i64 %or29.i.7.i818, %169
  %arrayidx2.i.8.i821 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 8
  %170 = load i64, i64* %arrayidx2.i.8.i821, align 16, !tbaa !3
  %add3.i.8.i822 = add i64 %add.i.8.i820, %170
  store i64 %add3.i.8.i822, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %171 = xor i64 %add.i.8.i820, -9223372036854775808
  %xor2.i.i.8.i824 = and i64 %171, %169
  %xor.i23.i.8.i825 = xor i64 %add3.i.8.i822, %add.i.8.i820
  %xor1.i24.i.8.i826 = xor i64 %add.i.8.i820, %170
  %or.i25.i.8.i827 = or i64 %xor.i23.i.8.i825, %xor1.i24.i.8.i826
  %xor2.i26.i.8.i828 = xor i64 %or.i25.i.8.i827, %add3.i.8.i822
  %shr.i30.i.8.i829 = or i64 %xor2.i26.i.8.i828, %xor2.i.i.8.i824
  %or29.i.8.i830 = lshr i64 %shr.i30.i.8.i829, 63
  %arrayidx.i.9.i831 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 0, i64 9
  %172 = load i64, i64* %arrayidx.i.9.i831, align 8, !tbaa !3
  %arrayidx2.i.9.i833 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t2, i64 0, i64 1, i64 9
  %173 = load i64, i64* %arrayidx2.i.9.i833, align 8, !tbaa !3
  %add.i.9.i832 = add i64 %173, %172
  %add3.i.9.i834 = add i64 %add.i.9.i832, %or29.i.8.i830
  store i64 %add3.i.9.i834, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p4(i64* nonnull %arraydecay17.i80, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay8.i) #10
  %174 = load i64, i64* %arraydecay17.i80, align 16, !tbaa !3
  %add3.i.i515 = shl i64 %174, 1
  store i64 %add3.i.i515, i64* %arraydecay13.i, align 16, !tbaa !3
  %or29.i.i520 = lshr i64 %174, 63
  %175 = load i64, i64* %arrayidx.i.1.i735, align 8, !tbaa !3
  %add.i.1.i522 = add i64 %175, %or29.i.i520
  %add3.i.1.i524 = add i64 %add.i.1.i522, %175
  store i64 %add3.i.1.i524, i64* %arrayidx5.i.1.i204, align 8, !tbaa !3
  %176 = xor i64 %add.i.1.i522, -9223372036854775808
  %xor2.i.i.1.i526 = and i64 %176, %175
  %xor.i23.i.1.i527 = xor i64 %add3.i.1.i524, %add.i.1.i522
  %xor1.i24.i.1.i528 = xor i64 %add.i.1.i522, %175
  %or.i25.i.1.i529 = or i64 %xor.i23.i.1.i527, %xor1.i24.i.1.i528
  %xor2.i26.i.1.i530 = xor i64 %or.i25.i.1.i529, %add3.i.1.i524
  %shr.i30.i.1.i531 = or i64 %xor2.i26.i.1.i530, %xor2.i.i.1.i526
  %or29.i.1.i532 = lshr i64 %shr.i30.i.1.i531, 63
  %177 = load i64, i64* %arrayidx.i.2.i747, align 16, !tbaa !3
  %add.i.2.i534 = add i64 %or29.i.1.i532, %177
  %add3.i.2.i536 = add i64 %add.i.2.i534, %177
  store i64 %add3.i.2.i536, i64* %arrayidx5.i.2.i216, align 16, !tbaa !3
  %178 = xor i64 %add.i.2.i534, -9223372036854775808
  %xor2.i.i.2.i538 = and i64 %178, %177
  %xor.i23.i.2.i539 = xor i64 %add3.i.2.i536, %add.i.2.i534
  %xor1.i24.i.2.i540 = xor i64 %add.i.2.i534, %177
  %or.i25.i.2.i541 = or i64 %xor.i23.i.2.i539, %xor1.i24.i.2.i540
  %xor2.i26.i.2.i542 = xor i64 %or.i25.i.2.i541, %add3.i.2.i536
  %shr.i30.i.2.i543 = or i64 %xor2.i26.i.2.i542, %xor2.i.i.2.i538
  %or29.i.2.i544 = lshr i64 %shr.i30.i.2.i543, 63
  %179 = load i64, i64* %arrayidx.i.3.i759, align 8, !tbaa !3
  %add.i.3.i546 = add i64 %or29.i.2.i544, %179
  %add3.i.3.i548 = add i64 %add.i.3.i546, %179
  store i64 %add3.i.3.i548, i64* %arrayidx5.i.3.i228, align 8, !tbaa !3
  %180 = xor i64 %add.i.3.i546, -9223372036854775808
  %xor2.i.i.3.i550 = and i64 %180, %179
  %xor.i23.i.3.i551 = xor i64 %add3.i.3.i548, %add.i.3.i546
  %xor1.i24.i.3.i552 = xor i64 %add.i.3.i546, %179
  %or.i25.i.3.i553 = or i64 %xor.i23.i.3.i551, %xor1.i24.i.3.i552
  %xor2.i26.i.3.i554 = xor i64 %or.i25.i.3.i553, %add3.i.3.i548
  %shr.i30.i.3.i555 = or i64 %xor2.i26.i.3.i554, %xor2.i.i.3.i550
  %or29.i.3.i556 = lshr i64 %shr.i30.i.3.i555, 63
  %181 = load i64, i64* %arrayidx.i.4.i771, align 16, !tbaa !3
  %add.i.4.i558 = add i64 %or29.i.3.i556, %181
  %add3.i.4.i560 = add i64 %add.i.4.i558, %181
  store i64 %add3.i.4.i560, i64* %arrayidx5.i.4.i240, align 16, !tbaa !3
  %182 = xor i64 %add.i.4.i558, -9223372036854775808
  %xor2.i.i.4.i562 = and i64 %182, %181
  %xor.i23.i.4.i563 = xor i64 %add3.i.4.i560, %add.i.4.i558
  %xor1.i24.i.4.i564 = xor i64 %add.i.4.i558, %181
  %or.i25.i.4.i565 = or i64 %xor.i23.i.4.i563, %xor1.i24.i.4.i564
  %xor2.i26.i.4.i566 = xor i64 %or.i25.i.4.i565, %add3.i.4.i560
  %shr.i30.i.4.i567 = or i64 %xor2.i26.i.4.i566, %xor2.i.i.4.i562
  %or29.i.4.i568 = lshr i64 %shr.i30.i.4.i567, 63
  %183 = load i64, i64* %arrayidx.i.5.i783, align 8, !tbaa !3
  %add.i.5.i570 = add i64 %or29.i.4.i568, %183
  %add3.i.5.i572 = add i64 %add.i.5.i570, %183
  store i64 %add3.i.5.i572, i64* %arrayidx5.i.5.i252, align 8, !tbaa !3
  %184 = xor i64 %add.i.5.i570, -9223372036854775808
  %xor2.i.i.5.i574 = and i64 %184, %183
  %xor.i23.i.5.i575 = xor i64 %add3.i.5.i572, %add.i.5.i570
  %xor1.i24.i.5.i576 = xor i64 %add.i.5.i570, %183
  %or.i25.i.5.i577 = or i64 %xor.i23.i.5.i575, %xor1.i24.i.5.i576
  %xor2.i26.i.5.i578 = xor i64 %or.i25.i.5.i577, %add3.i.5.i572
  %shr.i30.i.5.i579 = or i64 %xor2.i26.i.5.i578, %xor2.i.i.5.i574
  %or29.i.5.i580 = lshr i64 %shr.i30.i.5.i579, 63
  %185 = load i64, i64* %arrayidx.i.6.i795, align 16, !tbaa !3
  %add.i.6.i582 = add i64 %or29.i.5.i580, %185
  %add3.i.6.i584 = add i64 %add.i.6.i582, %185
  store i64 %add3.i.6.i584, i64* %arrayidx5.i.6.i264, align 16, !tbaa !3
  %186 = xor i64 %add.i.6.i582, -9223372036854775808
  %xor2.i.i.6.i586 = and i64 %186, %185
  %xor.i23.i.6.i587 = xor i64 %add3.i.6.i584, %add.i.6.i582
  %xor1.i24.i.6.i588 = xor i64 %add.i.6.i582, %185
  %or.i25.i.6.i589 = or i64 %xor.i23.i.6.i587, %xor1.i24.i.6.i588
  %xor2.i26.i.6.i590 = xor i64 %or.i25.i.6.i589, %add3.i.6.i584
  %shr.i30.i.6.i591 = or i64 %xor2.i26.i.6.i590, %xor2.i.i.6.i586
  %or29.i.6.i592 = lshr i64 %shr.i30.i.6.i591, 63
  %187 = load i64, i64* %arrayidx.i.7.i807, align 8, !tbaa !3
  %add.i.7.i594 = add i64 %or29.i.6.i592, %187
  %add3.i.7.i596 = add i64 %add.i.7.i594, %187
  store i64 %add3.i.7.i596, i64* %arrayidx5.i.7.i276, align 8, !tbaa !3
  %188 = xor i64 %add.i.7.i594, -9223372036854775808
  %xor2.i.i.7.i598 = and i64 %188, %187
  %xor.i23.i.7.i599 = xor i64 %add3.i.7.i596, %add.i.7.i594
  %xor1.i24.i.7.i600 = xor i64 %add.i.7.i594, %187
  %or.i25.i.7.i601 = or i64 %xor.i23.i.7.i599, %xor1.i24.i.7.i600
  %xor2.i26.i.7.i602 = xor i64 %or.i25.i.7.i601, %add3.i.7.i596
  %shr.i30.i.7.i603 = or i64 %xor2.i26.i.7.i602, %xor2.i.i.7.i598
  %or29.i.7.i604 = lshr i64 %shr.i30.i.7.i603, 63
  %189 = load i64, i64* %arrayidx.i.8.i819, align 16, !tbaa !3
  %add.i.8.i606 = add i64 %or29.i.7.i604, %189
  %add3.i.8.i608 = add i64 %add.i.8.i606, %189
  store i64 %add3.i.8.i608, i64* %arrayidx5.i.8.i288, align 16, !tbaa !3
  %190 = xor i64 %add.i.8.i606, -9223372036854775808
  %xor2.i.i.8.i610 = and i64 %190, %189
  %xor.i23.i.8.i611 = xor i64 %add3.i.8.i608, %add.i.8.i606
  %xor1.i24.i.8.i612 = xor i64 %add.i.8.i606, %189
  %or.i25.i.8.i613 = or i64 %xor.i23.i.8.i611, %xor1.i24.i.8.i612
  %xor2.i26.i.8.i614 = xor i64 %or.i25.i.8.i613, %add3.i.8.i608
  %shr.i30.i.8.i615 = or i64 %xor2.i26.i.8.i614, %xor2.i.i.8.i610
  %or29.i.8.i616 = lshr i64 %shr.i30.i.8.i615, 63
  %191 = load i64, i64* %arrayidx.i.9.i831, align 8, !tbaa !3
  %factor945 = shl i64 %191, 1
  %add3.i.9.i620 = or i64 %or29.i.8.i616, %factor945
  store i64 %add3.i.9.i620, i64* %arrayidx5.i.9.i300, align 8, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay3.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay17.i80) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay13.i, i64* nonnull %arraydecay22.i82, i64* nonnull %arraydecay.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i, i64* nonnull %arraydecay22.i82) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %4) #10
  %arraydecay59 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0
  call void @fp2mul610_mont([10 x i64]* %arraydecay, [10 x i64]* nonnull %arraydecay3, [10 x i64]* %arraydecay59)
  %arraydecay64 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 1, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay64)
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define void @xTPLe_fast(%struct.point_proj* nocapture readonly %P, %struct.point_proj* %Q, [10 x i64]* %A2, i32 %e) local_unnamed_addr #4 {
entry:
  %arrayidx.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 0
  %0 = load i64, i64* %arrayidx.i, align 8, !tbaa !3
  %arrayidx2.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 0
  store i64 %0, i64* %arrayidx2.i, align 8, !tbaa !3
  %arrayidx.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 1
  %1 = load i64, i64* %arrayidx.i.1, align 8, !tbaa !3
  %arrayidx2.i.1 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 1
  store i64 %1, i64* %arrayidx2.i.1, align 8, !tbaa !3
  %arrayidx.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 2
  %2 = load i64, i64* %arrayidx.i.2, align 8, !tbaa !3
  %arrayidx2.i.2 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 2
  store i64 %2, i64* %arrayidx2.i.2, align 8, !tbaa !3
  %arrayidx.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 3
  %3 = load i64, i64* %arrayidx.i.3, align 8, !tbaa !3
  %arrayidx2.i.3 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 3
  store i64 %3, i64* %arrayidx2.i.3, align 8, !tbaa !3
  %arrayidx.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 4
  %4 = load i64, i64* %arrayidx.i.4, align 8, !tbaa !3
  %arrayidx2.i.4 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 4
  store i64 %4, i64* %arrayidx2.i.4, align 8, !tbaa !3
  %arrayidx.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 5
  %5 = load i64, i64* %arrayidx.i.5, align 8, !tbaa !3
  %arrayidx2.i.5 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 5
  store i64 %5, i64* %arrayidx2.i.5, align 8, !tbaa !3
  %arrayidx.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 6
  %6 = load i64, i64* %arrayidx.i.6, align 8, !tbaa !3
  %arrayidx2.i.6 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 6
  store i64 %6, i64* %arrayidx2.i.6, align 8, !tbaa !3
  %arrayidx.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 7
  %7 = load i64, i64* %arrayidx.i.7, align 8, !tbaa !3
  %arrayidx2.i.7 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 7
  store i64 %7, i64* %arrayidx2.i.7, align 8, !tbaa !3
  %arrayidx.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 8
  %8 = load i64, i64* %arrayidx.i.8, align 8, !tbaa !3
  %arrayidx2.i.8 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 8
  store i64 %8, i64* %arrayidx2.i.8, align 8, !tbaa !3
  %arrayidx.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 9
  %9 = load i64, i64* %arrayidx.i.9, align 8, !tbaa !3
  %arrayidx2.i.9 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 9
  store i64 %9, i64* %arrayidx2.i.9, align 8, !tbaa !3
  %arrayidx.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 10
  %10 = load i64, i64* %arrayidx.i.10, align 8, !tbaa !3
  %arrayidx2.i.10 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 10
  store i64 %10, i64* %arrayidx2.i.10, align 8, !tbaa !3
  %arrayidx.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 11
  %11 = load i64, i64* %arrayidx.i.11, align 8, !tbaa !3
  %arrayidx2.i.11 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 11
  store i64 %11, i64* %arrayidx2.i.11, align 8, !tbaa !3
  %arrayidx.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 12
  %12 = load i64, i64* %arrayidx.i.12, align 8, !tbaa !3
  %arrayidx2.i.12 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 12
  store i64 %12, i64* %arrayidx2.i.12, align 8, !tbaa !3
  %arrayidx.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 13
  %13 = load i64, i64* %arrayidx.i.13, align 8, !tbaa !3
  %arrayidx2.i.13 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 13
  store i64 %13, i64* %arrayidx2.i.13, align 8, !tbaa !3
  %arrayidx.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 14
  %14 = load i64, i64* %arrayidx.i.14, align 8, !tbaa !3
  %arrayidx2.i.14 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 14
  store i64 %14, i64* %arrayidx2.i.14, align 8, !tbaa !3
  %arrayidx.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 15
  %15 = load i64, i64* %arrayidx.i.15, align 8, !tbaa !3
  %arrayidx2.i.15 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 15
  store i64 %15, i64* %arrayidx2.i.15, align 8, !tbaa !3
  %arrayidx.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 16
  %16 = load i64, i64* %arrayidx.i.16, align 8, !tbaa !3
  %arrayidx2.i.16 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 16
  store i64 %16, i64* %arrayidx2.i.16, align 8, !tbaa !3
  %arrayidx.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 17
  %17 = load i64, i64* %arrayidx.i.17, align 8, !tbaa !3
  %arrayidx2.i.17 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 17
  store i64 %17, i64* %arrayidx2.i.17, align 8, !tbaa !3
  %arrayidx.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 18
  %18 = load i64, i64* %arrayidx.i.18, align 8, !tbaa !3
  %arrayidx2.i.18 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 18
  store i64 %18, i64* %arrayidx2.i.18, align 8, !tbaa !3
  %arrayidx.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 19
  %19 = load i64, i64* %arrayidx.i.19, align 8, !tbaa !3
  %arrayidx2.i.19 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 19
  store i64 %19, i64* %arrayidx2.i.19, align 8, !tbaa !3
  %arrayidx.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 20
  %20 = load i64, i64* %arrayidx.i.20, align 8, !tbaa !3
  %arrayidx2.i.20 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 20
  store i64 %20, i64* %arrayidx2.i.20, align 8, !tbaa !3
  %arrayidx.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 21
  %21 = load i64, i64* %arrayidx.i.21, align 8, !tbaa !3
  %arrayidx2.i.21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 21
  store i64 %21, i64* %arrayidx2.i.21, align 8, !tbaa !3
  %arrayidx.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 22
  %22 = load i64, i64* %arrayidx.i.22, align 8, !tbaa !3
  %arrayidx2.i.22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 22
  store i64 %22, i64* %arrayidx2.i.22, align 8, !tbaa !3
  %arrayidx.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 23
  %23 = load i64, i64* %arrayidx.i.23, align 8, !tbaa !3
  %arrayidx2.i.23 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 23
  store i64 %23, i64* %arrayidx2.i.23, align 8, !tbaa !3
  %arrayidx.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 24
  %24 = load i64, i64* %arrayidx.i.24, align 8, !tbaa !3
  %arrayidx2.i.24 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 24
  store i64 %24, i64* %arrayidx2.i.24, align 8, !tbaa !3
  %arrayidx.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 25
  %25 = load i64, i64* %arrayidx.i.25, align 8, !tbaa !3
  %arrayidx2.i.25 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 25
  store i64 %25, i64* %arrayidx2.i.25, align 8, !tbaa !3
  %arrayidx.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 26
  %26 = load i64, i64* %arrayidx.i.26, align 8, !tbaa !3
  %arrayidx2.i.26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 26
  store i64 %26, i64* %arrayidx2.i.26, align 8, !tbaa !3
  %arrayidx.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 27
  %27 = load i64, i64* %arrayidx.i.27, align 8, !tbaa !3
  %arrayidx2.i.27 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 27
  store i64 %27, i64* %arrayidx2.i.27, align 8, !tbaa !3
  %arrayidx.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 28
  %28 = load i64, i64* %arrayidx.i.28, align 8, !tbaa !3
  %arrayidx2.i.28 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 28
  store i64 %28, i64* %arrayidx2.i.28, align 8, !tbaa !3
  %arrayidx.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 29
  %29 = load i64, i64* %arrayidx.i.29, align 8, !tbaa !3
  %arrayidx2.i.29 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 29
  store i64 %29, i64* %arrayidx2.i.29, align 8, !tbaa !3
  %arrayidx.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 30
  %30 = load i64, i64* %arrayidx.i.30, align 8, !tbaa !3
  %arrayidx2.i.30 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 30
  store i64 %30, i64* %arrayidx2.i.30, align 8, !tbaa !3
  %arrayidx.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 31
  %31 = load i64, i64* %arrayidx.i.31, align 8, !tbaa !3
  %arrayidx2.i.31 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 31
  store i64 %31, i64* %arrayidx2.i.31, align 8, !tbaa !3
  %arrayidx.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 32
  %32 = load i64, i64* %arrayidx.i.32, align 8, !tbaa !3
  %arrayidx2.i.32 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 32
  store i64 %32, i64* %arrayidx2.i.32, align 8, !tbaa !3
  %arrayidx.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 33
  %33 = load i64, i64* %arrayidx.i.33, align 8, !tbaa !3
  %arrayidx2.i.33 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 33
  store i64 %33, i64* %arrayidx2.i.33, align 8, !tbaa !3
  %arrayidx.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 34
  %34 = load i64, i64* %arrayidx.i.34, align 8, !tbaa !3
  %arrayidx2.i.34 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 34
  store i64 %34, i64* %arrayidx2.i.34, align 8, !tbaa !3
  %arrayidx.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 35
  %35 = load i64, i64* %arrayidx.i.35, align 8, !tbaa !3
  %arrayidx2.i.35 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 35
  store i64 %35, i64* %arrayidx2.i.35, align 8, !tbaa !3
  %arrayidx.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 36
  %36 = load i64, i64* %arrayidx.i.36, align 8, !tbaa !3
  %arrayidx2.i.36 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 36
  store i64 %36, i64* %arrayidx2.i.36, align 8, !tbaa !3
  %arrayidx.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 37
  %37 = load i64, i64* %arrayidx.i.37, align 8, !tbaa !3
  %arrayidx2.i.37 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 37
  store i64 %37, i64* %arrayidx2.i.37, align 8, !tbaa !3
  %arrayidx.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 38
  %38 = load i64, i64* %arrayidx.i.38, align 8, !tbaa !3
  %arrayidx2.i.38 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 38
  store i64 %38, i64* %arrayidx2.i.38, align 8, !tbaa !3
  %arrayidx.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %P, i64 0, i32 0, i64 0, i64 39
  %39 = load i64, i64* %arrayidx.i.39, align 8, !tbaa !3
  %arrayidx2.i.39 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %Q, i64 0, i32 0, i64 0, i64 39
  store i64 %39, i64* %arrayidx2.i.39, align 8, !tbaa !3
  %cmp5 = icmp sgt i32 %e, 0
  br i1 %cmp5, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body, %entry
  ret void

for.body:                                         ; preds = %entry, %for.body
  %i.06 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  tail call void @xTPL_fast(%struct.point_proj* %Q, %struct.point_proj* %Q, [10 x i64]* %A2)
  %inc = add nuw nsw i32 %i.06, 1
  %exitcond = icmp eq i32 %inc, %e
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

; Function Attrs: nounwind ssp uwtable
define i32 @random_mod_order_A_SIDHp610(i8* %random_digits) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @randombytes(i8* %random_digits, i64 39) #10
  %cmp = icmp eq i32 %call, 0
  br i1 %cmp, label %if.end, label %return

if.end:                                           ; preds = %entry
  %arrayidx = getelementptr inbounds i8, i8* %random_digits, i64 38
  %0 = load i8, i8* %arrayidx, align 1, !tbaa !7
  %1 = and i8 %0, 1
  store i8 %1, i8* %arrayidx, align 1, !tbaa !7
  br label %return

return:                                           ; preds = %entry, %if.end
  %retval.0 = phi i32 [ 0, %if.end ], [ 1, %entry ]
  ret i32 %retval.0
}

declare i32 @randombytes(i8*, i64) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define i32 @random_mod_order_B_SIDHp610(i8* %random_digits) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @randombytes(i8* %random_digits, i64 38) #10
  %cmp = icmp ne i32 %call, 0
  %. = zext i1 %cmp to i32
  ret i32 %.
}

; Function Attrs: nounwind ssp uwtable
define i32 @EphemeralKeyGeneration_A_SIDHp610(i8* %PrivateKeyA, i8* %PublicKeyA) local_unnamed_addr #4 {
entry:
  %temp.i.i.i.i = alloca [20 x i64], align 16
  %one.i.i.i = alloca [10 x i64], align 16
  %t.i = alloca [2 x [10 x i64]], align 16
  %R = alloca [1 x %struct.point_proj], align 16
  %phiP = alloca [1 x %struct.point_proj], align 16
  %phiQ = alloca [1 x %struct.point_proj], align 16
  %phiR = alloca [1 x %struct.point_proj], align 16
  %pts = alloca [8 x [1 x %struct.point_proj]], align 16
  %XPA = alloca [2 x [10 x i64]], align 16
  %XQA = alloca [2 x [10 x i64]], align 16
  %XRA = alloca [2 x [10 x i64]], align 16
  %coeff = alloca [3 x [2 x [10 x i64]]], align 16
  %A24plus = alloca [2 x [10 x i64]], align 16
  %C24 = alloca [2 x [10 x i64]], align 16
  %A = alloca [2 x [10 x i64]], align 16
  %pts_index = alloca [8 x i32], align 16
  %SecretKeyA = alloca [5 x i64], align 16
  %S = alloca [1 x %struct.point_proj], align 16
  %0 = bitcast [1 x %struct.point_proj]* %R to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %0) #10
  %1 = bitcast [1 x %struct.point_proj]* %phiP to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 320, i1 false)
  %2 = bitcast [1 x %struct.point_proj]* %phiQ to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 320, i1 false)
  %3 = bitcast [1 x %struct.point_proj]* %phiR to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 320, i1 false)
  %4 = bitcast [8 x [1 x %struct.point_proj]]* %pts to i8*
  call void @llvm.lifetime.start.p0i8(i64 2560, i8* nonnull %4) #10
  %5 = bitcast [2 x [10 x i64]]* %XPA to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  %6 = bitcast [2 x [10 x i64]]* %XQA to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %6) #10
  %7 = bitcast [2 x [10 x i64]]* %XRA to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  %8 = bitcast [3 x [2 x [10 x i64]]]* %coeff to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %8) #10
  %9 = bitcast [2 x [10 x i64]]* %A24plus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 160, i1 false)
  %10 = bitcast [2 x [10 x i64]]* %C24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 160, i1 false)
  %11 = bitcast [2 x [10 x i64]]* %A to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false)
  %12 = bitcast [8 x i32]* %pts_index to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %12) #10
  %13 = bitcast [5 x i64]* %SecretKeyA to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %13) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 0, i64 40, i1 false)
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPA, i64 0, i64 0
  %arraydecay1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQA, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRA, i64 0, i64 0
  %14 = bitcast [2 x [10 x i64]]* %XPA to <4 x i64>*
  store <4 x i64> <i64 5771904529248994682, i64 -8436915071433390351, i64 270330086766583390, i64 6481898407746275289>, <4 x i64>* %14, align 16, !tbaa !3
  %arrayidx2.4.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPA, i64 0, i64 0, i64 4
  %15 = bitcast i64* %arrayidx2.4.i.i to <4 x i64>*
  store <4 x i64> <i64 7865854910092666580, i64 -2826674533944143030, i64 -7553167192889215565, i64 -9032646596491157233>, <4 x i64>* %15, align 16, !tbaa !3
  %arrayidx2.8.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPA, i64 0, i64 0, i64 8
  %16 = bitcast i64* %arrayidx2.8.i.i to <4 x i64>*
  store <4 x i64> <i64 5194719131280954495, i64 1729770898, i64 -1965085922052779020, i64 -4812970318505102637>, <4 x i64>* %16, align 16, !tbaa !3
  %arrayidx2.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPA, i64 0, i64 1, i64 2
  %17 = bitcast i64* %arrayidx2.2.i to <4 x i64>*
  store <4 x i64> <i64 1977403254395278860, i64 2726390535525409621, i64 -248047565090072982, i64 -5454070453411567460>, <4 x i64>* %17, align 16, !tbaa !3
  %arrayidx2.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPA, i64 0, i64 1, i64 6
  %18 = bitcast i64* %arrayidx2.6.i to <4 x i64>*
  store <4 x i64> <i64 -2860923682387992558, i64 4095961562244124488, i64 -4917308312211097814, i64 5102423139>, <4 x i64>* %18, align 16, !tbaa !3
  %19 = bitcast [2 x [10 x i64]]* %XQA to <4 x i64>*
  store <4 x i64> <i64 2124736252400681868, i64 -7322998048931732039, i64 2202127831239085027, i64 -3257580811259719115>, <4 x i64>* %19, align 16, !tbaa !3
  %arrayidx2.4.i206 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQA, i64 0, i64 0, i64 4
  %20 = bitcast i64* %arrayidx2.4.i206 to <4 x i64>*
  store <4 x i64> <i64 4313963896834226850, i64 -5076443579667205976, i64 4921946642166740880, i64 -3805954528561435943>, <4 x i64>* %20, align 16, !tbaa !3
  %arrayidx2.8.i210 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQA, i64 0, i64 0, i64 8
  %21 = bitcast i64* %arrayidx2.8.i210 to <4 x i64>*
  store <4 x i64> <i64 -2637702132890644254, i64 7907518294, i64 2200917311302176889, i64 2939498022256786432>, <4 x i64>* %21, align 16, !tbaa !3
  %arrayidx2.2.i62.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQA, i64 0, i64 1, i64 2
  %22 = bitcast i64* %arrayidx2.2.i62.i to <4 x i64>*
  store <4 x i64> <i64 -2284167071920397343, i64 -8889311404158421409, i64 -3057031954716630490, i64 -4860527247048815703>, <4 x i64>* %22, align 16, !tbaa !3
  %arrayidx2.6.i70.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQA, i64 0, i64 1, i64 6
  %23 = bitcast i64* %arrayidx2.6.i70.i to <4 x i64>*
  store <4 x i64> <i64 -7932579696214058839, i64 334500554730375393, i64 6399318707077975086, i64 8976719684>, <4 x i64>* %23, align 16, !tbaa !3
  %24 = bitcast [2 x [10 x i64]]* %XRA to <4 x i64>*
  store <4 x i64> <i64 2746580562334225805, i64 -4441891846683360495, i64 -6980094913201629698, i64 -6647113845825354661>, <4 x i64>* %24, align 16, !tbaa !3
  %arrayidx2.4.i48.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRA, i64 0, i64 0, i64 4
  %25 = bitcast i64* %arrayidx2.4.i48.i to <4 x i64>*
  store <4 x i64> <i64 6714415832701611114, i64 -8334607330680099106, i64 7010145936394111770, i64 -403948467988784721>, <4 x i64>* %25, align 16, !tbaa !3
  %arrayidx2.8.i56.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRA, i64 0, i64 0, i64 8
  %26 = bitcast i64* %arrayidx2.8.i56.i to <4 x i64>*
  store <4 x i64> <i64 -7139691166611819809, i64 3478841981, i64 -5079986323839184192, i64 3119472779256121459>, <4 x i64>* %26, align 16, !tbaa !3
  %arrayidx2.2.i26.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRA, i64 0, i64 1, i64 2
  %27 = bitcast i64* %arrayidx2.2.i26.i to <4 x i64>*
  store <4 x i64> <i64 4709779656408495164, i64 -1878325030037470211, i64 -3755564803635956908, i64 5893360609436446022>, <4 x i64>* %27, align 16, !tbaa !3
  %arrayidx2.6.i34.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRA, i64 0, i64 1, i64 6
  %28 = bitcast i64* %arrayidx2.6.i34.i to <4 x i64>*
  store <4 x i64> <i64 6635037533545129430, i64 5031143778661013925, i64 2711723078310815363, i64 10114015515>, <4 x i64>* %28, align 16, !tbaa !3
  %arraydecay3 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0
  %arraydecay5 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0
  %arraydecay8 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0
  %arraydecay.i212 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 0
  %29 = bitcast [1 x %struct.point_proj]* %phiP to <4 x i64>*
  store <4 x i64> <i64 -4122797515158813510, i64 2405435625630280597, i64 -3749193287274905454, i64 -2935559660200231368>, <4 x i64>* %29, align 16, !tbaa !3
  %arrayidx2.4.i.i216 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 4
  %30 = bitcast i64* %arrayidx2.4.i.i216 to <4 x i64>*
  store <4 x i64> <i64 7035179512456608727, i64 -1088186176647096380, i64 2237320506219039519, i64 -4139295546001939262>, <4 x i64>* %30, align 16, !tbaa !3
  %arrayidx2.8.i.i220 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 8
  store i64 -2033832934895166963, i64* %arrayidx2.8.i.i220, align 16, !tbaa !3
  %arrayidx2.9.i.i221 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 9
  store i64 5379123413, i64* %arrayidx2.9.i.i221, align 8, !tbaa !3
  %arraydecay2.i222 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 1, i64 0
  %arraydecay5.i223 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 0
  %31 = bitcast i64* %arraydecay2.i222 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %31, i8 0, i64 80, i1 false)
  %32 = bitcast [1 x %struct.point_proj]* %phiQ to <4 x i64>*
  store <4 x i64> <i64 -754674776282359680, i64 8155755975969367465, i64 -7108179690244256889, i64 5678382275401384545>, <4 x i64>* %32, align 16, !tbaa !3
  %arrayidx2.4.i266 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 4
  %33 = bitcast i64* %arrayidx2.4.i266 to <4 x i64>*
  store <4 x i64> <i64 -5945512278495342032, i64 4726463275275376934, i64 -1362977618025674515, i64 4479281637794437063>, <4 x i64>* %33, align 16, !tbaa !3
  %arrayidx2.8.i270 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 8
  store i64 -906589179791040647, i64* %arrayidx2.8.i270, align 16, !tbaa !3
  %arrayidx2.9.i271 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 9
  store i64 9074793307, i64* %arrayidx2.9.i271, align 8, !tbaa !3
  %arraydecay8.i224 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 1, i64 0
  %arraydecay11.i234 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 0
  %34 = bitcast i64* %arraydecay8.i224 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %34, i8 0, i64 80, i1 false)
  %35 = bitcast [1 x %struct.point_proj]* %phiR to <4 x i64>*
  store <4 x i64> <i64 8829176751768485847, i64 4330345099806588278, i64 6439066249656508832, i64 -774629675044450053>, <4 x i64>* %35, align 16, !tbaa !3
  %arrayidx2.4.i48.i238 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 4
  %36 = bitcast i64* %arrayidx2.4.i48.i238 to <4 x i64>*
  store <4 x i64> <i64 -5503580640218556678, i64 -9083173236816041803, i64 -1462621330690897264, i64 -8763703354377076720>, <4 x i64>* %36, align 16, !tbaa !3
  %arrayidx2.8.i56.i242 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 8
  %arraydecay14.i244 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 0
  %37 = bitcast i64* %arrayidx2.8.i56.i242 to <4 x i64>*
  store <4 x i64> <i64 -2191538623876663267, i64 9017845420, i64 6790521807624498538, i64 -2290772438416721629>, <4 x i64>* %37, align 16, !tbaa !3
  %arrayidx2.2.i26.i246 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 2
  %38 = bitcast i64* %arrayidx2.2.i26.i246 to <4 x i64>*
  store <4 x i64> <i64 4283588130542979409, i64 514645655039295889, i64 8912678322428419353, i64 6038404330050892853>, <4 x i64>* %38, align 16, !tbaa !3
  %arrayidx2.6.i34.i250 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 6
  %39 = bitcast i64* %arrayidx2.6.i34.i250 to <4 x i64>*
  store <4 x i64> <i64 -1270586841300829686, i64 -8530139311933844284, i64 910728456329037494, i64 5513273805>, <4 x i64>* %39, align 16, !tbaa !3
  %Z = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay12, align 16, !tbaa !3
  %arrayidx2.1.i272 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i275 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 4
  %40 = bitcast i64* %arrayidx2.1.i272 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %40, i8 0, i64 24, i1 false)
  %41 = bitcast i64* %arrayidx2.4.i275 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %41, align 16, !tbaa !3
  %arrayidx2.8.i279 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i279, align 16, !tbaa !3
  %arrayidx2.9.i280 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i280, align 8, !tbaa !3
  %Z14 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1
  %arraydecay16 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z14, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay16, align 16, !tbaa !3
  %arrayidx2.1.i281 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i284 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 4
  %42 = bitcast i64* %arrayidx2.1.i281 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %42, i8 0, i64 24, i1 false)
  %43 = bitcast i64* %arrayidx2.4.i284 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %43, align 16, !tbaa !3
  %arrayidx2.8.i288 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i288, align 16, !tbaa !3
  %arrayidx2.9.i289 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i289, align 8, !tbaa !3
  %Z18 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1
  %arraydecay20 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z18, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay20, align 16, !tbaa !3
  %arrayidx2.1.i290 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i293 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 4
  %44 = bitcast i64* %arrayidx2.1.i290 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 0, i64 24, i1 false)
  %45 = bitcast i64* %arrayidx2.4.i293 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %45, align 16, !tbaa !3
  %arrayidx2.8.i297 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i297, align 16, !tbaa !3
  %arrayidx2.9.i298 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i298, align 8, !tbaa !3
  %arraydecay22 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 0
  %arrayidx2.1.i299 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 1
  %arrayidx2.4.i302 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 4
  %arrayidx2.8.i306 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 8
  %arrayidx2.9.i307 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 9
  %arraydecay23 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0
  store i64 3457782220, i64* %arraydecay22, align 16, !tbaa !3
  %46 = bitcast i64* %arrayidx2.1.i299 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %46, i8 0, i64 24, i1 false)
  %47 = bitcast i64* %arrayidx2.4.i302 to <4 x i64>*
  store <4 x i64> <i64 3776268287550160896, i64 -7263315013628922753, i64 1482863448970209336, i64 -6526766805794053180>, <4 x i64>* %47, align 16, !tbaa !3
  store i64 2797303665991966331, i64* %arrayidx2.8.i306, align 16, !tbaa !3
  store i64 8877888200, i64* %arrayidx2.9.i307, align 8, !tbaa !3
  %arraydecay6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 0
  %48 = load i64, i64* %arraydecay6.i, align 16, !tbaa !3
  %add3.i.i = shl i64 %48, 1
  store i64 %add3.i.i, i64* %arraydecay6.i, align 16, !tbaa !3
  %or29.i.i = lshr i64 %48, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 1
  %49 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %49, %or29.i.i
  %add3.i.1.i = add i64 %add.i.1.i, %49
  store i64 %add3.i.1.i, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %50 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %50, %49
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %49
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 2
  %51 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %51
  %add3.i.2.i = add i64 %add.i.2.i, %51
  store i64 %add3.i.2.i, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %52 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %52, %51
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %51
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 3
  %53 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %53
  %add3.i.3.i = add i64 %add.i.3.i, %53
  store i64 %add3.i.3.i, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %54 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %54, %53
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %53
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 4
  %55 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %55
  %add3.i.4.i = add i64 %add.i.4.i, %55
  store i64 %add3.i.4.i, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %56 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %56, %55
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %55
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 5
  %57 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %57
  %add3.i.5.i = add i64 %add.i.5.i, %57
  store i64 %add3.i.5.i, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %58 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %58, %57
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %57
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 6
  %59 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %59
  %add3.i.6.i = add i64 %add.i.6.i, %59
  store i64 %add3.i.6.i, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %60 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %60, %59
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %59
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 7
  %61 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %61
  %add3.i.7.i = add i64 %add.i.7.i, %61
  store i64 %add3.i.7.i, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %62 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %62, %61
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %61
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 8
  %63 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %63
  %add3.i.8.i = add i64 %add.i.8.i, %63
  store i64 %add3.i.8.i, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %64 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %64, %63
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %63
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 9
  %65 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor1253 = shl i64 %65, 1
  %add3.i.9.i = or i64 %or29.i.8.i, %factor1253
  store i64 %add3.i.9.i, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arraydecay28 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0
  %arraydecay4.i420 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 0
  store i64 6915564440, i64* %arraydecay4.i420, align 16, !tbaa !3
  %arrayidx5.i.1.i541 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 1
  %arrayidx5.i.4.i577 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 4
  %66 = bitcast i64* %arrayidx5.i.1.i541 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %66, i8 0, i64 24, i1 false)
  %67 = bitcast i64* %arrayidx5.i.4.i577 to <4 x i64>*
  store <4 x i64> <i64 7552536575100321792, i64 3920114046451706110, i64 2965726897940418673, i64 5393210462121445256>, <4 x i64>* %67, align 16, !tbaa !3
  %arrayidx5.i.8.i625 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 8
  store i64 5594607331983932663, i64* %arrayidx5.i.8.i625, align 16, !tbaa !3
  %arrayidx5.i.9.i637 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 9
  store i64 17755776400, i64* %arrayidx5.i.9.i637, align 8, !tbaa !3
  %arraydecay10.i423 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 0
  %add3.i.i424 = shl i64 %48, 2
  store i64 %add3.i.i424, i64* %arraydecay10.i423, align 16, !tbaa !3
  %xor.i23.i.i425 = xor i64 %add3.i.i424, %add3.i.i
  %68 = lshr i64 %48, 62
  %or29.i.i429 = and i64 %68, 1
  %add.i.1.i431 = add i64 %add3.i.1.i, %or29.i.i429
  %add3.i.1.i433 = add i64 %add.i.1.i431, %add3.i.1.i
  %arrayidx5.i.1.i434 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i433, i64* %arrayidx5.i.1.i434, align 8, !tbaa !3
  %69 = xor i64 %add.i.1.i431, -9223372036854775808
  %xor2.i.i.1.i435 = and i64 %69, %add3.i.1.i
  %xor.i23.i.1.i436 = xor i64 %add3.i.1.i433, %add.i.1.i431
  %xor1.i24.i.1.i437 = xor i64 %add.i.1.i431, %add3.i.1.i
  %or.i25.i.1.i438 = or i64 %xor.i23.i.1.i436, %xor1.i24.i.1.i437
  %xor2.i26.i.1.i439 = xor i64 %or.i25.i.1.i438, %add3.i.1.i433
  %shr.i30.i.1.i440 = or i64 %xor2.i26.i.1.i439, %xor2.i.i.1.i435
  %or29.i.1.i441 = lshr i64 %shr.i30.i.1.i440, 63
  %add.i.2.i443 = add i64 %add3.i.2.i, %or29.i.1.i441
  %add3.i.2.i445 = add i64 %add.i.2.i443, %add3.i.2.i
  %arrayidx5.i.2.i446 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i445, i64* %arrayidx5.i.2.i446, align 16, !tbaa !3
  %70 = xor i64 %add.i.2.i443, -9223372036854775808
  %xor2.i.i.2.i447 = and i64 %70, %add3.i.2.i
  %xor.i23.i.2.i448 = xor i64 %add3.i.2.i445, %add.i.2.i443
  %xor1.i24.i.2.i449 = xor i64 %add.i.2.i443, %add3.i.2.i
  %or.i25.i.2.i450 = or i64 %xor.i23.i.2.i448, %xor1.i24.i.2.i449
  %xor2.i26.i.2.i451 = xor i64 %or.i25.i.2.i450, %add3.i.2.i445
  %shr.i30.i.2.i452 = or i64 %xor2.i26.i.2.i451, %xor2.i.i.2.i447
  %or29.i.2.i453 = lshr i64 %shr.i30.i.2.i452, 63
  %add.i.3.i455 = add i64 %add3.i.3.i, %or29.i.2.i453
  %add3.i.3.i457 = add i64 %add.i.3.i455, %add3.i.3.i
  %arrayidx5.i.3.i458 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i457, i64* %arrayidx5.i.3.i458, align 8, !tbaa !3
  %71 = xor i64 %add.i.3.i455, -9223372036854775808
  %xor2.i.i.3.i459 = and i64 %71, %add3.i.3.i
  %xor.i23.i.3.i460 = xor i64 %add3.i.3.i457, %add.i.3.i455
  %xor1.i24.i.3.i461 = xor i64 %add.i.3.i455, %add3.i.3.i
  %or.i25.i.3.i462 = or i64 %xor.i23.i.3.i460, %xor1.i24.i.3.i461
  %xor2.i26.i.3.i463 = xor i64 %or.i25.i.3.i462, %add3.i.3.i457
  %shr.i30.i.3.i464 = or i64 %xor2.i26.i.3.i463, %xor2.i.i.3.i459
  %or29.i.3.i465 = lshr i64 %shr.i30.i.3.i464, 63
  %add.i.4.i467 = add i64 %add3.i.4.i, %or29.i.3.i465
  %add3.i.4.i469 = add i64 %add.i.4.i467, %add3.i.4.i
  %arrayidx5.i.4.i470 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i469, i64* %arrayidx5.i.4.i470, align 16, !tbaa !3
  %72 = xor i64 %add.i.4.i467, -9223372036854775808
  %xor2.i.i.4.i471 = and i64 %72, %add3.i.4.i
  %xor.i23.i.4.i472 = xor i64 %add3.i.4.i469, %add.i.4.i467
  %xor1.i24.i.4.i473 = xor i64 %add.i.4.i467, %add3.i.4.i
  %or.i25.i.4.i474 = or i64 %xor.i23.i.4.i472, %xor1.i24.i.4.i473
  %xor2.i26.i.4.i475 = xor i64 %or.i25.i.4.i474, %add3.i.4.i469
  %shr.i30.i.4.i476 = or i64 %xor2.i26.i.4.i475, %xor2.i.i.4.i471
  %or29.i.4.i477 = lshr i64 %shr.i30.i.4.i476, 63
  %add.i.5.i479 = add i64 %add3.i.5.i, %or29.i.4.i477
  %add3.i.5.i481 = add i64 %add.i.5.i479, %add3.i.5.i
  %arrayidx5.i.5.i482 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i481, i64* %arrayidx5.i.5.i482, align 8, !tbaa !3
  %73 = xor i64 %add.i.5.i479, -9223372036854775808
  %xor2.i.i.5.i483 = and i64 %73, %add3.i.5.i
  %xor.i23.i.5.i484 = xor i64 %add3.i.5.i481, %add.i.5.i479
  %xor1.i24.i.5.i485 = xor i64 %add.i.5.i479, %add3.i.5.i
  %or.i25.i.5.i486 = or i64 %xor.i23.i.5.i484, %xor1.i24.i.5.i485
  %xor2.i26.i.5.i487 = xor i64 %or.i25.i.5.i486, %add3.i.5.i481
  %shr.i30.i.5.i488 = or i64 %xor2.i26.i.5.i487, %xor2.i.i.5.i483
  %or29.i.5.i489 = lshr i64 %shr.i30.i.5.i488, 63
  %add.i.6.i491 = add i64 %add3.i.6.i, %or29.i.5.i489
  %add3.i.6.i493 = add i64 %add.i.6.i491, %add3.i.6.i
  %arrayidx5.i.6.i494 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i493, i64* %arrayidx5.i.6.i494, align 16, !tbaa !3
  %74 = xor i64 %add.i.6.i491, -9223372036854775808
  %xor2.i.i.6.i495 = and i64 %74, %add3.i.6.i
  %xor.i23.i.6.i496 = xor i64 %add3.i.6.i493, %add.i.6.i491
  %xor1.i24.i.6.i497 = xor i64 %add.i.6.i491, %add3.i.6.i
  %or.i25.i.6.i498 = or i64 %xor.i23.i.6.i496, %xor1.i24.i.6.i497
  %xor2.i26.i.6.i499 = xor i64 %or.i25.i.6.i498, %add3.i.6.i493
  %shr.i30.i.6.i500 = or i64 %xor2.i26.i.6.i499, %xor2.i.i.6.i495
  %or29.i.6.i501 = lshr i64 %shr.i30.i.6.i500, 63
  %add.i.7.i503 = add i64 %add3.i.7.i, %or29.i.6.i501
  %add3.i.7.i505 = add i64 %add.i.7.i503, %add3.i.7.i
  %arrayidx5.i.7.i506 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i505, i64* %arrayidx5.i.7.i506, align 8, !tbaa !3
  %75 = xor i64 %add.i.7.i503, -9223372036854775808
  %xor2.i.i.7.i507 = and i64 %75, %add3.i.7.i
  %xor.i23.i.7.i508 = xor i64 %add3.i.7.i505, %add.i.7.i503
  %xor1.i24.i.7.i509 = xor i64 %add.i.7.i503, %add3.i.7.i
  %or.i25.i.7.i510 = or i64 %xor.i23.i.7.i508, %xor1.i24.i.7.i509
  %xor2.i26.i.7.i511 = xor i64 %or.i25.i.7.i510, %add3.i.7.i505
  %shr.i30.i.7.i512 = or i64 %xor2.i26.i.7.i511, %xor2.i.i.7.i507
  %or29.i.7.i513 = lshr i64 %shr.i30.i.7.i512, 63
  %add.i.8.i515 = add i64 %add3.i.8.i, %or29.i.7.i513
  %add3.i.8.i517 = add i64 %add.i.8.i515, %add3.i.8.i
  %arrayidx5.i.8.i518 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i517, i64* %arrayidx5.i.8.i518, align 16, !tbaa !3
  %76 = xor i64 %add.i.8.i515, -9223372036854775808
  %xor2.i.i.8.i519 = and i64 %76, %add3.i.8.i
  %xor.i23.i.8.i520 = xor i64 %add3.i.8.i517, %add.i.8.i515
  %xor1.i24.i.8.i521 = xor i64 %add.i.8.i515, %add3.i.8.i
  %or.i25.i.8.i522 = or i64 %xor.i23.i.8.i520, %xor1.i24.i.8.i521
  %xor2.i26.i.8.i523 = xor i64 %or.i25.i.8.i522, %add3.i.8.i517
  %shr.i30.i.8.i524 = or i64 %xor2.i26.i.8.i523, %xor2.i.i.8.i519
  %or29.i.8.i525 = lshr i64 %shr.i30.i.8.i524, 63
  %factor1255 = shl i64 %add3.i.9.i, 1
  %add3.i.9.i529 = or i64 %factor1255, %or29.i.8.i525
  %arrayidx5.i.9.i530 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i529, i64* %arrayidx5.i.9.i530, align 8, !tbaa !3
  %arraydecay31 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0
  %arraydecay4.i640 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 0
  store i64 10373346660, i64* %arraydecay4.i640, align 16, !tbaa !3
  %arrayidx5.i.1.i761 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 1
  %arrayidx5.i.4.i797 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 4
  %77 = bitcast i64* %arrayidx5.i.1.i761 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %77, i8 0, i64 24, i1 false)
  %78 = bitcast i64* %arrayidx5.i.4.i797 to <4 x i64>*
  store <4 x i64> <i64 -7117939211059068928, i64 -3343200967177216643, i64 4448590346910628009, i64 -1133556343672607924>, <4 x i64>* %78, align 16, !tbaa !3
  %arrayidx5.i.8.i845 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 8
  store i64 8391910997975898994, i64* %arrayidx5.i.8.i845, align 16, !tbaa !3
  %arrayidx5.i.9.i857 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 9
  store i64 26633664600, i64* %arrayidx5.i.9.i857, align 8, !tbaa !3
  %arraydecay10.i643 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 0
  %add3.i.i644 = mul i64 %48, 6
  store i64 %add3.i.i644, i64* %arraydecay10.i643, align 16, !tbaa !3
  %xor.i23.i.i645 = xor i64 %add3.i.i644, %add3.i.i
  %or.i25.i.i647 = or i64 %xor.i23.i.i645, %xor.i23.i.i425
  %xor2.i26.i.i648 = xor i64 %or.i25.i.i647, %add3.i.i644
  %or29.i.i649 = lshr i64 %xor2.i26.i.i648, 63
  %add.i.1.i651 = add i64 %or29.i.i649, %add3.i.1.i
  %add3.i.1.i653 = add i64 %add3.i.1.i433, %add.i.1.i651
  %arrayidx5.i.1.i654 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i653, i64* %arrayidx5.i.1.i654, align 8, !tbaa !3
  %79 = xor i64 %add.i.1.i651, -9223372036854775808
  %xor2.i.i.1.i655 = and i64 %79, %add3.i.1.i
  %xor.i23.i.1.i656 = xor i64 %add3.i.1.i653, %add.i.1.i651
  %xor1.i24.i.1.i657 = xor i64 %add3.i.1.i433, %add.i.1.i651
  %or.i25.i.1.i658 = or i64 %xor.i23.i.1.i656, %xor1.i24.i.1.i657
  %xor2.i26.i.1.i659 = xor i64 %or.i25.i.1.i658, %add3.i.1.i653
  %shr.i30.i.1.i660 = or i64 %xor2.i26.i.1.i659, %xor2.i.i.1.i655
  %or29.i.1.i661 = lshr i64 %shr.i30.i.1.i660, 63
  %add.i.2.i663 = add i64 %or29.i.1.i661, %add3.i.2.i
  %add3.i.2.i665 = add i64 %add3.i.2.i445, %add.i.2.i663
  %arrayidx5.i.2.i666 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i665, i64* %arrayidx5.i.2.i666, align 16, !tbaa !3
  %80 = xor i64 %add.i.2.i663, -9223372036854775808
  %xor2.i.i.2.i667 = and i64 %80, %add3.i.2.i
  %xor.i23.i.2.i668 = xor i64 %add3.i.2.i665, %add.i.2.i663
  %xor1.i24.i.2.i669 = xor i64 %add3.i.2.i445, %add.i.2.i663
  %or.i25.i.2.i670 = or i64 %xor.i23.i.2.i668, %xor1.i24.i.2.i669
  %xor2.i26.i.2.i671 = xor i64 %or.i25.i.2.i670, %add3.i.2.i665
  %shr.i30.i.2.i672 = or i64 %xor2.i26.i.2.i671, %xor2.i.i.2.i667
  %or29.i.2.i673 = lshr i64 %shr.i30.i.2.i672, 63
  %add.i.3.i675 = add i64 %or29.i.2.i673, %add3.i.3.i
  %add3.i.3.i677 = add i64 %add3.i.3.i457, %add.i.3.i675
  %arrayidx5.i.3.i678 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i677, i64* %arrayidx5.i.3.i678, align 8, !tbaa !3
  %81 = xor i64 %add.i.3.i675, -9223372036854775808
  %xor2.i.i.3.i679 = and i64 %81, %add3.i.3.i
  %xor.i23.i.3.i680 = xor i64 %add3.i.3.i677, %add.i.3.i675
  %xor1.i24.i.3.i681 = xor i64 %add3.i.3.i457, %add.i.3.i675
  %or.i25.i.3.i682 = or i64 %xor.i23.i.3.i680, %xor1.i24.i.3.i681
  %xor2.i26.i.3.i683 = xor i64 %or.i25.i.3.i682, %add3.i.3.i677
  %shr.i30.i.3.i684 = or i64 %xor2.i26.i.3.i683, %xor2.i.i.3.i679
  %or29.i.3.i685 = lshr i64 %shr.i30.i.3.i684, 63
  %add.i.4.i687 = add i64 %or29.i.3.i685, %add3.i.4.i
  %add3.i.4.i689 = add i64 %add3.i.4.i469, %add.i.4.i687
  %arrayidx5.i.4.i690 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i689, i64* %arrayidx5.i.4.i690, align 16, !tbaa !3
  %82 = xor i64 %add.i.4.i687, -9223372036854775808
  %xor2.i.i.4.i691 = and i64 %82, %add3.i.4.i
  %xor.i23.i.4.i692 = xor i64 %add3.i.4.i689, %add.i.4.i687
  %xor1.i24.i.4.i693 = xor i64 %add3.i.4.i469, %add.i.4.i687
  %or.i25.i.4.i694 = or i64 %xor.i23.i.4.i692, %xor1.i24.i.4.i693
  %xor2.i26.i.4.i695 = xor i64 %or.i25.i.4.i694, %add3.i.4.i689
  %shr.i30.i.4.i696 = or i64 %xor2.i26.i.4.i695, %xor2.i.i.4.i691
  %or29.i.4.i697 = lshr i64 %shr.i30.i.4.i696, 63
  %add.i.5.i699 = add i64 %or29.i.4.i697, %add3.i.5.i
  %add3.i.5.i701 = add i64 %add3.i.5.i481, %add.i.5.i699
  %arrayidx5.i.5.i702 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i701, i64* %arrayidx5.i.5.i702, align 8, !tbaa !3
  %83 = xor i64 %add.i.5.i699, -9223372036854775808
  %xor2.i.i.5.i703 = and i64 %83, %add3.i.5.i
  %xor.i23.i.5.i704 = xor i64 %add3.i.5.i701, %add.i.5.i699
  %xor1.i24.i.5.i705 = xor i64 %add3.i.5.i481, %add.i.5.i699
  %or.i25.i.5.i706 = or i64 %xor.i23.i.5.i704, %xor1.i24.i.5.i705
  %xor2.i26.i.5.i707 = xor i64 %or.i25.i.5.i706, %add3.i.5.i701
  %shr.i30.i.5.i708 = or i64 %xor2.i26.i.5.i707, %xor2.i.i.5.i703
  %or29.i.5.i709 = lshr i64 %shr.i30.i.5.i708, 63
  %add.i.6.i711 = add i64 %or29.i.5.i709, %add3.i.6.i
  %add3.i.6.i713 = add i64 %add3.i.6.i493, %add.i.6.i711
  %arrayidx5.i.6.i714 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i713, i64* %arrayidx5.i.6.i714, align 16, !tbaa !3
  %84 = xor i64 %add.i.6.i711, -9223372036854775808
  %xor2.i.i.6.i715 = and i64 %84, %add3.i.6.i
  %xor.i23.i.6.i716 = xor i64 %add3.i.6.i713, %add.i.6.i711
  %xor1.i24.i.6.i717 = xor i64 %add3.i.6.i493, %add.i.6.i711
  %or.i25.i.6.i718 = or i64 %xor.i23.i.6.i716, %xor1.i24.i.6.i717
  %xor2.i26.i.6.i719 = xor i64 %or.i25.i.6.i718, %add3.i.6.i713
  %shr.i30.i.6.i720 = or i64 %xor2.i26.i.6.i719, %xor2.i.i.6.i715
  %or29.i.6.i721 = lshr i64 %shr.i30.i.6.i720, 63
  %add.i.7.i723 = add i64 %or29.i.6.i721, %add3.i.7.i
  %add3.i.7.i725 = add i64 %add3.i.7.i505, %add.i.7.i723
  %arrayidx5.i.7.i726 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i725, i64* %arrayidx5.i.7.i726, align 8, !tbaa !3
  %85 = xor i64 %add.i.7.i723, -9223372036854775808
  %xor2.i.i.7.i727 = and i64 %85, %add3.i.7.i
  %xor.i23.i.7.i728 = xor i64 %add3.i.7.i725, %add.i.7.i723
  %xor1.i24.i.7.i729 = xor i64 %add3.i.7.i505, %add.i.7.i723
  %or.i25.i.7.i730 = or i64 %xor.i23.i.7.i728, %xor1.i24.i.7.i729
  %xor2.i26.i.7.i731 = xor i64 %or.i25.i.7.i730, %add3.i.7.i725
  %shr.i30.i.7.i732 = or i64 %xor2.i26.i.7.i731, %xor2.i.i.7.i727
  %or29.i.7.i733 = lshr i64 %shr.i30.i.7.i732, 63
  %add.i.8.i735 = add i64 %or29.i.7.i733, %add3.i.8.i
  %add3.i.8.i737 = add i64 %add3.i.8.i517, %add.i.8.i735
  %arrayidx5.i.8.i738 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i737, i64* %arrayidx5.i.8.i738, align 16, !tbaa !3
  %86 = xor i64 %add.i.8.i735, -9223372036854775808
  %xor2.i.i.8.i739 = and i64 %86, %add3.i.8.i
  %xor.i23.i.8.i740 = xor i64 %add3.i.8.i737, %add.i.8.i735
  %xor1.i24.i.8.i741 = xor i64 %add3.i.8.i517, %add.i.8.i735
  %or.i25.i.8.i742 = or i64 %xor.i23.i.8.i740, %xor1.i24.i.8.i741
  %xor2.i26.i.8.i743 = xor i64 %or.i25.i.8.i742, %add3.i.8.i737
  %shr.i30.i.8.i744 = or i64 %xor2.i26.i.8.i743, %xor2.i.i.8.i739
  %or29.i.8.i745 = lshr i64 %shr.i30.i.8.i744, 63
  %add.i.9.i747 = add i64 %or29.i.8.i745, %add3.i.9.i
  %add3.i.9.i749 = add i64 %add.i.9.i747, %add3.i.9.i529
  %arrayidx5.i.9.i750 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i749, i64* %arrayidx5.i.9.i750, align 8, !tbaa !3
  store i64 13831128880, i64* %arraydecay22, align 16, !tbaa !3
  %87 = bitcast i64* %arrayidx2.1.i299 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %87, i8 0, i64 24, i1 false)
  %88 = bitcast i64* %arrayidx2.4.i302 to <4 x i64>*
  store <4 x i64> <i64 -3341670923508908032, i64 7840228092903412220, i64 5931453795880837346, i64 -7660323149466661104>, <4 x i64>* %88, align 16, !tbaa !3
  store i64 -7257529409741686290, i64* %arrayidx2.8.i306, align 16, !tbaa !3
  store i64 35511552800, i64* %arrayidx2.9.i307, align 8, !tbaa !3
  %add3.i.i876 = shl i64 %48, 3
  store i64 %add3.i.i876, i64* %arraydecay6.i, align 16, !tbaa !3
  %89 = lshr i64 %48, 61
  %or29.i.i881 = and i64 %89, 1
  %add.i.1.i883 = add i64 %add3.i.1.i433, %or29.i.i881
  %add3.i.1.i885 = add i64 %add.i.1.i883, %add3.i.1.i433
  store i64 %add3.i.1.i885, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %90 = xor i64 %add.i.1.i883, -9223372036854775808
  %xor2.i.i.1.i887 = and i64 %90, %add3.i.1.i433
  %xor.i23.i.1.i888 = xor i64 %add3.i.1.i885, %add.i.1.i883
  %xor1.i24.i.1.i889 = xor i64 %add.i.1.i883, %add3.i.1.i433
  %or.i25.i.1.i890 = or i64 %xor.i23.i.1.i888, %xor1.i24.i.1.i889
  %xor2.i26.i.1.i891 = xor i64 %or.i25.i.1.i890, %add3.i.1.i885
  %shr.i30.i.1.i892 = or i64 %xor2.i26.i.1.i891, %xor2.i.i.1.i887
  %or29.i.1.i893 = lshr i64 %shr.i30.i.1.i892, 63
  %add.i.2.i895 = add i64 %add3.i.2.i445, %or29.i.1.i893
  %add3.i.2.i897 = add i64 %add.i.2.i895, %add3.i.2.i445
  store i64 %add3.i.2.i897, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %91 = xor i64 %add.i.2.i895, -9223372036854775808
  %xor2.i.i.2.i899 = and i64 %91, %add3.i.2.i445
  %xor.i23.i.2.i900 = xor i64 %add3.i.2.i897, %add.i.2.i895
  %xor1.i24.i.2.i901 = xor i64 %add.i.2.i895, %add3.i.2.i445
  %or.i25.i.2.i902 = or i64 %xor.i23.i.2.i900, %xor1.i24.i.2.i901
  %xor2.i26.i.2.i903 = xor i64 %or.i25.i.2.i902, %add3.i.2.i897
  %shr.i30.i.2.i904 = or i64 %xor2.i26.i.2.i903, %xor2.i.i.2.i899
  %or29.i.2.i905 = lshr i64 %shr.i30.i.2.i904, 63
  %add.i.3.i907 = add i64 %add3.i.3.i457, %or29.i.2.i905
  %add3.i.3.i909 = add i64 %add.i.3.i907, %add3.i.3.i457
  store i64 %add3.i.3.i909, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %92 = xor i64 %add.i.3.i907, -9223372036854775808
  %xor2.i.i.3.i911 = and i64 %92, %add3.i.3.i457
  %xor.i23.i.3.i912 = xor i64 %add3.i.3.i909, %add.i.3.i907
  %xor1.i24.i.3.i913 = xor i64 %add.i.3.i907, %add3.i.3.i457
  %or.i25.i.3.i914 = or i64 %xor.i23.i.3.i912, %xor1.i24.i.3.i913
  %xor2.i26.i.3.i915 = xor i64 %or.i25.i.3.i914, %add3.i.3.i909
  %shr.i30.i.3.i916 = or i64 %xor2.i26.i.3.i915, %xor2.i.i.3.i911
  %or29.i.3.i917 = lshr i64 %shr.i30.i.3.i916, 63
  %add.i.4.i919 = add i64 %add3.i.4.i469, %or29.i.3.i917
  %add3.i.4.i921 = add i64 %add.i.4.i919, %add3.i.4.i469
  store i64 %add3.i.4.i921, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %93 = xor i64 %add.i.4.i919, -9223372036854775808
  %xor2.i.i.4.i923 = and i64 %93, %add3.i.4.i469
  %xor.i23.i.4.i924 = xor i64 %add3.i.4.i921, %add.i.4.i919
  %xor1.i24.i.4.i925 = xor i64 %add.i.4.i919, %add3.i.4.i469
  %or.i25.i.4.i926 = or i64 %xor.i23.i.4.i924, %xor1.i24.i.4.i925
  %xor2.i26.i.4.i927 = xor i64 %or.i25.i.4.i926, %add3.i.4.i921
  %shr.i30.i.4.i928 = or i64 %xor2.i26.i.4.i927, %xor2.i.i.4.i923
  %or29.i.4.i929 = lshr i64 %shr.i30.i.4.i928, 63
  %add.i.5.i931 = add i64 %add3.i.5.i481, %or29.i.4.i929
  %add3.i.5.i933 = add i64 %add.i.5.i931, %add3.i.5.i481
  store i64 %add3.i.5.i933, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %94 = xor i64 %add.i.5.i931, -9223372036854775808
  %xor2.i.i.5.i935 = and i64 %94, %add3.i.5.i481
  %xor.i23.i.5.i936 = xor i64 %add3.i.5.i933, %add.i.5.i931
  %xor1.i24.i.5.i937 = xor i64 %add.i.5.i931, %add3.i.5.i481
  %or.i25.i.5.i938 = or i64 %xor.i23.i.5.i936, %xor1.i24.i.5.i937
  %xor2.i26.i.5.i939 = xor i64 %or.i25.i.5.i938, %add3.i.5.i933
  %shr.i30.i.5.i940 = or i64 %xor2.i26.i.5.i939, %xor2.i.i.5.i935
  %or29.i.5.i941 = lshr i64 %shr.i30.i.5.i940, 63
  %add.i.6.i943 = add i64 %add3.i.6.i493, %or29.i.5.i941
  %add3.i.6.i945 = add i64 %add.i.6.i943, %add3.i.6.i493
  store i64 %add3.i.6.i945, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %95 = xor i64 %add.i.6.i943, -9223372036854775808
  %xor2.i.i.6.i947 = and i64 %95, %add3.i.6.i493
  %xor.i23.i.6.i948 = xor i64 %add3.i.6.i945, %add.i.6.i943
  %xor1.i24.i.6.i949 = xor i64 %add.i.6.i943, %add3.i.6.i493
  %or.i25.i.6.i950 = or i64 %xor.i23.i.6.i948, %xor1.i24.i.6.i949
  %xor2.i26.i.6.i951 = xor i64 %or.i25.i.6.i950, %add3.i.6.i945
  %shr.i30.i.6.i952 = or i64 %xor2.i26.i.6.i951, %xor2.i.i.6.i947
  %or29.i.6.i953 = lshr i64 %shr.i30.i.6.i952, 63
  %add.i.7.i955 = add i64 %add3.i.7.i505, %or29.i.6.i953
  %add3.i.7.i957 = add i64 %add.i.7.i955, %add3.i.7.i505
  store i64 %add3.i.7.i957, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %96 = xor i64 %add.i.7.i955, -9223372036854775808
  %xor2.i.i.7.i959 = and i64 %96, %add3.i.7.i505
  %xor.i23.i.7.i960 = xor i64 %add3.i.7.i957, %add.i.7.i955
  %xor1.i24.i.7.i961 = xor i64 %add.i.7.i955, %add3.i.7.i505
  %or.i25.i.7.i962 = or i64 %xor.i23.i.7.i960, %xor1.i24.i.7.i961
  %xor2.i26.i.7.i963 = xor i64 %or.i25.i.7.i962, %add3.i.7.i957
  %shr.i30.i.7.i964 = or i64 %xor2.i26.i.7.i963, %xor2.i.i.7.i959
  %or29.i.7.i965 = lshr i64 %shr.i30.i.7.i964, 63
  %add.i.8.i967 = add i64 %add3.i.8.i517, %or29.i.7.i965
  %add3.i.8.i969 = add i64 %add.i.8.i967, %add3.i.8.i517
  store i64 %add3.i.8.i969, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %97 = xor i64 %add.i.8.i967, -9223372036854775808
  %xor2.i.i.8.i971 = and i64 %97, %add3.i.8.i517
  %xor.i23.i.8.i972 = xor i64 %add3.i.8.i969, %add.i.8.i967
  %xor1.i24.i.8.i973 = xor i64 %add.i.8.i967, %add3.i.8.i517
  %or.i25.i.8.i974 = or i64 %xor.i23.i.8.i972, %xor1.i24.i.8.i973
  %xor2.i26.i.8.i975 = xor i64 %or.i25.i.8.i974, %add3.i.8.i969
  %shr.i30.i.8.i976 = or i64 %xor2.i26.i.8.i975, %xor2.i.i.8.i971
  %or29.i.8.i977 = lshr i64 %shr.i30.i.8.i976, 63
  %factor1257 = shl i64 %add3.i.9.i529, 1
  %add3.i.9.i981 = or i64 %factor1257, %or29.i.8.i977
  store i64 %add3.i.9.i981, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arraydecay35 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyA, i64 0, i64 0
  %arrayidx.i = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyA, i64 0, i64 4
  store i64 0, i64* %arrayidx.i, align 16, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %13, i8* align 1 %PrivateKeyA, i64 39, i1 false)
  %arraydecay40 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0
  call fastcc void @LADDER3PT([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay2, i64* nonnull %arraydecay35, i32 0, %struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay31)
  %98 = bitcast [1 x %struct.point_proj]* %S to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %98) #10
  %arraydecay43 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0
  %99 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %100 = load <4 x i64>, <4 x i64>* %99, align 16, !tbaa !3
  %101 = bitcast [1 x %struct.point_proj]* %S to <4 x i64>*
  store <4 x i64> %100, <4 x i64>* %101, align 16, !tbaa !3
  %arrayidx.i.4.i1096 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 4
  %arrayidx2.i.4.i1097 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 4
  %102 = bitcast i64* %arrayidx.i.4.i1096 to <4 x i64>*
  %103 = load <4 x i64>, <4 x i64>* %102, align 16, !tbaa !3
  %104 = bitcast i64* %arrayidx2.i.4.i1097 to <4 x i64>*
  store <4 x i64> %103, <4 x i64>* %104, align 16, !tbaa !3
  %arrayidx.i.8.i1104 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 8
  %arrayidx2.i.8.i1105 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 8
  %105 = bitcast i64* %arrayidx.i.8.i1104 to <4 x i64>*
  %106 = load <4 x i64>, <4 x i64>* %105, align 16, !tbaa !3
  %107 = bitcast i64* %arrayidx2.i.8.i1105 to <4 x i64>*
  store <4 x i64> %106, <4 x i64>* %107, align 16, !tbaa !3
  %arrayidx.i.12.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 12
  %arrayidx2.i.12.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 12
  %108 = bitcast i64* %arrayidx.i.12.i to <4 x i64>*
  %109 = load <4 x i64>, <4 x i64>* %108, align 16, !tbaa !3
  %110 = bitcast i64* %arrayidx2.i.12.i to <4 x i64>*
  store <4 x i64> %109, <4 x i64>* %110, align 16, !tbaa !3
  %arrayidx.i.16.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 16
  %arrayidx2.i.16.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 16
  %111 = bitcast i64* %arrayidx.i.16.i to <4 x i64>*
  %112 = load <4 x i64>, <4 x i64>* %111, align 16, !tbaa !3
  %113 = bitcast i64* %arrayidx2.i.16.i to <4 x i64>*
  store <4 x i64> %112, <4 x i64>* %113, align 16, !tbaa !3
  %arrayidx.i.20.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 20
  %arrayidx2.i.20.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 20
  %114 = bitcast i64* %arrayidx.i.20.i to <4 x i64>*
  %115 = load <4 x i64>, <4 x i64>* %114, align 16, !tbaa !3
  %116 = bitcast i64* %arrayidx2.i.20.i to <4 x i64>*
  store <4 x i64> %115, <4 x i64>* %116, align 16, !tbaa !3
  %arrayidx.i.24.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 24
  %arrayidx2.i.24.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 24
  %117 = bitcast i64* %arrayidx.i.24.i to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 16, !tbaa !3
  %119 = bitcast i64* %arrayidx2.i.24.i to <4 x i64>*
  store <4 x i64> %118, <4 x i64>* %119, align 16, !tbaa !3
  %arrayidx.i.28.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 28
  %arrayidx2.i.28.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 28
  %120 = bitcast i64* %arrayidx.i.28.i to <4 x i64>*
  %121 = load <4 x i64>, <4 x i64>* %120, align 16, !tbaa !3
  %122 = bitcast i64* %arrayidx2.i.28.i to <4 x i64>*
  store <4 x i64> %121, <4 x i64>* %122, align 16, !tbaa !3
  %arrayidx.i.32.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 32
  %arrayidx2.i.32.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 32
  %123 = bitcast i64* %arrayidx.i.32.i to <4 x i64>*
  %124 = load <4 x i64>, <4 x i64>* %123, align 16, !tbaa !3
  %125 = bitcast i64* %arrayidx2.i.32.i to <4 x i64>*
  store <4 x i64> %124, <4 x i64>* %125, align 16, !tbaa !3
  %arrayidx.i.36.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 36
  %arrayidx2.i.36.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 36
  %126 = bitcast i64* %arrayidx.i.36.i to <4 x i64>*
  %127 = load <4 x i64>, <4 x i64>* %126, align 16, !tbaa !3
  %128 = bitcast i64* %arrayidx2.i.36.i to <4 x i64>*
  store <4 x i64> %127, <4 x i64>* %128, align 16, !tbaa !3
  br label %for.body.i

for.body.i:                                       ; preds = %for.body.i, %entry
  %i.06.i = phi i32 [ %inc.i, %for.body.i ], [ 0, %entry ]
  call void @xDBL(%struct.point_proj* nonnull %arraydecay43, %struct.point_proj* nonnull %arraydecay43, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay28) #10
  %inc.i = add nuw nsw i32 %i.06.i, 1
  %exitcond.i = icmp eq i32 %inc.i, 304
  br i1 %exitcond.i, label %xDBLe.exit, label %for.body.i

xDBLe.exit:                                       ; preds = %for.body.i
  %arraydecay4 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0
  %arraydecay7 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0
  %arraydecay10 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0
  call void @get_2_isog(%struct.point_proj* nonnull %arraydecay43, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay28)
  call void @eval_2_isog(%struct.point_proj* nonnull %arraydecay3, %struct.point_proj* nonnull %arraydecay43)
  call void @eval_2_isog(%struct.point_proj* nonnull %arraydecay5, %struct.point_proj* nonnull %arraydecay43)
  call void @eval_2_isog(%struct.point_proj* nonnull %arraydecay8, %struct.point_proj* nonnull %arraydecay43)
  call void @eval_2_isog(%struct.point_proj* nonnull %arraydecay40, %struct.point_proj* nonnull %arraydecay43)
  %arraydecay85 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %coeff, i64 0, i64 0
  %arrayidx.2.i11.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 2
  %arrayidx.6.i19.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 6
  %arraydecay.i1121 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 0
  %arrayidx.4.i.i1129 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 4
  %arrayidx.8.i.i1137 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 8
  %arrayidx.2.i11.i1145 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 2
  %arrayidx.6.i19.i1153 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 6
  %129 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %130 = bitcast i64* %arrayidx.i.4.i1096 to <4 x i64>*
  %131 = bitcast i64* %arrayidx.i.8.i1104 to <4 x i64>*
  %132 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %133 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %134 = bitcast i64* %arraydecay.i1121 to <4 x i64>*
  %135 = bitcast i64* %arrayidx.4.i.i1129 to <4 x i64>*
  %136 = bitcast i64* %arrayidx.8.i.i1137 to <4 x i64>*
  %137 = bitcast i64* %arrayidx.2.i11.i1145 to <4 x i64>*
  %138 = bitcast i64* %arrayidx.6.i19.i1153 to <4 x i64>*
  %139 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %140 = bitcast i64* %arrayidx.i.4.i1096 to <4 x i64>*
  %141 = bitcast i64* %arrayidx.i.8.i1104 to <4 x i64>*
  %142 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %143 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %144 = bitcast i64* %arraydecay.i1121 to <4 x i64>*
  %145 = bitcast i64* %arrayidx.4.i.i1129 to <4 x i64>*
  %146 = bitcast i64* %arrayidx.8.i.i1137 to <4 x i64>*
  %147 = bitcast i64* %arrayidx.2.i11.i1145 to <4 x i64>*
  %148 = bitcast i64* %arrayidx.6.i19.i1153 to <4 x i64>*
  br label %while.cond.preheader

while.cond.preheader:                             ; preds = %for.end, %xDBLe.exit
  %ii.01268 = phi i32 [ 0, %xDBLe.exit ], [ %ii.1.lcssa, %for.end ]
  %npts.01267 = phi i32 [ 0, %xDBLe.exit ], [ %sub100, %for.end ]
  %index.01266 = phi i32 [ 0, %xDBLe.exit ], [ %190, %for.end ]
  %row.01265 = phi i32 [ 1, %xDBLe.exit ], [ %inc123, %for.end ]
  %sub = sub nuw nsw i32 152, %row.01265
  %cmp571258 = icmp ult i32 %index.01266, %sub
  br i1 %cmp571258, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond.preheader, %while.body
  %ii.11261 = phi i32 [ %inc75, %while.body ], [ %ii.01268, %while.cond.preheader ]
  %npts.11260 = phi i32 [ %inc, %while.body ], [ %npts.01267, %while.cond.preheader ]
  %index.11259 = phi i32 [ %add, %while.body ], [ %index.01266, %while.cond.preheader ]
  %idxprom = zext i32 %npts.11260 to i64
  %arraydecay2.i1109 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 0
  %149 = load <4 x i64>, <4 x i64>* %129, align 16, !tbaa !3
  %150 = bitcast i64* %arraydecay2.i1109 to <4 x i64>*
  store <4 x i64> %149, <4 x i64>* %150, align 16, !tbaa !3
  %arrayidx2.4.i.i1113 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 4
  %151 = load <4 x i64>, <4 x i64>* %130, align 16, !tbaa !3
  %152 = bitcast i64* %arrayidx2.4.i.i1113 to <4 x i64>*
  store <4 x i64> %151, <4 x i64>* %152, align 16, !tbaa !3
  %arrayidx2.8.i.i1117 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 8
  %153 = load <4 x i64>, <4 x i64>* %131, align 16, !tbaa !3
  %154 = bitcast i64* %arrayidx2.8.i.i1117 to <4 x i64>*
  store <4 x i64> %153, <4 x i64>* %154, align 16, !tbaa !3
  %arrayidx2.2.i12.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 2
  %155 = load <4 x i64>, <4 x i64>* %132, align 16, !tbaa !3
  %156 = bitcast i64* %arrayidx2.2.i12.i to <4 x i64>*
  store <4 x i64> %155, <4 x i64>* %156, align 16, !tbaa !3
  %arrayidx2.6.i20.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 6
  %157 = load <4 x i64>, <4 x i64>* %133, align 16, !tbaa !3
  %158 = bitcast i64* %arrayidx2.6.i20.i to <4 x i64>*
  store <4 x i64> %157, <4 x i64>* %158, align 16, !tbaa !3
  %arraydecay2.i1122 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 0
  %159 = load <4 x i64>, <4 x i64>* %134, align 16, !tbaa !3
  %160 = bitcast i64* %arraydecay2.i1122 to <4 x i64>*
  store <4 x i64> %159, <4 x i64>* %160, align 16, !tbaa !3
  %arrayidx2.4.i.i1130 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 4
  %161 = load <4 x i64>, <4 x i64>* %135, align 16, !tbaa !3
  %162 = bitcast i64* %arrayidx2.4.i.i1130 to <4 x i64>*
  store <4 x i64> %161, <4 x i64>* %162, align 16, !tbaa !3
  %arrayidx2.8.i.i1138 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 8
  %163 = load <4 x i64>, <4 x i64>* %136, align 16, !tbaa !3
  %164 = bitcast i64* %arrayidx2.8.i.i1138 to <4 x i64>*
  store <4 x i64> %163, <4 x i64>* %164, align 16, !tbaa !3
  %arrayidx2.2.i12.i1146 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 2
  %165 = load <4 x i64>, <4 x i64>* %137, align 16, !tbaa !3
  %166 = bitcast i64* %arrayidx2.2.i12.i1146 to <4 x i64>*
  store <4 x i64> %165, <4 x i64>* %166, align 16, !tbaa !3
  %arrayidx2.6.i20.i1154 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 6
  %167 = load <4 x i64>, <4 x i64>* %138, align 16, !tbaa !3
  %168 = bitcast i64* %arrayidx2.6.i20.i1154 to <4 x i64>*
  store <4 x i64> %167, <4 x i64>* %168, align 16, !tbaa !3
  %inc = add i32 %npts.11260, 1
  %arrayidx74 = getelementptr inbounds [8 x i32], [8 x i32]* %pts_index, i64 0, i64 %idxprom
  store i32 %index.11259, i32* %arrayidx74, align 4, !tbaa !59
  %inc75 = add i32 %ii.11261, 1
  %idxprom76 = zext i32 %ii.11261 to i64
  %arrayidx77 = getelementptr inbounds [151 x i32], [151 x i32]* @strat_Alice, i64 0, i64 %idxprom76
  %169 = load i32, i32* %arrayidx77, align 4, !tbaa !59
  %mul = shl i32 %169, 1
  call void @xDBLe(%struct.point_proj* nonnull %arraydecay40, %struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay28, i32 %mul)
  %add = add i32 %169, %index.11259
  %cmp57 = icmp ult i32 %add, %sub
  br i1 %cmp57, label %while.body, label %while.end

while.end:                                        ; preds = %while.body, %while.cond.preheader
  %npts.1.lcssa = phi i32 [ %npts.01267, %while.cond.preheader ], [ %inc, %while.body ]
  %ii.1.lcssa = phi i32 [ %ii.01268, %while.cond.preheader ], [ %inc75, %while.body ]
  call void @get_4_isog(%struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay28, [2 x [10 x i64]]* nonnull %arraydecay85)
  %cmp871263 = icmp eq i32 %npts.1.lcssa, 0
  br i1 %cmp871263, label %for.end, label %for.body88.preheader

for.body88.preheader:                             ; preds = %while.end
  %wide.trip.count = zext i32 %npts.1.lcssa to i64
  br label %for.body88

for.body88:                                       ; preds = %for.body88, %for.body88.preheader
  %indvars.iv = phi i64 [ 0, %for.body88.preheader ], [ %indvars.iv.next, %for.body88 ]
  %arraydecay91 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %indvars.iv, i64 0
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay91, [2 x [10 x i64]]* nonnull %arraydecay85)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.end, label %for.body88

for.end:                                          ; preds = %for.body88, %while.end
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay3, [2 x [10 x i64]]* nonnull %arraydecay85)
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay5, [2 x [10 x i64]]* nonnull %arraydecay85)
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay8, [2 x [10 x i64]]* nonnull %arraydecay85)
  %sub100 = add i32 %npts.1.lcssa, -1
  %idxprom101 = zext i32 %sub100 to i64
  %arraydecay.i1161 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 0, i64 0, i64 0
  %170 = bitcast i64* %arraydecay.i1161 to <4 x i64>*
  %171 = load <4 x i64>, <4 x i64>* %170, align 16, !tbaa !3
  store <4 x i64> %171, <4 x i64>* %139, align 16, !tbaa !3
  %arrayidx.4.i.i1169 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 0, i64 0, i64 4
  %172 = bitcast i64* %arrayidx.4.i.i1169 to <4 x i64>*
  %173 = load <4 x i64>, <4 x i64>* %172, align 16, !tbaa !3
  store <4 x i64> %173, <4 x i64>* %140, align 16, !tbaa !3
  %arrayidx.8.i.i1177 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 0, i64 0, i64 8
  %174 = bitcast i64* %arrayidx.8.i.i1177 to <4 x i64>*
  %175 = load <4 x i64>, <4 x i64>* %174, align 16, !tbaa !3
  store <4 x i64> %175, <4 x i64>* %141, align 16, !tbaa !3
  %arrayidx.2.i11.i1185 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 0, i64 1, i64 2
  %176 = bitcast i64* %arrayidx.2.i11.i1185 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 16, !tbaa !3
  store <4 x i64> %177, <4 x i64>* %142, align 16, !tbaa !3
  %arrayidx.6.i19.i1193 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 0, i64 1, i64 6
  %178 = bitcast i64* %arrayidx.6.i19.i1193 to <4 x i64>*
  %179 = load <4 x i64>, <4 x i64>* %178, align 16, !tbaa !3
  store <4 x i64> %179, <4 x i64>* %143, align 16, !tbaa !3
  %arraydecay.i1201 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 1, i64 0, i64 0
  %180 = bitcast i64* %arraydecay.i1201 to <4 x i64>*
  %181 = load <4 x i64>, <4 x i64>* %180, align 16, !tbaa !3
  store <4 x i64> %181, <4 x i64>* %144, align 16, !tbaa !3
  %arrayidx.4.i.i1209 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 1, i64 0, i64 4
  %182 = bitcast i64* %arrayidx.4.i.i1209 to <4 x i64>*
  %183 = load <4 x i64>, <4 x i64>* %182, align 16, !tbaa !3
  store <4 x i64> %183, <4 x i64>* %145, align 16, !tbaa !3
  %arrayidx.8.i.i1217 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 1, i64 0, i64 8
  %184 = bitcast i64* %arrayidx.8.i.i1217 to <4 x i64>*
  %185 = load <4 x i64>, <4 x i64>* %184, align 16, !tbaa !3
  store <4 x i64> %185, <4 x i64>* %146, align 16, !tbaa !3
  %arrayidx.2.i11.i1225 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 1, i64 1, i64 2
  %186 = bitcast i64* %arrayidx.2.i11.i1225 to <4 x i64>*
  %187 = load <4 x i64>, <4 x i64>* %186, align 16, !tbaa !3
  store <4 x i64> %187, <4 x i64>* %147, align 16, !tbaa !3
  %arrayidx.6.i19.i1233 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom101, i64 0, i32 1, i64 1, i64 6
  %188 = bitcast i64* %arrayidx.6.i19.i1233 to <4 x i64>*
  %189 = load <4 x i64>, <4 x i64>* %188, align 16, !tbaa !3
  store <4 x i64> %189, <4 x i64>* %148, align 16, !tbaa !3
  %arrayidx120 = getelementptr inbounds [8 x i32], [8 x i32]* %pts_index, i64 0, i64 %idxprom101
  %190 = load i32, i32* %arrayidx120, align 4, !tbaa !59
  %inc123 = add nuw nsw i32 %row.01265, 1
  %exitcond1269 = icmp eq i32 %inc123, 152
  br i1 %exitcond1269, label %for.end124, label %while.cond.preheader

for.end124:                                       ; preds = %for.end
  call void @get_4_isog(%struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay28, [2 x [10 x i64]]* nonnull %arraydecay85)
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay3, [2 x [10 x i64]]* nonnull %arraydecay85)
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay5, [2 x [10 x i64]]* nonnull %arraydecay85)
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay8, [2 x [10 x i64]]* nonnull %arraydecay85)
  %arraydecay137 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z, i64 0, i64 0
  %arraydecay140 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z14, i64 0, i64 0
  %arraydecay143 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z18, i64 0, i64 0
  call void @inv_3_way([10 x i64]* nonnull %arraydecay137, [10 x i64]* nonnull %arraydecay140, [10 x i64]* nonnull %arraydecay143)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay4, [10 x i64]* nonnull %arraydecay137, [10 x i64]* nonnull %arraydecay4)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay140, [10 x i64]* nonnull %arraydecay7)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay10, [10 x i64]* nonnull %arraydecay143, [10 x i64]* nonnull %arraydecay10)
  %191 = bitcast [2 x [10 x i64]]* %t.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %191) #10
  %arraydecay2.i.i1245 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 0, i64 0
  %192 = bitcast [10 x i64]* %one.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  %arrayidx.i.i.i1246 = getelementptr inbounds [10 x i64], [10 x i64]* %one.i.i.i, i64 0, i64 0
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  %193 = bitcast [20 x i64]* %temp.i.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i.i.i1247 = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay.i212, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  %arraydecay6.i.i1249 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i222, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  %194 = call i64 @llvm.objectsize.i64.p0i8(i8* %PublicKeyA, i1 false, i1 true) #10
  %call.i.i1250 = call i8* @__memcpy_chk(i8* %PublicKeyA, i8* nonnull %191, i64 77, i64 %194) #10
  %add.ptr.i1251 = getelementptr inbounds i8, i8* %PublicKeyA, i64 77
  %195 = bitcast i64* %arraydecay6.i.i1249 to i8*
  %196 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i1251, i1 false, i1 true) #10
  %call.i5.i1252 = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i1251, i8* nonnull %195, i64 77, i64 %196) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %191) #10
  %add.ptr = getelementptr inbounds i8, i8* %PublicKeyA, i64 154
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %191) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay5.i223, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay8.i224, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  %197 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr, i1 false, i1 true) #10
  %call.i.i867 = call i8* @__memcpy_chk(i8* nonnull %add.ptr, i8* nonnull %191, i64 77, i64 %197) #10
  %add.ptr.i868 = getelementptr inbounds i8, i8* %PublicKeyA, i64 231
  %198 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i868, i1 false, i1 true) #10
  %call.i5.i869 = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i868, i8* nonnull %195, i64 77, i64 %198) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %191) #10
  %add.ptr180 = getelementptr inbounds i8, i8* %PublicKeyA, i64 308
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %191) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay11.i234, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1245) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %192) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %192, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1246, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %193) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %193, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay14.i244, i64* nonnull %arrayidx.i.i.i1246, i64* nonnull %arraydecay.i.i.i.i1247, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1247, i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %193) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1249) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %192) #10
  %199 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr180, i1 false, i1 true) #10
  %call.i.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr180, i8* nonnull %191, i64 77, i64 %199) #10
  %add.ptr.i = getelementptr inbounds i8, i8* %PublicKeyA, i64 385
  %200 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i, i1 false, i1 true) #10
  %call.i5.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i, i8* nonnull %195, i64 77, i64 %200) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %191) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %98) #10
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %13) #10
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %12) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 2560, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %0) #10
  ret i32 0
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @LADDER3PT([10 x i64]* nocapture readonly %xP, [10 x i64]* nocapture readonly %xQ, [10 x i64]* nocapture readonly %xPQ, i64* nocapture readonly %m, i32 %AliceOrBob, %struct.point_proj* %R, [10 x i64]* nocapture readonly %A) unnamed_addr #4 {
entry:
  %R0 = alloca [1 x %struct.point_proj], align 16
  %R2 = alloca [1 x %struct.point_proj], align 16
  %A24 = alloca [2 x [10 x i64]], align 16
  %0 = bitcast [1 x %struct.point_proj]* %R0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %0) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %0, i8 0, i64 320, i1 false)
  %1 = bitcast [1 x %struct.point_proj]* %R2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 320, i1 false)
  %2 = bitcast [2 x [10 x i64]]* %A24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %2) #10
  %cmp = icmp eq i32 %AliceOrBob, 0
  %. = select i1 %cmp, i32 305, i32 304
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 0
  %arrayidx2.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 1
  %arrayidx2.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 2
  %arrayidx2.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 3
  %arrayidx2.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 4
  %arrayidx2.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 5
  %arrayidx2.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 6
  %arrayidx2.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 7
  %arrayidx2.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 8
  %arrayidx2.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0, i64 9
  %arraydecay1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 0
  store i64 8877888200, i64* %arrayidx2.9.i, align 8, !tbaa !3
  %arraydecay6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 0
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 1
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 2
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 3
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 4
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 5
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 9
  %arraydecay.i314 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 0
  %3 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24, i64 0, i64 1, i64 2
  %4 = bitcast i64* %3 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 64, i1 false)
  %5 = load i64, i64* %arraydecay.i314, align 8, !tbaa !3
  %add3.i.i427 = add i64 %5, 3457782220
  store i64 %add3.i.i427, i64* %arraydecay, align 16, !tbaa !3
  %6 = sub i64 -3457782221, %5
  %xor2.i26.i.i431 = and i64 %5, %6
  %or29.i.i432 = lshr i64 %xor2.i26.i.i431, 63
  %arrayidx.i.1.i433 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 1
  %7 = load i64, i64* %arrayidx.i.1.i433, align 8, !tbaa !3
  %add.i.1.i434 = add i64 %or29.i.i432, %7
  store i64 %add.i.1.i434, i64* %arrayidx2.1.i, align 8, !tbaa !3
  %8 = xor i64 %add.i.1.i434, -9223372036854775808
  %xor2.i.i.1.i438 = and i64 %8, %7
  %or29.i.1.i444 = lshr i64 %xor2.i.i.1.i438, 63
  %arrayidx.i.2.i445 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 2
  %9 = load i64, i64* %arrayidx.i.2.i445, align 8, !tbaa !3
  %add.i.2.i446 = add i64 %or29.i.1.i444, %9
  store i64 %add.i.2.i446, i64* %arrayidx2.2.i, align 16, !tbaa !3
  %10 = xor i64 %add.i.2.i446, -9223372036854775808
  %xor2.i.i.2.i450 = and i64 %10, %9
  %or29.i.2.i456 = lshr i64 %xor2.i.i.2.i450, 63
  %arrayidx.i.3.i457 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 3
  %11 = load i64, i64* %arrayidx.i.3.i457, align 8, !tbaa !3
  %add.i.3.i458 = add i64 %or29.i.2.i456, %11
  store i64 %add.i.3.i458, i64* %arrayidx2.3.i, align 8, !tbaa !3
  %12 = xor i64 %add.i.3.i458, -9223372036854775808
  %xor2.i.i.3.i462 = and i64 %12, %11
  %or29.i.3.i468 = lshr i64 %xor2.i.i.3.i462, 63
  %arrayidx.i.4.i469 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 4
  %13 = load i64, i64* %arrayidx.i.4.i469, align 8, !tbaa !3
  %add.i.4.i470 = add i64 %or29.i.3.i468, %13
  %add3.i.4.i472 = add i64 %add.i.4.i470, 3776268287550160896
  store i64 %add3.i.4.i472, i64* %arrayidx2.4.i, align 16, !tbaa !3
  %14 = xor i64 %add.i.4.i470, -9223372036854775808
  %xor2.i.i.4.i474 = and i64 %14, %13
  %15 = sub i64 -3776268287550160897, %add.i.4.i470
  %xor2.i26.i.4.i478 = and i64 %add.i.4.i470, %15
  %shr.i30.i.4.i479 = or i64 %xor2.i26.i.4.i478, %xor2.i.i.4.i474
  %or29.i.4.i480 = lshr i64 %shr.i30.i.4.i479, 63
  %arrayidx.i.5.i481 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 5
  %16 = load i64, i64* %arrayidx.i.5.i481, align 8, !tbaa !3
  %add.i.5.i482 = add i64 %or29.i.4.i480, %16
  %add3.i.5.i484 = add i64 %add.i.5.i482, -7263315013628922753
  store i64 %add3.i.5.i484, i64* %arrayidx2.5.i, align 8, !tbaa !3
  %17 = xor i64 %add.i.5.i482, -9223372036854775808
  %xor2.i.i.5.i486 = and i64 %17, %16
  %xor.i23.i.5.i487 = xor i64 %add3.i.5.i484, %add.i.5.i482
  %xor1.i24.i.5.i488 = xor i64 %add.i.5.i482, -9223372036854775808
  %or.i25.i.5.i489 = or i64 %xor.i23.i.5.i487, %xor1.i24.i.5.i488
  %xor2.i26.i.5.i490 = xor i64 %or.i25.i.5.i489, %add3.i.5.i484
  %shr.i30.i.5.i491 = or i64 %xor2.i26.i.5.i490, %xor2.i.i.5.i486
  %or29.i.5.i492 = lshr i64 %shr.i30.i.5.i491, 63
  %arrayidx.i.6.i493 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 6
  %18 = load i64, i64* %arrayidx.i.6.i493, align 8, !tbaa !3
  %add.i.6.i494 = add i64 %or29.i.5.i492, %18
  %add3.i.6.i496 = add i64 %add.i.6.i494, 1482863448970209336
  store i64 %add3.i.6.i496, i64* %arrayidx2.6.i, align 16, !tbaa !3
  %19 = xor i64 %add.i.6.i494, -9223372036854775808
  %xor2.i.i.6.i498 = and i64 %19, %18
  %20 = sub i64 -1482863448970209337, %add.i.6.i494
  %xor2.i26.i.6.i502 = and i64 %add.i.6.i494, %20
  %shr.i30.i.6.i503 = or i64 %xor2.i26.i.6.i502, %xor2.i.i.6.i498
  %or29.i.6.i504 = lshr i64 %shr.i30.i.6.i503, 63
  %arrayidx.i.7.i505 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 7
  %21 = load i64, i64* %arrayidx.i.7.i505, align 8, !tbaa !3
  %add.i.7.i506 = add i64 %or29.i.6.i504, %21
  %add3.i.7.i508 = add i64 %add.i.7.i506, -6526766805794053180
  store i64 %add3.i.7.i508, i64* %arrayidx2.7.i, align 8, !tbaa !3
  %22 = xor i64 %add.i.7.i506, -9223372036854775808
  %xor2.i.i.7.i510 = and i64 %22, %21
  %xor.i23.i.7.i511 = xor i64 %add3.i.7.i508, %add.i.7.i506
  %xor1.i24.i.7.i512 = xor i64 %add.i.7.i506, -9223372036854775808
  %or.i25.i.7.i513 = or i64 %xor.i23.i.7.i511, %xor1.i24.i.7.i512
  %xor2.i26.i.7.i514 = xor i64 %or.i25.i.7.i513, %add3.i.7.i508
  %shr.i30.i.7.i515 = or i64 %xor2.i26.i.7.i514, %xor2.i.i.7.i510
  %or29.i.7.i516 = lshr i64 %shr.i30.i.7.i515, 63
  %arrayidx.i.8.i517 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 8
  %23 = load i64, i64* %arrayidx.i.8.i517, align 8, !tbaa !3
  %add.i.8.i518 = add i64 %or29.i.7.i516, %23
  %add3.i.8.i520 = add i64 %add.i.8.i518, 2797303665991966331
  store i64 %add3.i.8.i520, i64* %arrayidx2.8.i, align 16, !tbaa !3
  %24 = xor i64 %add.i.8.i518, -9223372036854775808
  %xor2.i.i.8.i522 = and i64 %24, %23
  %25 = sub i64 -2797303665991966332, %add.i.8.i518
  %xor2.i26.i.8.i526 = and i64 %add.i.8.i518, %25
  %shr.i30.i.8.i527 = or i64 %xor2.i26.i.8.i526, %xor2.i.i.8.i522
  %or29.i.8.i528 = lshr i64 %shr.i30.i.8.i527, 63
  %arrayidx.i.9.i529 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 0, i64 9
  %26 = load i64, i64* %arrayidx.i.9.i529, align 8, !tbaa !3
  %add.i.9.i530 = add i64 %26, 8877888200
  %add3.i.9.i532 = add i64 %add.i.9.i530, %or29.i.8.i528
  store i64 %add3.i.9.i532, i64* %arrayidx2.9.i, align 8, !tbaa !3
  %arraydecay6.i317 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 0
  %27 = load i64, i64* %arraydecay6.i317, align 8, !tbaa !3
  store i64 %27, i64* %arraydecay6.i, align 16, !tbaa !3
  %arrayidx.i.1.i326 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 1
  %28 = load i64, i64* %arrayidx.i.1.i326, align 8, !tbaa !3
  store i64 %28, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %arrayidx.i.2.i338 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 2
  %29 = load i64, i64* %arrayidx.i.2.i338, align 8, !tbaa !3
  store i64 %29, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %arrayidx.i.3.i350 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 3
  %30 = load i64, i64* %arrayidx.i.3.i350, align 8, !tbaa !3
  store i64 %30, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %arrayidx.i.4.i362 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 4
  %31 = load i64, i64* %arrayidx.i.4.i362, align 8, !tbaa !3
  store i64 %31, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %arrayidx.i.5.i374 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 5
  %32 = bitcast i64* %arrayidx.i.5.i374 to <4 x i64>*
  %33 = load <4 x i64>, <4 x i64>* %32, align 8, !tbaa !3
  %34 = bitcast i64* %arrayidx.i.5.i to <4 x i64>*
  store <4 x i64> %33, <4 x i64>* %34, align 8, !tbaa !3
  %arrayidx.i.9.i422 = getelementptr inbounds [10 x i64], [10 x i64]* %A, i64 1, i64 9
  %35 = load i64, i64* %arrayidx.i.9.i422, align 8, !tbaa !3
  store i64 %35, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  call void @fpdiv2_610(i64* nonnull %arraydecay, i64* nonnull %arraydecay) #10
  call void @fpdiv2_610(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i) #10
  call void @fpdiv2_610(i64* nonnull %arraydecay, i64* nonnull %arraydecay) #10
  call void @fpdiv2_610(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i) #10
  %arraydecay10 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0
  %36 = bitcast [10 x i64]* %xQ to <4 x i64>*
  %37 = load <4 x i64>, <4 x i64>* %36, align 8, !tbaa !3
  %38 = bitcast [1 x %struct.point_proj]* %R0 to <4 x i64>*
  store <4 x i64> %37, <4 x i64>* %38, align 16, !tbaa !3
  %arrayidx.4.i.i278 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 0, i64 4
  %arrayidx2.4.i.i279 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 0, i64 0, i64 4
  %39 = bitcast i64* %arrayidx.4.i.i278 to <4 x i64>*
  %40 = load <4 x i64>, <4 x i64>* %39, align 8, !tbaa !3
  %41 = bitcast i64* %arrayidx2.4.i.i279 to <4 x i64>*
  store <4 x i64> %40, <4 x i64>* %41, align 16, !tbaa !3
  %arrayidx.8.i.i286 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 0, i64 8
  %arrayidx2.8.i.i287 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 0, i64 0, i64 8
  %42 = bitcast i64* %arrayidx.8.i.i286 to <4 x i64>*
  %43 = load <4 x i64>, <4 x i64>* %42, align 8, !tbaa !3
  %44 = bitcast i64* %arrayidx2.8.i.i287 to <4 x i64>*
  store <4 x i64> %43, <4 x i64>* %44, align 16, !tbaa !3
  %arrayidx.2.i11.i294 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 1, i64 2
  %arrayidx2.2.i12.i295 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 0, i64 1, i64 2
  %45 = bitcast i64* %arrayidx.2.i11.i294 to <4 x i64>*
  %46 = load <4 x i64>, <4 x i64>* %45, align 8, !tbaa !3
  %47 = bitcast i64* %arrayidx2.2.i12.i295 to <4 x i64>*
  store <4 x i64> %46, <4 x i64>* %47, align 16, !tbaa !3
  %arrayidx.6.i19.i302 = getelementptr inbounds [10 x i64], [10 x i64]* %xQ, i64 1, i64 6
  %arrayidx2.6.i20.i303 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 0, i64 1, i64 6
  %48 = bitcast i64* %arrayidx.6.i19.i302 to <4 x i64>*
  %49 = load <4 x i64>, <4 x i64>* %48, align 8, !tbaa !3
  %50 = bitcast i64* %arrayidx2.6.i20.i303 to <4 x i64>*
  store <4 x i64> %49, <4 x i64>* %50, align 16, !tbaa !3
  %51 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 1, i64 0, i64 0
  store i64 1728891110, i64* %51, align 16, !tbaa !3
  %arrayidx2.1.i261 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i264 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 1, i64 0, i64 4
  %52 = bitcast i64* %arrayidx2.1.i261 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 0, i64 24, i1 false)
  %53 = bitcast i64* %arrayidx2.4.i264 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %53, align 16, !tbaa !3
  %arrayidx2.8.i268 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i268, align 16, !tbaa !3
  %arrayidx2.9.i269 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R0, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i269, align 8, !tbaa !3
  %arraydecay14 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0
  %54 = bitcast [10 x i64]* %xPQ to <4 x i64>*
  %55 = load <4 x i64>, <4 x i64>* %54, align 8, !tbaa !3
  %56 = bitcast [1 x %struct.point_proj]* %R2 to <4 x i64>*
  store <4 x i64> %55, <4 x i64>* %56, align 16, !tbaa !3
  %arrayidx.4.i.i229 = getelementptr inbounds [10 x i64], [10 x i64]* %xPQ, i64 0, i64 4
  %arrayidx2.4.i.i230 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 4
  %57 = bitcast i64* %arrayidx.4.i.i229 to <4 x i64>*
  %58 = load <4 x i64>, <4 x i64>* %57, align 8, !tbaa !3
  %59 = bitcast i64* %arrayidx2.4.i.i230 to <4 x i64>*
  store <4 x i64> %58, <4 x i64>* %59, align 16, !tbaa !3
  %arrayidx.8.i.i237 = getelementptr inbounds [10 x i64], [10 x i64]* %xPQ, i64 0, i64 8
  %arrayidx2.8.i.i238 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 8
  %60 = bitcast i64* %arrayidx.8.i.i237 to <4 x i64>*
  %61 = load <4 x i64>, <4 x i64>* %60, align 8, !tbaa !3
  %62 = bitcast i64* %arrayidx2.8.i.i238 to <4 x i64>*
  store <4 x i64> %61, <4 x i64>* %62, align 16, !tbaa !3
  %arrayidx.2.i11.i245 = getelementptr inbounds [10 x i64], [10 x i64]* %xPQ, i64 1, i64 2
  %arrayidx2.2.i12.i246 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 2
  %63 = bitcast i64* %arrayidx.2.i11.i245 to <4 x i64>*
  %64 = load <4 x i64>, <4 x i64>* %63, align 8, !tbaa !3
  %65 = bitcast i64* %arrayidx2.2.i12.i246 to <4 x i64>*
  store <4 x i64> %64, <4 x i64>* %65, align 16, !tbaa !3
  %arrayidx.6.i19.i253 = getelementptr inbounds [10 x i64], [10 x i64]* %xPQ, i64 1, i64 6
  %arrayidx2.6.i20.i254 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 6
  %66 = bitcast i64* %arrayidx.6.i19.i253 to <4 x i64>*
  %67 = load <4 x i64>, <4 x i64>* %66, align 8, !tbaa !3
  %68 = bitcast i64* %arrayidx2.6.i20.i254 to <4 x i64>*
  store <4 x i64> %67, <4 x i64>* %68, align 16, !tbaa !3
  %69 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 0
  store i64 1728891110, i64* %69, align 16, !tbaa !3
  %arrayidx2.1.i212 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i215 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 4
  %70 = bitcast i64* %arrayidx2.1.i212 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %70, i8 0, i64 24, i1 false)
  %71 = bitcast i64* %arrayidx2.4.i215 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %71, align 16, !tbaa !3
  %arrayidx2.8.i219 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i219, align 16, !tbaa !3
  %arrayidx2.9.i220 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i220, align 8, !tbaa !3
  %arraydecay21 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0
  %arraydecay.i208 = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 0
  %arraydecay2.i209 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 0
  %72 = load i64, i64* %arraydecay.i208, align 8, !tbaa !3
  store i64 %72, i64* %arraydecay2.i209, align 8, !tbaa !3
  %arrayidx.1.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 1
  %73 = load i64, i64* %arrayidx.1.i.i, align 8, !tbaa !3
  %arrayidx2.1.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 1
  store i64 %73, i64* %arrayidx2.1.i.i, align 8, !tbaa !3
  %arrayidx.2.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 2
  %74 = load i64, i64* %arrayidx.2.i.i, align 8, !tbaa !3
  %arrayidx2.2.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 2
  store i64 %74, i64* %arrayidx2.2.i.i, align 8, !tbaa !3
  %arrayidx.3.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 3
  %75 = load i64, i64* %arrayidx.3.i.i, align 8, !tbaa !3
  %arrayidx2.3.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 3
  store i64 %75, i64* %arrayidx2.3.i.i, align 8, !tbaa !3
  %arrayidx.4.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 4
  %76 = load i64, i64* %arrayidx.4.i.i, align 8, !tbaa !3
  %arrayidx2.4.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 4
  store i64 %76, i64* %arrayidx2.4.i.i, align 8, !tbaa !3
  %arrayidx.5.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 5
  %77 = load i64, i64* %arrayidx.5.i.i, align 8, !tbaa !3
  %arrayidx2.5.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 5
  store i64 %77, i64* %arrayidx2.5.i.i, align 8, !tbaa !3
  %arrayidx.6.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 6
  %78 = load i64, i64* %arrayidx.6.i.i, align 8, !tbaa !3
  %arrayidx2.6.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 6
  store i64 %78, i64* %arrayidx2.6.i.i, align 8, !tbaa !3
  %arrayidx.7.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 7
  %79 = load i64, i64* %arrayidx.7.i.i, align 8, !tbaa !3
  %arrayidx2.7.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 7
  store i64 %79, i64* %arrayidx2.7.i.i, align 8, !tbaa !3
  %arrayidx.8.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 8
  %80 = load i64, i64* %arrayidx.8.i.i, align 8, !tbaa !3
  %arrayidx2.8.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 8
  store i64 %80, i64* %arrayidx2.8.i.i, align 8, !tbaa !3
  %arrayidx.9.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 0, i64 9
  %81 = load i64, i64* %arrayidx.9.i.i, align 8, !tbaa !3
  %arrayidx2.9.i.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 9
  store i64 %81, i64* %arrayidx2.9.i.i, align 8, !tbaa !3
  %arraydecay4.i210 = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 0
  %arraydecay6.i211 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 0
  %82 = load i64, i64* %arraydecay4.i210, align 8, !tbaa !3
  store i64 %82, i64* %arraydecay6.i211, align 8, !tbaa !3
  %arrayidx.1.i9.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 1
  %83 = load i64, i64* %arrayidx.1.i9.i, align 8, !tbaa !3
  %arrayidx2.1.i10.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 1
  store i64 %83, i64* %arrayidx2.1.i10.i, align 8, !tbaa !3
  %arrayidx.2.i11.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 2
  %84 = load i64, i64* %arrayidx.2.i11.i, align 8, !tbaa !3
  %arrayidx2.2.i12.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 2
  store i64 %84, i64* %arrayidx2.2.i12.i, align 8, !tbaa !3
  %arrayidx.3.i13.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 3
  %85 = load i64, i64* %arrayidx.3.i13.i, align 8, !tbaa !3
  %arrayidx2.3.i14.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 3
  store i64 %85, i64* %arrayidx2.3.i14.i, align 8, !tbaa !3
  %arrayidx.4.i15.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 4
  %86 = load i64, i64* %arrayidx.4.i15.i, align 8, !tbaa !3
  %arrayidx2.4.i16.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 4
  store i64 %86, i64* %arrayidx2.4.i16.i, align 8, !tbaa !3
  %arrayidx.5.i17.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 5
  %87 = load i64, i64* %arrayidx.5.i17.i, align 8, !tbaa !3
  %arrayidx2.5.i18.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 5
  store i64 %87, i64* %arrayidx2.5.i18.i, align 8, !tbaa !3
  %arrayidx.6.i19.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 6
  %88 = load i64, i64* %arrayidx.6.i19.i, align 8, !tbaa !3
  %arrayidx2.6.i20.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 6
  store i64 %88, i64* %arrayidx2.6.i20.i, align 8, !tbaa !3
  %arrayidx.7.i21.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 7
  %89 = load i64, i64* %arrayidx.7.i21.i, align 8, !tbaa !3
  %arrayidx2.7.i22.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 7
  store i64 %89, i64* %arrayidx2.7.i22.i, align 8, !tbaa !3
  %arrayidx.8.i23.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 8
  %90 = load i64, i64* %arrayidx.8.i23.i, align 8, !tbaa !3
  %arrayidx2.8.i24.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 8
  store i64 %90, i64* %arrayidx2.8.i24.i, align 8, !tbaa !3
  %arrayidx.9.i25.i = getelementptr inbounds [10 x i64], [10 x i64]* %xP, i64 1, i64 9
  %91 = load i64, i64* %arrayidx.9.i25.i, align 8, !tbaa !3
  %arrayidx2.9.i26.i = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 9
  store i64 %91, i64* %arrayidx2.9.i26.i, align 8, !tbaa !3
  %Z22 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1
  %arraydecay23 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z22, i64 0, i64 0
  %92 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z22, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %92, align 8, !tbaa !3
  %arrayidx2.1.i199 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i202 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 4
  %93 = bitcast i64* %arrayidx2.1.i199 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %93, i8 0, i64 24, i1 false)
  %94 = bitcast i64* %arrayidx2.4.i202 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %94, align 8, !tbaa !3
  %arrayidx2.8.i206 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i206, align 8, !tbaa !3
  %arrayidx2.9.i207 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i207, align 8, !tbaa !3
  %arraydecay26 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 0
  %a5.i = bitcast i64* %arraydecay26 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %a5.i, i8 0, i64 80, i1 false) #10
  %95 = bitcast %struct.point_proj* %R to <2 x i64>*
  %96 = bitcast [1 x %struct.point_proj]* %R2 to <2 x i64>*
  %97 = bitcast %struct.point_proj* %R to <2 x i64>*
  %98 = bitcast [1 x %struct.point_proj]* %R2 to <2 x i64>*
  %99 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 0
  %100 = bitcast i64* %99 to <2 x i64>*
  %101 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 0
  %102 = bitcast i64* %101 to <2 x i64>*
  %103 = bitcast i64* %99 to <2 x i64>*
  %104 = bitcast i64* %101 to <2 x i64>*
  %105 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 0
  %106 = bitcast i64* %105 to <2 x i64>*
  %107 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 0
  %108 = bitcast i64* %107 to <2 x i64>*
  %109 = bitcast i64* %105 to <2 x i64>*
  %110 = bitcast i64* %107 to <2 x i64>*
  %111 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 0
  %112 = bitcast i64* %111 to <2 x i64>*
  %113 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 0
  %114 = bitcast i64* %113 to <2 x i64>*
  %115 = bitcast i64* %111 to <2 x i64>*
  %116 = bitcast i64* %113 to <2 x i64>*
  %117 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 2
  %118 = bitcast i64* %117 to <2 x i64>*
  %119 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 2
  %120 = bitcast i64* %119 to <2 x i64>*
  %121 = bitcast i64* %117 to <2 x i64>*
  %122 = bitcast i64* %119 to <2 x i64>*
  %123 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 2
  %124 = bitcast i64* %123 to <2 x i64>*
  %125 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 2
  %126 = bitcast i64* %125 to <2 x i64>*
  %127 = bitcast i64* %123 to <2 x i64>*
  %128 = bitcast i64* %125 to <2 x i64>*
  %129 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 2
  %130 = bitcast i64* %129 to <2 x i64>*
  %131 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 2
  %132 = bitcast i64* %131 to <2 x i64>*
  %133 = bitcast i64* %129 to <2 x i64>*
  %134 = bitcast i64* %131 to <2 x i64>*
  %135 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 2
  %136 = bitcast i64* %135 to <2 x i64>*
  %137 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 2
  %138 = bitcast i64* %137 to <2 x i64>*
  %139 = bitcast i64* %135 to <2 x i64>*
  %140 = bitcast i64* %137 to <2 x i64>*
  %141 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 4
  %142 = bitcast i64* %141 to <2 x i64>*
  %143 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 4
  %144 = bitcast i64* %143 to <2 x i64>*
  %145 = bitcast i64* %141 to <2 x i64>*
  %146 = bitcast i64* %143 to <2 x i64>*
  %147 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 4
  %148 = bitcast i64* %147 to <2 x i64>*
  %149 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 4
  %150 = bitcast i64* %149 to <2 x i64>*
  %151 = bitcast i64* %147 to <2 x i64>*
  %152 = bitcast i64* %149 to <2 x i64>*
  %153 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 4
  %154 = bitcast i64* %153 to <2 x i64>*
  %155 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 4
  %156 = bitcast i64* %155 to <2 x i64>*
  %157 = bitcast i64* %153 to <2 x i64>*
  %158 = bitcast i64* %155 to <2 x i64>*
  %159 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 4
  %160 = bitcast i64* %159 to <2 x i64>*
  %161 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 4
  %162 = bitcast i64* %161 to <2 x i64>*
  %163 = bitcast i64* %159 to <2 x i64>*
  %164 = bitcast i64* %161 to <2 x i64>*
  %165 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 6
  %166 = bitcast i64* %165 to <2 x i64>*
  %167 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 6
  %168 = bitcast i64* %167 to <2 x i64>*
  %169 = bitcast i64* %165 to <2 x i64>*
  %170 = bitcast i64* %167 to <2 x i64>*
  %171 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 6
  %172 = bitcast i64* %171 to <2 x i64>*
  %173 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 6
  %174 = bitcast i64* %173 to <2 x i64>*
  %175 = bitcast i64* %171 to <2 x i64>*
  %176 = bitcast i64* %173 to <2 x i64>*
  %177 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 6
  %178 = bitcast i64* %177 to <2 x i64>*
  %179 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 6
  %180 = bitcast i64* %179 to <2 x i64>*
  %181 = bitcast i64* %177 to <2 x i64>*
  %182 = bitcast i64* %179 to <2 x i64>*
  %183 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 6
  %184 = bitcast i64* %183 to <2 x i64>*
  %185 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 6
  %186 = bitcast i64* %185 to <2 x i64>*
  %187 = bitcast i64* %183 to <2 x i64>*
  %188 = bitcast i64* %185 to <2 x i64>*
  %189 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 8
  %190 = bitcast i64* %189 to <2 x i64>*
  %191 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 8
  %192 = bitcast i64* %191 to <2 x i64>*
  %193 = bitcast i64* %189 to <2 x i64>*
  %194 = bitcast i64* %191 to <2 x i64>*
  %195 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 8
  %196 = bitcast i64* %195 to <2 x i64>*
  %197 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 8
  %198 = bitcast i64* %197 to <2 x i64>*
  %199 = bitcast i64* %195 to <2 x i64>*
  %200 = bitcast i64* %197 to <2 x i64>*
  %201 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 8
  %202 = bitcast i64* %201 to <2 x i64>*
  %203 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 8
  %204 = bitcast i64* %203 to <2 x i64>*
  %205 = bitcast i64* %201 to <2 x i64>*
  %206 = bitcast i64* %203 to <2 x i64>*
  %207 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 8
  %208 = bitcast i64* %207 to <2 x i64>*
  %209 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 8
  %210 = bitcast i64* %209 to <2 x i64>*
  %211 = bitcast i64* %207 to <2 x i64>*
  %212 = bitcast i64* %209 to <2 x i64>*
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %prevbit.0540 = phi i32 [ 0, %entry ], [ %conv, %for.body ]
  %i.0539 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %213 = lshr i32 %i.0539, 6
  %214 = zext i32 %213 to i64
  %arrayidx28 = getelementptr inbounds i64, i64* %m, i64 %214
  %215 = load i64, i64* %arrayidx28, align 8, !tbaa !3
  %and = and i32 %i.0539, 63
  %sh_prom = zext i32 %and to i64
  %shr29 = lshr i64 %215, %sh_prom
  %216 = trunc i64 %shr29 to i32
  %conv = and i32 %216, 1
  %xor = xor i32 %conv, %prevbit.0540
  %217 = zext i32 %xor to i64
  %sub = sub nsw i64 0, %217
  %broadcast.splatinsert542 = insertelement <2 x i64> undef, i64 %sub, i32 0
  %broadcast.splat543 = shufflevector <2 x i64> %broadcast.splatinsert542, <2 x i64> undef, <2 x i32> zeroinitializer
  %wide.load = load <2 x i64>, <2 x i64>* %95, align 8, !tbaa !3
  %wide.load541 = load <2 x i64>, <2 x i64>* %96, align 16, !tbaa !3
  %218 = xor <2 x i64> %wide.load541, %wide.load
  %219 = and <2 x i64> %218, %broadcast.splat543
  %220 = xor <2 x i64> %219, %wide.load
  store <2 x i64> %220, <2 x i64>* %97, align 8, !tbaa !3
  %221 = xor <2 x i64> %219, %wide.load541
  store <2 x i64> %221, <2 x i64>* %98, align 16, !tbaa !3
  %wide.load544 = load <2 x i64>, <2 x i64>* %100, align 8, !tbaa !3
  %wide.load545 = load <2 x i64>, <2 x i64>* %102, align 16, !tbaa !3
  %222 = xor <2 x i64> %wide.load545, %wide.load544
  %223 = and <2 x i64> %222, %broadcast.splat543
  %224 = xor <2 x i64> %223, %wide.load544
  store <2 x i64> %224, <2 x i64>* %103, align 8, !tbaa !3
  %225 = xor <2 x i64> %223, %wide.load545
  store <2 x i64> %225, <2 x i64>* %104, align 16, !tbaa !3
  %wide.load546 = load <2 x i64>, <2 x i64>* %106, align 8, !tbaa !3
  %wide.load547 = load <2 x i64>, <2 x i64>* %108, align 16, !tbaa !3
  %226 = xor <2 x i64> %wide.load547, %wide.load546
  %227 = and <2 x i64> %226, %broadcast.splat543
  %228 = xor <2 x i64> %227, %wide.load546
  store <2 x i64> %228, <2 x i64>* %109, align 8, !tbaa !3
  %229 = xor <2 x i64> %227, %wide.load547
  store <2 x i64> %229, <2 x i64>* %110, align 16, !tbaa !3
  %wide.load548 = load <2 x i64>, <2 x i64>* %112, align 8, !tbaa !3
  %wide.load549 = load <2 x i64>, <2 x i64>* %114, align 16, !tbaa !3
  %230 = xor <2 x i64> %wide.load549, %wide.load548
  %231 = and <2 x i64> %230, %broadcast.splat543
  %232 = xor <2 x i64> %231, %wide.load548
  store <2 x i64> %232, <2 x i64>* %115, align 8, !tbaa !3
  %233 = xor <2 x i64> %231, %wide.load549
  store <2 x i64> %233, <2 x i64>* %116, align 16, !tbaa !3
  %wide.load.1 = load <2 x i64>, <2 x i64>* %118, align 8, !tbaa !3
  %wide.load541.1 = load <2 x i64>, <2 x i64>* %120, align 16, !tbaa !3
  %234 = xor <2 x i64> %wide.load541.1, %wide.load.1
  %235 = and <2 x i64> %234, %broadcast.splat543
  %236 = xor <2 x i64> %235, %wide.load.1
  store <2 x i64> %236, <2 x i64>* %121, align 8, !tbaa !3
  %237 = xor <2 x i64> %235, %wide.load541.1
  store <2 x i64> %237, <2 x i64>* %122, align 16, !tbaa !3
  %wide.load544.1 = load <2 x i64>, <2 x i64>* %124, align 8, !tbaa !3
  %wide.load545.1 = load <2 x i64>, <2 x i64>* %126, align 16, !tbaa !3
  %238 = xor <2 x i64> %wide.load545.1, %wide.load544.1
  %239 = and <2 x i64> %238, %broadcast.splat543
  %240 = xor <2 x i64> %239, %wide.load544.1
  store <2 x i64> %240, <2 x i64>* %127, align 8, !tbaa !3
  %241 = xor <2 x i64> %239, %wide.load545.1
  store <2 x i64> %241, <2 x i64>* %128, align 16, !tbaa !3
  %wide.load546.1 = load <2 x i64>, <2 x i64>* %130, align 8, !tbaa !3
  %wide.load547.1 = load <2 x i64>, <2 x i64>* %132, align 16, !tbaa !3
  %242 = xor <2 x i64> %wide.load547.1, %wide.load546.1
  %243 = and <2 x i64> %242, %broadcast.splat543
  %244 = xor <2 x i64> %243, %wide.load546.1
  store <2 x i64> %244, <2 x i64>* %133, align 8, !tbaa !3
  %245 = xor <2 x i64> %243, %wide.load547.1
  store <2 x i64> %245, <2 x i64>* %134, align 16, !tbaa !3
  %wide.load548.1 = load <2 x i64>, <2 x i64>* %136, align 8, !tbaa !3
  %wide.load549.1 = load <2 x i64>, <2 x i64>* %138, align 16, !tbaa !3
  %246 = xor <2 x i64> %wide.load549.1, %wide.load548.1
  %247 = and <2 x i64> %246, %broadcast.splat543
  %248 = xor <2 x i64> %247, %wide.load548.1
  store <2 x i64> %248, <2 x i64>* %139, align 8, !tbaa !3
  %249 = xor <2 x i64> %247, %wide.load549.1
  store <2 x i64> %249, <2 x i64>* %140, align 16, !tbaa !3
  %wide.load.2 = load <2 x i64>, <2 x i64>* %142, align 8, !tbaa !3
  %wide.load541.2 = load <2 x i64>, <2 x i64>* %144, align 16, !tbaa !3
  %250 = xor <2 x i64> %wide.load541.2, %wide.load.2
  %251 = and <2 x i64> %250, %broadcast.splat543
  %252 = xor <2 x i64> %251, %wide.load.2
  store <2 x i64> %252, <2 x i64>* %145, align 8, !tbaa !3
  %253 = xor <2 x i64> %251, %wide.load541.2
  store <2 x i64> %253, <2 x i64>* %146, align 16, !tbaa !3
  %wide.load544.2 = load <2 x i64>, <2 x i64>* %148, align 8, !tbaa !3
  %wide.load545.2 = load <2 x i64>, <2 x i64>* %150, align 16, !tbaa !3
  %254 = xor <2 x i64> %wide.load545.2, %wide.load544.2
  %255 = and <2 x i64> %254, %broadcast.splat543
  %256 = xor <2 x i64> %255, %wide.load544.2
  store <2 x i64> %256, <2 x i64>* %151, align 8, !tbaa !3
  %257 = xor <2 x i64> %255, %wide.load545.2
  store <2 x i64> %257, <2 x i64>* %152, align 16, !tbaa !3
  %wide.load546.2 = load <2 x i64>, <2 x i64>* %154, align 8, !tbaa !3
  %wide.load547.2 = load <2 x i64>, <2 x i64>* %156, align 16, !tbaa !3
  %258 = xor <2 x i64> %wide.load547.2, %wide.load546.2
  %259 = and <2 x i64> %258, %broadcast.splat543
  %260 = xor <2 x i64> %259, %wide.load546.2
  store <2 x i64> %260, <2 x i64>* %157, align 8, !tbaa !3
  %261 = xor <2 x i64> %259, %wide.load547.2
  store <2 x i64> %261, <2 x i64>* %158, align 16, !tbaa !3
  %wide.load548.2 = load <2 x i64>, <2 x i64>* %160, align 8, !tbaa !3
  %wide.load549.2 = load <2 x i64>, <2 x i64>* %162, align 16, !tbaa !3
  %262 = xor <2 x i64> %wide.load549.2, %wide.load548.2
  %263 = and <2 x i64> %262, %broadcast.splat543
  %264 = xor <2 x i64> %263, %wide.load548.2
  store <2 x i64> %264, <2 x i64>* %163, align 8, !tbaa !3
  %265 = xor <2 x i64> %263, %wide.load549.2
  store <2 x i64> %265, <2 x i64>* %164, align 16, !tbaa !3
  %wide.load.3 = load <2 x i64>, <2 x i64>* %166, align 8, !tbaa !3
  %wide.load541.3 = load <2 x i64>, <2 x i64>* %168, align 16, !tbaa !3
  %266 = xor <2 x i64> %wide.load541.3, %wide.load.3
  %267 = and <2 x i64> %266, %broadcast.splat543
  %268 = xor <2 x i64> %267, %wide.load.3
  store <2 x i64> %268, <2 x i64>* %169, align 8, !tbaa !3
  %269 = xor <2 x i64> %267, %wide.load541.3
  store <2 x i64> %269, <2 x i64>* %170, align 16, !tbaa !3
  %wide.load544.3 = load <2 x i64>, <2 x i64>* %172, align 8, !tbaa !3
  %wide.load545.3 = load <2 x i64>, <2 x i64>* %174, align 16, !tbaa !3
  %270 = xor <2 x i64> %wide.load545.3, %wide.load544.3
  %271 = and <2 x i64> %270, %broadcast.splat543
  %272 = xor <2 x i64> %271, %wide.load544.3
  store <2 x i64> %272, <2 x i64>* %175, align 8, !tbaa !3
  %273 = xor <2 x i64> %271, %wide.load545.3
  store <2 x i64> %273, <2 x i64>* %176, align 16, !tbaa !3
  %wide.load546.3 = load <2 x i64>, <2 x i64>* %178, align 8, !tbaa !3
  %wide.load547.3 = load <2 x i64>, <2 x i64>* %180, align 16, !tbaa !3
  %274 = xor <2 x i64> %wide.load547.3, %wide.load546.3
  %275 = and <2 x i64> %274, %broadcast.splat543
  %276 = xor <2 x i64> %275, %wide.load546.3
  store <2 x i64> %276, <2 x i64>* %181, align 8, !tbaa !3
  %277 = xor <2 x i64> %275, %wide.load547.3
  store <2 x i64> %277, <2 x i64>* %182, align 16, !tbaa !3
  %wide.load548.3 = load <2 x i64>, <2 x i64>* %184, align 8, !tbaa !3
  %wide.load549.3 = load <2 x i64>, <2 x i64>* %186, align 16, !tbaa !3
  %278 = xor <2 x i64> %wide.load549.3, %wide.load548.3
  %279 = and <2 x i64> %278, %broadcast.splat543
  %280 = xor <2 x i64> %279, %wide.load548.3
  store <2 x i64> %280, <2 x i64>* %187, align 8, !tbaa !3
  %281 = xor <2 x i64> %279, %wide.load549.3
  store <2 x i64> %281, <2 x i64>* %188, align 16, !tbaa !3
  %wide.load.4 = load <2 x i64>, <2 x i64>* %190, align 8, !tbaa !3
  %wide.load541.4 = load <2 x i64>, <2 x i64>* %192, align 16, !tbaa !3
  %282 = xor <2 x i64> %wide.load541.4, %wide.load.4
  %283 = and <2 x i64> %282, %broadcast.splat543
  %284 = xor <2 x i64> %283, %wide.load.4
  store <2 x i64> %284, <2 x i64>* %193, align 8, !tbaa !3
  %285 = xor <2 x i64> %283, %wide.load541.4
  store <2 x i64> %285, <2 x i64>* %194, align 16, !tbaa !3
  %wide.load544.4 = load <2 x i64>, <2 x i64>* %196, align 8, !tbaa !3
  %wide.load545.4 = load <2 x i64>, <2 x i64>* %198, align 16, !tbaa !3
  %286 = xor <2 x i64> %wide.load545.4, %wide.load544.4
  %287 = and <2 x i64> %286, %broadcast.splat543
  %288 = xor <2 x i64> %287, %wide.load544.4
  store <2 x i64> %288, <2 x i64>* %199, align 8, !tbaa !3
  %289 = xor <2 x i64> %287, %wide.load545.4
  store <2 x i64> %289, <2 x i64>* %200, align 16, !tbaa !3
  %wide.load546.4 = load <2 x i64>, <2 x i64>* %202, align 8, !tbaa !3
  %wide.load547.4 = load <2 x i64>, <2 x i64>* %204, align 16, !tbaa !3
  %290 = xor <2 x i64> %wide.load547.4, %wide.load546.4
  %291 = and <2 x i64> %290, %broadcast.splat543
  %292 = xor <2 x i64> %291, %wide.load546.4
  store <2 x i64> %292, <2 x i64>* %205, align 8, !tbaa !3
  %293 = xor <2 x i64> %291, %wide.load547.4
  store <2 x i64> %293, <2 x i64>* %206, align 16, !tbaa !3
  %wide.load548.4 = load <2 x i64>, <2 x i64>* %208, align 8, !tbaa !3
  %wide.load549.4 = load <2 x i64>, <2 x i64>* %210, align 16, !tbaa !3
  %294 = xor <2 x i64> %wide.load549.4, %wide.load548.4
  %295 = and <2 x i64> %294, %broadcast.splat543
  %296 = xor <2 x i64> %295, %wide.load548.4
  store <2 x i64> %296, <2 x i64>* %211, align 8, !tbaa !3
  %297 = xor <2 x i64> %295, %wide.load549.4
  store <2 x i64> %297, <2 x i64>* %212, align 16, !tbaa !3
  call void @xDBLADD(%struct.point_proj* nonnull %arraydecay10, %struct.point_proj* nonnull %arraydecay14, [10 x i64]* nonnull %arraydecay21, [10 x i64]* nonnull %arraydecay23, [10 x i64]* nonnull %arraydecay1)
  %inc = add nuw nsw i32 %i.0539, 1
  %exitcond = icmp eq i32 %inc, %.
  br i1 %exitcond, label %vector.ph553, label %for.body

vector.ph553:                                     ; preds = %for.body
  %298 = zext i32 %conv to i64
  %sub42 = sub nsw i64 0, %298
  %broadcast.splatinsert563 = insertelement <2 x i64> undef, i64 %sub42, i32 0
  %broadcast.splat564 = shufflevector <2 x i64> %broadcast.splatinsert563, <2 x i64> undef, <2 x i32> zeroinitializer
  %299 = bitcast %struct.point_proj* %R to <2 x i64>*
  %wide.load561 = load <2 x i64>, <2 x i64>* %299, align 8, !tbaa !3
  %300 = bitcast [1 x %struct.point_proj]* %R2 to <2 x i64>*
  %wide.load562 = load <2 x i64>, <2 x i64>* %300, align 16, !tbaa !3
  %301 = xor <2 x i64> %wide.load562, %wide.load561
  %302 = and <2 x i64> %301, %broadcast.splat564
  %303 = xor <2 x i64> %302, %wide.load561
  %304 = bitcast %struct.point_proj* %R to <2 x i64>*
  store <2 x i64> %303, <2 x i64>* %304, align 8, !tbaa !3
  %305 = xor <2 x i64> %302, %wide.load562
  %306 = bitcast [1 x %struct.point_proj]* %R2 to <2 x i64>*
  store <2 x i64> %305, <2 x i64>* %306, align 16, !tbaa !3
  %307 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 0
  %308 = bitcast i64* %307 to <2 x i64>*
  %wide.load565 = load <2 x i64>, <2 x i64>* %308, align 8, !tbaa !3
  %309 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 0
  %310 = bitcast i64* %309 to <2 x i64>*
  %wide.load566 = load <2 x i64>, <2 x i64>* %310, align 16, !tbaa !3
  %311 = xor <2 x i64> %wide.load566, %wide.load565
  %312 = and <2 x i64> %311, %broadcast.splat564
  %313 = xor <2 x i64> %312, %wide.load565
  %314 = bitcast i64* %307 to <2 x i64>*
  store <2 x i64> %313, <2 x i64>* %314, align 8, !tbaa !3
  %315 = xor <2 x i64> %312, %wide.load566
  %316 = bitcast i64* %309 to <2 x i64>*
  store <2 x i64> %315, <2 x i64>* %316, align 16, !tbaa !3
  %317 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 0
  %318 = bitcast i64* %317 to <2 x i64>*
  %wide.load567 = load <2 x i64>, <2 x i64>* %318, align 8, !tbaa !3
  %319 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 0
  %320 = bitcast i64* %319 to <2 x i64>*
  %wide.load568 = load <2 x i64>, <2 x i64>* %320, align 16, !tbaa !3
  %321 = xor <2 x i64> %wide.load568, %wide.load567
  %322 = and <2 x i64> %321, %broadcast.splat564
  %323 = xor <2 x i64> %322, %wide.load567
  %324 = bitcast i64* %317 to <2 x i64>*
  store <2 x i64> %323, <2 x i64>* %324, align 8, !tbaa !3
  %325 = xor <2 x i64> %322, %wide.load568
  %326 = bitcast i64* %319 to <2 x i64>*
  store <2 x i64> %325, <2 x i64>* %326, align 16, !tbaa !3
  %327 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 0
  %328 = bitcast i64* %327 to <2 x i64>*
  %wide.load569 = load <2 x i64>, <2 x i64>* %328, align 8, !tbaa !3
  %329 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 0
  %330 = bitcast i64* %329 to <2 x i64>*
  %wide.load570 = load <2 x i64>, <2 x i64>* %330, align 16, !tbaa !3
  %331 = xor <2 x i64> %wide.load570, %wide.load569
  %332 = and <2 x i64> %331, %broadcast.splat564
  %333 = xor <2 x i64> %332, %wide.load569
  %334 = bitcast i64* %327 to <2 x i64>*
  store <2 x i64> %333, <2 x i64>* %334, align 8, !tbaa !3
  %335 = xor <2 x i64> %332, %wide.load570
  %336 = bitcast i64* %329 to <2 x i64>*
  store <2 x i64> %335, <2 x i64>* %336, align 16, !tbaa !3
  %337 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 2
  %338 = bitcast i64* %337 to <2 x i64>*
  %wide.load561.1 = load <2 x i64>, <2 x i64>* %338, align 8, !tbaa !3
  %339 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 2
  %340 = bitcast i64* %339 to <2 x i64>*
  %wide.load562.1 = load <2 x i64>, <2 x i64>* %340, align 16, !tbaa !3
  %341 = xor <2 x i64> %wide.load562.1, %wide.load561.1
  %342 = and <2 x i64> %341, %broadcast.splat564
  %343 = xor <2 x i64> %342, %wide.load561.1
  %344 = bitcast i64* %337 to <2 x i64>*
  store <2 x i64> %343, <2 x i64>* %344, align 8, !tbaa !3
  %345 = xor <2 x i64> %342, %wide.load562.1
  %346 = bitcast i64* %339 to <2 x i64>*
  store <2 x i64> %345, <2 x i64>* %346, align 16, !tbaa !3
  %347 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 2
  %348 = bitcast i64* %347 to <2 x i64>*
  %wide.load565.1 = load <2 x i64>, <2 x i64>* %348, align 8, !tbaa !3
  %349 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 2
  %350 = bitcast i64* %349 to <2 x i64>*
  %wide.load566.1 = load <2 x i64>, <2 x i64>* %350, align 16, !tbaa !3
  %351 = xor <2 x i64> %wide.load566.1, %wide.load565.1
  %352 = and <2 x i64> %351, %broadcast.splat564
  %353 = xor <2 x i64> %352, %wide.load565.1
  %354 = bitcast i64* %347 to <2 x i64>*
  store <2 x i64> %353, <2 x i64>* %354, align 8, !tbaa !3
  %355 = xor <2 x i64> %352, %wide.load566.1
  %356 = bitcast i64* %349 to <2 x i64>*
  store <2 x i64> %355, <2 x i64>* %356, align 16, !tbaa !3
  %357 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 2
  %358 = bitcast i64* %357 to <2 x i64>*
  %wide.load567.1 = load <2 x i64>, <2 x i64>* %358, align 8, !tbaa !3
  %359 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 2
  %360 = bitcast i64* %359 to <2 x i64>*
  %wide.load568.1 = load <2 x i64>, <2 x i64>* %360, align 16, !tbaa !3
  %361 = xor <2 x i64> %wide.load568.1, %wide.load567.1
  %362 = and <2 x i64> %361, %broadcast.splat564
  %363 = xor <2 x i64> %362, %wide.load567.1
  %364 = bitcast i64* %357 to <2 x i64>*
  store <2 x i64> %363, <2 x i64>* %364, align 8, !tbaa !3
  %365 = xor <2 x i64> %362, %wide.load568.1
  %366 = bitcast i64* %359 to <2 x i64>*
  store <2 x i64> %365, <2 x i64>* %366, align 16, !tbaa !3
  %367 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 2
  %368 = bitcast i64* %367 to <2 x i64>*
  %wide.load569.1 = load <2 x i64>, <2 x i64>* %368, align 8, !tbaa !3
  %369 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 2
  %370 = bitcast i64* %369 to <2 x i64>*
  %wide.load570.1 = load <2 x i64>, <2 x i64>* %370, align 16, !tbaa !3
  %371 = xor <2 x i64> %wide.load570.1, %wide.load569.1
  %372 = and <2 x i64> %371, %broadcast.splat564
  %373 = xor <2 x i64> %372, %wide.load569.1
  %374 = bitcast i64* %367 to <2 x i64>*
  store <2 x i64> %373, <2 x i64>* %374, align 8, !tbaa !3
  %375 = xor <2 x i64> %372, %wide.load570.1
  %376 = bitcast i64* %369 to <2 x i64>*
  store <2 x i64> %375, <2 x i64>* %376, align 16, !tbaa !3
  %377 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 4
  %378 = bitcast i64* %377 to <2 x i64>*
  %wide.load561.2 = load <2 x i64>, <2 x i64>* %378, align 8, !tbaa !3
  %379 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 4
  %380 = bitcast i64* %379 to <2 x i64>*
  %wide.load562.2 = load <2 x i64>, <2 x i64>* %380, align 16, !tbaa !3
  %381 = xor <2 x i64> %wide.load562.2, %wide.load561.2
  %382 = and <2 x i64> %381, %broadcast.splat564
  %383 = xor <2 x i64> %382, %wide.load561.2
  %384 = bitcast i64* %377 to <2 x i64>*
  store <2 x i64> %383, <2 x i64>* %384, align 8, !tbaa !3
  %385 = xor <2 x i64> %382, %wide.load562.2
  %386 = bitcast i64* %379 to <2 x i64>*
  store <2 x i64> %385, <2 x i64>* %386, align 16, !tbaa !3
  %387 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 4
  %388 = bitcast i64* %387 to <2 x i64>*
  %wide.load565.2 = load <2 x i64>, <2 x i64>* %388, align 8, !tbaa !3
  %389 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 4
  %390 = bitcast i64* %389 to <2 x i64>*
  %wide.load566.2 = load <2 x i64>, <2 x i64>* %390, align 16, !tbaa !3
  %391 = xor <2 x i64> %wide.load566.2, %wide.load565.2
  %392 = and <2 x i64> %391, %broadcast.splat564
  %393 = xor <2 x i64> %392, %wide.load565.2
  %394 = bitcast i64* %387 to <2 x i64>*
  store <2 x i64> %393, <2 x i64>* %394, align 8, !tbaa !3
  %395 = xor <2 x i64> %392, %wide.load566.2
  %396 = bitcast i64* %389 to <2 x i64>*
  store <2 x i64> %395, <2 x i64>* %396, align 16, !tbaa !3
  %397 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 4
  %398 = bitcast i64* %397 to <2 x i64>*
  %wide.load567.2 = load <2 x i64>, <2 x i64>* %398, align 8, !tbaa !3
  %399 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 4
  %400 = bitcast i64* %399 to <2 x i64>*
  %wide.load568.2 = load <2 x i64>, <2 x i64>* %400, align 16, !tbaa !3
  %401 = xor <2 x i64> %wide.load568.2, %wide.load567.2
  %402 = and <2 x i64> %401, %broadcast.splat564
  %403 = xor <2 x i64> %402, %wide.load567.2
  %404 = bitcast i64* %397 to <2 x i64>*
  store <2 x i64> %403, <2 x i64>* %404, align 8, !tbaa !3
  %405 = xor <2 x i64> %402, %wide.load568.2
  %406 = bitcast i64* %399 to <2 x i64>*
  store <2 x i64> %405, <2 x i64>* %406, align 16, !tbaa !3
  %407 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 4
  %408 = bitcast i64* %407 to <2 x i64>*
  %wide.load569.2 = load <2 x i64>, <2 x i64>* %408, align 8, !tbaa !3
  %409 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 4
  %410 = bitcast i64* %409 to <2 x i64>*
  %wide.load570.2 = load <2 x i64>, <2 x i64>* %410, align 16, !tbaa !3
  %411 = xor <2 x i64> %wide.load570.2, %wide.load569.2
  %412 = and <2 x i64> %411, %broadcast.splat564
  %413 = xor <2 x i64> %412, %wide.load569.2
  %414 = bitcast i64* %407 to <2 x i64>*
  store <2 x i64> %413, <2 x i64>* %414, align 8, !tbaa !3
  %415 = xor <2 x i64> %412, %wide.load570.2
  %416 = bitcast i64* %409 to <2 x i64>*
  store <2 x i64> %415, <2 x i64>* %416, align 16, !tbaa !3
  %417 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 6
  %418 = bitcast i64* %417 to <2 x i64>*
  %wide.load561.3 = load <2 x i64>, <2 x i64>* %418, align 8, !tbaa !3
  %419 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 6
  %420 = bitcast i64* %419 to <2 x i64>*
  %wide.load562.3 = load <2 x i64>, <2 x i64>* %420, align 16, !tbaa !3
  %421 = xor <2 x i64> %wide.load562.3, %wide.load561.3
  %422 = and <2 x i64> %421, %broadcast.splat564
  %423 = xor <2 x i64> %422, %wide.load561.3
  %424 = bitcast i64* %417 to <2 x i64>*
  store <2 x i64> %423, <2 x i64>* %424, align 8, !tbaa !3
  %425 = xor <2 x i64> %422, %wide.load562.3
  %426 = bitcast i64* %419 to <2 x i64>*
  store <2 x i64> %425, <2 x i64>* %426, align 16, !tbaa !3
  %427 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 6
  %428 = bitcast i64* %427 to <2 x i64>*
  %wide.load565.3 = load <2 x i64>, <2 x i64>* %428, align 8, !tbaa !3
  %429 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 6
  %430 = bitcast i64* %429 to <2 x i64>*
  %wide.load566.3 = load <2 x i64>, <2 x i64>* %430, align 16, !tbaa !3
  %431 = xor <2 x i64> %wide.load566.3, %wide.load565.3
  %432 = and <2 x i64> %431, %broadcast.splat564
  %433 = xor <2 x i64> %432, %wide.load565.3
  %434 = bitcast i64* %427 to <2 x i64>*
  store <2 x i64> %433, <2 x i64>* %434, align 8, !tbaa !3
  %435 = xor <2 x i64> %432, %wide.load566.3
  %436 = bitcast i64* %429 to <2 x i64>*
  store <2 x i64> %435, <2 x i64>* %436, align 16, !tbaa !3
  %437 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 6
  %438 = bitcast i64* %437 to <2 x i64>*
  %wide.load567.3 = load <2 x i64>, <2 x i64>* %438, align 8, !tbaa !3
  %439 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 6
  %440 = bitcast i64* %439 to <2 x i64>*
  %wide.load568.3 = load <2 x i64>, <2 x i64>* %440, align 16, !tbaa !3
  %441 = xor <2 x i64> %wide.load568.3, %wide.load567.3
  %442 = and <2 x i64> %441, %broadcast.splat564
  %443 = xor <2 x i64> %442, %wide.load567.3
  %444 = bitcast i64* %437 to <2 x i64>*
  store <2 x i64> %443, <2 x i64>* %444, align 8, !tbaa !3
  %445 = xor <2 x i64> %442, %wide.load568.3
  %446 = bitcast i64* %439 to <2 x i64>*
  store <2 x i64> %445, <2 x i64>* %446, align 16, !tbaa !3
  %447 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 6
  %448 = bitcast i64* %447 to <2 x i64>*
  %wide.load569.3 = load <2 x i64>, <2 x i64>* %448, align 8, !tbaa !3
  %449 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 6
  %450 = bitcast i64* %449 to <2 x i64>*
  %wide.load570.3 = load <2 x i64>, <2 x i64>* %450, align 16, !tbaa !3
  %451 = xor <2 x i64> %wide.load570.3, %wide.load569.3
  %452 = and <2 x i64> %451, %broadcast.splat564
  %453 = xor <2 x i64> %452, %wide.load569.3
  %454 = bitcast i64* %447 to <2 x i64>*
  store <2 x i64> %453, <2 x i64>* %454, align 8, !tbaa !3
  %455 = xor <2 x i64> %452, %wide.load570.3
  %456 = bitcast i64* %449 to <2 x i64>*
  store <2 x i64> %455, <2 x i64>* %456, align 16, !tbaa !3
  %457 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 0, i64 8
  %458 = bitcast i64* %457 to <2 x i64>*
  %wide.load561.4 = load <2 x i64>, <2 x i64>* %458, align 8, !tbaa !3
  %459 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 0, i64 8
  %460 = bitcast i64* %459 to <2 x i64>*
  %wide.load562.4 = load <2 x i64>, <2 x i64>* %460, align 16, !tbaa !3
  %461 = xor <2 x i64> %wide.load562.4, %wide.load561.4
  %462 = and <2 x i64> %461, %broadcast.splat564
  %463 = xor <2 x i64> %462, %wide.load561.4
  %464 = bitcast i64* %457 to <2 x i64>*
  store <2 x i64> %463, <2 x i64>* %464, align 8, !tbaa !3
  %465 = xor <2 x i64> %462, %wide.load562.4
  %466 = bitcast i64* %459 to <2 x i64>*
  store <2 x i64> %465, <2 x i64>* %466, align 16, !tbaa !3
  %467 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 0, i64 1, i64 8
  %468 = bitcast i64* %467 to <2 x i64>*
  %wide.load565.4 = load <2 x i64>, <2 x i64>* %468, align 8, !tbaa !3
  %469 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 0, i64 1, i64 8
  %470 = bitcast i64* %469 to <2 x i64>*
  %wide.load566.4 = load <2 x i64>, <2 x i64>* %470, align 16, !tbaa !3
  %471 = xor <2 x i64> %wide.load566.4, %wide.load565.4
  %472 = and <2 x i64> %471, %broadcast.splat564
  %473 = xor <2 x i64> %472, %wide.load565.4
  %474 = bitcast i64* %467 to <2 x i64>*
  store <2 x i64> %473, <2 x i64>* %474, align 8, !tbaa !3
  %475 = xor <2 x i64> %472, %wide.load566.4
  %476 = bitcast i64* %469 to <2 x i64>*
  store <2 x i64> %475, <2 x i64>* %476, align 16, !tbaa !3
  %477 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 0, i64 8
  %478 = bitcast i64* %477 to <2 x i64>*
  %wide.load567.4 = load <2 x i64>, <2 x i64>* %478, align 8, !tbaa !3
  %479 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 0, i64 8
  %480 = bitcast i64* %479 to <2 x i64>*
  %wide.load568.4 = load <2 x i64>, <2 x i64>* %480, align 16, !tbaa !3
  %481 = xor <2 x i64> %wide.load568.4, %wide.load567.4
  %482 = and <2 x i64> %481, %broadcast.splat564
  %483 = xor <2 x i64> %482, %wide.load567.4
  %484 = bitcast i64* %477 to <2 x i64>*
  store <2 x i64> %483, <2 x i64>* %484, align 8, !tbaa !3
  %485 = xor <2 x i64> %482, %wide.load568.4
  %486 = bitcast i64* %479 to <2 x i64>*
  store <2 x i64> %485, <2 x i64>* %486, align 16, !tbaa !3
  %487 = getelementptr inbounds %struct.point_proj, %struct.point_proj* %R, i64 0, i32 1, i64 1, i64 8
  %488 = bitcast i64* %487 to <2 x i64>*
  %wide.load569.4 = load <2 x i64>, <2 x i64>* %488, align 8, !tbaa !3
  %489 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R2, i64 0, i64 0, i32 1, i64 1, i64 8
  %490 = bitcast i64* %489 to <2 x i64>*
  %wide.load570.4 = load <2 x i64>, <2 x i64>* %490, align 16, !tbaa !3
  %491 = xor <2 x i64> %wide.load570.4, %wide.load569.4
  %492 = and <2 x i64> %491, %broadcast.splat564
  %493 = xor <2 x i64> %492, %wide.load569.4
  %494 = bitcast i64* %487 to <2 x i64>*
  store <2 x i64> %493, <2 x i64>* %494, align 8, !tbaa !3
  %495 = xor <2 x i64> %492, %wide.load570.4
  %496 = bitcast i64* %489 to <2 x i64>*
  store <2 x i64> %495, <2 x i64>* %496, align 16, !tbaa !3
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %0) #10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define i32 @EphemeralKeyGeneration_B_SIDHp610(i8* %PrivateKeyB, i8* %PublicKeyB) local_unnamed_addr #4 {
entry:
  %temp.i.i.i.i = alloca [20 x i64], align 16
  %one.i.i.i = alloca [10 x i64], align 16
  %t.i = alloca [2 x [10 x i64]], align 16
  %R = alloca [1 x %struct.point_proj], align 16
  %phiP = alloca [1 x %struct.point_proj], align 16
  %phiQ = alloca [1 x %struct.point_proj], align 16
  %phiR = alloca [1 x %struct.point_proj], align 16
  %pts = alloca [10 x [1 x %struct.point_proj]], align 16
  %XPB = alloca [2 x [10 x i64]], align 16
  %XQB = alloca [2 x [10 x i64]], align 16
  %XRB = alloca [2 x [10 x i64]], align 16
  %coeff = alloca [3 x [2 x [10 x i64]]], align 16
  %A24plus = alloca [2 x [10 x i64]], align 16
  %A24minus = alloca [2 x [10 x i64]], align 16
  %A = alloca [2 x [10 x i64]], align 16
  %pts_index = alloca [10 x i32], align 16
  %SecretKeyB = alloca [5 x i64], align 16
  %0 = bitcast [1 x %struct.point_proj]* %R to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %0) #10
  %1 = bitcast [1 x %struct.point_proj]* %phiP to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1, i8 0, i64 320, i1 false)
  %2 = bitcast [1 x %struct.point_proj]* %phiQ to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %2) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %2, i8 0, i64 320, i1 false)
  %3 = bitcast [1 x %struct.point_proj]* %phiR to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %3) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 320, i1 false)
  %4 = bitcast [10 x [1 x %struct.point_proj]]* %pts to i8*
  call void @llvm.lifetime.start.p0i8(i64 3200, i8* nonnull %4) #10
  %5 = bitcast [2 x [10 x i64]]* %XPB to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  %6 = bitcast [2 x [10 x i64]]* %XQB to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %6) #10
  %7 = bitcast [2 x [10 x i64]]* %XRB to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  %8 = bitcast [3 x [2 x [10 x i64]]]* %coeff to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %8) #10
  %9 = bitcast [2 x [10 x i64]]* %A24plus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 160, i1 false)
  %10 = bitcast [2 x [10 x i64]]* %A24minus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 160, i1 false)
  %11 = bitcast [2 x [10 x i64]]* %A to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false)
  %12 = bitcast [10 x i32]* %pts_index to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %12) #10
  %13 = bitcast [5 x i64]* %SecretKeyB to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %13) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 0, i64 40, i1 false)
  %arraydecay = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPB, i64 0, i64 0
  %arraydecay1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQB, i64 0, i64 0
  %arraydecay2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRB, i64 0, i64 0
  %14 = bitcast [2 x [10 x i64]]* %XPB to <4 x i64>*
  store <4 x i64> <i64 -4122797515158813510, i64 2405435625630280597, i64 -3749193287274905454, i64 -2935559660200231368>, <4 x i64>* %14, align 16, !tbaa !3
  %arrayidx2.4.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPB, i64 0, i64 0, i64 4
  %15 = bitcast i64* %arrayidx2.4.i.i to <4 x i64>*
  store <4 x i64> <i64 7035179512456608727, i64 -1088186176647096380, i64 2237320506219039519, i64 -4139295546001939262>, <4 x i64>* %15, align 16, !tbaa !3
  %arrayidx2.8.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPB, i64 0, i64 0, i64 8
  store i64 -2033832934895166963, i64* %arrayidx2.8.i.i, align 16, !tbaa !3
  %arrayidx2.9.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPB, i64 0, i64 0, i64 9
  store i64 5379123413, i64* %arrayidx2.9.i.i, align 8, !tbaa !3
  %arraydecay2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XPB, i64 0, i64 1, i64 0
  %16 = bitcast i64* %arraydecay2.i to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 0, i64 80, i1 false)
  %17 = bitcast [2 x [10 x i64]]* %XQB to <4 x i64>*
  store <4 x i64> <i64 -754674776282359680, i64 8155755975969367465, i64 -7108179690244256889, i64 5678382275401384545>, <4 x i64>* %17, align 16, !tbaa !3
  %arrayidx2.4.i191 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQB, i64 0, i64 0, i64 4
  %18 = bitcast i64* %arrayidx2.4.i191 to <4 x i64>*
  store <4 x i64> <i64 -5945512278495342032, i64 4726463275275376934, i64 -1362977618025674515, i64 4479281637794437063>, <4 x i64>* %18, align 16, !tbaa !3
  %arrayidx2.8.i195 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQB, i64 0, i64 0, i64 8
  store i64 -906589179791040647, i64* %arrayidx2.8.i195, align 16, !tbaa !3
  %arrayidx2.9.i196 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQB, i64 0, i64 0, i64 9
  store i64 9074793307, i64* %arrayidx2.9.i196, align 8, !tbaa !3
  %arraydecay8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XQB, i64 0, i64 1, i64 0
  %19 = bitcast i64* %arraydecay8.i to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %19, i8 0, i64 80, i1 false)
  %20 = bitcast [2 x [10 x i64]]* %XRB to <4 x i64>*
  store <4 x i64> <i64 8829176751768485847, i64 4330345099806588278, i64 6439066249656508832, i64 -774629675044450053>, <4 x i64>* %20, align 16, !tbaa !3
  %arrayidx2.4.i48.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRB, i64 0, i64 0, i64 4
  %21 = bitcast i64* %arrayidx2.4.i48.i to <4 x i64>*
  store <4 x i64> <i64 -5503580640218556678, i64 -9083173236816041803, i64 -1462621330690897264, i64 -8763703354377076720>, <4 x i64>* %21, align 16, !tbaa !3
  %arrayidx2.8.i56.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRB, i64 0, i64 0, i64 8
  %22 = bitcast i64* %arrayidx2.8.i56.i to <4 x i64>*
  store <4 x i64> <i64 -2191538623876663267, i64 9017845420, i64 6790521807624498538, i64 -2290772438416721629>, <4 x i64>* %22, align 16, !tbaa !3
  %arrayidx2.2.i26.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRB, i64 0, i64 1, i64 2
  %23 = bitcast i64* %arrayidx2.2.i26.i to <4 x i64>*
  store <4 x i64> <i64 4283588130542979409, i64 514645655039295889, i64 8912678322428419353, i64 6038404330050892853>, <4 x i64>* %23, align 16, !tbaa !3
  %arrayidx2.6.i34.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %XRB, i64 0, i64 1, i64 6
  %24 = bitcast i64* %arrayidx2.6.i34.i to <4 x i64>*
  store <4 x i64> <i64 -1270586841300829686, i64 -8530139311933844284, i64 910728456329037494, i64 5513273805>, <4 x i64>* %24, align 16, !tbaa !3
  %arraydecay3 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0
  %arraydecay5 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0
  %arraydecay8 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0
  %arraydecay.i197 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 0
  %25 = bitcast [1 x %struct.point_proj]* %phiP to <4 x i64>*
  store <4 x i64> <i64 5771904529248994682, i64 -8436915071433390351, i64 270330086766583390, i64 6481898407746275289>, <4 x i64>* %25, align 16, !tbaa !3
  %arrayidx2.4.i.i201 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 4
  %26 = bitcast i64* %arrayidx2.4.i.i201 to <4 x i64>*
  store <4 x i64> <i64 7865854910092666580, i64 -2826674533944143030, i64 -7553167192889215565, i64 -9032646596491157233>, <4 x i64>* %26, align 16, !tbaa !3
  %arrayidx2.8.i.i205 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0, i64 8
  %arraydecay2.i207 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 1, i64 0
  %27 = bitcast i64* %arrayidx2.8.i.i205 to <4 x i64>*
  store <4 x i64> <i64 5194719131280954495, i64 1729770898, i64 -1965085922052779020, i64 -4812970318505102637>, <4 x i64>* %27, align 16, !tbaa !3
  %arrayidx2.2.i240 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 1, i64 2
  %28 = bitcast i64* %arrayidx2.2.i240 to <4 x i64>*
  store <4 x i64> <i64 1977403254395278860, i64 2726390535525409621, i64 -248047565090072982, i64 -5454070453411567460>, <4 x i64>* %28, align 16, !tbaa !3
  %arrayidx2.6.i244 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 1, i64 6
  %29 = bitcast i64* %arrayidx2.6.i244 to <4 x i64>*
  store <4 x i64> <i64 -2860923682387992558, i64 4095961562244124488, i64 -4917308312211097814, i64 5102423139>, <4 x i64>* %29, align 16, !tbaa !3
  %arraydecay5.i208 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 0
  %30 = bitcast [1 x %struct.point_proj]* %phiQ to <4 x i64>*
  store <4 x i64> <i64 2124736252400681868, i64 -7322998048931732039, i64 2202127831239085027, i64 -3257580811259719115>, <4 x i64>* %30, align 16, !tbaa !3
  %arrayidx2.4.i251 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 4
  %31 = bitcast i64* %arrayidx2.4.i251 to <4 x i64>*
  store <4 x i64> <i64 4313963896834226850, i64 -5076443579667205976, i64 4921946642166740880, i64 -3805954528561435943>, <4 x i64>* %31, align 16, !tbaa !3
  %arrayidx2.8.i255 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0, i64 8
  %arraydecay8.i209 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 1, i64 0
  %32 = bitcast i64* %arrayidx2.8.i255 to <4 x i64>*
  store <4 x i64> <i64 -2637702132890644254, i64 7907518294, i64 2200917311302176889, i64 2939498022256786432>, <4 x i64>* %32, align 16, !tbaa !3
  %arrayidx2.2.i62.i211 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 1, i64 2
  %33 = bitcast i64* %arrayidx2.2.i62.i211 to <4 x i64>*
  store <4 x i64> <i64 -2284167071920397343, i64 -8889311404158421409, i64 -3057031954716630490, i64 -4860527247048815703>, <4 x i64>* %33, align 16, !tbaa !3
  %arrayidx2.6.i70.i215 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 1, i64 6
  %34 = bitcast i64* %arrayidx2.6.i70.i215 to <4 x i64>*
  store <4 x i64> <i64 -7932579696214058839, i64 334500554730375393, i64 6399318707077975086, i64 8976719684>, <4 x i64>* %34, align 16, !tbaa !3
  %arraydecay11.i219 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 0
  %35 = bitcast [1 x %struct.point_proj]* %phiR to <4 x i64>*
  store <4 x i64> <i64 2746580562334225805, i64 -4441891846683360495, i64 -6980094913201629698, i64 -6647113845825354661>, <4 x i64>* %35, align 16, !tbaa !3
  %arrayidx2.4.i48.i223 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 4
  %36 = bitcast i64* %arrayidx2.4.i48.i223 to <4 x i64>*
  store <4 x i64> <i64 6714415832701611114, i64 -8334607330680099106, i64 7010145936394111770, i64 -403948467988784721>, <4 x i64>* %36, align 16, !tbaa !3
  %arrayidx2.8.i56.i227 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0, i64 8
  %arraydecay14.i229 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 0
  %37 = bitcast i64* %arrayidx2.8.i56.i227 to <4 x i64>*
  store <4 x i64> <i64 -7139691166611819809, i64 3478841981, i64 -5079986323839184192, i64 3119472779256121459>, <4 x i64>* %37, align 16, !tbaa !3
  %arrayidx2.2.i26.i231 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 2
  %38 = bitcast i64* %arrayidx2.2.i26.i231 to <4 x i64>*
  store <4 x i64> <i64 4709779656408495164, i64 -1878325030037470211, i64 -3755564803635956908, i64 5893360609436446022>, <4 x i64>* %38, align 16, !tbaa !3
  %arrayidx2.6.i34.i235 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 1, i64 6
  %39 = bitcast i64* %arrayidx2.6.i34.i235 to <4 x i64>*
  store <4 x i64> <i64 6635037533545129430, i64 5031143778661013925, i64 2711723078310815363, i64 10114015515>, <4 x i64>* %39, align 16, !tbaa !3
  %Z = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay12, align 16, !tbaa !3
  %arrayidx2.1.i257 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i260 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 4
  %40 = bitcast i64* %arrayidx2.1.i257 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %40, i8 0, i64 24, i1 false)
  %41 = bitcast i64* %arrayidx2.4.i260 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %41, align 16, !tbaa !3
  %arrayidx2.8.i264 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i264, align 16, !tbaa !3
  %arrayidx2.9.i265 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i265, align 8, !tbaa !3
  %Z14 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1
  %arraydecay16 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z14, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay16, align 16, !tbaa !3
  %arrayidx2.1.i266 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i269 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 4
  %42 = bitcast i64* %arrayidx2.1.i266 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %42, i8 0, i64 24, i1 false)
  %43 = bitcast i64* %arrayidx2.4.i269 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %43, align 16, !tbaa !3
  %arrayidx2.8.i273 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i273, align 16, !tbaa !3
  %arrayidx2.9.i274 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i274, align 8, !tbaa !3
  %Z18 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1
  %arraydecay20 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z18, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %arraydecay20, align 16, !tbaa !3
  %arrayidx2.1.i275 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.4.i278 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 4
  %44 = bitcast i64* %arrayidx2.1.i275 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 0, i64 24, i1 false)
  %45 = bitcast i64* %arrayidx2.4.i278 to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %45, align 16, !tbaa !3
  %arrayidx2.8.i282 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i282, align 16, !tbaa !3
  %arrayidx2.9.i283 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i283, align 8, !tbaa !3
  %arraydecay22 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 0
  %arrayidx2.1.i284 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 1
  %arrayidx2.4.i287 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 4
  %arrayidx2.8.i291 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 8
  %arrayidx2.9.i292 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 9
  %arraydecay23 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0
  store i64 3457782220, i64* %arraydecay22, align 16, !tbaa !3
  %46 = bitcast i64* %arrayidx2.1.i284 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %46, i8 0, i64 24, i1 false)
  %47 = bitcast i64* %arrayidx2.4.i287 to <4 x i64>*
  store <4 x i64> <i64 3776268287550160896, i64 -7263315013628922753, i64 1482863448970209336, i64 -6526766805794053180>, <4 x i64>* %47, align 16, !tbaa !3
  store i64 2797303665991966331, i64* %arrayidx2.8.i291, align 16, !tbaa !3
  store i64 8877888200, i64* %arrayidx2.9.i292, align 8, !tbaa !3
  %arraydecay6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 0
  %48 = load i64, i64* %arraydecay6.i, align 16, !tbaa !3
  %add3.i.i = shl i64 %48, 1
  store i64 %add3.i.i, i64* %arraydecay6.i, align 16, !tbaa !3
  %or29.i.i = lshr i64 %48, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 1
  %49 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %49, %or29.i.i
  %add3.i.1.i = add i64 %add.i.1.i, %49
  store i64 %add3.i.1.i, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %50 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %50, %49
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %49
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 2
  %51 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %51
  %add3.i.2.i = add i64 %add.i.2.i, %51
  store i64 %add3.i.2.i, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %52 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %52, %51
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %51
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 3
  %53 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %53
  %add3.i.3.i = add i64 %add.i.3.i, %53
  store i64 %add3.i.3.i, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %54 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %54, %53
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %53
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 4
  %55 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %55
  %add3.i.4.i = add i64 %add.i.4.i, %55
  store i64 %add3.i.4.i, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %56 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %56, %55
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %55
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 5
  %57 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %57
  %add3.i.5.i = add i64 %add.i.5.i, %57
  store i64 %add3.i.5.i, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %58 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %58, %57
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %57
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 6
  %59 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %59
  %add3.i.6.i = add i64 %add.i.6.i, %59
  store i64 %add3.i.6.i, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %60 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %60, %59
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %59
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 7
  %61 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %61
  %add3.i.7.i = add i64 %add.i.7.i, %61
  store i64 %add3.i.7.i, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %62 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %62, %61
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %61
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 8
  %63 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %63
  %add3.i.8.i = add i64 %add.i.8.i, %63
  store i64 %add3.i.8.i, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %64 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %64, %63
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %63
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 9
  %65 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %factor1220 = shl i64 %65, 1
  %add3.i.9.i = or i64 %or29.i.8.i, %factor1220
  store i64 %add3.i.9.i, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arraydecay28 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0
  %arraydecay4.i405 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 0
  store i64 6915564440, i64* %arraydecay4.i405, align 16, !tbaa !3
  %arrayidx5.i.1.i526 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 1
  %arrayidx5.i.4.i562 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 4
  %66 = bitcast i64* %arrayidx5.i.1.i526 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %66, i8 0, i64 24, i1 false)
  %67 = bitcast i64* %arrayidx5.i.4.i562 to <4 x i64>*
  store <4 x i64> <i64 7552536575100321792, i64 3920114046451706110, i64 2965726897940418673, i64 5393210462121445256>, <4 x i64>* %67, align 16, !tbaa !3
  %arrayidx5.i.8.i610 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 8
  store i64 5594607331983932663, i64* %arrayidx5.i.8.i610, align 16, !tbaa !3
  %arrayidx5.i.9.i622 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 9
  store i64 17755776400, i64* %arrayidx5.i.9.i622, align 8, !tbaa !3
  %arraydecay10.i408 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 0
  %add3.i.i409 = shl i64 %48, 2
  store i64 %add3.i.i409, i64* %arraydecay10.i408, align 16, !tbaa !3
  %xor.i23.i.i410 = xor i64 %add3.i.i409, %add3.i.i
  %68 = lshr i64 %48, 62
  %or29.i.i414 = and i64 %68, 1
  %add.i.1.i416 = add i64 %add3.i.1.i, %or29.i.i414
  %add3.i.1.i418 = add i64 %add.i.1.i416, %add3.i.1.i
  %arrayidx5.i.1.i419 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i418, i64* %arrayidx5.i.1.i419, align 8, !tbaa !3
  %69 = xor i64 %add.i.1.i416, -9223372036854775808
  %xor2.i.i.1.i420 = and i64 %69, %add3.i.1.i
  %xor.i23.i.1.i421 = xor i64 %add3.i.1.i418, %add.i.1.i416
  %xor1.i24.i.1.i422 = xor i64 %add.i.1.i416, %add3.i.1.i
  %or.i25.i.1.i423 = or i64 %xor.i23.i.1.i421, %xor1.i24.i.1.i422
  %xor2.i26.i.1.i424 = xor i64 %or.i25.i.1.i423, %add3.i.1.i418
  %shr.i30.i.1.i425 = or i64 %xor2.i26.i.1.i424, %xor2.i.i.1.i420
  %or29.i.1.i426 = lshr i64 %shr.i30.i.1.i425, 63
  %add.i.2.i428 = add i64 %add3.i.2.i, %or29.i.1.i426
  %add3.i.2.i430 = add i64 %add.i.2.i428, %add3.i.2.i
  %arrayidx5.i.2.i431 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i430, i64* %arrayidx5.i.2.i431, align 16, !tbaa !3
  %70 = xor i64 %add.i.2.i428, -9223372036854775808
  %xor2.i.i.2.i432 = and i64 %70, %add3.i.2.i
  %xor.i23.i.2.i433 = xor i64 %add3.i.2.i430, %add.i.2.i428
  %xor1.i24.i.2.i434 = xor i64 %add.i.2.i428, %add3.i.2.i
  %or.i25.i.2.i435 = or i64 %xor.i23.i.2.i433, %xor1.i24.i.2.i434
  %xor2.i26.i.2.i436 = xor i64 %or.i25.i.2.i435, %add3.i.2.i430
  %shr.i30.i.2.i437 = or i64 %xor2.i26.i.2.i436, %xor2.i.i.2.i432
  %or29.i.2.i438 = lshr i64 %shr.i30.i.2.i437, 63
  %add.i.3.i440 = add i64 %add3.i.3.i, %or29.i.2.i438
  %add3.i.3.i442 = add i64 %add.i.3.i440, %add3.i.3.i
  %arrayidx5.i.3.i443 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i442, i64* %arrayidx5.i.3.i443, align 8, !tbaa !3
  %71 = xor i64 %add.i.3.i440, -9223372036854775808
  %xor2.i.i.3.i444 = and i64 %71, %add3.i.3.i
  %xor.i23.i.3.i445 = xor i64 %add3.i.3.i442, %add.i.3.i440
  %xor1.i24.i.3.i446 = xor i64 %add.i.3.i440, %add3.i.3.i
  %or.i25.i.3.i447 = or i64 %xor.i23.i.3.i445, %xor1.i24.i.3.i446
  %xor2.i26.i.3.i448 = xor i64 %or.i25.i.3.i447, %add3.i.3.i442
  %shr.i30.i.3.i449 = or i64 %xor2.i26.i.3.i448, %xor2.i.i.3.i444
  %or29.i.3.i450 = lshr i64 %shr.i30.i.3.i449, 63
  %add.i.4.i452 = add i64 %add3.i.4.i, %or29.i.3.i450
  %add3.i.4.i454 = add i64 %add.i.4.i452, %add3.i.4.i
  %arrayidx5.i.4.i455 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i454, i64* %arrayidx5.i.4.i455, align 16, !tbaa !3
  %72 = xor i64 %add.i.4.i452, -9223372036854775808
  %xor2.i.i.4.i456 = and i64 %72, %add3.i.4.i
  %xor.i23.i.4.i457 = xor i64 %add3.i.4.i454, %add.i.4.i452
  %xor1.i24.i.4.i458 = xor i64 %add.i.4.i452, %add3.i.4.i
  %or.i25.i.4.i459 = or i64 %xor.i23.i.4.i457, %xor1.i24.i.4.i458
  %xor2.i26.i.4.i460 = xor i64 %or.i25.i.4.i459, %add3.i.4.i454
  %shr.i30.i.4.i461 = or i64 %xor2.i26.i.4.i460, %xor2.i.i.4.i456
  %or29.i.4.i462 = lshr i64 %shr.i30.i.4.i461, 63
  %add.i.5.i464 = add i64 %add3.i.5.i, %or29.i.4.i462
  %add3.i.5.i466 = add i64 %add.i.5.i464, %add3.i.5.i
  %arrayidx5.i.5.i467 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i466, i64* %arrayidx5.i.5.i467, align 8, !tbaa !3
  %73 = xor i64 %add.i.5.i464, -9223372036854775808
  %xor2.i.i.5.i468 = and i64 %73, %add3.i.5.i
  %xor.i23.i.5.i469 = xor i64 %add3.i.5.i466, %add.i.5.i464
  %xor1.i24.i.5.i470 = xor i64 %add.i.5.i464, %add3.i.5.i
  %or.i25.i.5.i471 = or i64 %xor.i23.i.5.i469, %xor1.i24.i.5.i470
  %xor2.i26.i.5.i472 = xor i64 %or.i25.i.5.i471, %add3.i.5.i466
  %shr.i30.i.5.i473 = or i64 %xor2.i26.i.5.i472, %xor2.i.i.5.i468
  %or29.i.5.i474 = lshr i64 %shr.i30.i.5.i473, 63
  %add.i.6.i476 = add i64 %add3.i.6.i, %or29.i.5.i474
  %add3.i.6.i478 = add i64 %add.i.6.i476, %add3.i.6.i
  %arrayidx5.i.6.i479 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i478, i64* %arrayidx5.i.6.i479, align 16, !tbaa !3
  %74 = xor i64 %add.i.6.i476, -9223372036854775808
  %xor2.i.i.6.i480 = and i64 %74, %add3.i.6.i
  %xor.i23.i.6.i481 = xor i64 %add3.i.6.i478, %add.i.6.i476
  %xor1.i24.i.6.i482 = xor i64 %add.i.6.i476, %add3.i.6.i
  %or.i25.i.6.i483 = or i64 %xor.i23.i.6.i481, %xor1.i24.i.6.i482
  %xor2.i26.i.6.i484 = xor i64 %or.i25.i.6.i483, %add3.i.6.i478
  %shr.i30.i.6.i485 = or i64 %xor2.i26.i.6.i484, %xor2.i.i.6.i480
  %or29.i.6.i486 = lshr i64 %shr.i30.i.6.i485, 63
  %add.i.7.i488 = add i64 %add3.i.7.i, %or29.i.6.i486
  %add3.i.7.i490 = add i64 %add.i.7.i488, %add3.i.7.i
  %arrayidx5.i.7.i491 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i490, i64* %arrayidx5.i.7.i491, align 8, !tbaa !3
  %75 = xor i64 %add.i.7.i488, -9223372036854775808
  %xor2.i.i.7.i492 = and i64 %75, %add3.i.7.i
  %xor.i23.i.7.i493 = xor i64 %add3.i.7.i490, %add.i.7.i488
  %xor1.i24.i.7.i494 = xor i64 %add.i.7.i488, %add3.i.7.i
  %or.i25.i.7.i495 = or i64 %xor.i23.i.7.i493, %xor1.i24.i.7.i494
  %xor2.i26.i.7.i496 = xor i64 %or.i25.i.7.i495, %add3.i.7.i490
  %shr.i30.i.7.i497 = or i64 %xor2.i26.i.7.i496, %xor2.i.i.7.i492
  %or29.i.7.i498 = lshr i64 %shr.i30.i.7.i497, 63
  %add.i.8.i500 = add i64 %add3.i.8.i, %or29.i.7.i498
  %add3.i.8.i502 = add i64 %add.i.8.i500, %add3.i.8.i
  %arrayidx5.i.8.i503 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i502, i64* %arrayidx5.i.8.i503, align 16, !tbaa !3
  %76 = xor i64 %add.i.8.i500, -9223372036854775808
  %xor2.i.i.8.i504 = and i64 %76, %add3.i.8.i
  %xor.i23.i.8.i505 = xor i64 %add3.i.8.i502, %add.i.8.i500
  %xor1.i24.i.8.i506 = xor i64 %add.i.8.i500, %add3.i.8.i
  %or.i25.i.8.i507 = or i64 %xor.i23.i.8.i505, %xor1.i24.i.8.i506
  %xor2.i26.i.8.i508 = xor i64 %or.i25.i.8.i507, %add3.i.8.i502
  %shr.i30.i.8.i509 = or i64 %xor2.i26.i.8.i508, %xor2.i.i.8.i504
  %or29.i.8.i510 = lshr i64 %shr.i30.i.8.i509, 63
  %factor1222 = shl i64 %add3.i.9.i, 1
  %add3.i.9.i514 = or i64 %factor1222, %or29.i.8.i510
  %arrayidx5.i.9.i515 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i514, i64* %arrayidx5.i.9.i515, align 8, !tbaa !3
  %arraydecay31 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0
  %arraydecay4.i625 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 0
  store i64 10373346660, i64* %arraydecay4.i625, align 16, !tbaa !3
  %arrayidx5.i.1.i746 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 1
  %arrayidx5.i.4.i782 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 4
  %77 = bitcast i64* %arrayidx5.i.1.i746 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %77, i8 0, i64 24, i1 false)
  %78 = bitcast i64* %arrayidx5.i.4.i782 to <4 x i64>*
  store <4 x i64> <i64 -7117939211059068928, i64 -3343200967177216643, i64 4448590346910628009, i64 -1133556343672607924>, <4 x i64>* %78, align 16, !tbaa !3
  %arrayidx5.i.8.i830 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 8
  store i64 8391910997975898994, i64* %arrayidx5.i.8.i830, align 16, !tbaa !3
  %arrayidx5.i.9.i842 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 9
  store i64 26633664600, i64* %arrayidx5.i.9.i842, align 8, !tbaa !3
  %arraydecay10.i628 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 0
  %add3.i.i629 = mul i64 %48, 6
  store i64 %add3.i.i629, i64* %arraydecay10.i628, align 16, !tbaa !3
  %xor.i23.i.i630 = xor i64 %add3.i.i629, %add3.i.i
  %or.i25.i.i632 = or i64 %xor.i23.i.i630, %xor.i23.i.i410
  %xor2.i26.i.i633 = xor i64 %or.i25.i.i632, %add3.i.i629
  %or29.i.i634 = lshr i64 %xor2.i26.i.i633, 63
  %add.i.1.i636 = add i64 %or29.i.i634, %add3.i.1.i
  %add3.i.1.i638 = add i64 %add3.i.1.i418, %add.i.1.i636
  %arrayidx5.i.1.i639 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i638, i64* %arrayidx5.i.1.i639, align 8, !tbaa !3
  %79 = xor i64 %add.i.1.i636, -9223372036854775808
  %xor2.i.i.1.i640 = and i64 %79, %add3.i.1.i
  %xor.i23.i.1.i641 = xor i64 %add3.i.1.i638, %add.i.1.i636
  %xor1.i24.i.1.i642 = xor i64 %add3.i.1.i418, %add.i.1.i636
  %or.i25.i.1.i643 = or i64 %xor.i23.i.1.i641, %xor1.i24.i.1.i642
  %xor2.i26.i.1.i644 = xor i64 %or.i25.i.1.i643, %add3.i.1.i638
  %shr.i30.i.1.i645 = or i64 %xor2.i26.i.1.i644, %xor2.i.i.1.i640
  %or29.i.1.i646 = lshr i64 %shr.i30.i.1.i645, 63
  %add.i.2.i648 = add i64 %or29.i.1.i646, %add3.i.2.i
  %add3.i.2.i650 = add i64 %add3.i.2.i430, %add.i.2.i648
  %arrayidx5.i.2.i651 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i650, i64* %arrayidx5.i.2.i651, align 16, !tbaa !3
  %80 = xor i64 %add.i.2.i648, -9223372036854775808
  %xor2.i.i.2.i652 = and i64 %80, %add3.i.2.i
  %xor.i23.i.2.i653 = xor i64 %add3.i.2.i650, %add.i.2.i648
  %xor1.i24.i.2.i654 = xor i64 %add3.i.2.i430, %add.i.2.i648
  %or.i25.i.2.i655 = or i64 %xor.i23.i.2.i653, %xor1.i24.i.2.i654
  %xor2.i26.i.2.i656 = xor i64 %or.i25.i.2.i655, %add3.i.2.i650
  %shr.i30.i.2.i657 = or i64 %xor2.i26.i.2.i656, %xor2.i.i.2.i652
  %or29.i.2.i658 = lshr i64 %shr.i30.i.2.i657, 63
  %add.i.3.i660 = add i64 %or29.i.2.i658, %add3.i.3.i
  %add3.i.3.i662 = add i64 %add3.i.3.i442, %add.i.3.i660
  %arrayidx5.i.3.i663 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i662, i64* %arrayidx5.i.3.i663, align 8, !tbaa !3
  %81 = xor i64 %add.i.3.i660, -9223372036854775808
  %xor2.i.i.3.i664 = and i64 %81, %add3.i.3.i
  %xor.i23.i.3.i665 = xor i64 %add3.i.3.i662, %add.i.3.i660
  %xor1.i24.i.3.i666 = xor i64 %add3.i.3.i442, %add.i.3.i660
  %or.i25.i.3.i667 = or i64 %xor.i23.i.3.i665, %xor1.i24.i.3.i666
  %xor2.i26.i.3.i668 = xor i64 %or.i25.i.3.i667, %add3.i.3.i662
  %shr.i30.i.3.i669 = or i64 %xor2.i26.i.3.i668, %xor2.i.i.3.i664
  %or29.i.3.i670 = lshr i64 %shr.i30.i.3.i669, 63
  %add.i.4.i672 = add i64 %or29.i.3.i670, %add3.i.4.i
  %add3.i.4.i674 = add i64 %add3.i.4.i454, %add.i.4.i672
  %arrayidx5.i.4.i675 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i674, i64* %arrayidx5.i.4.i675, align 16, !tbaa !3
  %82 = xor i64 %add.i.4.i672, -9223372036854775808
  %xor2.i.i.4.i676 = and i64 %82, %add3.i.4.i
  %xor.i23.i.4.i677 = xor i64 %add3.i.4.i674, %add.i.4.i672
  %xor1.i24.i.4.i678 = xor i64 %add3.i.4.i454, %add.i.4.i672
  %or.i25.i.4.i679 = or i64 %xor.i23.i.4.i677, %xor1.i24.i.4.i678
  %xor2.i26.i.4.i680 = xor i64 %or.i25.i.4.i679, %add3.i.4.i674
  %shr.i30.i.4.i681 = or i64 %xor2.i26.i.4.i680, %xor2.i.i.4.i676
  %or29.i.4.i682 = lshr i64 %shr.i30.i.4.i681, 63
  %add.i.5.i684 = add i64 %or29.i.4.i682, %add3.i.5.i
  %add3.i.5.i686 = add i64 %add3.i.5.i466, %add.i.5.i684
  %arrayidx5.i.5.i687 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i686, i64* %arrayidx5.i.5.i687, align 8, !tbaa !3
  %83 = xor i64 %add.i.5.i684, -9223372036854775808
  %xor2.i.i.5.i688 = and i64 %83, %add3.i.5.i
  %xor.i23.i.5.i689 = xor i64 %add3.i.5.i686, %add.i.5.i684
  %xor1.i24.i.5.i690 = xor i64 %add3.i.5.i466, %add.i.5.i684
  %or.i25.i.5.i691 = or i64 %xor.i23.i.5.i689, %xor1.i24.i.5.i690
  %xor2.i26.i.5.i692 = xor i64 %or.i25.i.5.i691, %add3.i.5.i686
  %shr.i30.i.5.i693 = or i64 %xor2.i26.i.5.i692, %xor2.i.i.5.i688
  %or29.i.5.i694 = lshr i64 %shr.i30.i.5.i693, 63
  %add.i.6.i696 = add i64 %or29.i.5.i694, %add3.i.6.i
  %add3.i.6.i698 = add i64 %add3.i.6.i478, %add.i.6.i696
  %arrayidx5.i.6.i699 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i698, i64* %arrayidx5.i.6.i699, align 16, !tbaa !3
  %84 = xor i64 %add.i.6.i696, -9223372036854775808
  %xor2.i.i.6.i700 = and i64 %84, %add3.i.6.i
  %xor.i23.i.6.i701 = xor i64 %add3.i.6.i698, %add.i.6.i696
  %xor1.i24.i.6.i702 = xor i64 %add3.i.6.i478, %add.i.6.i696
  %or.i25.i.6.i703 = or i64 %xor.i23.i.6.i701, %xor1.i24.i.6.i702
  %xor2.i26.i.6.i704 = xor i64 %or.i25.i.6.i703, %add3.i.6.i698
  %shr.i30.i.6.i705 = or i64 %xor2.i26.i.6.i704, %xor2.i.i.6.i700
  %or29.i.6.i706 = lshr i64 %shr.i30.i.6.i705, 63
  %add.i.7.i708 = add i64 %or29.i.6.i706, %add3.i.7.i
  %add3.i.7.i710 = add i64 %add3.i.7.i490, %add.i.7.i708
  %arrayidx5.i.7.i711 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i710, i64* %arrayidx5.i.7.i711, align 8, !tbaa !3
  %85 = xor i64 %add.i.7.i708, -9223372036854775808
  %xor2.i.i.7.i712 = and i64 %85, %add3.i.7.i
  %xor.i23.i.7.i713 = xor i64 %add3.i.7.i710, %add.i.7.i708
  %xor1.i24.i.7.i714 = xor i64 %add3.i.7.i490, %add.i.7.i708
  %or.i25.i.7.i715 = or i64 %xor.i23.i.7.i713, %xor1.i24.i.7.i714
  %xor2.i26.i.7.i716 = xor i64 %or.i25.i.7.i715, %add3.i.7.i710
  %shr.i30.i.7.i717 = or i64 %xor2.i26.i.7.i716, %xor2.i.i.7.i712
  %or29.i.7.i718 = lshr i64 %shr.i30.i.7.i717, 63
  %add.i.8.i720 = add i64 %or29.i.7.i718, %add3.i.8.i
  %add3.i.8.i722 = add i64 %add3.i.8.i502, %add.i.8.i720
  %arrayidx5.i.8.i723 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i722, i64* %arrayidx5.i.8.i723, align 16, !tbaa !3
  %86 = xor i64 %add.i.8.i720, -9223372036854775808
  %xor2.i.i.8.i724 = and i64 %86, %add3.i.8.i
  %xor.i23.i.8.i725 = xor i64 %add3.i.8.i722, %add.i.8.i720
  %xor1.i24.i.8.i726 = xor i64 %add3.i.8.i502, %add.i.8.i720
  %or.i25.i.8.i727 = or i64 %xor.i23.i.8.i725, %xor1.i24.i.8.i726
  %xor2.i26.i.8.i728 = xor i64 %or.i25.i.8.i727, %add3.i.8.i722
  %shr.i30.i.8.i729 = or i64 %xor2.i26.i.8.i728, %xor2.i.i.8.i724
  %or29.i.8.i730 = lshr i64 %shr.i30.i.8.i729, 63
  %add.i.9.i732 = add i64 %or29.i.8.i730, %add3.i.9.i
  %add3.i.9.i734 = add i64 %add.i.9.i732, %add3.i.9.i514
  %arrayidx5.i.9.i735 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i734, i64* %arrayidx5.i.9.i735, align 8, !tbaa !3
  store i64 13831128880, i64* %arraydecay22, align 16, !tbaa !3
  %87 = bitcast i64* %arrayidx2.1.i284 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %87, i8 0, i64 24, i1 false)
  %88 = bitcast i64* %arrayidx2.4.i287 to <4 x i64>*
  store <4 x i64> <i64 -3341670923508908032, i64 7840228092903412220, i64 5931453795880837346, i64 -7660323149466661104>, <4 x i64>* %88, align 16, !tbaa !3
  store i64 -7257529409741686290, i64* %arrayidx2.8.i291, align 16, !tbaa !3
  store i64 35511552800, i64* %arrayidx2.9.i292, align 8, !tbaa !3
  %add3.i.i861 = shl i64 %48, 3
  store i64 %add3.i.i861, i64* %arraydecay6.i, align 16, !tbaa !3
  %89 = lshr i64 %48, 61
  %or29.i.i866 = and i64 %89, 1
  %add.i.1.i868 = add i64 %add3.i.1.i418, %or29.i.i866
  %add3.i.1.i870 = add i64 %add.i.1.i868, %add3.i.1.i418
  store i64 %add3.i.1.i870, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %90 = xor i64 %add.i.1.i868, -9223372036854775808
  %xor2.i.i.1.i872 = and i64 %90, %add3.i.1.i418
  %xor.i23.i.1.i873 = xor i64 %add3.i.1.i870, %add.i.1.i868
  %xor1.i24.i.1.i874 = xor i64 %add.i.1.i868, %add3.i.1.i418
  %or.i25.i.1.i875 = or i64 %xor.i23.i.1.i873, %xor1.i24.i.1.i874
  %xor2.i26.i.1.i876 = xor i64 %or.i25.i.1.i875, %add3.i.1.i870
  %shr.i30.i.1.i877 = or i64 %xor2.i26.i.1.i876, %xor2.i.i.1.i872
  %or29.i.1.i878 = lshr i64 %shr.i30.i.1.i877, 63
  %add.i.2.i880 = add i64 %add3.i.2.i430, %or29.i.1.i878
  %add3.i.2.i882 = add i64 %add.i.2.i880, %add3.i.2.i430
  store i64 %add3.i.2.i882, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %91 = xor i64 %add.i.2.i880, -9223372036854775808
  %xor2.i.i.2.i884 = and i64 %91, %add3.i.2.i430
  %xor.i23.i.2.i885 = xor i64 %add3.i.2.i882, %add.i.2.i880
  %xor1.i24.i.2.i886 = xor i64 %add.i.2.i880, %add3.i.2.i430
  %or.i25.i.2.i887 = or i64 %xor.i23.i.2.i885, %xor1.i24.i.2.i886
  %xor2.i26.i.2.i888 = xor i64 %or.i25.i.2.i887, %add3.i.2.i882
  %shr.i30.i.2.i889 = or i64 %xor2.i26.i.2.i888, %xor2.i.i.2.i884
  %or29.i.2.i890 = lshr i64 %shr.i30.i.2.i889, 63
  %add.i.3.i892 = add i64 %add3.i.3.i442, %or29.i.2.i890
  %add3.i.3.i894 = add i64 %add.i.3.i892, %add3.i.3.i442
  store i64 %add3.i.3.i894, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %92 = xor i64 %add.i.3.i892, -9223372036854775808
  %xor2.i.i.3.i896 = and i64 %92, %add3.i.3.i442
  %xor.i23.i.3.i897 = xor i64 %add3.i.3.i894, %add.i.3.i892
  %xor1.i24.i.3.i898 = xor i64 %add.i.3.i892, %add3.i.3.i442
  %or.i25.i.3.i899 = or i64 %xor.i23.i.3.i897, %xor1.i24.i.3.i898
  %xor2.i26.i.3.i900 = xor i64 %or.i25.i.3.i899, %add3.i.3.i894
  %shr.i30.i.3.i901 = or i64 %xor2.i26.i.3.i900, %xor2.i.i.3.i896
  %or29.i.3.i902 = lshr i64 %shr.i30.i.3.i901, 63
  %add.i.4.i904 = add i64 %add3.i.4.i454, %or29.i.3.i902
  %add3.i.4.i906 = add i64 %add.i.4.i904, %add3.i.4.i454
  store i64 %add3.i.4.i906, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %93 = xor i64 %add.i.4.i904, -9223372036854775808
  %xor2.i.i.4.i908 = and i64 %93, %add3.i.4.i454
  %xor.i23.i.4.i909 = xor i64 %add3.i.4.i906, %add.i.4.i904
  %xor1.i24.i.4.i910 = xor i64 %add.i.4.i904, %add3.i.4.i454
  %or.i25.i.4.i911 = or i64 %xor.i23.i.4.i909, %xor1.i24.i.4.i910
  %xor2.i26.i.4.i912 = xor i64 %or.i25.i.4.i911, %add3.i.4.i906
  %shr.i30.i.4.i913 = or i64 %xor2.i26.i.4.i912, %xor2.i.i.4.i908
  %or29.i.4.i914 = lshr i64 %shr.i30.i.4.i913, 63
  %add.i.5.i916 = add i64 %add3.i.5.i466, %or29.i.4.i914
  %add3.i.5.i918 = add i64 %add.i.5.i916, %add3.i.5.i466
  store i64 %add3.i.5.i918, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %94 = xor i64 %add.i.5.i916, -9223372036854775808
  %xor2.i.i.5.i920 = and i64 %94, %add3.i.5.i466
  %xor.i23.i.5.i921 = xor i64 %add3.i.5.i918, %add.i.5.i916
  %xor1.i24.i.5.i922 = xor i64 %add.i.5.i916, %add3.i.5.i466
  %or.i25.i.5.i923 = or i64 %xor.i23.i.5.i921, %xor1.i24.i.5.i922
  %xor2.i26.i.5.i924 = xor i64 %or.i25.i.5.i923, %add3.i.5.i918
  %shr.i30.i.5.i925 = or i64 %xor2.i26.i.5.i924, %xor2.i.i.5.i920
  %or29.i.5.i926 = lshr i64 %shr.i30.i.5.i925, 63
  %add.i.6.i928 = add i64 %add3.i.6.i478, %or29.i.5.i926
  %add3.i.6.i930 = add i64 %add.i.6.i928, %add3.i.6.i478
  store i64 %add3.i.6.i930, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %95 = xor i64 %add.i.6.i928, -9223372036854775808
  %xor2.i.i.6.i932 = and i64 %95, %add3.i.6.i478
  %xor.i23.i.6.i933 = xor i64 %add3.i.6.i930, %add.i.6.i928
  %xor1.i24.i.6.i934 = xor i64 %add.i.6.i928, %add3.i.6.i478
  %or.i25.i.6.i935 = or i64 %xor.i23.i.6.i933, %xor1.i24.i.6.i934
  %xor2.i26.i.6.i936 = xor i64 %or.i25.i.6.i935, %add3.i.6.i930
  %shr.i30.i.6.i937 = or i64 %xor2.i26.i.6.i936, %xor2.i.i.6.i932
  %or29.i.6.i938 = lshr i64 %shr.i30.i.6.i937, 63
  %add.i.7.i940 = add i64 %add3.i.7.i490, %or29.i.6.i938
  %add3.i.7.i942 = add i64 %add.i.7.i940, %add3.i.7.i490
  store i64 %add3.i.7.i942, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %96 = xor i64 %add.i.7.i940, -9223372036854775808
  %xor2.i.i.7.i944 = and i64 %96, %add3.i.7.i490
  %xor.i23.i.7.i945 = xor i64 %add3.i.7.i942, %add.i.7.i940
  %xor1.i24.i.7.i946 = xor i64 %add.i.7.i940, %add3.i.7.i490
  %or.i25.i.7.i947 = or i64 %xor.i23.i.7.i945, %xor1.i24.i.7.i946
  %xor2.i26.i.7.i948 = xor i64 %or.i25.i.7.i947, %add3.i.7.i942
  %shr.i30.i.7.i949 = or i64 %xor2.i26.i.7.i948, %xor2.i.i.7.i944
  %or29.i.7.i950 = lshr i64 %shr.i30.i.7.i949, 63
  %add.i.8.i952 = add i64 %add3.i.8.i502, %or29.i.7.i950
  %add3.i.8.i954 = add i64 %add.i.8.i952, %add3.i.8.i502
  store i64 %add3.i.8.i954, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %97 = xor i64 %add.i.8.i952, -9223372036854775808
  %xor2.i.i.8.i956 = and i64 %97, %add3.i.8.i502
  %xor.i23.i.8.i957 = xor i64 %add3.i.8.i954, %add.i.8.i952
  %xor1.i24.i.8.i958 = xor i64 %add.i.8.i952, %add3.i.8.i502
  %or.i25.i.8.i959 = or i64 %xor.i23.i.8.i957, %xor1.i24.i.8.i958
  %xor2.i26.i.8.i960 = xor i64 %or.i25.i.8.i959, %add3.i.8.i954
  %shr.i30.i.8.i961 = or i64 %xor2.i26.i.8.i960, %xor2.i.i.8.i956
  %or29.i.8.i962 = lshr i64 %shr.i30.i.8.i961, 63
  %factor1224 = shl i64 %add3.i.9.i514, 1
  %add3.i.9.i966 = or i64 %factor1224, %or29.i.8.i962
  store i64 %add3.i.9.i966, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arraydecay35 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyB, i64 0, i64 0
  %arrayidx.i = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyB, i64 0, i64 4
  store i64 0, i64* %arrayidx.i, align 16, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %13, i8* align 1 %PrivateKeyB, i64 38, i1 false)
  %arraydecay40 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0
  call fastcc void @LADDER3PT([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay1, [10 x i64]* nonnull %arraydecay2, i64* nonnull %arraydecay35, i32 1, %struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay31)
  %arrayidx.4.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 4
  %arrayidx.8.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 8
  %arrayidx.2.i11.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 2
  %arrayidx.6.i19.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 6
  %arraydecay.i1088 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 0
  %arrayidx.4.i.i1096 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 4
  %arrayidx.8.i.i1104 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 8
  %arrayidx.2.i11.i1112 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 2
  %arrayidx.6.i19.i1120 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 6
  %arraydecay70 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %coeff, i64 0, i64 0
  %98 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %99 = bitcast i64* %arrayidx.4.i.i to <4 x i64>*
  %100 = bitcast i64* %arrayidx.8.i.i to <4 x i64>*
  %101 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %102 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %103 = bitcast i64* %arraydecay.i1088 to <4 x i64>*
  %104 = bitcast i64* %arrayidx.4.i.i1096 to <4 x i64>*
  %105 = bitcast i64* %arrayidx.8.i.i1104 to <4 x i64>*
  %106 = bitcast i64* %arrayidx.2.i11.i1112 to <4 x i64>*
  %107 = bitcast i64* %arrayidx.6.i19.i1120 to <4 x i64>*
  %108 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %109 = bitcast i64* %arrayidx.4.i.i to <4 x i64>*
  %110 = bitcast i64* %arrayidx.8.i.i to <4 x i64>*
  %111 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %112 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %113 = bitcast i64* %arraydecay.i1088 to <4 x i64>*
  %114 = bitcast i64* %arrayidx.4.i.i1096 to <4 x i64>*
  %115 = bitcast i64* %arrayidx.8.i.i1104 to <4 x i64>*
  %116 = bitcast i64* %arrayidx.2.i11.i1112 to <4 x i64>*
  %117 = bitcast i64* %arrayidx.6.i19.i1120 to <4 x i64>*
  br label %while.cond.preheader

while.cond.preheader:                             ; preds = %for.end, %entry
  %ii.01235 = phi i32 [ 0, %entry ], [ %ii.1.lcssa, %for.end ]
  %npts.01234 = phi i32 [ 0, %entry ], [ %sub85, %for.end ]
  %index.01233 = phi i32 [ 0, %entry ], [ %159, %for.end ]
  %row.01232 = phi i32 [ 1, %entry ], [ %inc108, %for.end ]
  %sub = sub nuw nsw i32 192, %row.01232
  %cmp421225 = icmp ult i32 %index.01233, %sub
  br i1 %cmp421225, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond.preheader, %while.body
  %ii.11228 = phi i32 [ %inc60, %while.body ], [ %ii.01235, %while.cond.preheader ]
  %npts.11227 = phi i32 [ %inc, %while.body ], [ %npts.01234, %while.cond.preheader ]
  %index.11226 = phi i32 [ %add, %while.body ], [ %index.01233, %while.cond.preheader ]
  %idxprom = zext i32 %npts.11227 to i64
  %arraydecay2.i1076 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 0
  %118 = load <4 x i64>, <4 x i64>* %98, align 16, !tbaa !3
  %119 = bitcast i64* %arraydecay2.i1076 to <4 x i64>*
  store <4 x i64> %118, <4 x i64>* %119, align 16, !tbaa !3
  %arrayidx2.4.i.i1080 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 4
  %120 = load <4 x i64>, <4 x i64>* %99, align 16, !tbaa !3
  %121 = bitcast i64* %arrayidx2.4.i.i1080 to <4 x i64>*
  store <4 x i64> %120, <4 x i64>* %121, align 16, !tbaa !3
  %arrayidx2.8.i.i1084 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 8
  %122 = load <4 x i64>, <4 x i64>* %100, align 16, !tbaa !3
  %123 = bitcast i64* %arrayidx2.8.i.i1084 to <4 x i64>*
  store <4 x i64> %122, <4 x i64>* %123, align 16, !tbaa !3
  %arrayidx2.2.i12.i = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 2
  %124 = load <4 x i64>, <4 x i64>* %101, align 16, !tbaa !3
  %125 = bitcast i64* %arrayidx2.2.i12.i to <4 x i64>*
  store <4 x i64> %124, <4 x i64>* %125, align 16, !tbaa !3
  %arrayidx2.6.i20.i = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 6
  %126 = load <4 x i64>, <4 x i64>* %102, align 16, !tbaa !3
  %127 = bitcast i64* %arrayidx2.6.i20.i to <4 x i64>*
  store <4 x i64> %126, <4 x i64>* %127, align 16, !tbaa !3
  %arraydecay2.i1089 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 0
  %128 = load <4 x i64>, <4 x i64>* %103, align 16, !tbaa !3
  %129 = bitcast i64* %arraydecay2.i1089 to <4 x i64>*
  store <4 x i64> %128, <4 x i64>* %129, align 16, !tbaa !3
  %arrayidx2.4.i.i1097 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 4
  %130 = load <4 x i64>, <4 x i64>* %104, align 16, !tbaa !3
  %131 = bitcast i64* %arrayidx2.4.i.i1097 to <4 x i64>*
  store <4 x i64> %130, <4 x i64>* %131, align 16, !tbaa !3
  %arrayidx2.8.i.i1105 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 8
  %132 = load <4 x i64>, <4 x i64>* %105, align 16, !tbaa !3
  %133 = bitcast i64* %arrayidx2.8.i.i1105 to <4 x i64>*
  store <4 x i64> %132, <4 x i64>* %133, align 16, !tbaa !3
  %arrayidx2.2.i12.i1113 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 2
  %134 = load <4 x i64>, <4 x i64>* %106, align 16, !tbaa !3
  %135 = bitcast i64* %arrayidx2.2.i12.i1113 to <4 x i64>*
  store <4 x i64> %134, <4 x i64>* %135, align 16, !tbaa !3
  %arrayidx2.6.i20.i1121 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 6
  %136 = load <4 x i64>, <4 x i64>* %107, align 16, !tbaa !3
  %137 = bitcast i64* %arrayidx2.6.i20.i1121 to <4 x i64>*
  store <4 x i64> %136, <4 x i64>* %137, align 16, !tbaa !3
  %inc = add i32 %npts.11227, 1
  %arrayidx59 = getelementptr inbounds [10 x i32], [10 x i32]* %pts_index, i64 0, i64 %idxprom
  store i32 %index.11226, i32* %arrayidx59, align 4, !tbaa !59
  %inc60 = add i32 %ii.11228, 1
  %idxprom61 = zext i32 %ii.11228 to i64
  %arrayidx62 = getelementptr inbounds [191 x i32], [191 x i32]* @strat_Bob, i64 0, i64 %idxprom61
  %138 = load i32, i32* %arrayidx62, align 4, !tbaa !59
  call void @xTPLe(%struct.point_proj* nonnull %arraydecay40, %struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay28, [10 x i64]* nonnull %arraydecay23, i32 %138)
  %add = add i32 %138, %index.11226
  %cmp42 = icmp ult i32 %add, %sub
  br i1 %cmp42, label %while.body, label %while.end

while.end:                                        ; preds = %while.body, %while.cond.preheader
  %npts.1.lcssa = phi i32 [ %npts.01234, %while.cond.preheader ], [ %inc, %while.body ]
  %ii.1.lcssa = phi i32 [ %ii.01235, %while.cond.preheader ], [ %inc60, %while.body ]
  call void @get_3_isog(%struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay28, [10 x i64]* nonnull %arraydecay23, [2 x [10 x i64]]* nonnull %arraydecay70)
  %cmp721230 = icmp eq i32 %npts.1.lcssa, 0
  br i1 %cmp721230, label %for.end, label %for.body73.preheader

for.body73.preheader:                             ; preds = %while.end
  %wide.trip.count = zext i32 %npts.1.lcssa to i64
  br label %for.body73

for.body73:                                       ; preds = %for.body73, %for.body73.preheader
  %indvars.iv = phi i64 [ 0, %for.body73.preheader ], [ %indvars.iv.next, %for.body73 ]
  %arraydecay76 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %indvars.iv, i64 0
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay76, [2 x [10 x i64]]* nonnull %arraydecay70)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.end, label %for.body73

for.end:                                          ; preds = %for.body73, %while.end
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay3, [2 x [10 x i64]]* nonnull %arraydecay70)
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay5, [2 x [10 x i64]]* nonnull %arraydecay70)
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay8, [2 x [10 x i64]]* nonnull %arraydecay70)
  %sub85 = add i32 %npts.1.lcssa, -1
  %idxprom86 = zext i32 %sub85 to i64
  %arraydecay.i1128 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 0, i64 0, i64 0
  %139 = bitcast i64* %arraydecay.i1128 to <4 x i64>*
  %140 = load <4 x i64>, <4 x i64>* %139, align 16, !tbaa !3
  store <4 x i64> %140, <4 x i64>* %108, align 16, !tbaa !3
  %arrayidx.4.i.i1136 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 0, i64 0, i64 4
  %141 = bitcast i64* %arrayidx.4.i.i1136 to <4 x i64>*
  %142 = load <4 x i64>, <4 x i64>* %141, align 16, !tbaa !3
  store <4 x i64> %142, <4 x i64>* %109, align 16, !tbaa !3
  %arrayidx.8.i.i1144 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 0, i64 0, i64 8
  %143 = bitcast i64* %arrayidx.8.i.i1144 to <4 x i64>*
  %144 = load <4 x i64>, <4 x i64>* %143, align 16, !tbaa !3
  store <4 x i64> %144, <4 x i64>* %110, align 16, !tbaa !3
  %arrayidx.2.i11.i1152 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 0, i64 1, i64 2
  %145 = bitcast i64* %arrayidx.2.i11.i1152 to <4 x i64>*
  %146 = load <4 x i64>, <4 x i64>* %145, align 16, !tbaa !3
  store <4 x i64> %146, <4 x i64>* %111, align 16, !tbaa !3
  %arrayidx.6.i19.i1160 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 0, i64 1, i64 6
  %147 = bitcast i64* %arrayidx.6.i19.i1160 to <4 x i64>*
  %148 = load <4 x i64>, <4 x i64>* %147, align 16, !tbaa !3
  store <4 x i64> %148, <4 x i64>* %112, align 16, !tbaa !3
  %arraydecay.i1168 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 1, i64 0, i64 0
  %149 = bitcast i64* %arraydecay.i1168 to <4 x i64>*
  %150 = load <4 x i64>, <4 x i64>* %149, align 16, !tbaa !3
  store <4 x i64> %150, <4 x i64>* %113, align 16, !tbaa !3
  %arrayidx.4.i.i1176 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 1, i64 0, i64 4
  %151 = bitcast i64* %arrayidx.4.i.i1176 to <4 x i64>*
  %152 = load <4 x i64>, <4 x i64>* %151, align 16, !tbaa !3
  store <4 x i64> %152, <4 x i64>* %114, align 16, !tbaa !3
  %arrayidx.8.i.i1184 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 1, i64 0, i64 8
  %153 = bitcast i64* %arrayidx.8.i.i1184 to <4 x i64>*
  %154 = load <4 x i64>, <4 x i64>* %153, align 16, !tbaa !3
  store <4 x i64> %154, <4 x i64>* %115, align 16, !tbaa !3
  %arrayidx.2.i11.i1192 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 1, i64 1, i64 2
  %155 = bitcast i64* %arrayidx.2.i11.i1192 to <4 x i64>*
  %156 = load <4 x i64>, <4 x i64>* %155, align 16, !tbaa !3
  store <4 x i64> %156, <4 x i64>* %116, align 16, !tbaa !3
  %arrayidx.6.i19.i1200 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom86, i64 0, i32 1, i64 1, i64 6
  %157 = bitcast i64* %arrayidx.6.i19.i1200 to <4 x i64>*
  %158 = load <4 x i64>, <4 x i64>* %157, align 16, !tbaa !3
  store <4 x i64> %158, <4 x i64>* %117, align 16, !tbaa !3
  %arrayidx105 = getelementptr inbounds [10 x i32], [10 x i32]* %pts_index, i64 0, i64 %idxprom86
  %159 = load i32, i32* %arrayidx105, align 4, !tbaa !59
  %inc108 = add nuw nsw i32 %row.01232, 1
  %exitcond1236 = icmp eq i32 %inc108, 192
  br i1 %exitcond1236, label %for.end109, label %while.cond.preheader

for.end109:                                       ; preds = %for.end
  %arraydecay4 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiP, i64 0, i64 0, i32 0, i64 0
  %arraydecay7 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiQ, i64 0, i64 0, i32 0, i64 0
  %arraydecay10 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %phiR, i64 0, i64 0, i32 0, i64 0
  call void @get_3_isog(%struct.point_proj* nonnull %arraydecay40, [10 x i64]* nonnull %arraydecay28, [10 x i64]* nonnull %arraydecay23, [2 x [10 x i64]]* nonnull %arraydecay70)
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay3, [2 x [10 x i64]]* nonnull %arraydecay70)
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay5, [2 x [10 x i64]]* nonnull %arraydecay70)
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay8, [2 x [10 x i64]]* nonnull %arraydecay70)
  %arraydecay122 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z, i64 0, i64 0
  %arraydecay125 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z14, i64 0, i64 0
  %arraydecay128 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z18, i64 0, i64 0
  call void @inv_3_way([10 x i64]* nonnull %arraydecay122, [10 x i64]* nonnull %arraydecay125, [10 x i64]* nonnull %arraydecay128)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay4, [10 x i64]* nonnull %arraydecay122, [10 x i64]* nonnull %arraydecay4)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay7, [10 x i64]* nonnull %arraydecay125, [10 x i64]* nonnull %arraydecay7)
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay10, [10 x i64]* nonnull %arraydecay128, [10 x i64]* nonnull %arraydecay10)
  %160 = bitcast [2 x [10 x i64]]* %t.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %160) #10
  %arraydecay2.i.i1212 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 0, i64 0
  %161 = bitcast [10 x i64]* %one.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  %arrayidx.i.i.i1213 = getelementptr inbounds [10 x i64], [10 x i64]* %one.i.i.i, i64 0, i64 0
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  %162 = bitcast [20 x i64]* %temp.i.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i.i.i1214 = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay.i197, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  %arraydecay6.i.i1216 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i207, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  %163 = call i64 @llvm.objectsize.i64.p0i8(i8* %PublicKeyB, i1 false, i1 true) #10
  %call.i.i1217 = call i8* @__memcpy_chk(i8* %PublicKeyB, i8* nonnull %160, i64 77, i64 %163) #10
  %add.ptr.i1218 = getelementptr inbounds i8, i8* %PublicKeyB, i64 77
  %164 = bitcast i64* %arraydecay6.i.i1216 to i8*
  %165 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i1218, i1 false, i1 true) #10
  %call.i5.i1219 = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i1218, i8* nonnull %164, i64 77, i64 %165) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %160) #10
  %add.ptr = getelementptr inbounds i8, i8* %PublicKeyB, i64 154
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %160) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay5.i208, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay8.i209, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  %166 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr, i1 false, i1 true) #10
  %call.i.i852 = call i8* @__memcpy_chk(i8* nonnull %add.ptr, i8* nonnull %160, i64 77, i64 %166) #10
  %add.ptr.i853 = getelementptr inbounds i8, i8* %PublicKeyB, i64 231
  %167 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i853, i1 false, i1 true) #10
  %call.i5.i854 = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i853, i8* nonnull %164, i64 77, i64 %167) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %160) #10
  %add.ptr165 = getelementptr inbounds i8, i8* %PublicKeyB, i64 308
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %160) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay11.i219, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i1212) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %161) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %161, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i1213, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %162) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %162, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay14.i229, i64* nonnull %arrayidx.i.i.i1213, i64* nonnull %arraydecay.i.i.i.i1214, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i1214, i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %162) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i1216) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %161) #10
  %168 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr165, i1 false, i1 true) #10
  %call.i.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr165, i8* nonnull %160, i64 77, i64 %168) #10
  %add.ptr.i = getelementptr inbounds i8, i8* %PublicKeyB, i64 385
  %169 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i, i1 false, i1 true) #10
  %call.i5.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i, i8* nonnull %164, i64 77, i64 %169) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %160) #10
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %13) #10
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %12) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %10) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 3200, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %0) #10
  ret i32 0
}

; Function Attrs: nounwind ssp uwtable
define i32 @EphemeralSecretAgreement_A_SIDHp610(i8* %PrivateKeyA, i8* %PublicKeyB, i8* %SharedSecretA) local_unnamed_addr #4 {
entry:
  %one.i.i.i = alloca [10 x i64], align 16
  %t.i = alloca [2 x [10 x i64]], align 16
  %temp.i.i.i.i = alloca [20 x i64], align 16
  %R = alloca [1 x %struct.point_proj], align 16
  %pts = alloca [8 x [1 x %struct.point_proj]], align 16
  %coeff = alloca [3 x [2 x [10 x i64]]], align 16
  %PKB = alloca [3 x [2 x [10 x i64]]], align 16
  %jinv = alloca [2 x [10 x i64]], align 16
  %A24plus = alloca [2 x [10 x i64]], align 16
  %C24 = alloca [2 x [10 x i64]], align 16
  %A = alloca [2 x [10 x i64]], align 16
  %pts_index = alloca [8 x i32], align 16
  %SecretKeyA = alloca [5 x i64], align 16
  %S = alloca [1 x %struct.point_proj], align 16
  %0 = bitcast [1 x %struct.point_proj]* %R to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %0) #10
  %1 = bitcast [8 x [1 x %struct.point_proj]]* %pts to i8*
  call void @llvm.lifetime.start.p0i8(i64 2560, i8* nonnull %1) #10
  %2 = bitcast [3 x [2 x [10 x i64]]]* %coeff to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %2) #10
  %3 = bitcast [3 x [2 x [10 x i64]]]* %PKB to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %3) #10
  %4 = bitcast [2 x [10 x i64]]* %jinv to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  %5 = bitcast [2 x [10 x i64]]* %A24plus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false)
  %6 = bitcast [2 x [10 x i64]]* %C24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %6, i8 0, i64 160, i1 false)
  %7 = bitcast [2 x [10 x i64]]* %A to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false)
  %8 = bitcast [8 x i32]* %pts_index to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #10
  %9 = bitcast [5 x i64]* %SecretKeyA to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 40, i1 false)
  %arraydecay = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 0
  %arrayidx.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i, align 8, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %3, i8* align 1 %PublicKeyB, i64 77, i1 false)
  %add.ptr.i = getelementptr inbounds i8, i8* %PublicKeyB, i64 77
  %arraydecay2.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 0
  %arrayidx.i7.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i, align 8, !tbaa !3
  %10 = bitcast i64* %arraydecay2.i to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %10, i8* nonnull align 1 %add.ptr.i, i64 77, i1 false)
  %11 = bitcast [20 x i64]* %temp.i.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay.i, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %add.ptr = getelementptr inbounds i8, i8* %PublicKeyB, i64 154
  %arraydecay2 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0
  %arraydecay.i144 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay2, i64 0, i64 0
  %arrayidx.i.i145 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i145, align 8, !tbaa !3
  %12 = bitcast [10 x i64]* %arraydecay2 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %12, i8* nonnull align 1 %add.ptr, i64 77, i1 false)
  %add.ptr.i147 = getelementptr inbounds i8, i8* %PublicKeyB, i64 231
  %arraydecay2.i148 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 0
  %arrayidx.i7.i149 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i149, align 8, !tbaa !3
  %13 = bitcast i64* %arraydecay2.i148 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %13, i8* nonnull align 1 %add.ptr.i147, i64 77, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i144, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i144) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i148, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i148) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %add.ptr3 = getelementptr inbounds i8, i8* %PublicKeyB, i64 308
  %arraydecay5 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 0
  %arraydecay.i153 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay5, i64 0, i64 0
  %arrayidx.i.i154 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i154, align 8, !tbaa !3
  %14 = bitcast [10 x i64]* %arraydecay5 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %14, i8* nonnull align 1 %add.ptr3, i64 77, i1 false)
  %add.ptr.i156 = getelementptr inbounds i8, i8* %PublicKeyB, i64 385
  %arraydecay2.i157 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 1, i64 0
  %arrayidx.i7.i158 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i158, align 8, !tbaa !3
  %15 = bitcast i64* %arraydecay2.i157 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %15, i8* nonnull align 1 %add.ptr.i156, i64 77, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i153, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i153) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i157, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i157) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0
  call void @get_A([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay5, [10 x i64]* nonnull %arraydecay12)
  %arrayidx5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 0
  store i64 3457782220, i64* %arrayidx5.i, align 16, !tbaa !3
  %arrayidx5.i.1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 1
  %arrayidx5.i.2 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 2
  %arrayidx5.i.3 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 3
  %arrayidx5.i.4 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 4
  %16 = bitcast i64* %arrayidx5.i.1 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 0, i64 24, i1 false)
  %arrayidx5.i.5 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 5
  %arrayidx5.i.6 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 6
  %arrayidx5.i.7 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 7
  %17 = bitcast i64* %arrayidx5.i.4 to <4 x i64>*
  store <4 x i64> <i64 3776268287550160896, i64 -7263315013628922753, i64 1482863448970209336, i64 -6526766805794053180>, <4 x i64>* %17, align 16, !tbaa !3
  %arrayidx5.i.8 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 8
  store i64 2797303665991966331, i64* %arrayidx5.i.8, align 16, !tbaa !3
  %arrayidx5.i.9 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0, i64 9
  store i64 8877888200, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %arraydecay16 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 0
  %arraydecay.i161 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 0
  %18 = load i64, i64* %arraydecay.i161, align 16, !tbaa !3
  %add3.i.i163 = add i64 %18, 3457782220
  store i64 %add3.i.i163, i64* %arraydecay4.i, align 16, !tbaa !3
  %19 = sub i64 -3457782221, %18
  %xor2.i26.i.i167 = and i64 %18, %19
  %or29.i.i168 = lshr i64 %xor2.i26.i.i167, 63
  %arrayidx.i.1.i169 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 1
  %20 = load i64, i64* %arrayidx.i.1.i169, align 8, !tbaa !3
  %add.i.1.i170 = add i64 %or29.i.i168, %20
  %arrayidx5.i.1.i173 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 1
  store i64 %add.i.1.i170, i64* %arrayidx5.i.1.i173, align 8, !tbaa !3
  %21 = xor i64 %add.i.1.i170, -9223372036854775808
  %xor2.i.i.1.i174 = and i64 %21, %20
  %or29.i.1.i180 = lshr i64 %xor2.i.i.1.i174, 63
  %arrayidx.i.2.i181 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 2
  %22 = load i64, i64* %arrayidx.i.2.i181, align 16, !tbaa !3
  %add.i.2.i182 = add i64 %or29.i.1.i180, %22
  %arrayidx5.i.2.i185 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 2
  store i64 %add.i.2.i182, i64* %arrayidx5.i.2.i185, align 16, !tbaa !3
  %23 = xor i64 %add.i.2.i182, -9223372036854775808
  %xor2.i.i.2.i186 = and i64 %23, %22
  %or29.i.2.i192 = lshr i64 %xor2.i.i.2.i186, 63
  %arrayidx.i.3.i193 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 3
  %24 = load i64, i64* %arrayidx.i.3.i193, align 8, !tbaa !3
  %add.i.3.i194 = add i64 %or29.i.2.i192, %24
  %arrayidx5.i.3.i197 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 3
  store i64 %add.i.3.i194, i64* %arrayidx5.i.3.i197, align 8, !tbaa !3
  %25 = xor i64 %add.i.3.i194, -9223372036854775808
  %xor2.i.i.3.i198 = and i64 %25, %24
  %or29.i.3.i204 = lshr i64 %xor2.i.i.3.i198, 63
  %arrayidx.i.4.i205 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 4
  %26 = load i64, i64* %arrayidx.i.4.i205, align 16, !tbaa !3
  %add.i.4.i206 = add i64 %or29.i.3.i204, %26
  %add3.i.4.i208 = add i64 %add.i.4.i206, 3776268287550160896
  %arrayidx5.i.4.i209 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 4
  store i64 %add3.i.4.i208, i64* %arrayidx5.i.4.i209, align 16, !tbaa !3
  %27 = xor i64 %add.i.4.i206, -9223372036854775808
  %xor2.i.i.4.i210 = and i64 %27, %26
  %28 = sub i64 -3776268287550160897, %add.i.4.i206
  %xor2.i26.i.4.i214 = and i64 %add.i.4.i206, %28
  %shr.i30.i.4.i215 = or i64 %xor2.i26.i.4.i214, %xor2.i.i.4.i210
  %or29.i.4.i216 = lshr i64 %shr.i30.i.4.i215, 63
  %arrayidx.i.5.i217 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 5
  %29 = load i64, i64* %arrayidx.i.5.i217, align 8, !tbaa !3
  %add.i.5.i218 = add i64 %or29.i.4.i216, %29
  %add3.i.5.i220 = add i64 %add.i.5.i218, -7263315013628922753
  %arrayidx5.i.5.i221 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 5
  store i64 %add3.i.5.i220, i64* %arrayidx5.i.5.i221, align 8, !tbaa !3
  %30 = xor i64 %add.i.5.i218, -9223372036854775808
  %xor2.i.i.5.i222 = and i64 %30, %29
  %xor.i23.i.5.i223 = xor i64 %add3.i.5.i220, %add.i.5.i218
  %xor1.i24.i.5.i224 = xor i64 %add.i.5.i218, -9223372036854775808
  %or.i25.i.5.i225 = or i64 %xor.i23.i.5.i223, %xor1.i24.i.5.i224
  %xor2.i26.i.5.i226 = xor i64 %or.i25.i.5.i225, %add3.i.5.i220
  %shr.i30.i.5.i227 = or i64 %xor2.i26.i.5.i226, %xor2.i.i.5.i222
  %or29.i.5.i228 = lshr i64 %shr.i30.i.5.i227, 63
  %arrayidx.i.6.i229 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 6
  %31 = load i64, i64* %arrayidx.i.6.i229, align 16, !tbaa !3
  %add.i.6.i230 = add i64 %or29.i.5.i228, %31
  %add3.i.6.i232 = add i64 %add.i.6.i230, 1482863448970209336
  %arrayidx5.i.6.i233 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 6
  store i64 %add3.i.6.i232, i64* %arrayidx5.i.6.i233, align 16, !tbaa !3
  %32 = xor i64 %add.i.6.i230, -9223372036854775808
  %xor2.i.i.6.i234 = and i64 %32, %31
  %33 = sub i64 -1482863448970209337, %add.i.6.i230
  %xor2.i26.i.6.i238 = and i64 %add.i.6.i230, %33
  %shr.i30.i.6.i239 = or i64 %xor2.i26.i.6.i238, %xor2.i.i.6.i234
  %or29.i.6.i240 = lshr i64 %shr.i30.i.6.i239, 63
  %arrayidx.i.7.i241 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 7
  %34 = load i64, i64* %arrayidx.i.7.i241, align 8, !tbaa !3
  %add.i.7.i242 = add i64 %or29.i.6.i240, %34
  %add3.i.7.i244 = add i64 %add.i.7.i242, -6526766805794053180
  %arrayidx5.i.7.i245 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 7
  store i64 %add3.i.7.i244, i64* %arrayidx5.i.7.i245, align 8, !tbaa !3
  %35 = xor i64 %add.i.7.i242, -9223372036854775808
  %xor2.i.i.7.i246 = and i64 %35, %34
  %xor.i23.i.7.i247 = xor i64 %add3.i.7.i244, %add.i.7.i242
  %xor1.i24.i.7.i248 = xor i64 %add.i.7.i242, -9223372036854775808
  %or.i25.i.7.i249 = or i64 %xor.i23.i.7.i247, %xor1.i24.i.7.i248
  %xor2.i26.i.7.i250 = xor i64 %or.i25.i.7.i249, %add3.i.7.i244
  %shr.i30.i.7.i251 = or i64 %xor2.i26.i.7.i250, %xor2.i.i.7.i246
  %or29.i.7.i252 = lshr i64 %shr.i30.i.7.i251, 63
  %arrayidx.i.8.i253 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 8
  %36 = load i64, i64* %arrayidx.i.8.i253, align 16, !tbaa !3
  %add.i.8.i254 = add i64 %or29.i.7.i252, %36
  %add3.i.8.i256 = add i64 %add.i.8.i254, 2797303665991966331
  %arrayidx5.i.8.i257 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 8
  store i64 %add3.i.8.i256, i64* %arrayidx5.i.8.i257, align 16, !tbaa !3
  %37 = xor i64 %add.i.8.i254, -9223372036854775808
  %xor2.i.i.8.i258 = and i64 %37, %36
  %38 = sub i64 -2797303665991966332, %add.i.8.i254
  %xor2.i26.i.8.i262 = and i64 %add.i.8.i254, %38
  %shr.i30.i.8.i263 = or i64 %xor2.i26.i.8.i262, %xor2.i.i.8.i258
  %or29.i.8.i264 = lshr i64 %shr.i30.i.8.i263, 63
  %arrayidx.i.9.i265 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 9
  %39 = load i64, i64* %arrayidx.i.9.i265, align 8, !tbaa !3
  %40 = load i64, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %add.i.9.i266 = add i64 %40, %39
  %add3.i.9.i268 = add i64 %add.i.9.i266, %or29.i.8.i264
  %arrayidx5.i.9.i269 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 9
  store i64 %add3.i.9.i268, i64* %arrayidx5.i.9.i269, align 8, !tbaa !3
  %arraydecay6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 0
  %41 = load i64, i64* %arraydecay6.i, align 16, !tbaa !3
  %42 = load i64, i64* %arraydecay8.i, align 16, !tbaa !3
  %add3.i.i = add i64 %42, %41
  store i64 %add3.i.i, i64* %arraydecay10.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %41
  %xor1.i24.i.i = xor i64 %42, %41
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 1
  %43 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %43
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 1
  %44 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %44
  %arrayidx5.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %45 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %45, %43
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %44
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 2
  %46 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %46
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 2
  %47 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %47
  %arrayidx5.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %48 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %48, %46
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %47
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 3
  %49 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %49
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 3
  %50 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %50
  %arrayidx5.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %51 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %51, %49
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %50
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 4
  %52 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %52
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 4
  %53 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %53
  %arrayidx5.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %54 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %54, %52
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %53
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 5
  %55 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %55
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 5
  %56 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %56
  %arrayidx5.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %57 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %57, %55
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %56
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 6
  %58 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %58
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 6
  %59 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %59
  %arrayidx5.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %60 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %60, %58
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %59
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 7
  %61 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %61
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 7
  %62 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %62
  %arrayidx5.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %63 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %63, %61
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %62
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 8
  %64 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %64
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 8
  %65 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %65
  %arrayidx5.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %66 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %66, %64
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %65
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 9
  %67 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %C24, i64 0, i64 1, i64 9
  %68 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %68, %67
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %69 = load i64, i64* %arrayidx5.i, align 16, !tbaa !3
  %add3.i275 = shl i64 %69, 1
  store i64 %add3.i275, i64* %arrayidx5.i, align 16, !tbaa !3
  %or29.i283 = lshr i64 %69, 63
  %70 = load i64, i64* %arrayidx5.i.1, align 8, !tbaa !3
  %add.i273.1 = add i64 %70, %or29.i283
  %add3.i275.1 = add i64 %add.i273.1, %70
  store i64 %add3.i275.1, i64* %arrayidx5.i.1, align 8, !tbaa !3
  %71 = xor i64 %add.i273.1, -9223372036854775808
  %xor2.i.i277.1 = and i64 %71, %70
  %xor.i23.i278.1 = xor i64 %add3.i275.1, %add.i273.1
  %xor1.i24.i279.1 = xor i64 %add.i273.1, %70
  %or.i25.i280.1 = or i64 %xor.i23.i278.1, %xor1.i24.i279.1
  %xor2.i26.i281.1 = xor i64 %or.i25.i280.1, %add3.i275.1
  %shr.i30.i282.1 = or i64 %xor2.i26.i281.1, %xor2.i.i277.1
  %or29.i283.1 = lshr i64 %shr.i30.i282.1, 63
  %72 = load i64, i64* %arrayidx5.i.2, align 16, !tbaa !3
  %add.i273.2 = add i64 %72, %or29.i283.1
  %add3.i275.2 = add i64 %add.i273.2, %72
  store i64 %add3.i275.2, i64* %arrayidx5.i.2, align 16, !tbaa !3
  %73 = xor i64 %add.i273.2, -9223372036854775808
  %xor2.i.i277.2 = and i64 %73, %72
  %xor.i23.i278.2 = xor i64 %add3.i275.2, %add.i273.2
  %xor1.i24.i279.2 = xor i64 %add.i273.2, %72
  %or.i25.i280.2 = or i64 %xor.i23.i278.2, %xor1.i24.i279.2
  %xor2.i26.i281.2 = xor i64 %or.i25.i280.2, %add3.i275.2
  %shr.i30.i282.2 = or i64 %xor2.i26.i281.2, %xor2.i.i277.2
  %or29.i283.2 = lshr i64 %shr.i30.i282.2, 63
  %74 = load i64, i64* %arrayidx5.i.3, align 8, !tbaa !3
  %add.i273.3 = add i64 %74, %or29.i283.2
  %add3.i275.3 = add i64 %add.i273.3, %74
  store i64 %add3.i275.3, i64* %arrayidx5.i.3, align 8, !tbaa !3
  %75 = xor i64 %add.i273.3, -9223372036854775808
  %xor2.i.i277.3 = and i64 %75, %74
  %xor.i23.i278.3 = xor i64 %add3.i275.3, %add.i273.3
  %xor1.i24.i279.3 = xor i64 %add.i273.3, %74
  %or.i25.i280.3 = or i64 %xor.i23.i278.3, %xor1.i24.i279.3
  %xor2.i26.i281.3 = xor i64 %or.i25.i280.3, %add3.i275.3
  %shr.i30.i282.3 = or i64 %xor2.i26.i281.3, %xor2.i.i277.3
  %or29.i283.3 = lshr i64 %shr.i30.i282.3, 63
  %76 = load i64, i64* %arrayidx5.i.4, align 16, !tbaa !3
  %add.i273.4 = add i64 %76, %or29.i283.3
  %add3.i275.4 = add i64 %add.i273.4, %76
  store i64 %add3.i275.4, i64* %arrayidx5.i.4, align 16, !tbaa !3
  %77 = xor i64 %add.i273.4, -9223372036854775808
  %xor2.i.i277.4 = and i64 %77, %76
  %xor.i23.i278.4 = xor i64 %add3.i275.4, %add.i273.4
  %xor1.i24.i279.4 = xor i64 %add.i273.4, %76
  %or.i25.i280.4 = or i64 %xor.i23.i278.4, %xor1.i24.i279.4
  %xor2.i26.i281.4 = xor i64 %or.i25.i280.4, %add3.i275.4
  %shr.i30.i282.4 = or i64 %xor2.i26.i281.4, %xor2.i.i277.4
  %or29.i283.4 = lshr i64 %shr.i30.i282.4, 63
  %78 = load i64, i64* %arrayidx5.i.5, align 8, !tbaa !3
  %add.i273.5 = add i64 %78, %or29.i283.4
  %add3.i275.5 = add i64 %add.i273.5, %78
  store i64 %add3.i275.5, i64* %arrayidx5.i.5, align 8, !tbaa !3
  %79 = xor i64 %add.i273.5, -9223372036854775808
  %xor2.i.i277.5 = and i64 %79, %78
  %xor.i23.i278.5 = xor i64 %add3.i275.5, %add.i273.5
  %xor1.i24.i279.5 = xor i64 %add.i273.5, %78
  %or.i25.i280.5 = or i64 %xor.i23.i278.5, %xor1.i24.i279.5
  %xor2.i26.i281.5 = xor i64 %or.i25.i280.5, %add3.i275.5
  %shr.i30.i282.5 = or i64 %xor2.i26.i281.5, %xor2.i.i277.5
  %or29.i283.5 = lshr i64 %shr.i30.i282.5, 63
  %80 = load i64, i64* %arrayidx5.i.6, align 16, !tbaa !3
  %add.i273.6 = add i64 %80, %or29.i283.5
  %add3.i275.6 = add i64 %add.i273.6, %80
  store i64 %add3.i275.6, i64* %arrayidx5.i.6, align 16, !tbaa !3
  %81 = xor i64 %add.i273.6, -9223372036854775808
  %xor2.i.i277.6 = and i64 %81, %80
  %xor.i23.i278.6 = xor i64 %add3.i275.6, %add.i273.6
  %xor1.i24.i279.6 = xor i64 %add.i273.6, %80
  %or.i25.i280.6 = or i64 %xor.i23.i278.6, %xor1.i24.i279.6
  %xor2.i26.i281.6 = xor i64 %or.i25.i280.6, %add3.i275.6
  %shr.i30.i282.6 = or i64 %xor2.i26.i281.6, %xor2.i.i277.6
  %or29.i283.6 = lshr i64 %shr.i30.i282.6, 63
  %82 = load i64, i64* %arrayidx5.i.7, align 8, !tbaa !3
  %add.i273.7 = add i64 %82, %or29.i283.6
  %add3.i275.7 = add i64 %add.i273.7, %82
  store i64 %add3.i275.7, i64* %arrayidx5.i.7, align 8, !tbaa !3
  %83 = xor i64 %add.i273.7, -9223372036854775808
  %xor2.i.i277.7 = and i64 %83, %82
  %xor.i23.i278.7 = xor i64 %add3.i275.7, %add.i273.7
  %xor1.i24.i279.7 = xor i64 %add.i273.7, %82
  %or.i25.i280.7 = or i64 %xor.i23.i278.7, %xor1.i24.i279.7
  %xor2.i26.i281.7 = xor i64 %or.i25.i280.7, %add3.i275.7
  %shr.i30.i282.7 = or i64 %xor2.i26.i281.7, %xor2.i.i277.7
  %or29.i283.7 = lshr i64 %shr.i30.i282.7, 63
  %84 = load i64, i64* %arrayidx5.i.8, align 16, !tbaa !3
  %add.i273.8 = add i64 %84, %or29.i283.7
  %add3.i275.8 = add i64 %add.i273.8, %84
  store i64 %add3.i275.8, i64* %arrayidx5.i.8, align 16, !tbaa !3
  %85 = xor i64 %add.i273.8, -9223372036854775808
  %xor2.i.i277.8 = and i64 %85, %84
  %xor.i23.i278.8 = xor i64 %add3.i275.8, %add.i273.8
  %xor1.i24.i279.8 = xor i64 %add.i273.8, %84
  %or.i25.i280.8 = or i64 %xor.i23.i278.8, %xor1.i24.i279.8
  %xor2.i26.i281.8 = xor i64 %or.i25.i280.8, %add3.i275.8
  %shr.i30.i282.8 = or i64 %xor2.i26.i281.8, %xor2.i.i277.8
  %or29.i283.8 = lshr i64 %shr.i30.i282.8, 63
  %86 = load i64, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %add.i273.9 = add i64 %86, %or29.i283.8
  %add3.i275.9 = add i64 %add.i273.9, %86
  store i64 %add3.i275.9, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %arraydecay17 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0
  %arraydecay25 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyA, i64 0, i64 0
  %arrayidx.i289 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyA, i64 0, i64 4
  store i64 0, i64* %arrayidx.i289, align 16, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %9, i8* align 1 %PrivateKeyA, i64 39, i1 false)
  %arraydecay33 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0
  call fastcc void @LADDER3PT([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay5, i64* nonnull %arraydecay25, i32 0, %struct.point_proj* nonnull %arraydecay33, [10 x i64]* nonnull %arraydecay12)
  %87 = bitcast [1 x %struct.point_proj]* %S to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %87) #10
  %arraydecay36 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0
  %88 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %89 = load <4 x i64>, <4 x i64>* %88, align 16, !tbaa !3
  %90 = bitcast [1 x %struct.point_proj]* %S to <4 x i64>*
  store <4 x i64> %89, <4 x i64>* %90, align 16, !tbaa !3
  %arrayidx.i.4.i297 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 4
  %arrayidx2.i.4.i298 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 4
  %91 = bitcast i64* %arrayidx.i.4.i297 to <4 x i64>*
  %92 = load <4 x i64>, <4 x i64>* %91, align 16, !tbaa !3
  %93 = bitcast i64* %arrayidx2.i.4.i298 to <4 x i64>*
  store <4 x i64> %92, <4 x i64>* %93, align 16, !tbaa !3
  %arrayidx.i.8.i305 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 8
  %arrayidx2.i.8.i306 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 8
  %94 = bitcast i64* %arrayidx.i.8.i305 to <4 x i64>*
  %95 = load <4 x i64>, <4 x i64>* %94, align 16, !tbaa !3
  %96 = bitcast i64* %arrayidx2.i.8.i306 to <4 x i64>*
  store <4 x i64> %95, <4 x i64>* %96, align 16, !tbaa !3
  %arrayidx.i.12.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 12
  %arrayidx2.i.12.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 12
  %97 = bitcast i64* %arrayidx.i.12.i to <4 x i64>*
  %98 = load <4 x i64>, <4 x i64>* %97, align 16, !tbaa !3
  %99 = bitcast i64* %arrayidx2.i.12.i to <4 x i64>*
  store <4 x i64> %98, <4 x i64>* %99, align 16, !tbaa !3
  %arrayidx.i.16.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 16
  %arrayidx2.i.16.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 16
  %100 = bitcast i64* %arrayidx.i.16.i to <4 x i64>*
  %101 = load <4 x i64>, <4 x i64>* %100, align 16, !tbaa !3
  %102 = bitcast i64* %arrayidx2.i.16.i to <4 x i64>*
  store <4 x i64> %101, <4 x i64>* %102, align 16, !tbaa !3
  %arrayidx.i.20.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 20
  %arrayidx2.i.20.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 20
  %103 = bitcast i64* %arrayidx.i.20.i to <4 x i64>*
  %104 = load <4 x i64>, <4 x i64>* %103, align 16, !tbaa !3
  %105 = bitcast i64* %arrayidx2.i.20.i to <4 x i64>*
  store <4 x i64> %104, <4 x i64>* %105, align 16, !tbaa !3
  %arrayidx.i.24.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 24
  %arrayidx2.i.24.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 24
  %106 = bitcast i64* %arrayidx.i.24.i to <4 x i64>*
  %107 = load <4 x i64>, <4 x i64>* %106, align 16, !tbaa !3
  %108 = bitcast i64* %arrayidx2.i.24.i to <4 x i64>*
  store <4 x i64> %107, <4 x i64>* %108, align 16, !tbaa !3
  %arrayidx.i.28.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 28
  %arrayidx2.i.28.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 28
  %109 = bitcast i64* %arrayidx.i.28.i to <4 x i64>*
  %110 = load <4 x i64>, <4 x i64>* %109, align 16, !tbaa !3
  %111 = bitcast i64* %arrayidx2.i.28.i to <4 x i64>*
  store <4 x i64> %110, <4 x i64>* %111, align 16, !tbaa !3
  %arrayidx.i.32.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 32
  %arrayidx2.i.32.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 32
  %112 = bitcast i64* %arrayidx.i.32.i to <4 x i64>*
  %113 = load <4 x i64>, <4 x i64>* %112, align 16, !tbaa !3
  %114 = bitcast i64* %arrayidx2.i.32.i to <4 x i64>*
  store <4 x i64> %113, <4 x i64>* %114, align 16, !tbaa !3
  %arrayidx.i.36.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 36
  %arrayidx2.i.36.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %S, i64 0, i64 0, i32 0, i64 0, i64 36
  %115 = bitcast i64* %arrayidx.i.36.i to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 16, !tbaa !3
  %117 = bitcast i64* %arrayidx2.i.36.i to <4 x i64>*
  store <4 x i64> %116, <4 x i64>* %117, align 16, !tbaa !3
  br label %for.body.i310

for.body.i310:                                    ; preds = %for.body.i310, %entry
  %i.06.i = phi i32 [ %inc.i, %for.body.i310 ], [ 0, %entry ]
  call void @xDBL(%struct.point_proj* nonnull %arraydecay36, %struct.point_proj* nonnull %arraydecay36, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16) #10
  %inc.i = add nuw nsw i32 %i.06.i, 1
  %exitcond.i309 = icmp eq i32 %inc.i, 304
  br i1 %exitcond.i309, label %xDBLe.exit, label %for.body.i310

xDBLe.exit:                                       ; preds = %for.body.i310
  call void @get_2_isog(%struct.point_proj* nonnull %arraydecay36, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16)
  call void @eval_2_isog(%struct.point_proj* nonnull %arraydecay33, %struct.point_proj* nonnull %arraydecay36)
  %arraydecay70 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %coeff, i64 0, i64 0
  %arrayidx.2.i11.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 2
  %arrayidx.6.i19.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 6
  %arraydecay.i315 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 0
  %arrayidx.4.i.i323 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 4
  %arrayidx.8.i.i331 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 8
  %arrayidx.2.i11.i339 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 2
  %arrayidx.6.i19.i347 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 6
  %118 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %119 = bitcast i64* %arrayidx.i.4.i297 to <4 x i64>*
  %120 = bitcast i64* %arrayidx.i.8.i305 to <4 x i64>*
  %121 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %122 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %123 = bitcast i64* %arraydecay.i315 to <4 x i64>*
  %124 = bitcast i64* %arrayidx.4.i.i323 to <4 x i64>*
  %125 = bitcast i64* %arrayidx.8.i.i331 to <4 x i64>*
  %126 = bitcast i64* %arrayidx.2.i11.i339 to <4 x i64>*
  %127 = bitcast i64* %arrayidx.6.i19.i347 to <4 x i64>*
  %128 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %129 = bitcast i64* %arrayidx.i.4.i297 to <4 x i64>*
  %130 = bitcast i64* %arrayidx.i.8.i305 to <4 x i64>*
  %131 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %132 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %133 = bitcast i64* %arraydecay.i315 to <4 x i64>*
  %134 = bitcast i64* %arrayidx.4.i.i323 to <4 x i64>*
  %135 = bitcast i64* %arrayidx.8.i.i331 to <4 x i64>*
  %136 = bitcast i64* %arrayidx.2.i11.i339 to <4 x i64>*
  %137 = bitcast i64* %arrayidx.6.i19.i347 to <4 x i64>*
  br label %while.cond.preheader

while.cond.preheader:                             ; preds = %for.end, %xDBLe.exit
  %ii.0682 = phi i32 [ 0, %xDBLe.exit ], [ %ii.1.lcssa, %for.end ]
  %npts.0681 = phi i32 [ 0, %xDBLe.exit ], [ %sub79, %for.end ]
  %index.0680 = phi i32 [ 0, %xDBLe.exit ], [ %179, %for.end ]
  %row.0679 = phi i32 [ 1, %xDBLe.exit ], [ %inc102, %for.end ]
  %sub = sub nuw nsw i32 152, %row.0679
  %cmp44672 = icmp ult i32 %index.0680, %sub
  br i1 %cmp44672, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond.preheader, %while.body
  %ii.1675 = phi i32 [ %inc60, %while.body ], [ %ii.0682, %while.cond.preheader ]
  %npts.1674 = phi i32 [ %inc, %while.body ], [ %npts.0681, %while.cond.preheader ]
  %index.1673 = phi i32 [ %add, %while.body ], [ %index.0680, %while.cond.preheader ]
  %idxprom = zext i32 %npts.1674 to i64
  %arraydecay2.i312 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 0
  %138 = load <4 x i64>, <4 x i64>* %118, align 16, !tbaa !3
  %139 = bitcast i64* %arraydecay2.i312 to <4 x i64>*
  store <4 x i64> %138, <4 x i64>* %139, align 16, !tbaa !3
  %arrayidx2.4.i.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 4
  %140 = load <4 x i64>, <4 x i64>* %119, align 16, !tbaa !3
  %141 = bitcast i64* %arrayidx2.4.i.i to <4 x i64>*
  store <4 x i64> %140, <4 x i64>* %141, align 16, !tbaa !3
  %arrayidx2.8.i.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 8
  %142 = load <4 x i64>, <4 x i64>* %120, align 16, !tbaa !3
  %143 = bitcast i64* %arrayidx2.8.i.i to <4 x i64>*
  store <4 x i64> %142, <4 x i64>* %143, align 16, !tbaa !3
  %arrayidx2.2.i12.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 2
  %144 = load <4 x i64>, <4 x i64>* %121, align 16, !tbaa !3
  %145 = bitcast i64* %arrayidx2.2.i12.i to <4 x i64>*
  store <4 x i64> %144, <4 x i64>* %145, align 16, !tbaa !3
  %arrayidx2.6.i20.i = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 6
  %146 = load <4 x i64>, <4 x i64>* %122, align 16, !tbaa !3
  %147 = bitcast i64* %arrayidx2.6.i20.i to <4 x i64>*
  store <4 x i64> %146, <4 x i64>* %147, align 16, !tbaa !3
  %arraydecay2.i316 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 0
  %148 = load <4 x i64>, <4 x i64>* %123, align 16, !tbaa !3
  %149 = bitcast i64* %arraydecay2.i316 to <4 x i64>*
  store <4 x i64> %148, <4 x i64>* %149, align 16, !tbaa !3
  %arrayidx2.4.i.i324 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 4
  %150 = load <4 x i64>, <4 x i64>* %124, align 16, !tbaa !3
  %151 = bitcast i64* %arrayidx2.4.i.i324 to <4 x i64>*
  store <4 x i64> %150, <4 x i64>* %151, align 16, !tbaa !3
  %arrayidx2.8.i.i332 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 8
  %152 = load <4 x i64>, <4 x i64>* %125, align 16, !tbaa !3
  %153 = bitcast i64* %arrayidx2.8.i.i332 to <4 x i64>*
  store <4 x i64> %152, <4 x i64>* %153, align 16, !tbaa !3
  %arrayidx2.2.i12.i340 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 2
  %154 = load <4 x i64>, <4 x i64>* %126, align 16, !tbaa !3
  %155 = bitcast i64* %arrayidx2.2.i12.i340 to <4 x i64>*
  store <4 x i64> %154, <4 x i64>* %155, align 16, !tbaa !3
  %arrayidx2.6.i20.i348 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 6
  %156 = load <4 x i64>, <4 x i64>* %127, align 16, !tbaa !3
  %157 = bitcast i64* %arrayidx2.6.i20.i348 to <4 x i64>*
  store <4 x i64> %156, <4 x i64>* %157, align 16, !tbaa !3
  %inc = add i32 %npts.1674, 1
  %arrayidx59 = getelementptr inbounds [8 x i32], [8 x i32]* %pts_index, i64 0, i64 %idxprom
  store i32 %index.1673, i32* %arrayidx59, align 4, !tbaa !59
  %inc60 = add i32 %ii.1675, 1
  %idxprom61 = zext i32 %ii.1675 to i64
  %arrayidx62 = getelementptr inbounds [151 x i32], [151 x i32]* @strat_Alice, i64 0, i64 %idxprom61
  %158 = load i32, i32* %arrayidx62, align 4, !tbaa !59
  %mul = shl i32 %158, 1
  call void @xDBLe(%struct.point_proj* nonnull %arraydecay33, %struct.point_proj* nonnull %arraydecay33, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16, i32 %mul)
  %add = add i32 %158, %index.1673
  %cmp44 = icmp ult i32 %add, %sub
  br i1 %cmp44, label %while.body, label %while.end

while.end:                                        ; preds = %while.body, %while.cond.preheader
  %npts.1.lcssa = phi i32 [ %npts.0681, %while.cond.preheader ], [ %inc, %while.body ]
  %ii.1.lcssa = phi i32 [ %ii.0682, %while.cond.preheader ], [ %inc60, %while.body ]
  call void @get_4_isog(%struct.point_proj* nonnull %arraydecay33, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16, [2 x [10 x i64]]* nonnull %arraydecay70)
  %cmp72677 = icmp eq i32 %npts.1.lcssa, 0
  br i1 %cmp72677, label %for.end, label %for.body73.preheader

for.body73.preheader:                             ; preds = %while.end
  %wide.trip.count = zext i32 %npts.1.lcssa to i64
  br label %for.body73

for.body73:                                       ; preds = %for.body73, %for.body73.preheader
  %indvars.iv = phi i64 [ 0, %for.body73.preheader ], [ %indvars.iv.next, %for.body73 ]
  %arraydecay76 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %indvars.iv, i64 0
  call void @eval_4_isog(%struct.point_proj* nonnull %arraydecay76, [2 x [10 x i64]]* nonnull %arraydecay70)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.end, label %for.body73

for.end:                                          ; preds = %for.body73, %while.end
  %sub79 = add i32 %npts.1.lcssa, -1
  %idxprom80 = zext i32 %sub79 to i64
  %arraydecay.i355 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 0, i64 0, i64 0
  %159 = bitcast i64* %arraydecay.i355 to <4 x i64>*
  %160 = load <4 x i64>, <4 x i64>* %159, align 16, !tbaa !3
  store <4 x i64> %160, <4 x i64>* %128, align 16, !tbaa !3
  %arrayidx.4.i.i363 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 0, i64 0, i64 4
  %161 = bitcast i64* %arrayidx.4.i.i363 to <4 x i64>*
  %162 = load <4 x i64>, <4 x i64>* %161, align 16, !tbaa !3
  store <4 x i64> %162, <4 x i64>* %129, align 16, !tbaa !3
  %arrayidx.8.i.i371 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 0, i64 0, i64 8
  %163 = bitcast i64* %arrayidx.8.i.i371 to <4 x i64>*
  %164 = load <4 x i64>, <4 x i64>* %163, align 16, !tbaa !3
  store <4 x i64> %164, <4 x i64>* %130, align 16, !tbaa !3
  %arrayidx.2.i11.i379 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 0, i64 1, i64 2
  %165 = bitcast i64* %arrayidx.2.i11.i379 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 16, !tbaa !3
  store <4 x i64> %166, <4 x i64>* %131, align 16, !tbaa !3
  %arrayidx.6.i19.i387 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 0, i64 1, i64 6
  %167 = bitcast i64* %arrayidx.6.i19.i387 to <4 x i64>*
  %168 = load <4 x i64>, <4 x i64>* %167, align 16, !tbaa !3
  store <4 x i64> %168, <4 x i64>* %132, align 16, !tbaa !3
  %arraydecay.i395 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 1, i64 0, i64 0
  %169 = bitcast i64* %arraydecay.i395 to <4 x i64>*
  %170 = load <4 x i64>, <4 x i64>* %169, align 16, !tbaa !3
  store <4 x i64> %170, <4 x i64>* %133, align 16, !tbaa !3
  %arrayidx.4.i.i403 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 1, i64 0, i64 4
  %171 = bitcast i64* %arrayidx.4.i.i403 to <4 x i64>*
  %172 = load <4 x i64>, <4 x i64>* %171, align 16, !tbaa !3
  store <4 x i64> %172, <4 x i64>* %134, align 16, !tbaa !3
  %arrayidx.8.i.i411 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 1, i64 0, i64 8
  %173 = bitcast i64* %arrayidx.8.i.i411 to <4 x i64>*
  %174 = load <4 x i64>, <4 x i64>* %173, align 16, !tbaa !3
  store <4 x i64> %174, <4 x i64>* %135, align 16, !tbaa !3
  %arrayidx.2.i11.i419 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 1, i64 1, i64 2
  %175 = bitcast i64* %arrayidx.2.i11.i419 to <4 x i64>*
  %176 = load <4 x i64>, <4 x i64>* %175, align 16, !tbaa !3
  store <4 x i64> %176, <4 x i64>* %136, align 16, !tbaa !3
  %arrayidx.6.i19.i427 = getelementptr inbounds [8 x [1 x %struct.point_proj]], [8 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom80, i64 0, i32 1, i64 1, i64 6
  %177 = bitcast i64* %arrayidx.6.i19.i427 to <4 x i64>*
  %178 = load <4 x i64>, <4 x i64>* %177, align 16, !tbaa !3
  store <4 x i64> %178, <4 x i64>* %137, align 16, !tbaa !3
  %arrayidx99 = getelementptr inbounds [8 x i32], [8 x i32]* %pts_index, i64 0, i64 %idxprom80
  %179 = load i32, i32* %arrayidx99, align 4, !tbaa !59
  %inc102 = add nuw nsw i32 %row.0679, 1
  %exitcond683 = icmp eq i32 %inc102, 152
  br i1 %exitcond683, label %for.end103, label %while.cond.preheader

for.end103:                                       ; preds = %for.end
  call void @get_4_isog(%struct.point_proj* nonnull %arraydecay33, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16, [2 x [10 x i64]]* nonnull %arraydecay70)
  %180 = load i64, i64* %arraydecay4.i, align 16, !tbaa !3
  %add3.i.i548 = shl i64 %180, 1
  store i64 %add3.i.i548, i64* %arraydecay4.i, align 16, !tbaa !3
  %or29.i.i553 = lshr i64 %180, 63
  %181 = load i64, i64* %arrayidx5.i.1.i173, align 8, !tbaa !3
  %add.i.1.i555 = add i64 %181, %or29.i.i553
  %add3.i.1.i557 = add i64 %add.i.1.i555, %181
  store i64 %add3.i.1.i557, i64* %arrayidx5.i.1.i173, align 8, !tbaa !3
  %182 = xor i64 %add.i.1.i555, -9223372036854775808
  %xor2.i.i.1.i559 = and i64 %182, %181
  %xor.i23.i.1.i560 = xor i64 %add3.i.1.i557, %add.i.1.i555
  %xor1.i24.i.1.i561 = xor i64 %add.i.1.i555, %181
  %or.i25.i.1.i562 = or i64 %xor.i23.i.1.i560, %xor1.i24.i.1.i561
  %xor2.i26.i.1.i563 = xor i64 %or.i25.i.1.i562, %add3.i.1.i557
  %shr.i30.i.1.i564 = or i64 %xor2.i26.i.1.i563, %xor2.i.i.1.i559
  %or29.i.1.i565 = lshr i64 %shr.i30.i.1.i564, 63
  %183 = load i64, i64* %arrayidx5.i.2.i185, align 16, !tbaa !3
  %add.i.2.i567 = add i64 %or29.i.1.i565, %183
  %add3.i.2.i569 = add i64 %add.i.2.i567, %183
  store i64 %add3.i.2.i569, i64* %arrayidx5.i.2.i185, align 16, !tbaa !3
  %184 = xor i64 %add.i.2.i567, -9223372036854775808
  %xor2.i.i.2.i571 = and i64 %184, %183
  %xor.i23.i.2.i572 = xor i64 %add3.i.2.i569, %add.i.2.i567
  %xor1.i24.i.2.i573 = xor i64 %add.i.2.i567, %183
  %or.i25.i.2.i574 = or i64 %xor.i23.i.2.i572, %xor1.i24.i.2.i573
  %xor2.i26.i.2.i575 = xor i64 %or.i25.i.2.i574, %add3.i.2.i569
  %shr.i30.i.2.i576 = or i64 %xor2.i26.i.2.i575, %xor2.i.i.2.i571
  %or29.i.2.i577 = lshr i64 %shr.i30.i.2.i576, 63
  %185 = load i64, i64* %arrayidx5.i.3.i197, align 8, !tbaa !3
  %add.i.3.i579 = add i64 %or29.i.2.i577, %185
  %add3.i.3.i581 = add i64 %add.i.3.i579, %185
  store i64 %add3.i.3.i581, i64* %arrayidx5.i.3.i197, align 8, !tbaa !3
  %186 = xor i64 %add.i.3.i579, -9223372036854775808
  %xor2.i.i.3.i583 = and i64 %186, %185
  %xor.i23.i.3.i584 = xor i64 %add3.i.3.i581, %add.i.3.i579
  %xor1.i24.i.3.i585 = xor i64 %add.i.3.i579, %185
  %or.i25.i.3.i586 = or i64 %xor.i23.i.3.i584, %xor1.i24.i.3.i585
  %xor2.i26.i.3.i587 = xor i64 %or.i25.i.3.i586, %add3.i.3.i581
  %shr.i30.i.3.i588 = or i64 %xor2.i26.i.3.i587, %xor2.i.i.3.i583
  %or29.i.3.i589 = lshr i64 %shr.i30.i.3.i588, 63
  %187 = load i64, i64* %arrayidx5.i.4.i209, align 16, !tbaa !3
  %add.i.4.i591 = add i64 %or29.i.3.i589, %187
  %add3.i.4.i593 = add i64 %add.i.4.i591, %187
  store i64 %add3.i.4.i593, i64* %arrayidx5.i.4.i209, align 16, !tbaa !3
  %188 = xor i64 %add.i.4.i591, -9223372036854775808
  %xor2.i.i.4.i595 = and i64 %188, %187
  %xor.i23.i.4.i596 = xor i64 %add3.i.4.i593, %add.i.4.i591
  %xor1.i24.i.4.i597 = xor i64 %add.i.4.i591, %187
  %or.i25.i.4.i598 = or i64 %xor.i23.i.4.i596, %xor1.i24.i.4.i597
  %xor2.i26.i.4.i599 = xor i64 %or.i25.i.4.i598, %add3.i.4.i593
  %shr.i30.i.4.i600 = or i64 %xor2.i26.i.4.i599, %xor2.i.i.4.i595
  %or29.i.4.i601 = lshr i64 %shr.i30.i.4.i600, 63
  %189 = load i64, i64* %arrayidx5.i.5.i221, align 8, !tbaa !3
  %add.i.5.i603 = add i64 %or29.i.4.i601, %189
  %add3.i.5.i605 = add i64 %add.i.5.i603, %189
  store i64 %add3.i.5.i605, i64* %arrayidx5.i.5.i221, align 8, !tbaa !3
  %190 = xor i64 %add.i.5.i603, -9223372036854775808
  %xor2.i.i.5.i607 = and i64 %190, %189
  %xor.i23.i.5.i608 = xor i64 %add3.i.5.i605, %add.i.5.i603
  %xor1.i24.i.5.i609 = xor i64 %add.i.5.i603, %189
  %or.i25.i.5.i610 = or i64 %xor.i23.i.5.i608, %xor1.i24.i.5.i609
  %xor2.i26.i.5.i611 = xor i64 %or.i25.i.5.i610, %add3.i.5.i605
  %shr.i30.i.5.i612 = or i64 %xor2.i26.i.5.i611, %xor2.i.i.5.i607
  %or29.i.5.i613 = lshr i64 %shr.i30.i.5.i612, 63
  %191 = load i64, i64* %arrayidx5.i.6.i233, align 16, !tbaa !3
  %add.i.6.i615 = add i64 %or29.i.5.i613, %191
  %add3.i.6.i617 = add i64 %add.i.6.i615, %191
  store i64 %add3.i.6.i617, i64* %arrayidx5.i.6.i233, align 16, !tbaa !3
  %192 = xor i64 %add.i.6.i615, -9223372036854775808
  %xor2.i.i.6.i619 = and i64 %192, %191
  %xor.i23.i.6.i620 = xor i64 %add3.i.6.i617, %add.i.6.i615
  %xor1.i24.i.6.i621 = xor i64 %add.i.6.i615, %191
  %or.i25.i.6.i622 = or i64 %xor.i23.i.6.i620, %xor1.i24.i.6.i621
  %xor2.i26.i.6.i623 = xor i64 %or.i25.i.6.i622, %add3.i.6.i617
  %shr.i30.i.6.i624 = or i64 %xor2.i26.i.6.i623, %xor2.i.i.6.i619
  %or29.i.6.i625 = lshr i64 %shr.i30.i.6.i624, 63
  %193 = load i64, i64* %arrayidx5.i.7.i245, align 8, !tbaa !3
  %add.i.7.i627 = add i64 %or29.i.6.i625, %193
  %add3.i.7.i629 = add i64 %add.i.7.i627, %193
  store i64 %add3.i.7.i629, i64* %arrayidx5.i.7.i245, align 8, !tbaa !3
  %194 = xor i64 %add.i.7.i627, -9223372036854775808
  %xor2.i.i.7.i631 = and i64 %194, %193
  %xor.i23.i.7.i632 = xor i64 %add3.i.7.i629, %add.i.7.i627
  %xor1.i24.i.7.i633 = xor i64 %add.i.7.i627, %193
  %or.i25.i.7.i634 = or i64 %xor.i23.i.7.i632, %xor1.i24.i.7.i633
  %xor2.i26.i.7.i635 = xor i64 %or.i25.i.7.i634, %add3.i.7.i629
  %shr.i30.i.7.i636 = or i64 %xor2.i26.i.7.i635, %xor2.i.i.7.i631
  %or29.i.7.i637 = lshr i64 %shr.i30.i.7.i636, 63
  %195 = load i64, i64* %arrayidx5.i.8.i257, align 16, !tbaa !3
  %add.i.8.i639 = add i64 %or29.i.7.i637, %195
  %add3.i.8.i641 = add i64 %add.i.8.i639, %195
  store i64 %add3.i.8.i641, i64* %arrayidx5.i.8.i257, align 16, !tbaa !3
  %196 = xor i64 %add.i.8.i639, -9223372036854775808
  %xor2.i.i.8.i643 = and i64 %196, %195
  %xor.i23.i.8.i644 = xor i64 %add3.i.8.i641, %add.i.8.i639
  %xor1.i24.i.8.i645 = xor i64 %add.i.8.i639, %195
  %or.i25.i.8.i646 = or i64 %xor.i23.i.8.i644, %xor1.i24.i.8.i645
  %xor2.i26.i.8.i647 = xor i64 %or.i25.i.8.i646, %add3.i.8.i641
  %shr.i30.i.8.i648 = or i64 %xor2.i26.i.8.i647, %xor2.i.i.8.i643
  %or29.i.8.i649 = lshr i64 %shr.i30.i.8.i648, 63
  %197 = load i64, i64* %arrayidx5.i.9.i269, align 8, !tbaa !3
  %factor = shl i64 %197, 1
  %add3.i.9.i653 = or i64 %or29.i.8.i649, %factor
  store i64 %add3.i.9.i653, i64* %arrayidx5.i.9.i269, align 8, !tbaa !3
  %198 = load i64, i64* %arraydecay10.i, align 16, !tbaa !3
  %add3.i.i441 = shl i64 %198, 1
  store i64 %add3.i.i441, i64* %arraydecay10.i, align 16, !tbaa !3
  %or29.i.i446 = lshr i64 %198, 63
  %199 = load i64, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %add.i.1.i448 = add i64 %199, %or29.i.i446
  %add3.i.1.i450 = add i64 %add.i.1.i448, %199
  store i64 %add3.i.1.i450, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %200 = xor i64 %add.i.1.i448, -9223372036854775808
  %xor2.i.i.1.i452 = and i64 %200, %199
  %xor.i23.i.1.i453 = xor i64 %add3.i.1.i450, %add.i.1.i448
  %xor1.i24.i.1.i454 = xor i64 %add.i.1.i448, %199
  %or.i25.i.1.i455 = or i64 %xor.i23.i.1.i453, %xor1.i24.i.1.i454
  %xor2.i26.i.1.i456 = xor i64 %or.i25.i.1.i455, %add3.i.1.i450
  %shr.i30.i.1.i457 = or i64 %xor2.i26.i.1.i456, %xor2.i.i.1.i452
  %or29.i.1.i458 = lshr i64 %shr.i30.i.1.i457, 63
  %201 = load i64, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %add.i.2.i460 = add i64 %or29.i.1.i458, %201
  %add3.i.2.i462 = add i64 %add.i.2.i460, %201
  store i64 %add3.i.2.i462, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %202 = xor i64 %add.i.2.i460, -9223372036854775808
  %xor2.i.i.2.i464 = and i64 %202, %201
  %xor.i23.i.2.i465 = xor i64 %add3.i.2.i462, %add.i.2.i460
  %xor1.i24.i.2.i466 = xor i64 %add.i.2.i460, %201
  %or.i25.i.2.i467 = or i64 %xor.i23.i.2.i465, %xor1.i24.i.2.i466
  %xor2.i26.i.2.i468 = xor i64 %or.i25.i.2.i467, %add3.i.2.i462
  %shr.i30.i.2.i469 = or i64 %xor2.i26.i.2.i468, %xor2.i.i.2.i464
  %or29.i.2.i470 = lshr i64 %shr.i30.i.2.i469, 63
  %203 = load i64, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %add.i.3.i472 = add i64 %or29.i.2.i470, %203
  %add3.i.3.i474 = add i64 %add.i.3.i472, %203
  store i64 %add3.i.3.i474, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %204 = xor i64 %add.i.3.i472, -9223372036854775808
  %xor2.i.i.3.i476 = and i64 %204, %203
  %xor.i23.i.3.i477 = xor i64 %add3.i.3.i474, %add.i.3.i472
  %xor1.i24.i.3.i478 = xor i64 %add.i.3.i472, %203
  %or.i25.i.3.i479 = or i64 %xor.i23.i.3.i477, %xor1.i24.i.3.i478
  %xor2.i26.i.3.i480 = xor i64 %or.i25.i.3.i479, %add3.i.3.i474
  %shr.i30.i.3.i481 = or i64 %xor2.i26.i.3.i480, %xor2.i.i.3.i476
  %or29.i.3.i482 = lshr i64 %shr.i30.i.3.i481, 63
  %205 = load i64, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %add.i.4.i484 = add i64 %or29.i.3.i482, %205
  %add3.i.4.i486 = add i64 %add.i.4.i484, %205
  store i64 %add3.i.4.i486, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %206 = xor i64 %add.i.4.i484, -9223372036854775808
  %xor2.i.i.4.i488 = and i64 %206, %205
  %xor.i23.i.4.i489 = xor i64 %add3.i.4.i486, %add.i.4.i484
  %xor1.i24.i.4.i490 = xor i64 %add.i.4.i484, %205
  %or.i25.i.4.i491 = or i64 %xor.i23.i.4.i489, %xor1.i24.i.4.i490
  %xor2.i26.i.4.i492 = xor i64 %or.i25.i.4.i491, %add3.i.4.i486
  %shr.i30.i.4.i493 = or i64 %xor2.i26.i.4.i492, %xor2.i.i.4.i488
  %or29.i.4.i494 = lshr i64 %shr.i30.i.4.i493, 63
  %207 = load i64, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %add.i.5.i496 = add i64 %or29.i.4.i494, %207
  %add3.i.5.i498 = add i64 %add.i.5.i496, %207
  store i64 %add3.i.5.i498, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %208 = xor i64 %add.i.5.i496, -9223372036854775808
  %xor2.i.i.5.i500 = and i64 %208, %207
  %xor.i23.i.5.i501 = xor i64 %add3.i.5.i498, %add.i.5.i496
  %xor1.i24.i.5.i502 = xor i64 %add.i.5.i496, %207
  %or.i25.i.5.i503 = or i64 %xor.i23.i.5.i501, %xor1.i24.i.5.i502
  %xor2.i26.i.5.i504 = xor i64 %or.i25.i.5.i503, %add3.i.5.i498
  %shr.i30.i.5.i505 = or i64 %xor2.i26.i.5.i504, %xor2.i.i.5.i500
  %or29.i.5.i506 = lshr i64 %shr.i30.i.5.i505, 63
  %209 = load i64, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %add.i.6.i508 = add i64 %or29.i.5.i506, %209
  %add3.i.6.i510 = add i64 %add.i.6.i508, %209
  store i64 %add3.i.6.i510, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %210 = xor i64 %add.i.6.i508, -9223372036854775808
  %xor2.i.i.6.i512 = and i64 %210, %209
  %xor.i23.i.6.i513 = xor i64 %add3.i.6.i510, %add.i.6.i508
  %xor1.i24.i.6.i514 = xor i64 %add.i.6.i508, %209
  %or.i25.i.6.i515 = or i64 %xor.i23.i.6.i513, %xor1.i24.i.6.i514
  %xor2.i26.i.6.i516 = xor i64 %or.i25.i.6.i515, %add3.i.6.i510
  %shr.i30.i.6.i517 = or i64 %xor2.i26.i.6.i516, %xor2.i.i.6.i512
  %or29.i.6.i518 = lshr i64 %shr.i30.i.6.i517, 63
  %211 = load i64, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %add.i.7.i520 = add i64 %or29.i.6.i518, %211
  %add3.i.7.i522 = add i64 %add.i.7.i520, %211
  store i64 %add3.i.7.i522, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %212 = xor i64 %add.i.7.i520, -9223372036854775808
  %xor2.i.i.7.i524 = and i64 %212, %211
  %xor.i23.i.7.i525 = xor i64 %add3.i.7.i522, %add.i.7.i520
  %xor1.i24.i.7.i526 = xor i64 %add.i.7.i520, %211
  %or.i25.i.7.i527 = or i64 %xor.i23.i.7.i525, %xor1.i24.i.7.i526
  %xor2.i26.i.7.i528 = xor i64 %or.i25.i.7.i527, %add3.i.7.i522
  %shr.i30.i.7.i529 = or i64 %xor2.i26.i.7.i528, %xor2.i.i.7.i524
  %or29.i.7.i530 = lshr i64 %shr.i30.i.7.i529, 63
  %213 = load i64, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %add.i.8.i532 = add i64 %or29.i.7.i530, %213
  %add3.i.8.i534 = add i64 %add.i.8.i532, %213
  store i64 %add3.i.8.i534, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %214 = xor i64 %add.i.8.i532, -9223372036854775808
  %xor2.i.i.8.i536 = and i64 %214, %213
  %xor.i23.i.8.i537 = xor i64 %add3.i.8.i534, %add.i.8.i532
  %xor1.i24.i.8.i538 = xor i64 %add.i.8.i532, %213
  %or.i25.i.8.i539 = or i64 %xor.i23.i.8.i537, %xor1.i24.i.8.i538
  %xor2.i26.i.8.i540 = xor i64 %or.i25.i.8.i539, %add3.i.8.i534
  %shr.i30.i.8.i541 = or i64 %xor2.i26.i.8.i540, %xor2.i.i.8.i536
  %or29.i.8.i542 = lshr i64 %shr.i30.i.8.i541, 63
  %215 = load i64, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  %factor671 = shl i64 %215, 1
  %add3.i.9.i546 = or i64 %or29.i.8.i542, %factor671
  store i64 %add3.i.9.i546, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @fpsub610(i64* nonnull %arraydecay4.i, i64* nonnull %arrayidx5.i, i64* nonnull %arraydecay4.i) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i, i64* nonnull %arraydecay4.i) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay119 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 0
  call void @j_inv([10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay16, [10 x i64]* nonnull %arraydecay119)
  %216 = bitcast [2 x [10 x i64]]* %t.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %216) #10
  %arraydecay.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 0, i64 0
  %arraydecay2.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 0, i64 0
  %217 = bitcast [10 x i64]* %one.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %217) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %217, i8 0, i64 80, i1 false) #10
  %arrayidx.i.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %one.i.i.i, i64 0, i64 0
  store i64 1, i64* %arrayidx.i.i.i, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i.i, i64* nonnull %arrayidx.i.i.i, i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %217) #10
  %arraydecay4.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 1, i64 0
  %arraydecay6.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %t.i, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %217) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %217, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4.i.i, i64* nonnull %arrayidx.i.i.i, i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay6.i.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %217) #10
  %218 = call i64 @llvm.objectsize.i64.p0i8(i8* %SharedSecretA, i1 false, i1 true) #10
  %call.i.i669 = call i8* @__memcpy_chk(i8* %SharedSecretA, i8* nonnull %216, i64 77, i64 %218) #10
  %add.ptr.i670 = getelementptr inbounds i8, i8* %SharedSecretA, i64 77
  %219 = bitcast i64* %arraydecay6.i.i to i8*
  %220 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i670, i1 false, i1 true) #10
  %call.i5.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i670, i8* nonnull %219, i64 77, i64 %220) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %216) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %87) #10
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 2560, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %0) #10
  ret i32 0
}

; Function Attrs: nounwind ssp uwtable
define i32 @EphemeralSecretAgreement_B_extended(i8* %PrivateKeyB, i8* %PublicKeyA, i8* %SharedSecretB, i32 %sike) local_unnamed_addr #4 {
entry:
  %one.i.i.i = alloca [10 x i64], align 16
  %P.i = alloca [1 x %struct.point_proj], align 16
  %Q.i = alloca [1 x %struct.point_proj], align 16
  %A2.i = alloca [2 x [10 x i64]], align 16
  %tmp1.i = alloca [2 x [10 x i64]], align 16
  %tmp2.i = alloca [2 x [10 x i64]], align 16
  %temp.i.i.i.i = alloca [20 x i64], align 16
  %R = alloca [1 x %struct.point_proj], align 16
  %pts = alloca [10 x [1 x %struct.point_proj]], align 16
  %coeff = alloca [3 x [2 x [10 x i64]]], align 16
  %PKB = alloca [3 x [2 x [10 x i64]]], align 16
  %jinv = alloca [2 x [10 x i64]], align 16
  %A24plus = alloca [2 x [10 x i64]], align 16
  %A24minus = alloca [2 x [10 x i64]], align 16
  %A = alloca [2 x [10 x i64]], align 16
  %pts_index = alloca [10 x i32], align 16
  %SecretKeyB = alloca [5 x i64], align 16
  %0 = bitcast [1 x %struct.point_proj]* %R to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %0) #10
  %1 = bitcast [10 x [1 x %struct.point_proj]]* %pts to i8*
  call void @llvm.lifetime.start.p0i8(i64 3200, i8* nonnull %1) #10
  %2 = bitcast [3 x [2 x [10 x i64]]]* %coeff to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %2) #10
  %3 = bitcast [3 x [2 x [10 x i64]]]* %PKB to i8*
  call void @llvm.lifetime.start.p0i8(i64 480, i8* nonnull %3) #10
  %4 = bitcast [2 x [10 x i64]]* %jinv to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %4) #10
  %5 = bitcast [2 x [10 x i64]]* %A24plus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 0, i64 160, i1 false)
  %6 = bitcast [2 x [10 x i64]]* %A24minus to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %6, i8 0, i64 160, i1 false)
  %7 = bitcast [2 x [10 x i64]]* %A to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 0, i64 160, i1 false)
  %8 = bitcast [10 x i32]* %pts_index to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %8) #10
  %9 = bitcast [5 x i64]* %SecretKeyB to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %9) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 0, i64 40, i1 false)
  %arraydecay = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0
  %arraydecay.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 0
  %arrayidx.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i, align 8, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %3, i8* align 1 %PublicKeyA, i64 77, i1 false)
  %add.ptr.i = getelementptr inbounds i8, i8* %PublicKeyA, i64 77
  %arraydecay2.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 0
  %arrayidx.i7.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i, align 8, !tbaa !3
  %10 = bitcast i64* %arraydecay2.i to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %10, i8* nonnull align 1 %add.ptr.i, i64 77, i1 false)
  %11 = bitcast [20 x i64]* %temp.i.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  %arraydecay.i.i.i.i = getelementptr inbounds [20 x i64], [20 x i64]* %temp.i.i.i.i, i64 0, i64 0
  call void @mp_mul(i64* nonnull %arraydecay.i, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %add.ptr = getelementptr inbounds i8, i8* %PublicKeyA, i64 154
  %arraydecay2 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0
  %arraydecay.i155 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay2, i64 0, i64 0
  %arrayidx.i.i156 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i156, align 8, !tbaa !3
  %12 = bitcast [10 x i64]* %arraydecay2 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %12, i8* nonnull align 1 %add.ptr, i64 77, i1 false)
  %add.ptr.i158 = getelementptr inbounds i8, i8* %PublicKeyA, i64 231
  %arraydecay2.i159 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 0
  %arrayidx.i7.i160 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i160, align 8, !tbaa !3
  %13 = bitcast i64* %arraydecay2.i159 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %13, i8* nonnull align 1 %add.ptr.i158, i64 77, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i155, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i155) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i159, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i159) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %add.ptr3 = getelementptr inbounds i8, i8* %PublicKeyA, i64 308
  %arraydecay5 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 0
  %arraydecay.i164 = getelementptr inbounds [10 x i64], [10 x i64]* %arraydecay5, i64 0, i64 0
  %arrayidx.i.i165 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 0, i64 9
  store i64 0, i64* %arrayidx.i.i165, align 8, !tbaa !3
  %14 = bitcast [10 x i64]* %arraydecay5 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %14, i8* nonnull align 1 %add.ptr3, i64 77, i1 false)
  %add.ptr.i167 = getelementptr inbounds i8, i8* %PublicKeyA, i64 385
  %arraydecay2.i168 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 1, i64 0
  %arrayidx.i7.i169 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 2, i64 1, i64 9
  store i64 0, i64* %arrayidx.i7.i169, align 8, !tbaa !3
  %15 = bitcast i64* %arraydecay2.i168 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %15, i8* nonnull align 1 %add.ptr.i167, i64 77, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i164, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay.i164) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay2.i168, i64* getelementptr inbounds ([10 x i64], [10 x i64]* @Montgomery_R2, i64 0, i64 0), i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i168) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  %arraydecay12 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0
  call void @get_A([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay5, [10 x i64]* nonnull %arraydecay12)
  %arrayidx5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 0
  store i64 3457782220, i64* %arrayidx5.i, align 16, !tbaa !3
  %arrayidx5.i.1 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 1
  %arrayidx5.i.4 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 4
  %16 = bitcast i64* %arrayidx5.i.1 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 0, i64 24, i1 false)
  %17 = bitcast i64* %arrayidx5.i.4 to <4 x i64>*
  store <4 x i64> <i64 3776268287550160896, i64 -7263315013628922753, i64 1482863448970209336, i64 -6526766805794053180>, <4 x i64>* %17, align 16, !tbaa !3
  %arrayidx5.i.8 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 8
  store i64 2797303665991966331, i64* %arrayidx5.i.8, align 16, !tbaa !3
  %arrayidx5.i.9 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0, i64 9
  store i64 8877888200, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %arraydecay16 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 0
  %arraydecay17 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0
  %arraydecay.i172 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 0
  %arraydecay4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 0
  %18 = load i64, i64* %arraydecay.i172, align 16, !tbaa !3
  %add3.i.i174 = add i64 %18, 3457782220
  store i64 %add3.i.i174, i64* %arraydecay4.i, align 16, !tbaa !3
  %19 = sub i64 -3457782221, %18
  %xor2.i26.i.i178 = and i64 %18, %19
  %or29.i.i179 = lshr i64 %xor2.i26.i.i178, 63
  %arrayidx.i.1.i180 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 1
  %20 = load i64, i64* %arrayidx.i.1.i180, align 8, !tbaa !3
  %add.i.1.i181 = add i64 %or29.i.i179, %20
  %arrayidx5.i.1.i184 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 1
  store i64 %add.i.1.i181, i64* %arrayidx5.i.1.i184, align 8, !tbaa !3
  %21 = xor i64 %add.i.1.i181, -9223372036854775808
  %xor2.i.i.1.i185 = and i64 %21, %20
  %or29.i.1.i191 = lshr i64 %xor2.i.i.1.i185, 63
  %arrayidx.i.2.i192 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 2
  %22 = load i64, i64* %arrayidx.i.2.i192, align 16, !tbaa !3
  %add.i.2.i193 = add i64 %or29.i.1.i191, %22
  %arrayidx5.i.2.i196 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 2
  store i64 %add.i.2.i193, i64* %arrayidx5.i.2.i196, align 16, !tbaa !3
  %23 = xor i64 %add.i.2.i193, -9223372036854775808
  %xor2.i.i.2.i197 = and i64 %23, %22
  %or29.i.2.i203 = lshr i64 %xor2.i.i.2.i197, 63
  %arrayidx.i.3.i204 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 3
  %24 = load i64, i64* %arrayidx.i.3.i204, align 8, !tbaa !3
  %add.i.3.i205 = add i64 %or29.i.2.i203, %24
  %arrayidx5.i.3.i208 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 3
  store i64 %add.i.3.i205, i64* %arrayidx5.i.3.i208, align 8, !tbaa !3
  %25 = xor i64 %add.i.3.i205, -9223372036854775808
  %xor2.i.i.3.i209 = and i64 %25, %24
  %or29.i.3.i215 = lshr i64 %xor2.i.i.3.i209, 63
  %arrayidx.i.4.i216 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 4
  %26 = load i64, i64* %arrayidx.i.4.i216, align 16, !tbaa !3
  %add.i.4.i217 = add i64 %or29.i.3.i215, %26
  %add3.i.4.i219 = add i64 %add.i.4.i217, 3776268287550160896
  %arrayidx5.i.4.i220 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 4
  store i64 %add3.i.4.i219, i64* %arrayidx5.i.4.i220, align 16, !tbaa !3
  %27 = xor i64 %add.i.4.i217, -9223372036854775808
  %xor2.i.i.4.i221 = and i64 %27, %26
  %28 = sub i64 -3776268287550160897, %add.i.4.i217
  %xor2.i26.i.4.i225 = and i64 %add.i.4.i217, %28
  %shr.i30.i.4.i226 = or i64 %xor2.i26.i.4.i225, %xor2.i.i.4.i221
  %or29.i.4.i227 = lshr i64 %shr.i30.i.4.i226, 63
  %arrayidx.i.5.i228 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 5
  %29 = load i64, i64* %arrayidx.i.5.i228, align 8, !tbaa !3
  %add.i.5.i229 = add i64 %or29.i.4.i227, %29
  %add3.i.5.i231 = add i64 %add.i.5.i229, -7263315013628922753
  %arrayidx5.i.5.i232 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 5
  store i64 %add3.i.5.i231, i64* %arrayidx5.i.5.i232, align 8, !tbaa !3
  %30 = xor i64 %add.i.5.i229, -9223372036854775808
  %xor2.i.i.5.i233 = and i64 %30, %29
  %xor.i23.i.5.i234 = xor i64 %add3.i.5.i231, %add.i.5.i229
  %xor1.i24.i.5.i235 = xor i64 %add.i.5.i229, -9223372036854775808
  %or.i25.i.5.i236 = or i64 %xor.i23.i.5.i234, %xor1.i24.i.5.i235
  %xor2.i26.i.5.i237 = xor i64 %or.i25.i.5.i236, %add3.i.5.i231
  %shr.i30.i.5.i238 = or i64 %xor2.i26.i.5.i237, %xor2.i.i.5.i233
  %or29.i.5.i239 = lshr i64 %shr.i30.i.5.i238, 63
  %arrayidx.i.6.i240 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 6
  %31 = load i64, i64* %arrayidx.i.6.i240, align 16, !tbaa !3
  %add.i.6.i241 = add i64 %or29.i.5.i239, %31
  %add3.i.6.i243 = add i64 %add.i.6.i241, 1482863448970209336
  %arrayidx5.i.6.i244 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 6
  store i64 %add3.i.6.i243, i64* %arrayidx5.i.6.i244, align 16, !tbaa !3
  %32 = xor i64 %add.i.6.i241, -9223372036854775808
  %xor2.i.i.6.i245 = and i64 %32, %31
  %33 = sub i64 -1482863448970209337, %add.i.6.i241
  %xor2.i26.i.6.i249 = and i64 %add.i.6.i241, %33
  %shr.i30.i.6.i250 = or i64 %xor2.i26.i.6.i249, %xor2.i.i.6.i245
  %or29.i.6.i251 = lshr i64 %shr.i30.i.6.i250, 63
  %arrayidx.i.7.i252 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 7
  %34 = load i64, i64* %arrayidx.i.7.i252, align 8, !tbaa !3
  %add.i.7.i253 = add i64 %or29.i.6.i251, %34
  %add3.i.7.i255 = add i64 %add.i.7.i253, -6526766805794053180
  %arrayidx5.i.7.i256 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 7
  store i64 %add3.i.7.i255, i64* %arrayidx5.i.7.i256, align 8, !tbaa !3
  %35 = xor i64 %add.i.7.i253, -9223372036854775808
  %xor2.i.i.7.i257 = and i64 %35, %34
  %xor.i23.i.7.i258 = xor i64 %add3.i.7.i255, %add.i.7.i253
  %xor1.i24.i.7.i259 = xor i64 %add.i.7.i253, -9223372036854775808
  %or.i25.i.7.i260 = or i64 %xor.i23.i.7.i258, %xor1.i24.i.7.i259
  %xor2.i26.i.7.i261 = xor i64 %or.i25.i.7.i260, %add3.i.7.i255
  %shr.i30.i.7.i262 = or i64 %xor2.i26.i.7.i261, %xor2.i.i.7.i257
  %or29.i.7.i263 = lshr i64 %shr.i30.i.7.i262, 63
  %arrayidx.i.8.i264 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 8
  %36 = load i64, i64* %arrayidx.i.8.i264, align 16, !tbaa !3
  %add.i.8.i265 = add i64 %or29.i.7.i263, %36
  %add3.i.8.i267 = add i64 %add.i.8.i265, 2797303665991966331
  %arrayidx5.i.8.i268 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 8
  store i64 %add3.i.8.i267, i64* %arrayidx5.i.8.i268, align 16, !tbaa !3
  %37 = xor i64 %add.i.8.i265, -9223372036854775808
  %xor2.i.i.8.i269 = and i64 %37, %36
  %38 = sub i64 -2797303665991966332, %add.i.8.i265
  %xor2.i26.i.8.i273 = and i64 %add.i.8.i265, %38
  %shr.i30.i.8.i274 = or i64 %xor2.i26.i.8.i273, %xor2.i.i.8.i269
  %or29.i.8.i275 = lshr i64 %shr.i30.i.8.i274, 63
  %arrayidx.i.9.i276 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 0, i64 9
  %39 = load i64, i64* %arrayidx.i.9.i276, align 8, !tbaa !3
  %40 = load i64, i64* %arrayidx5.i.9, align 8, !tbaa !3
  %add.i.9.i277 = add i64 %40, %39
  %add3.i.9.i279 = add i64 %add.i.9.i277, %or29.i.8.i275
  %arrayidx5.i.9.i280 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 0, i64 9
  store i64 %add3.i.9.i279, i64* %arrayidx5.i.9.i280, align 8, !tbaa !3
  %arraydecay6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 0
  %arraydecay8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 0
  %arraydecay10.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 0
  %41 = load i64, i64* %arraydecay6.i, align 16, !tbaa !3
  %42 = load i64, i64* %arraydecay8.i, align 16, !tbaa !3
  %add3.i.i = add i64 %42, %41
  store i64 %add3.i.i, i64* %arraydecay10.i, align 16, !tbaa !3
  %xor.i23.i.i = xor i64 %add3.i.i, %41
  %xor1.i24.i.i = xor i64 %42, %41
  %or.i25.i.i = or i64 %xor.i23.i.i, %xor1.i24.i.i
  %xor2.i26.i.i = xor i64 %or.i25.i.i, %add3.i.i
  %or29.i.i = lshr i64 %xor2.i26.i.i, 63
  %arrayidx.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 1
  %43 = load i64, i64* %arrayidx.i.1.i, align 8, !tbaa !3
  %add.i.1.i = add i64 %or29.i.i, %43
  %arrayidx2.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 1
  %44 = load i64, i64* %arrayidx2.i.1.i, align 8, !tbaa !3
  %add3.i.1.i = add i64 %add.i.1.i, %44
  %arrayidx5.i.1.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 1
  store i64 %add3.i.1.i, i64* %arrayidx5.i.1.i, align 8, !tbaa !3
  %45 = xor i64 %add.i.1.i, -9223372036854775808
  %xor2.i.i.1.i = and i64 %45, %43
  %xor.i23.i.1.i = xor i64 %add3.i.1.i, %add.i.1.i
  %xor1.i24.i.1.i = xor i64 %add.i.1.i, %44
  %or.i25.i.1.i = or i64 %xor.i23.i.1.i, %xor1.i24.i.1.i
  %xor2.i26.i.1.i = xor i64 %or.i25.i.1.i, %add3.i.1.i
  %shr.i30.i.1.i = or i64 %xor2.i26.i.1.i, %xor2.i.i.1.i
  %or29.i.1.i = lshr i64 %shr.i30.i.1.i, 63
  %arrayidx.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 2
  %46 = load i64, i64* %arrayidx.i.2.i, align 16, !tbaa !3
  %add.i.2.i = add i64 %or29.i.1.i, %46
  %arrayidx2.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 2
  %47 = load i64, i64* %arrayidx2.i.2.i, align 16, !tbaa !3
  %add3.i.2.i = add i64 %add.i.2.i, %47
  %arrayidx5.i.2.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 2
  store i64 %add3.i.2.i, i64* %arrayidx5.i.2.i, align 16, !tbaa !3
  %48 = xor i64 %add.i.2.i, -9223372036854775808
  %xor2.i.i.2.i = and i64 %48, %46
  %xor.i23.i.2.i = xor i64 %add3.i.2.i, %add.i.2.i
  %xor1.i24.i.2.i = xor i64 %add.i.2.i, %47
  %or.i25.i.2.i = or i64 %xor.i23.i.2.i, %xor1.i24.i.2.i
  %xor2.i26.i.2.i = xor i64 %or.i25.i.2.i, %add3.i.2.i
  %shr.i30.i.2.i = or i64 %xor2.i26.i.2.i, %xor2.i.i.2.i
  %or29.i.2.i = lshr i64 %shr.i30.i.2.i, 63
  %arrayidx.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 3
  %49 = load i64, i64* %arrayidx.i.3.i, align 8, !tbaa !3
  %add.i.3.i = add i64 %or29.i.2.i, %49
  %arrayidx2.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 3
  %50 = load i64, i64* %arrayidx2.i.3.i, align 8, !tbaa !3
  %add3.i.3.i = add i64 %add.i.3.i, %50
  %arrayidx5.i.3.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 3
  store i64 %add3.i.3.i, i64* %arrayidx5.i.3.i, align 8, !tbaa !3
  %51 = xor i64 %add.i.3.i, -9223372036854775808
  %xor2.i.i.3.i = and i64 %51, %49
  %xor.i23.i.3.i = xor i64 %add3.i.3.i, %add.i.3.i
  %xor1.i24.i.3.i = xor i64 %add.i.3.i, %50
  %or.i25.i.3.i = or i64 %xor.i23.i.3.i, %xor1.i24.i.3.i
  %xor2.i26.i.3.i = xor i64 %or.i25.i.3.i, %add3.i.3.i
  %shr.i30.i.3.i = or i64 %xor2.i26.i.3.i, %xor2.i.i.3.i
  %or29.i.3.i = lshr i64 %shr.i30.i.3.i, 63
  %arrayidx.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 4
  %52 = load i64, i64* %arrayidx.i.4.i, align 16, !tbaa !3
  %add.i.4.i = add i64 %or29.i.3.i, %52
  %arrayidx2.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 4
  %53 = load i64, i64* %arrayidx2.i.4.i, align 16, !tbaa !3
  %add3.i.4.i = add i64 %add.i.4.i, %53
  %arrayidx5.i.4.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 4
  store i64 %add3.i.4.i, i64* %arrayidx5.i.4.i, align 16, !tbaa !3
  %54 = xor i64 %add.i.4.i, -9223372036854775808
  %xor2.i.i.4.i = and i64 %54, %52
  %xor.i23.i.4.i = xor i64 %add3.i.4.i, %add.i.4.i
  %xor1.i24.i.4.i = xor i64 %add.i.4.i, %53
  %or.i25.i.4.i = or i64 %xor.i23.i.4.i, %xor1.i24.i.4.i
  %xor2.i26.i.4.i = xor i64 %or.i25.i.4.i, %add3.i.4.i
  %shr.i30.i.4.i = or i64 %xor2.i26.i.4.i, %xor2.i.i.4.i
  %or29.i.4.i = lshr i64 %shr.i30.i.4.i, 63
  %arrayidx.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 5
  %55 = load i64, i64* %arrayidx.i.5.i, align 8, !tbaa !3
  %add.i.5.i = add i64 %or29.i.4.i, %55
  %arrayidx2.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 5
  %56 = load i64, i64* %arrayidx2.i.5.i, align 8, !tbaa !3
  %add3.i.5.i = add i64 %add.i.5.i, %56
  %arrayidx5.i.5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 5
  store i64 %add3.i.5.i, i64* %arrayidx5.i.5.i, align 8, !tbaa !3
  %57 = xor i64 %add.i.5.i, -9223372036854775808
  %xor2.i.i.5.i = and i64 %57, %55
  %xor.i23.i.5.i = xor i64 %add3.i.5.i, %add.i.5.i
  %xor1.i24.i.5.i = xor i64 %add.i.5.i, %56
  %or.i25.i.5.i = or i64 %xor.i23.i.5.i, %xor1.i24.i.5.i
  %xor2.i26.i.5.i = xor i64 %or.i25.i.5.i, %add3.i.5.i
  %shr.i30.i.5.i = or i64 %xor2.i26.i.5.i, %xor2.i.i.5.i
  %or29.i.5.i = lshr i64 %shr.i30.i.5.i, 63
  %arrayidx.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 6
  %58 = load i64, i64* %arrayidx.i.6.i, align 16, !tbaa !3
  %add.i.6.i = add i64 %or29.i.5.i, %58
  %arrayidx2.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 6
  %59 = load i64, i64* %arrayidx2.i.6.i, align 16, !tbaa !3
  %add3.i.6.i = add i64 %add.i.6.i, %59
  %arrayidx5.i.6.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 6
  store i64 %add3.i.6.i, i64* %arrayidx5.i.6.i, align 16, !tbaa !3
  %60 = xor i64 %add.i.6.i, -9223372036854775808
  %xor2.i.i.6.i = and i64 %60, %58
  %xor.i23.i.6.i = xor i64 %add3.i.6.i, %add.i.6.i
  %xor1.i24.i.6.i = xor i64 %add.i.6.i, %59
  %or.i25.i.6.i = or i64 %xor.i23.i.6.i, %xor1.i24.i.6.i
  %xor2.i26.i.6.i = xor i64 %or.i25.i.6.i, %add3.i.6.i
  %shr.i30.i.6.i = or i64 %xor2.i26.i.6.i, %xor2.i.i.6.i
  %or29.i.6.i = lshr i64 %shr.i30.i.6.i, 63
  %arrayidx.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 7
  %61 = load i64, i64* %arrayidx.i.7.i, align 8, !tbaa !3
  %add.i.7.i = add i64 %or29.i.6.i, %61
  %arrayidx2.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 7
  %62 = load i64, i64* %arrayidx2.i.7.i, align 8, !tbaa !3
  %add3.i.7.i = add i64 %add.i.7.i, %62
  %arrayidx5.i.7.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 7
  store i64 %add3.i.7.i, i64* %arrayidx5.i.7.i, align 8, !tbaa !3
  %63 = xor i64 %add.i.7.i, -9223372036854775808
  %xor2.i.i.7.i = and i64 %63, %61
  %xor.i23.i.7.i = xor i64 %add3.i.7.i, %add.i.7.i
  %xor1.i24.i.7.i = xor i64 %add.i.7.i, %62
  %or.i25.i.7.i = or i64 %xor.i23.i.7.i, %xor1.i24.i.7.i
  %xor2.i26.i.7.i = xor i64 %or.i25.i.7.i, %add3.i.7.i
  %shr.i30.i.7.i = or i64 %xor2.i26.i.7.i, %xor2.i.i.7.i
  %or29.i.7.i = lshr i64 %shr.i30.i.7.i, 63
  %arrayidx.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 8
  %64 = load i64, i64* %arrayidx.i.8.i, align 16, !tbaa !3
  %add.i.8.i = add i64 %or29.i.7.i, %64
  %arrayidx2.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 8
  %65 = load i64, i64* %arrayidx2.i.8.i, align 16, !tbaa !3
  %add3.i.8.i = add i64 %add.i.8.i, %65
  %arrayidx5.i.8.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 8
  store i64 %add3.i.8.i, i64* %arrayidx5.i.8.i, align 16, !tbaa !3
  %66 = xor i64 %add.i.8.i, -9223372036854775808
  %xor2.i.i.8.i = and i64 %66, %64
  %xor.i23.i.8.i = xor i64 %add3.i.8.i, %add.i.8.i
  %xor1.i24.i.8.i = xor i64 %add.i.8.i, %65
  %or.i25.i.8.i = or i64 %xor.i23.i.8.i, %xor1.i24.i.8.i
  %xor2.i26.i.8.i = xor i64 %or.i25.i.8.i, %add3.i.8.i
  %shr.i30.i.8.i = or i64 %xor2.i26.i.8.i, %xor2.i.i.8.i
  %or29.i.8.i = lshr i64 %shr.i30.i.8.i, 63
  %arrayidx.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A, i64 0, i64 1, i64 9
  %67 = load i64, i64* %arrayidx.i.9.i, align 8, !tbaa !3
  %arrayidx2.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24minus, i64 0, i64 1, i64 9
  %68 = load i64, i64* %arrayidx2.i.9.i, align 8, !tbaa !3
  %add.i.9.i = add i64 %68, %67
  %add3.i.9.i = add i64 %add.i.9.i, %or29.i.8.i
  %arrayidx5.i.9.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A24plus, i64 0, i64 1, i64 9
  store i64 %add3.i.9.i, i64* %arrayidx5.i.9.i, align 8, !tbaa !3
  call void @mp_sub610_p2(i64* nonnull %arraydecay.i172, i64* nonnull %arrayidx5.i, i64* nonnull %arrayidx5.i) #10
  call void @mp_sub610_p2(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay8.i) #10
  %cmp = icmp eq i32 %sike, 1
  br i1 %cmp, label %if.then, label %if.end28

if.then:                                          ; preds = %entry
  %69 = bitcast [1 x %struct.point_proj]* %P.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %69) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %69, i8 0, i64 320, i1 false) #10
  %70 = bitcast [1 x %struct.point_proj]* %Q.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %70, i8 0, i64 320, i1 false) #10
  %71 = bitcast [2 x [10 x i64]]* %A2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %71) #10
  %72 = bitcast [2 x [10 x i64]]* %tmp1.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %72) #10
  %73 = bitcast [2 x [10 x i64]]* %tmp2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %73) #10
  %arraydecay.i287 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A2.i, i64 0, i64 0
  %arraydecay2.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A2.i, i64 0, i64 0, i64 0
  call void @fpdiv2_610(i64* nonnull %arraydecay.i172, i64* nonnull %arraydecay2.i.i) #10
  %arraydecay6.i.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A2.i, i64 0, i64 1, i64 0
  call void @fpdiv2_610(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i.i) #10
  %arraydecay2.i288 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0
  %arraydecay3.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 0, i64 0
  %74 = bitcast [3 x [2 x [10 x i64]]]* %PKB to <4 x i64>*
  %75 = load <4 x i64>, <4 x i64>* %74, align 16, !tbaa !3
  %76 = bitcast [1 x %struct.point_proj]* %P.i to <4 x i64>*
  store <4 x i64> %75, <4 x i64>* %76, align 16, !tbaa !3
  %arrayidx.4.i.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 4
  %arrayidx2.4.i.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 0, i64 0, i64 4
  %77 = bitcast i64* %arrayidx.4.i.i.i to <4 x i64>*
  %78 = load <4 x i64>, <4 x i64>* %77, align 16, !tbaa !3
  %79 = bitcast i64* %arrayidx2.4.i.i.i to <4 x i64>*
  store <4 x i64> %78, <4 x i64>* %79, align 16, !tbaa !3
  %arrayidx.8.i.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 0, i64 8
  %arrayidx2.8.i.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 0, i64 0, i64 8
  %80 = bitcast i64* %arrayidx.8.i.i.i to <4 x i64>*
  %81 = load <4 x i64>, <4 x i64>* %80, align 16, !tbaa !3
  %82 = bitcast i64* %arrayidx2.8.i.i.i to <4 x i64>*
  store <4 x i64> %81, <4 x i64>* %82, align 16, !tbaa !3
  %arrayidx.2.i11.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 2
  %arrayidx2.2.i12.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 0, i64 1, i64 2
  %83 = bitcast i64* %arrayidx.2.i11.i.i to <4 x i64>*
  %84 = load <4 x i64>, <4 x i64>* %83, align 16, !tbaa !3
  %85 = bitcast i64* %arrayidx2.2.i12.i.i to <4 x i64>*
  store <4 x i64> %84, <4 x i64>* %85, align 16, !tbaa !3
  %arrayidx.6.i19.i.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 0, i64 1, i64 6
  %arrayidx2.6.i20.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 0, i64 1, i64 6
  %86 = bitcast i64* %arrayidx.6.i19.i.i to <4 x i64>*
  %87 = load <4 x i64>, <4 x i64>* %86, align 16, !tbaa !3
  %88 = bitcast i64* %arrayidx2.6.i20.i.i to <4 x i64>*
  store <4 x i64> %87, <4 x i64>* %88, align 16, !tbaa !3
  %Z.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1
  %arraydecay5.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z.i, i64 0, i64 0
  %89 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z.i, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %89, align 16, !tbaa !3
  %arrayidx2.1.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.2.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 2
  %arrayidx2.3.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 3
  %arrayidx2.4.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 4
  %90 = bitcast i64* %arrayidx2.1.i.i to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 0, i64 24, i1 false) #10
  %arrayidx2.5.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 5
  %arrayidx2.6.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 6
  %arrayidx2.7.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 7
  %91 = bitcast i64* %arrayidx2.4.i.i to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %91, align 16, !tbaa !3
  %arrayidx2.8.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i.i, align 16, !tbaa !3
  %arrayidx2.9.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i.i, align 8, !tbaa !3
  %arraydecay8.i289 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0
  %arraydecay10.i290 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 0, i64 0
  %arraydecay.i131.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0, i64 0
  %92 = bitcast i64* %arraydecay.i131.i to <4 x i64>*
  %93 = load <4 x i64>, <4 x i64>* %92, align 16, !tbaa !3
  %94 = bitcast [1 x %struct.point_proj]* %Q.i to <4 x i64>*
  store <4 x i64> %93, <4 x i64>* %94, align 16, !tbaa !3
  %arrayidx.4.i.i139.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0, i64 4
  %arrayidx2.4.i.i140.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 0, i64 0, i64 4
  %95 = bitcast i64* %arrayidx.4.i.i139.i to <4 x i64>*
  %96 = load <4 x i64>, <4 x i64>* %95, align 16, !tbaa !3
  %97 = bitcast i64* %arrayidx2.4.i.i140.i to <4 x i64>*
  store <4 x i64> %96, <4 x i64>* %97, align 16, !tbaa !3
  %arrayidx.8.i.i147.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 0, i64 8
  %arrayidx2.8.i.i148.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 0, i64 0, i64 8
  %98 = bitcast i64* %arrayidx.8.i.i147.i to <4 x i64>*
  %99 = load <4 x i64>, <4 x i64>* %98, align 16, !tbaa !3
  %100 = bitcast i64* %arrayidx2.8.i.i148.i to <4 x i64>*
  store <4 x i64> %99, <4 x i64>* %100, align 16, !tbaa !3
  %arrayidx.2.i11.i155.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 2
  %arrayidx2.2.i12.i156.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 0, i64 1, i64 2
  %101 = bitcast i64* %arrayidx.2.i11.i155.i to <4 x i64>*
  %102 = load <4 x i64>, <4 x i64>* %101, align 16, !tbaa !3
  %103 = bitcast i64* %arrayidx2.2.i12.i156.i to <4 x i64>*
  store <4 x i64> %102, <4 x i64>* %103, align 16, !tbaa !3
  %arrayidx.6.i19.i163.i = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %PKB, i64 0, i64 1, i64 1, i64 6
  %arrayidx2.6.i20.i164.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 0, i64 1, i64 6
  %104 = bitcast i64* %arrayidx.6.i19.i163.i to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 16, !tbaa !3
  %106 = bitcast i64* %arrayidx2.6.i20.i164.i to <4 x i64>*
  store <4 x i64> %105, <4 x i64>* %106, align 16, !tbaa !3
  %Z12.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1
  %arraydecay13.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z12.i, i64 0, i64 0
  %107 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %Z12.i, i64 0, i64 0, i64 0
  store i64 1728891110, i64* %107, align 16, !tbaa !3
  %arrayidx2.1.i171.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 1
  %arrayidx2.2.i172.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 2
  %arrayidx2.3.i173.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 3
  %arrayidx2.4.i174.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 4
  %108 = bitcast i64* %arrayidx2.1.i171.i to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %108, i8 0, i64 24, i1 false) #10
  %arrayidx2.5.i175.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 5
  %arrayidx2.6.i176.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 6
  %arrayidx2.7.i177.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 7
  %109 = bitcast i64* %arrayidx2.4.i174.i to <4 x i64>*
  store <4 x i64> <i64 -7335237893079695360, i64 5591714530040314431, i64 741431724485104668, i64 -3263383402897026590>, <4 x i64>* %109, align 16, !tbaa !3
  %arrayidx2.8.i178.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 8
  store i64 1398651832995983165, i64* %arrayidx2.8.i178.i, align 16, !tbaa !3
  %arrayidx2.9.i179.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 0, i64 9
  store i64 4438944100, i64* %arrayidx2.9.i179.i, align 8, !tbaa !3
  call void @xTPLe_fast(%struct.point_proj* nonnull %arraydecay2.i288, %struct.point_proj* nonnull %arraydecay2.i288, [10 x i64]* nonnull %arraydecay.i287, i32 191) #10
  call void @xTPLe_fast(%struct.point_proj* nonnull %arraydecay8.i289, %struct.point_proj* nonnull %arraydecay8.i289, [10 x i64]* nonnull %arraydecay.i287, i32 191) #10
  call void @fpcorrection610(i64* nonnull %89) #10
  %arraydecay2.i280.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay2.i280.i) #10
  call void @fpcorrection610(i64* nonnull %107) #10
  %arraydecay2.i282.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay2.i282.i) #10
  %110 = load i64, i64* %89, align 16, !tbaa !3
  %111 = load i64, i64* %arrayidx2.1.i.i, align 8
  %112 = or i64 %111, %110
  %113 = load i64, i64* %arrayidx2.2.i.i, align 16
  %114 = or i64 %112, %113
  %115 = load i64, i64* %arrayidx2.3.i.i, align 8
  %116 = or i64 %114, %115
  %117 = load i64, i64* %arrayidx2.4.i.i, align 16
  %118 = or i64 %116, %117
  %119 = load i64, i64* %arrayidx2.5.i.i, align 8
  %120 = or i64 %118, %119
  %121 = load i64, i64* %arrayidx2.6.i.i, align 16
  %122 = or i64 %120, %121
  %123 = load i64, i64* %arrayidx2.7.i.i, align 8
  %124 = or i64 %122, %123
  %125 = load i64, i64* %arrayidx2.8.i.i, align 16
  %126 = or i64 %124, %125
  %127 = load i64, i64* %arrayidx2.9.i.i, align 8
  %128 = or i64 %126, %127
  %129 = load i64, i64* %arraydecay2.i280.i, align 16
  %130 = or i64 %128, %129
  %131 = icmp eq i64 %130, 0
  br i1 %131, label %for.cond.i318.i, label %lor.lhs.false.i

for.cond.i318.i:                                  ; preds = %if.then
  %arrayidx.1.i316.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 1
  %132 = load i64, i64* %arrayidx.1.i316.i, align 8, !tbaa !3
  %cmp1.1.i317.i = icmp eq i64 %132, 0
  br i1 %cmp1.1.i317.i, label %for.cond.1.i322.i, label %lor.lhs.false.i

for.cond.1.i322.i:                                ; preds = %for.cond.i318.i
  %arrayidx.2.i320.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 2
  %133 = load i64, i64* %arrayidx.2.i320.i, align 16, !tbaa !3
  %cmp1.2.i321.i = icmp eq i64 %133, 0
  br i1 %cmp1.2.i321.i, label %for.cond.2.i325.i, label %lor.lhs.false.i

for.cond.2.i325.i:                                ; preds = %for.cond.1.i322.i
  %arrayidx.3.i323.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 3
  %134 = load i64, i64* %arrayidx.3.i323.i, align 8, !tbaa !3
  %cmp1.3.i324.i = icmp eq i64 %134, 0
  br i1 %cmp1.3.i324.i, label %for.cond.3.i328.i, label %lor.lhs.false.i

for.cond.3.i328.i:                                ; preds = %for.cond.2.i325.i
  %arrayidx.4.i326.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 4
  %135 = load i64, i64* %arrayidx.4.i326.i, align 16, !tbaa !3
  %cmp1.4.i327.i = icmp eq i64 %135, 0
  br i1 %cmp1.4.i327.i, label %for.cond.4.i331.i, label %lor.lhs.false.i

for.cond.4.i331.i:                                ; preds = %for.cond.3.i328.i
  %arrayidx.5.i329.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 5
  %136 = load i64, i64* %arrayidx.5.i329.i, align 8, !tbaa !3
  %cmp1.5.i330.i = icmp eq i64 %136, 0
  br i1 %cmp1.5.i330.i, label %for.cond.5.i334.i, label %lor.lhs.false.i

for.cond.5.i334.i:                                ; preds = %for.cond.4.i331.i
  %arrayidx.6.i332.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 6
  %137 = load i64, i64* %arrayidx.6.i332.i, align 16, !tbaa !3
  %cmp1.6.i333.i = icmp eq i64 %137, 0
  br i1 %cmp1.6.i333.i, label %for.cond.6.i337.i, label %lor.lhs.false.i

for.cond.6.i337.i:                                ; preds = %for.cond.5.i334.i
  %arrayidx.7.i335.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 7
  %138 = load i64, i64* %arrayidx.7.i335.i, align 8, !tbaa !3
  %cmp1.7.i336.i = icmp eq i64 %138, 0
  br i1 %cmp1.7.i336.i, label %for.cond.7.i340.i, label %lor.lhs.false.i

for.cond.7.i340.i:                                ; preds = %for.cond.6.i337.i
  %arrayidx.8.i338.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 8
  %139 = load i64, i64* %arrayidx.8.i338.i, align 16, !tbaa !3
  %cmp1.8.i339.i = icmp eq i64 %139, 0
  br i1 %cmp1.8.i339.i, label %is_felm_zero.exit345.i, label %lor.lhs.false.i

is_felm_zero.exit345.i:                           ; preds = %for.cond.7.i340.i
  %arrayidx.9.i341.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 9
  %140 = load i64, i64* %arrayidx.9.i341.i, align 8, !tbaa !3
  %cmp1.9.i342.i = icmp eq i64 %140, 0
  br i1 %cmp1.9.i342.i, label %cleanup.critedge, label %lor.lhs.false.i

lor.lhs.false.i:                                  ; preds = %is_felm_zero.exit345.i, %for.cond.7.i340.i, %for.cond.6.i337.i, %for.cond.5.i334.i, %for.cond.4.i331.i, %for.cond.3.i328.i, %for.cond.2.i325.i, %for.cond.1.i322.i, %for.cond.i318.i, %if.then
  %141 = load i64, i64* %107, align 16, !tbaa !3
  %142 = load i64, i64* %arrayidx2.1.i171.i, align 8
  %143 = or i64 %142, %141
  %144 = load i64, i64* %arrayidx2.2.i172.i, align 16
  %145 = or i64 %143, %144
  %146 = load i64, i64* %arrayidx2.3.i173.i, align 8
  %147 = or i64 %145, %146
  %148 = load i64, i64* %arrayidx2.4.i174.i, align 16
  %149 = or i64 %147, %148
  %150 = load i64, i64* %arrayidx2.5.i175.i, align 8
  %151 = or i64 %149, %150
  %152 = load i64, i64* %arrayidx2.6.i176.i, align 16
  %153 = or i64 %151, %152
  %154 = load i64, i64* %arrayidx2.7.i177.i, align 8
  %155 = or i64 %153, %154
  %156 = load i64, i64* %arrayidx2.8.i178.i, align 16
  %157 = or i64 %155, %156
  %158 = load i64, i64* %arrayidx2.9.i179.i, align 8
  %159 = or i64 %157, %158
  %160 = load i64, i64* %arraydecay2.i282.i, align 16
  %161 = or i64 %159, %160
  %162 = icmp eq i64 %161, 0
  br i1 %162, label %for.cond.i382.i, label %if.end.i

for.cond.i382.i:                                  ; preds = %lor.lhs.false.i
  %arrayidx.1.i380.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 1
  %163 = load i64, i64* %arrayidx.1.i380.i, align 8, !tbaa !3
  %cmp1.1.i381.i = icmp eq i64 %163, 0
  br i1 %cmp1.1.i381.i, label %for.cond.1.i386.i, label %if.end.i

for.cond.1.i386.i:                                ; preds = %for.cond.i382.i
  %arrayidx.2.i384.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 2
  %164 = load i64, i64* %arrayidx.2.i384.i, align 16, !tbaa !3
  %cmp1.2.i385.i = icmp eq i64 %164, 0
  br i1 %cmp1.2.i385.i, label %for.cond.2.i389.i, label %if.end.i

for.cond.2.i389.i:                                ; preds = %for.cond.1.i386.i
  %arrayidx.3.i387.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 3
  %165 = load i64, i64* %arrayidx.3.i387.i, align 8, !tbaa !3
  %cmp1.3.i388.i = icmp eq i64 %165, 0
  br i1 %cmp1.3.i388.i, label %for.cond.3.i392.i, label %if.end.i

for.cond.3.i392.i:                                ; preds = %for.cond.2.i389.i
  %arrayidx.4.i390.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 4
  %166 = load i64, i64* %arrayidx.4.i390.i, align 16, !tbaa !3
  %cmp1.4.i391.i = icmp eq i64 %166, 0
  br i1 %cmp1.4.i391.i, label %for.cond.4.i395.i, label %if.end.i

for.cond.4.i395.i:                                ; preds = %for.cond.3.i392.i
  %arrayidx.5.i393.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 5
  %167 = load i64, i64* %arrayidx.5.i393.i, align 8, !tbaa !3
  %cmp1.5.i394.i = icmp eq i64 %167, 0
  br i1 %cmp1.5.i394.i, label %for.cond.5.i398.i, label %if.end.i

for.cond.5.i398.i:                                ; preds = %for.cond.4.i395.i
  %arrayidx.6.i396.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 6
  %168 = load i64, i64* %arrayidx.6.i396.i, align 16, !tbaa !3
  %cmp1.6.i397.i = icmp eq i64 %168, 0
  br i1 %cmp1.6.i397.i, label %for.cond.6.i401.i, label %if.end.i

for.cond.6.i401.i:                                ; preds = %for.cond.5.i398.i
  %arrayidx.7.i399.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 7
  %169 = load i64, i64* %arrayidx.7.i399.i, align 8, !tbaa !3
  %cmp1.7.i400.i = icmp eq i64 %169, 0
  br i1 %cmp1.7.i400.i, label %for.cond.7.i404.i, label %if.end.i

for.cond.7.i404.i:                                ; preds = %for.cond.6.i401.i
  %arrayidx.8.i402.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 8
  %170 = load i64, i64* %arrayidx.8.i402.i, align 16, !tbaa !3
  %cmp1.8.i403.i = icmp eq i64 %170, 0
  br i1 %cmp1.8.i403.i, label %is_felm_zero.exit409.i, label %if.end.i

is_felm_zero.exit409.i:                           ; preds = %for.cond.7.i404.i
  %arrayidx.9.i405.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 9
  %171 = load i64, i64* %arrayidx.9.i405.i, align 8, !tbaa !3
  %cmp1.9.i406.i = icmp eq i64 %171, 0
  br i1 %cmp1.9.i406.i, label %cleanup.critedge460, label %if.end.i

if.end.i:                                         ; preds = %is_felm_zero.exit409.i, %for.cond.7.i404.i, %for.cond.6.i401.i, %for.cond.5.i398.i, %for.cond.4.i395.i, %for.cond.3.i392.i, %for.cond.2.i389.i, %for.cond.1.i386.i, %for.cond.i382.i, %lor.lhs.false.i
  %arraydecay55.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp1.i, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay3.i, [10 x i64]* nonnull %arraydecay13.i, [10 x i64]* nonnull %arraydecay55.i) #10
  %arraydecay62.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp2.i, i64 0, i64 0
  call void @fp2mul610_mont([10 x i64]* nonnull %arraydecay5.i, [10 x i64]* nonnull %arraydecay10.i290, [10 x i64]* nonnull %arraydecay62.i) #10
  %arraydecay.i413.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp1.i, i64 0, i64 0, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay.i413.i) #10
  %arraydecay2.i414.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp1.i, i64 0, i64 1, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay2.i414.i) #10
  %arraydecay.i415.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp2.i, i64 0, i64 0, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay.i415.i) #10
  %arraydecay2.i416.i = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %tmp2.i, i64 0, i64 1, i64 0
  call void @fpcorrection610(i64* nonnull %arraydecay2.i416.i) #10
  %call67.i = call i32 @memcmp(i8* nonnull %72, i8* nonnull %73, i64 154) #10
  %cmp.i = icmp eq i32 %call67.i, 0
  br i1 %cmp.i, label %cleanup.critedge461, label %if.end69.i

if.end69.i:                                       ; preds = %if.end.i
  call void @xTPL_fast(%struct.point_proj* nonnull %arraydecay2.i288, %struct.point_proj* nonnull %arraydecay2.i288, [10 x i64]* nonnull %arraydecay.i287) #10
  call void @xTPL_fast(%struct.point_proj* nonnull %arraydecay8.i289, %struct.point_proj* nonnull %arraydecay8.i289, [10 x i64]* nonnull %arraydecay.i287) #10
  call void @fpcorrection610(i64* nonnull %89) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i280.i) #10
  call void @fpcorrection610(i64* nonnull %107) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i282.i) #10
  %172 = load i64, i64* %89, align 16, !tbaa !3
  %173 = load i64, i64* %arrayidx2.1.i.i, align 8
  %174 = or i64 %173, %172
  %175 = load i64, i64* %arrayidx2.2.i.i, align 16
  %176 = or i64 %174, %175
  %177 = load i64, i64* %arrayidx2.3.i.i, align 8
  %178 = or i64 %176, %177
  %179 = load i64, i64* %arrayidx2.4.i.i, align 16
  %180 = or i64 %178, %179
  %181 = load i64, i64* %arrayidx2.5.i.i, align 8
  %182 = or i64 %180, %181
  %183 = load i64, i64* %arrayidx2.6.i.i, align 16
  %184 = or i64 %182, %183
  %185 = load i64, i64* %arrayidx2.7.i.i, align 8
  %186 = or i64 %184, %185
  %187 = load i64, i64* %arrayidx2.8.i.i, align 16
  %188 = or i64 %186, %187
  %189 = load i64, i64* %arrayidx2.9.i.i, align 8
  %190 = or i64 %188, %189
  %191 = load i64, i64* %arraydecay2.i280.i, align 16
  %192 = or i64 %190, %191
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %for.cond.i216.i, label %cleanup.critedge465

for.cond.i216.i:                                  ; preds = %if.end69.i
  %arrayidx.1.i214.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 1
  %194 = load i64, i64* %arrayidx.1.i214.i, align 8, !tbaa !3
  %cmp1.1.i215.i = icmp eq i64 %194, 0
  br i1 %cmp1.1.i215.i, label %for.cond.1.i220.i, label %cleanup.critedge473

for.cond.1.i220.i:                                ; preds = %for.cond.i216.i
  %arrayidx.2.i218.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 2
  %195 = load i64, i64* %arrayidx.2.i218.i, align 16, !tbaa !3
  %cmp1.2.i219.i = icmp eq i64 %195, 0
  br i1 %cmp1.2.i219.i, label %for.cond.2.i223.i, label %cleanup.critedge472

for.cond.2.i223.i:                                ; preds = %for.cond.1.i220.i
  %arrayidx.3.i221.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 3
  %196 = load i64, i64* %arrayidx.3.i221.i, align 8, !tbaa !3
  %cmp1.3.i222.i = icmp eq i64 %196, 0
  br i1 %cmp1.3.i222.i, label %for.cond.3.i226.i, label %cleanup.critedge471

for.cond.3.i226.i:                                ; preds = %for.cond.2.i223.i
  %arrayidx.4.i224.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 4
  %197 = load i64, i64* %arrayidx.4.i224.i, align 16, !tbaa !3
  %cmp1.4.i225.i = icmp eq i64 %197, 0
  br i1 %cmp1.4.i225.i, label %for.cond.4.i229.i, label %cleanup.critedge470

for.cond.4.i229.i:                                ; preds = %for.cond.3.i226.i
  %arrayidx.5.i227.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 5
  %198 = load i64, i64* %arrayidx.5.i227.i, align 8, !tbaa !3
  %cmp1.5.i228.i = icmp eq i64 %198, 0
  br i1 %cmp1.5.i228.i, label %for.cond.5.i232.i, label %cleanup.critedge469

for.cond.5.i232.i:                                ; preds = %for.cond.4.i229.i
  %arrayidx.6.i230.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 6
  %199 = load i64, i64* %arrayidx.6.i230.i, align 16, !tbaa !3
  %cmp1.6.i231.i = icmp eq i64 %199, 0
  br i1 %cmp1.6.i231.i, label %for.cond.6.i235.i, label %cleanup.critedge468

for.cond.6.i235.i:                                ; preds = %for.cond.5.i232.i
  %arrayidx.7.i233.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 7
  %200 = load i64, i64* %arrayidx.7.i233.i, align 8, !tbaa !3
  %cmp1.7.i234.i = icmp eq i64 %200, 0
  br i1 %cmp1.7.i234.i, label %for.cond.7.i238.i, label %cleanup.critedge467

for.cond.7.i238.i:                                ; preds = %for.cond.6.i235.i
  %arrayidx.8.i236.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 8
  %201 = load i64, i64* %arrayidx.8.i236.i, align 16, !tbaa !3
  %cmp1.8.i237.i = icmp eq i64 %201, 0
  br i1 %cmp1.8.i237.i, label %is_felm_zero.exit243.i, label %cleanup.critedge466

is_felm_zero.exit243.i:                           ; preds = %for.cond.7.i238.i
  %arrayidx.9.i239.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %P.i, i64 0, i64 0, i32 1, i64 1, i64 9
  %202 = load i64, i64* %arrayidx.9.i239.i, align 8, !tbaa !3
  %203 = load i64, i64* %107, align 16
  %204 = or i64 %203, %202
  %205 = load i64, i64* %arrayidx2.1.i171.i, align 8
  %206 = or i64 %204, %205
  %207 = load i64, i64* %arrayidx2.2.i172.i, align 16
  %208 = or i64 %206, %207
  %209 = load i64, i64* %arrayidx2.3.i173.i, align 8
  %210 = or i64 %208, %209
  %211 = load i64, i64* %arrayidx2.4.i174.i, align 16
  %212 = or i64 %210, %211
  %213 = load i64, i64* %arrayidx2.5.i175.i, align 8
  %214 = or i64 %212, %213
  %215 = load i64, i64* %arrayidx2.6.i176.i, align 16
  %216 = or i64 %214, %215
  %217 = load i64, i64* %arrayidx2.7.i177.i, align 8
  %218 = or i64 %216, %217
  %219 = load i64, i64* %arrayidx2.8.i178.i, align 16
  %220 = or i64 %218, %219
  %221 = load i64, i64* %arrayidx2.9.i179.i, align 8
  %222 = or i64 %220, %221
  %223 = load i64, i64* %arraydecay2.i282.i, align 16
  %224 = or i64 %222, %223
  %225 = icmp eq i64 %224, 0
  br i1 %225, label %for.cond.i.i, label %cleanup.critedge463

for.cond.i.i:                                     ; preds = %is_felm_zero.exit243.i
  %arrayidx.1.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 1
  %226 = load i64, i64* %arrayidx.1.i.i, align 8, !tbaa !3
  %cmp1.1.i.i = icmp eq i64 %226, 0
  br i1 %cmp1.1.i.i, label %for.cond.1.i.i, label %cleanup.critedge481

for.cond.1.i.i:                                   ; preds = %for.cond.i.i
  %arrayidx.2.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 2
  %227 = load i64, i64* %arrayidx.2.i.i, align 16, !tbaa !3
  %cmp1.2.i.i = icmp eq i64 %227, 0
  br i1 %cmp1.2.i.i, label %for.cond.2.i.i, label %cleanup.critedge480

for.cond.2.i.i:                                   ; preds = %for.cond.1.i.i
  %arrayidx.3.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 3
  %228 = load i64, i64* %arrayidx.3.i.i, align 8, !tbaa !3
  %cmp1.3.i.i = icmp eq i64 %228, 0
  br i1 %cmp1.3.i.i, label %for.cond.3.i.i, label %cleanup.critedge479

for.cond.3.i.i:                                   ; preds = %for.cond.2.i.i
  %arrayidx.4.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 4
  %229 = load i64, i64* %arrayidx.4.i.i, align 16, !tbaa !3
  %cmp1.4.i.i = icmp eq i64 %229, 0
  br i1 %cmp1.4.i.i, label %for.cond.4.i.i, label %cleanup.critedge478

for.cond.4.i.i:                                   ; preds = %for.cond.3.i.i
  %arrayidx.5.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 5
  %230 = load i64, i64* %arrayidx.5.i.i, align 8, !tbaa !3
  %cmp1.5.i.i = icmp eq i64 %230, 0
  br i1 %cmp1.5.i.i, label %for.cond.5.i.i, label %cleanup.critedge477

for.cond.5.i.i:                                   ; preds = %for.cond.4.i.i
  %arrayidx.6.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 6
  %231 = load i64, i64* %arrayidx.6.i.i, align 16, !tbaa !3
  %cmp1.6.i.i = icmp eq i64 %231, 0
  br i1 %cmp1.6.i.i, label %for.cond.6.i.i, label %cleanup.critedge476

for.cond.6.i.i:                                   ; preds = %for.cond.5.i.i
  %arrayidx.7.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 7
  %232 = load i64, i64* %arrayidx.7.i.i, align 8, !tbaa !3
  %cmp1.7.i.i = icmp eq i64 %232, 0
  br i1 %cmp1.7.i.i, label %for.cond.7.i.i, label %cleanup.critedge475

for.cond.7.i.i:                                   ; preds = %for.cond.6.i.i
  %arrayidx.8.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 8
  %233 = load i64, i64* %arrayidx.8.i.i, align 16, !tbaa !3
  %cmp1.8.i.i = icmp eq i64 %233, 0
  br i1 %cmp1.8.i.i, label %is_felm_zero.exit.i, label %cleanup.critedge474

is_felm_zero.exit.i:                              ; preds = %for.cond.7.i.i
  %arrayidx.9.i.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %Q.i, i64 0, i64 0, i32 1, i64 1, i64 9
  %234 = load i64, i64* %arrayidx.9.i.i, align 8, !tbaa !3
  %cmp1.9.i.i = icmp eq i64 %234, 0
  br i1 %cmp1.9.i.i, label %if.end110.i, label %cleanup.critedge462

if.end110.i:                                      ; preds = %is_felm_zero.exit.i
  %call113.i = call zeroext i8 @is_sqr_fp2([10 x i64]* nonnull %arraydecay17, i64* nonnull %arraydecay.i413.i) #10
  %tobool114.i = icmp eq i8 %call113.i, 0
  br i1 %tobool114.i, label %cleanup.critedge464, label %lor.lhs.false115.i

lor.lhs.false115.i:                               ; preds = %if.end110.i
  %call118.i = call zeroext i8 @is_sqr_fp2([10 x i64]* nonnull %arraydecay16, i64* nonnull %arraydecay.i413.i) #10
  %tobool119.i = icmp eq i8 %call118.i, 0
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br i1 %tobool119.i, label %cleanup, label %if.end28

if.end28:                                         ; preds = %lor.lhs.false115.i, %entry
  %arraydecay29 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyB, i64 0, i64 0
  %arrayidx.i291 = getelementptr inbounds [5 x i64], [5 x i64]* %SecretKeyB, i64 0, i64 4
  store i64 0, i64* %arrayidx.i291, align 16, !tbaa !3
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %9, i8* align 1 %PrivateKeyB, i64 38, i1 false)
  %arraydecay37 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0
  call fastcc void @LADDER3PT([10 x i64]* nonnull %arraydecay, [10 x i64]* nonnull %arraydecay2, [10 x i64]* nonnull %arraydecay5, i64* nonnull %arraydecay29, i32 1, %struct.point_proj* nonnull %arraydecay37, [10 x i64]* nonnull %arraydecay12)
  %arraydecay66 = getelementptr inbounds [3 x [2 x [10 x i64]]], [3 x [2 x [10 x i64]]]* %coeff, i64 0, i64 0
  %arrayidx.4.i.i300 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 4
  %arrayidx.8.i.i308 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 0, i64 8
  %arrayidx.2.i11.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 2
  %arrayidx.6.i19.i = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 0, i64 1, i64 6
  %arraydecay.i314 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 0
  %arrayidx.4.i.i322 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 4
  %arrayidx.8.i.i330 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 0, i64 8
  %arrayidx.2.i11.i338 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 2
  %arrayidx.6.i19.i346 = getelementptr inbounds [1 x %struct.point_proj], [1 x %struct.point_proj]* %R, i64 0, i64 0, i32 1, i64 1, i64 6
  %235 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %236 = bitcast i64* %arrayidx.4.i.i300 to <4 x i64>*
  %237 = bitcast i64* %arrayidx.8.i.i308 to <4 x i64>*
  %238 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %239 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %240 = bitcast i64* %arraydecay.i314 to <4 x i64>*
  %241 = bitcast i64* %arrayidx.4.i.i322 to <4 x i64>*
  %242 = bitcast i64* %arrayidx.8.i.i330 to <4 x i64>*
  %243 = bitcast i64* %arrayidx.2.i11.i338 to <4 x i64>*
  %244 = bitcast i64* %arrayidx.6.i19.i346 to <4 x i64>*
  %245 = bitcast [1 x %struct.point_proj]* %R to <4 x i64>*
  %246 = bitcast i64* %arrayidx.4.i.i300 to <4 x i64>*
  %247 = bitcast i64* %arrayidx.8.i.i308 to <4 x i64>*
  %248 = bitcast i64* %arrayidx.2.i11.i to <4 x i64>*
  %249 = bitcast i64* %arrayidx.6.i19.i to <4 x i64>*
  %250 = bitcast i64* %arraydecay.i314 to <4 x i64>*
  %251 = bitcast i64* %arrayidx.4.i.i322 to <4 x i64>*
  %252 = bitcast i64* %arrayidx.8.i.i330 to <4 x i64>*
  %253 = bitcast i64* %arrayidx.2.i11.i338 to <4 x i64>*
  %254 = bitcast i64* %arrayidx.6.i19.i346 to <4 x i64>*
  br label %while.cond.preheader

while.cond.preheader:                             ; preds = %for.end, %if.end28
  %ii.0492 = phi i32 [ 0, %if.end28 ], [ %ii.1.lcssa, %for.end ]
  %npts.0491 = phi i32 [ 0, %if.end28 ], [ %sub75, %for.end ]
  %index.0490 = phi i32 [ 0, %if.end28 ], [ %296, %for.end ]
  %row.0489 = phi i32 [ 1, %if.end28 ], [ %inc98, %for.end ]
  %sub = sub nuw nsw i32 192, %row.0489
  %cmp40482 = icmp ult i32 %index.0490, %sub
  br i1 %cmp40482, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond.preheader, %while.body
  %ii.1485 = phi i32 [ %inc56, %while.body ], [ %ii.0492, %while.cond.preheader ]
  %npts.1484 = phi i32 [ %inc, %while.body ], [ %npts.0491, %while.cond.preheader ]
  %index.1483 = phi i32 [ %add, %while.body ], [ %index.0490, %while.cond.preheader ]
  %idxprom = zext i32 %npts.1484 to i64
  %arraydecay2.i293 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 0
  %255 = load <4 x i64>, <4 x i64>* %235, align 16, !tbaa !3
  %256 = bitcast i64* %arraydecay2.i293 to <4 x i64>*
  store <4 x i64> %255, <4 x i64>* %256, align 16, !tbaa !3
  %arrayidx2.4.i.i301 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 4
  %257 = load <4 x i64>, <4 x i64>* %236, align 16, !tbaa !3
  %258 = bitcast i64* %arrayidx2.4.i.i301 to <4 x i64>*
  store <4 x i64> %257, <4 x i64>* %258, align 16, !tbaa !3
  %arrayidx2.8.i.i309 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 0, i64 8
  %259 = load <4 x i64>, <4 x i64>* %237, align 16, !tbaa !3
  %260 = bitcast i64* %arrayidx2.8.i.i309 to <4 x i64>*
  store <4 x i64> %259, <4 x i64>* %260, align 16, !tbaa !3
  %arrayidx2.2.i12.i = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 2
  %261 = load <4 x i64>, <4 x i64>* %238, align 16, !tbaa !3
  %262 = bitcast i64* %arrayidx2.2.i12.i to <4 x i64>*
  store <4 x i64> %261, <4 x i64>* %262, align 16, !tbaa !3
  %arrayidx2.6.i20.i = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 0, i64 1, i64 6
  %263 = load <4 x i64>, <4 x i64>* %239, align 16, !tbaa !3
  %264 = bitcast i64* %arrayidx2.6.i20.i to <4 x i64>*
  store <4 x i64> %263, <4 x i64>* %264, align 16, !tbaa !3
  %arraydecay2.i315 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 0
  %265 = load <4 x i64>, <4 x i64>* %240, align 16, !tbaa !3
  %266 = bitcast i64* %arraydecay2.i315 to <4 x i64>*
  store <4 x i64> %265, <4 x i64>* %266, align 16, !tbaa !3
  %arrayidx2.4.i.i323 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 4
  %267 = load <4 x i64>, <4 x i64>* %241, align 16, !tbaa !3
  %268 = bitcast i64* %arrayidx2.4.i.i323 to <4 x i64>*
  store <4 x i64> %267, <4 x i64>* %268, align 16, !tbaa !3
  %arrayidx2.8.i.i331 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 0, i64 8
  %269 = load <4 x i64>, <4 x i64>* %242, align 16, !tbaa !3
  %270 = bitcast i64* %arrayidx2.8.i.i331 to <4 x i64>*
  store <4 x i64> %269, <4 x i64>* %270, align 16, !tbaa !3
  %arrayidx2.2.i12.i339 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 2
  %271 = load <4 x i64>, <4 x i64>* %243, align 16, !tbaa !3
  %272 = bitcast i64* %arrayidx2.2.i12.i339 to <4 x i64>*
  store <4 x i64> %271, <4 x i64>* %272, align 16, !tbaa !3
  %arrayidx2.6.i20.i347 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom, i64 0, i32 1, i64 1, i64 6
  %273 = load <4 x i64>, <4 x i64>* %244, align 16, !tbaa !3
  %274 = bitcast i64* %arrayidx2.6.i20.i347 to <4 x i64>*
  store <4 x i64> %273, <4 x i64>* %274, align 16, !tbaa !3
  %inc = add i32 %npts.1484, 1
  %arrayidx55 = getelementptr inbounds [10 x i32], [10 x i32]* %pts_index, i64 0, i64 %idxprom
  store i32 %index.1483, i32* %arrayidx55, align 4, !tbaa !59
  %inc56 = add i32 %ii.1485, 1
  %idxprom57 = zext i32 %ii.1485 to i64
  %arrayidx58 = getelementptr inbounds [191 x i32], [191 x i32]* @strat_Bob, i64 0, i64 %idxprom57
  %275 = load i32, i32* %arrayidx58, align 4, !tbaa !59
  call void @xTPLe(%struct.point_proj* nonnull %arraydecay37, %struct.point_proj* nonnull %arraydecay37, [10 x i64]* nonnull %arraydecay16, [10 x i64]* nonnull %arraydecay17, i32 %275)
  %add = add i32 %275, %index.1483
  %cmp40 = icmp ult i32 %add, %sub
  br i1 %cmp40, label %while.body, label %while.end

while.end:                                        ; preds = %while.body, %while.cond.preheader
  %npts.1.lcssa = phi i32 [ %npts.0491, %while.cond.preheader ], [ %inc, %while.body ]
  %ii.1.lcssa = phi i32 [ %ii.0492, %while.cond.preheader ], [ %inc56, %while.body ]
  call void @get_3_isog(%struct.point_proj* nonnull %arraydecay37, [10 x i64]* nonnull %arraydecay16, [10 x i64]* nonnull %arraydecay17, [2 x [10 x i64]]* nonnull %arraydecay66)
  %cmp68487 = icmp eq i32 %npts.1.lcssa, 0
  br i1 %cmp68487, label %for.end, label %for.body69.preheader

for.body69.preheader:                             ; preds = %while.end
  %wide.trip.count = zext i32 %npts.1.lcssa to i64
  br label %for.body69

for.body69:                                       ; preds = %for.body69, %for.body69.preheader
  %indvars.iv = phi i64 [ 0, %for.body69.preheader ], [ %indvars.iv.next, %for.body69 ]
  %arraydecay72 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %indvars.iv, i64 0
  call void @eval_3_isog(%struct.point_proj* nonnull %arraydecay72, [2 x [10 x i64]]* nonnull %arraydecay66)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.end, label %for.body69

for.end:                                          ; preds = %for.body69, %while.end
  %sub75 = add i32 %npts.1.lcssa, -1
  %idxprom76 = zext i32 %sub75 to i64
  %arraydecay.i354 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 0, i64 0, i64 0
  %276 = bitcast i64* %arraydecay.i354 to <4 x i64>*
  %277 = load <4 x i64>, <4 x i64>* %276, align 16, !tbaa !3
  store <4 x i64> %277, <4 x i64>* %245, align 16, !tbaa !3
  %arrayidx.4.i.i362 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 0, i64 0, i64 4
  %278 = bitcast i64* %arrayidx.4.i.i362 to <4 x i64>*
  %279 = load <4 x i64>, <4 x i64>* %278, align 16, !tbaa !3
  store <4 x i64> %279, <4 x i64>* %246, align 16, !tbaa !3
  %arrayidx.8.i.i370 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 0, i64 0, i64 8
  %280 = bitcast i64* %arrayidx.8.i.i370 to <4 x i64>*
  %281 = load <4 x i64>, <4 x i64>* %280, align 16, !tbaa !3
  store <4 x i64> %281, <4 x i64>* %247, align 16, !tbaa !3
  %arrayidx.2.i11.i378 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 0, i64 1, i64 2
  %282 = bitcast i64* %arrayidx.2.i11.i378 to <4 x i64>*
  %283 = load <4 x i64>, <4 x i64>* %282, align 16, !tbaa !3
  store <4 x i64> %283, <4 x i64>* %248, align 16, !tbaa !3
  %arrayidx.6.i19.i386 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 0, i64 1, i64 6
  %284 = bitcast i64* %arrayidx.6.i19.i386 to <4 x i64>*
  %285 = load <4 x i64>, <4 x i64>* %284, align 16, !tbaa !3
  store <4 x i64> %285, <4 x i64>* %249, align 16, !tbaa !3
  %arraydecay.i394 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 1, i64 0, i64 0
  %286 = bitcast i64* %arraydecay.i394 to <4 x i64>*
  %287 = load <4 x i64>, <4 x i64>* %286, align 16, !tbaa !3
  store <4 x i64> %287, <4 x i64>* %250, align 16, !tbaa !3
  %arrayidx.4.i.i402 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 1, i64 0, i64 4
  %288 = bitcast i64* %arrayidx.4.i.i402 to <4 x i64>*
  %289 = load <4 x i64>, <4 x i64>* %288, align 16, !tbaa !3
  store <4 x i64> %289, <4 x i64>* %251, align 16, !tbaa !3
  %arrayidx.8.i.i410 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 1, i64 0, i64 8
  %290 = bitcast i64* %arrayidx.8.i.i410 to <4 x i64>*
  %291 = load <4 x i64>, <4 x i64>* %290, align 16, !tbaa !3
  store <4 x i64> %291, <4 x i64>* %252, align 16, !tbaa !3
  %arrayidx.2.i11.i418 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 1, i64 1, i64 2
  %292 = bitcast i64* %arrayidx.2.i11.i418 to <4 x i64>*
  %293 = load <4 x i64>, <4 x i64>* %292, align 16, !tbaa !3
  store <4 x i64> %293, <4 x i64>* %253, align 16, !tbaa !3
  %arrayidx.6.i19.i426 = getelementptr inbounds [10 x [1 x %struct.point_proj]], [10 x [1 x %struct.point_proj]]* %pts, i64 0, i64 %idxprom76, i64 0, i32 1, i64 1, i64 6
  %294 = bitcast i64* %arrayidx.6.i19.i426 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 16, !tbaa !3
  store <4 x i64> %295, <4 x i64>* %254, align 16, !tbaa !3
  %arrayidx95 = getelementptr inbounds [10 x i32], [10 x i32]* %pts_index, i64 0, i64 %idxprom76
  %296 = load i32, i32* %arrayidx95, align 4, !tbaa !59
  %inc98 = add nuw nsw i32 %row.0489, 1
  %exitcond493 = icmp eq i32 %inc98, 192
  br i1 %exitcond493, label %for.end99, label %while.cond.preheader

for.end99:                                        ; preds = %for.end
  call void @get_3_isog(%struct.point_proj* nonnull %arraydecay37, [10 x i64]* nonnull %arraydecay16, [10 x i64]* nonnull %arraydecay17, [2 x [10 x i64]]* nonnull %arraydecay66)
  call void @fpadd610(i64* nonnull %arraydecay4.i, i64* nonnull %arrayidx5.i, i64* nonnull %arraydecay.i172) #10
  call void @fpadd610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay6.i) #10
  call void @fpadd610(i64* nonnull %arraydecay.i172, i64* nonnull %arraydecay.i172, i64* nonnull %arraydecay.i172) #10
  call void @fpadd610(i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i, i64* nonnull %arraydecay6.i) #10
  call void @fpsub610(i64* nonnull %arraydecay4.i, i64* nonnull %arrayidx5.i, i64* nonnull %arraydecay4.i) #10
  call void @fpsub610(i64* nonnull %arraydecay10.i, i64* nonnull %arraydecay8.i, i64* nonnull %arraydecay10.i) #10
  %arraydecay115 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 0
  call void @j_inv([10 x i64]* nonnull %arraydecay12, [10 x i64]* nonnull %arraydecay17, [10 x i64]* nonnull %arraydecay115)
  %297 = bitcast [2 x [10 x i64]]* %A2.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %297) #10
  %arraydecay.i.i453 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 0, i64 0
  %arraydecay2.i.i454 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A2.i, i64 0, i64 0, i64 0
  %298 = bitcast [10 x i64]* %one.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %298) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %298, i8 0, i64 80, i1 false) #10
  %arrayidx.i.i.i = getelementptr inbounds [10 x i64], [10 x i64]* %one.i.i.i, i64 0, i64 0
  store i64 1, i64* %arrayidx.i.i.i, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay.i.i453, i64* nonnull %arrayidx.i.i.i, i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay2.i.i454) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @fpcorrection610(i64* nonnull %arraydecay2.i.i454) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %298) #10
  %arraydecay4.i.i456 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %jinv, i64 0, i64 1, i64 0
  %arraydecay6.i.i457 = getelementptr inbounds [2 x [10 x i64]], [2 x [10 x i64]]* %A2.i, i64 0, i64 1, i64 0
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %298) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %298, i8 0, i64 80, i1 false) #10
  store i64 1, i64* %arrayidx.i.i.i, align 16, !tbaa !3
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %11) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 0, i64 160, i1 false) #10
  call void @mp_mul(i64* nonnull %arraydecay4.i.i456, i64* nonnull %arrayidx.i.i.i, i64* nonnull %arraydecay.i.i.i.i, i32 10) #10
  call void @rdc_mont(i64* nonnull %arraydecay.i.i.i.i, i64* nonnull %arraydecay6.i.i457) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %11) #10
  call void @fpcorrection610(i64* nonnull %arraydecay6.i.i457) #10
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %298) #10
  %299 = call i64 @llvm.objectsize.i64.p0i8(i8* %SharedSecretB, i1 false, i1 true) #10
  %call.i.i458 = call i8* @__memcpy_chk(i8* %SharedSecretB, i8* nonnull %297, i64 77, i64 %299) #10
  %add.ptr.i459 = getelementptr inbounds i8, i8* %SharedSecretB, i64 77
  %300 = bitcast i64* %arraydecay6.i.i457 to i8*
  %301 = call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %add.ptr.i459, i1 false, i1 true) #10
  %call.i5.i = call i8* @__memcpy_chk(i8* nonnull %add.ptr.i459, i8* nonnull %300, i64 77, i64 %301) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %297) #10
  br label %cleanup

cleanup.critedge:                                 ; preds = %is_felm_zero.exit345.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge460:                              ; preds = %is_felm_zero.exit409.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge461:                              ; preds = %if.end.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge462:                              ; preds = %is_felm_zero.exit.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge463:                              ; preds = %is_felm_zero.exit243.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge464:                              ; preds = %if.end110.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge465:                              ; preds = %if.end69.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge466:                              ; preds = %for.cond.7.i238.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge467:                              ; preds = %for.cond.6.i235.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge468:                              ; preds = %for.cond.5.i232.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge469:                              ; preds = %for.cond.4.i229.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge470:                              ; preds = %for.cond.3.i226.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge471:                              ; preds = %for.cond.2.i223.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge472:                              ; preds = %for.cond.1.i220.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge473:                              ; preds = %for.cond.i216.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge474:                              ; preds = %for.cond.7.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge475:                              ; preds = %for.cond.6.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge476:                              ; preds = %for.cond.5.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge477:                              ; preds = %for.cond.4.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge478:                              ; preds = %for.cond.3.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge479:                              ; preds = %for.cond.2.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge480:                              ; preds = %for.cond.1.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup.critedge481:                              ; preds = %for.cond.i.i
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %73) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %72) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %71) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %70) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %69) #10
  br label %cleanup

cleanup:                                          ; preds = %cleanup.critedge481, %cleanup.critedge480, %cleanup.critedge479, %cleanup.critedge478, %cleanup.critedge477, %cleanup.critedge476, %cleanup.critedge475, %cleanup.critedge474, %cleanup.critedge473, %cleanup.critedge472, %cleanup.critedge471, %cleanup.critedge470, %cleanup.critedge469, %cleanup.critedge468, %cleanup.critedge467, %cleanup.critedge466, %cleanup.critedge465, %cleanup.critedge464, %cleanup.critedge463, %cleanup.critedge462, %cleanup.critedge461, %cleanup.critedge460, %cleanup.critedge, %lor.lhs.false115.i, %for.end99
  %retval.0 = phi i32 [ 0, %for.end99 ], [ 1, %lor.lhs.false115.i ], [ 1, %cleanup.critedge ], [ 1, %cleanup.critedge460 ], [ 1, %cleanup.critedge461 ], [ 1, %cleanup.critedge462 ], [ 1, %cleanup.critedge463 ], [ 1, %cleanup.critedge464 ], [ 1, %cleanup.critedge465 ], [ 1, %cleanup.critedge466 ], [ 1, %cleanup.critedge467 ], [ 1, %cleanup.critedge468 ], [ 1, %cleanup.critedge469 ], [ 1, %cleanup.critedge470 ], [ 1, %cleanup.critedge471 ], [ 1, %cleanup.critedge472 ], [ 1, %cleanup.critedge473 ], [ 1, %cleanup.critedge474 ], [ 1, %cleanup.critedge475 ], [ 1, %cleanup.critedge476 ], [ 1, %cleanup.critedge477 ], [ 1, %cleanup.critedge478 ], [ 1, %cleanup.critedge479 ], [ 1, %cleanup.critedge480 ], [ 1, %cleanup.critedge481 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %9) #10
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %7) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %6) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %5) #10
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 480, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 3200, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 320, i8* nonnull %0) #10
  ret i32 %retval.0
}

; Function Attrs: nounwind ssp uwtable
define i32 @EphemeralSecretAgreement_B_SIDHp610(i8* %PrivateKeyB, i8* %PublicKeyA, i8* %SharedSecretB) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @EphemeralSecretAgreement_B_extended(i8* %PrivateKeyB, i8* %PublicKeyA, i8* %SharedSecretB, i32 0)
  ret i32 %call
}

; Function Attrs: nounwind ssp uwtable
define i32 @crypto_kem_keypair_SIKEp610(i8* %pk, i8* %sk) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @randombytes(i8* %sk, i64 24) #10
  %cmp = icmp eq i32 %call, 0
  br i1 %cmp, label %lor.lhs.false, label %return

lor.lhs.false:                                    ; preds = %entry
  %add.ptr = getelementptr inbounds i8, i8* %sk, i64 24
  %call.i = tail call i32 @randombytes(i8* nonnull %add.ptr, i64 38) #10
  %cmp.i = icmp eq i32 %call.i, 0
  br i1 %cmp.i, label %if.end, label %return

if.end:                                           ; preds = %lor.lhs.false
  %call4 = tail call i32 @EphemeralKeyGeneration_B_SIDHp610(i8* nonnull %add.ptr, i8* %pk)
  %arrayidx = getelementptr inbounds i8, i8* %sk, i64 62
  %0 = tail call i64 @llvm.objectsize.i64.p0i8(i8* nonnull %arrayidx, i1 false, i1 true)
  %call6 = tail call i8* @__memcpy_chk(i8* nonnull %arrayidx, i8* %pk, i64 462, i64 %0) #10
  br label %return

return:                                           ; preds = %entry, %lor.lhs.false, %if.end
  %retval.0 = phi i32 [ 0, %if.end ], [ 1, %lor.lhs.false ], [ 1, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind
declare i8* @__memcpy_chk(i8*, i8*, i64, i64) local_unnamed_addr #8

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.objectsize.i64.p0i8(i8*, i1, i1) #9

; Function Attrs: nounwind ssp uwtable
define i32 @crypto_kem_enc_SIKEp610(i8* %ct, i8* %ss, i8* %pk) local_unnamed_addr #4 {
entry:
  %ephemeralsk = alloca [39 x i8], align 16
  %jinvariant = alloca [154 x i8], align 16
  %h = alloca [24 x i8], align 16
  %temp = alloca [510 x i8], align 16
  %0 = getelementptr inbounds [39 x i8], [39 x i8]* %ephemeralsk, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 39, i8* nonnull %0) #10
  %1 = getelementptr inbounds [154 x i8], [154 x i8]* %jinvariant, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 154, i8* nonnull %1) #10
  %2 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %2) #10
  %3 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 510, i8* nonnull %3) #10
  %call = call i32 @randombytes(i8* nonnull %3, i64 24) #10
  %cmp = icmp eq i32 %call, 0
  br i1 %cmp, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %arrayidx = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 24
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %arrayidx, i8* align 1 %pk, i64 462, i1 false)
  call void @shake256(i8* nonnull %0, i64 39, i8* nonnull %3, i64 486) #10
  %arrayidx3 = getelementptr inbounds [39 x i8], [39 x i8]* %ephemeralsk, i64 0, i64 38
  %4 = load i8, i8* %arrayidx3, align 2, !tbaa !7
  %5 = and i8 %4, 1
  store i8 %5, i8* %arrayidx3, align 2, !tbaa !7
  %call6 = call i32 @EphemeralKeyGeneration_A_SIDHp610(i8* nonnull %0, i8* %ct)
  %call9 = call i32 @EphemeralSecretAgreement_A_SIDHp610(i8* nonnull %0, i8* %pk, i8* nonnull %1)
  call void @shake256(i8* nonnull %2, i64 24, i8* nonnull %1, i64 154) #10
  %arrayidx21 = getelementptr inbounds i8, i8* %ct, i64 462
  %6 = bitcast [510 x i8]* %temp to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 16, !tbaa !7
  %8 = bitcast [24 x i8]* %h to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 16, !tbaa !7
  %10 = xor <16 x i8> %9, %7
  %11 = bitcast i8* %arrayidx21 to <16 x i8>*
  store <16 x i8> %10, <16 x i8>* %11, align 1, !tbaa !7
  %arrayidx14.16 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 16
  %12 = load i8, i8* %arrayidx14.16, align 16, !tbaa !7
  %arrayidx17.16 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 16
  %13 = load i8, i8* %arrayidx17.16, align 16, !tbaa !7
  %xor35.16 = xor i8 %13, %12
  %arrayidx21.16 = getelementptr inbounds i8, i8* %ct, i64 478
  store i8 %xor35.16, i8* %arrayidx21.16, align 1, !tbaa !7
  %arrayidx14.17 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 17
  %14 = load i8, i8* %arrayidx14.17, align 1, !tbaa !7
  %arrayidx17.17 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 17
  %15 = load i8, i8* %arrayidx17.17, align 1, !tbaa !7
  %xor35.17 = xor i8 %15, %14
  %arrayidx21.17 = getelementptr inbounds i8, i8* %ct, i64 479
  store i8 %xor35.17, i8* %arrayidx21.17, align 1, !tbaa !7
  %arrayidx14.18 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 18
  %16 = load i8, i8* %arrayidx14.18, align 2, !tbaa !7
  %arrayidx17.18 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 18
  %17 = load i8, i8* %arrayidx17.18, align 2, !tbaa !7
  %xor35.18 = xor i8 %17, %16
  %arrayidx21.18 = getelementptr inbounds i8, i8* %ct, i64 480
  store i8 %xor35.18, i8* %arrayidx21.18, align 1, !tbaa !7
  %arrayidx14.19 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 19
  %18 = load i8, i8* %arrayidx14.19, align 1, !tbaa !7
  %arrayidx17.19 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 19
  %19 = load i8, i8* %arrayidx17.19, align 1, !tbaa !7
  %xor35.19 = xor i8 %19, %18
  %arrayidx21.19 = getelementptr inbounds i8, i8* %ct, i64 481
  store i8 %xor35.19, i8* %arrayidx21.19, align 1, !tbaa !7
  %arrayidx14.20 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 20
  %20 = load i8, i8* %arrayidx14.20, align 4, !tbaa !7
  %arrayidx17.20 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 20
  %21 = load i8, i8* %arrayidx17.20, align 4, !tbaa !7
  %xor35.20 = xor i8 %21, %20
  %arrayidx21.20 = getelementptr inbounds i8, i8* %ct, i64 482
  store i8 %xor35.20, i8* %arrayidx21.20, align 1, !tbaa !7
  %arrayidx14.21 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 21
  %22 = load i8, i8* %arrayidx14.21, align 1, !tbaa !7
  %arrayidx17.21 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 21
  %23 = load i8, i8* %arrayidx17.21, align 1, !tbaa !7
  %xor35.21 = xor i8 %23, %22
  %arrayidx21.21 = getelementptr inbounds i8, i8* %ct, i64 483
  store i8 %xor35.21, i8* %arrayidx21.21, align 1, !tbaa !7
  %arrayidx14.22 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 22
  %24 = load i8, i8* %arrayidx14.22, align 2, !tbaa !7
  %arrayidx17.22 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 22
  %25 = load i8, i8* %arrayidx17.22, align 2, !tbaa !7
  %xor35.22 = xor i8 %25, %24
  %arrayidx21.22 = getelementptr inbounds i8, i8* %ct, i64 484
  store i8 %xor35.22, i8* %arrayidx21.22, align 1, !tbaa !7
  %arrayidx14.23 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 23
  %26 = load i8, i8* %arrayidx14.23, align 1, !tbaa !7
  %arrayidx17.23 = getelementptr inbounds [24 x i8], [24 x i8]* %h, i64 0, i64 23
  %27 = load i8, i8* %arrayidx17.23, align 1, !tbaa !7
  %xor35.23 = xor i8 %27, %26
  %arrayidx21.23 = getelementptr inbounds i8, i8* %ct, i64 485
  store i8 %xor35.23, i8* %arrayidx21.23, align 1, !tbaa !7
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %arrayidx, i8* align 1 %ct, i64 486, i1 false)
  call void @shake256(i8* %ss, i64 24, i8* nonnull %3, i64 510) #10
  br label %cleanup

cleanup:                                          ; preds = %entry, %if.end
  %retval.0 = phi i32 [ 0, %if.end ], [ 1, %entry ]
  call void @llvm.lifetime.end.p0i8(i64 510, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 154, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 39, i8* nonnull %0) #10
  ret i32 %retval.0
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1) #1

declare void @shake256(i8*, i64, i8*, i64) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define i32 @crypto_kem_dec_SIKEp610(i8* %ss, i8* %ct, i8* %sk) local_unnamed_addr #4 {
entry:
  %ephemeralsk_ = alloca [39 x i8], align 16
  %jinvariant_ = alloca [154 x i8], align 16
  %h_ = alloca [24 x i8], align 16
  %c0_ = alloca [462 x i8], align 16
  %temp = alloca [510 x i8], align 16
  %0 = getelementptr inbounds [39 x i8], [39 x i8]* %ephemeralsk_, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 39, i8* nonnull %0) #10
  %1 = getelementptr inbounds [154 x i8], [154 x i8]* %jinvariant_, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 154, i8* nonnull %1) #10
  %2 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %2) #10
  %3 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 462, i8* nonnull %3) #10
  %4 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 510, i8* nonnull %4) #10
  %add.ptr = getelementptr inbounds i8, i8* %sk, i64 24
  %call = call i32 @EphemeralSecretAgreement_B_extended(i8* nonnull %add.ptr, i8* %ct, i8* nonnull %1, i32 1)
  %tobool = icmp eq i32 %call, 0
  br i1 %tobool, label %if.end, label %entry.Hashing_crit_edge

entry.Hashing_crit_edge:                          ; preds = %entry
  %.pre = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 1
  %.pre43 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 2
  %.pre44 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 3
  %.pre45 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 4
  %.pre46 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 5
  %.pre47 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 6
  %.pre48 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 7
  %.pre49 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 8
  %.pre50 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 9
  %.pre51 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 10
  %.pre52 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 11
  %.pre53 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 12
  %.pre54 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 13
  %.pre55 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 14
  %.pre56 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 15
  %.pre57 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 16
  %.pre58 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 17
  %.pre59 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 18
  %.pre60 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 19
  %.pre61 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 20
  %.pre62 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 21
  %.pre63 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 22
  %.pre64 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 23
  %.pre65 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 24
  br label %Hashing

if.end:                                           ; preds = %entry
  call void @shake256(i8* nonnull %2, i64 24, i8* nonnull %1, i64 154) #10
  %arrayidx = getelementptr inbounds i8, i8* %ct, i64 462
  %arrayidx9.1 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 1
  %arrayidx9.2 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 2
  %arrayidx9.3 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 3
  %arrayidx9.4 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 4
  %arrayidx9.5 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 5
  %arrayidx9.6 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 6
  %arrayidx9.7 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 7
  %arrayidx9.8 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 8
  %arrayidx9.9 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 9
  %arrayidx9.10 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 10
  %arrayidx9.11 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 11
  %arrayidx9.12 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 12
  %arrayidx9.13 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 13
  %arrayidx9.14 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 14
  %5 = bitcast i8* %arrayidx to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1, !tbaa !7
  %7 = bitcast [24 x i8]* %h_ to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 16, !tbaa !7
  %9 = xor <16 x i8> %8, %6
  %arrayidx9.15 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 15
  %10 = bitcast [510 x i8]* %temp to <16 x i8>*
  store <16 x i8> %9, <16 x i8>* %10, align 16, !tbaa !7
  %arrayidx.16 = getelementptr inbounds i8, i8* %ct, i64 478
  %11 = load i8, i8* %arrayidx.16, align 1, !tbaa !7
  %arrayidx5.16 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 16
  %12 = load i8, i8* %arrayidx5.16, align 16, !tbaa !7
  %xor35.16 = xor i8 %12, %11
  %arrayidx9.16 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 16
  store i8 %xor35.16, i8* %arrayidx9.16, align 16, !tbaa !7
  %arrayidx.17 = getelementptr inbounds i8, i8* %ct, i64 479
  %13 = load i8, i8* %arrayidx.17, align 1, !tbaa !7
  %arrayidx5.17 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 17
  %14 = load i8, i8* %arrayidx5.17, align 1, !tbaa !7
  %xor35.17 = xor i8 %14, %13
  %arrayidx9.17 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 17
  store i8 %xor35.17, i8* %arrayidx9.17, align 1, !tbaa !7
  %arrayidx.18 = getelementptr inbounds i8, i8* %ct, i64 480
  %15 = load i8, i8* %arrayidx.18, align 1, !tbaa !7
  %arrayidx5.18 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 18
  %16 = load i8, i8* %arrayidx5.18, align 2, !tbaa !7
  %xor35.18 = xor i8 %16, %15
  %arrayidx9.18 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 18
  store i8 %xor35.18, i8* %arrayidx9.18, align 2, !tbaa !7
  %arrayidx.19 = getelementptr inbounds i8, i8* %ct, i64 481
  %17 = load i8, i8* %arrayidx.19, align 1, !tbaa !7
  %arrayidx5.19 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 19
  %18 = load i8, i8* %arrayidx5.19, align 1, !tbaa !7
  %xor35.19 = xor i8 %18, %17
  %arrayidx9.19 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 19
  store i8 %xor35.19, i8* %arrayidx9.19, align 1, !tbaa !7
  %arrayidx.20 = getelementptr inbounds i8, i8* %ct, i64 482
  %19 = load i8, i8* %arrayidx.20, align 1, !tbaa !7
  %arrayidx5.20 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 20
  %20 = load i8, i8* %arrayidx5.20, align 4, !tbaa !7
  %xor35.20 = xor i8 %20, %19
  %arrayidx9.20 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 20
  store i8 %xor35.20, i8* %arrayidx9.20, align 4, !tbaa !7
  %arrayidx.21 = getelementptr inbounds i8, i8* %ct, i64 483
  %21 = load i8, i8* %arrayidx.21, align 1, !tbaa !7
  %arrayidx5.21 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 21
  %22 = load i8, i8* %arrayidx5.21, align 1, !tbaa !7
  %xor35.21 = xor i8 %22, %21
  %arrayidx9.21 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 21
  store i8 %xor35.21, i8* %arrayidx9.21, align 1, !tbaa !7
  %arrayidx.22 = getelementptr inbounds i8, i8* %ct, i64 484
  %23 = load i8, i8* %arrayidx.22, align 1, !tbaa !7
  %arrayidx5.22 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 22
  %24 = load i8, i8* %arrayidx5.22, align 2, !tbaa !7
  %xor35.22 = xor i8 %24, %23
  %arrayidx9.22 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 22
  store i8 %xor35.22, i8* %arrayidx9.22, align 2, !tbaa !7
  %arrayidx.23 = getelementptr inbounds i8, i8* %ct, i64 485
  %25 = load i8, i8* %arrayidx.23, align 1, !tbaa !7
  %arrayidx5.23 = getelementptr inbounds [24 x i8], [24 x i8]* %h_, i64 0, i64 23
  %26 = load i8, i8* %arrayidx5.23, align 1, !tbaa !7
  %xor35.23 = xor i8 %26, %25
  %arrayidx9.23 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 23
  store i8 %xor35.23, i8* %arrayidx9.23, align 1, !tbaa !7
  %arrayidx10 = getelementptr inbounds [510 x i8], [510 x i8]* %temp, i64 0, i64 24
  %arrayidx11 = getelementptr inbounds i8, i8* %sk, i64 62
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %arrayidx10, i8* nonnull align 1 %arrayidx11, i64 462, i1 false)
  call void @shake256(i8* nonnull %0, i64 39, i8* nonnull %4, i64 486) #10
  %arrayidx14 = getelementptr inbounds [39 x i8], [39 x i8]* %ephemeralsk_, i64 0, i64 38
  %27 = load i8, i8* %arrayidx14, align 2, !tbaa !7
  %28 = and i8 %27, 1
  store i8 %28, i8* %arrayidx14, align 2, !tbaa !7
  %call19 = call i32 @EphemeralKeyGeneration_A_SIDHp610(i8* nonnull %0, i8* nonnull %3)
  %29 = bitcast [462 x i8]* %c0_ to <8 x i8>*
  %wide.load = load <8 x i8>, <8 x i8>* %29, align 16, !tbaa !7
  %30 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 8
  %31 = bitcast i8* %30 to <8 x i8>*
  %wide.load72 = load <8 x i8>, <8 x i8>* %31, align 8, !tbaa !7
  %32 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 16
  %33 = bitcast i8* %32 to <8 x i8>*
  %wide.load73 = load <8 x i8>, <8 x i8>* %33, align 16, !tbaa !7
  %34 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 24
  %35 = bitcast i8* %34 to <8 x i8>*
  %wide.load74 = load <8 x i8>, <8 x i8>* %35, align 8, !tbaa !7
  %36 = bitcast i8* %ct to <8 x i8>*
  %wide.load75 = load <8 x i8>, <8 x i8>* %36, align 1, !tbaa !7
  %37 = getelementptr inbounds i8, i8* %ct, i64 8
  %38 = bitcast i8* %37 to <8 x i8>*
  %wide.load76 = load <8 x i8>, <8 x i8>* %38, align 1, !tbaa !7
  %39 = getelementptr inbounds i8, i8* %ct, i64 16
  %40 = bitcast i8* %39 to <8 x i8>*
  %wide.load77 = load <8 x i8>, <8 x i8>* %40, align 1, !tbaa !7
  %41 = getelementptr inbounds i8, i8* %ct, i64 24
  %42 = bitcast i8* %41 to <8 x i8>*
  %wide.load78 = load <8 x i8>, <8 x i8>* %42, align 1, !tbaa !7
  %43 = xor <8 x i8> %wide.load75, %wide.load
  %44 = xor <8 x i8> %wide.load76, %wide.load72
  %45 = xor <8 x i8> %wide.load77, %wide.load73
  %46 = xor <8 x i8> %wide.load78, %wide.load74
  %47 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 32
  %48 = bitcast i8* %47 to <8 x i8>*
  %wide.load.1 = load <8 x i8>, <8 x i8>* %48, align 16, !tbaa !7
  %49 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 40
  %50 = bitcast i8* %49 to <8 x i8>*
  %wide.load72.1 = load <8 x i8>, <8 x i8>* %50, align 8, !tbaa !7
  %51 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 48
  %52 = bitcast i8* %51 to <8 x i8>*
  %wide.load73.1 = load <8 x i8>, <8 x i8>* %52, align 16, !tbaa !7
  %53 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 56
  %54 = bitcast i8* %53 to <8 x i8>*
  %wide.load74.1 = load <8 x i8>, <8 x i8>* %54, align 8, !tbaa !7
  %55 = getelementptr inbounds i8, i8* %ct, i64 32
  %56 = bitcast i8* %55 to <8 x i8>*
  %wide.load75.1 = load <8 x i8>, <8 x i8>* %56, align 1, !tbaa !7
  %57 = getelementptr inbounds i8, i8* %ct, i64 40
  %58 = bitcast i8* %57 to <8 x i8>*
  %wide.load76.1 = load <8 x i8>, <8 x i8>* %58, align 1, !tbaa !7
  %59 = getelementptr inbounds i8, i8* %ct, i64 48
  %60 = bitcast i8* %59 to <8 x i8>*
  %wide.load77.1 = load <8 x i8>, <8 x i8>* %60, align 1, !tbaa !7
  %61 = getelementptr inbounds i8, i8* %ct, i64 56
  %62 = bitcast i8* %61 to <8 x i8>*
  %wide.load78.1 = load <8 x i8>, <8 x i8>* %62, align 1, !tbaa !7
  %63 = xor <8 x i8> %wide.load75.1, %wide.load.1
  %64 = xor <8 x i8> %wide.load76.1, %wide.load72.1
  %65 = xor <8 x i8> %wide.load77.1, %wide.load73.1
  %66 = xor <8 x i8> %wide.load78.1, %wide.load74.1
  %67 = or <8 x i8> %43, %63
  %68 = or <8 x i8> %44, %64
  %69 = or <8 x i8> %45, %65
  %70 = or <8 x i8> %46, %66
  %71 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 64
  %72 = bitcast i8* %71 to <8 x i8>*
  %wide.load.2 = load <8 x i8>, <8 x i8>* %72, align 16, !tbaa !7
  %73 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 72
  %74 = bitcast i8* %73 to <8 x i8>*
  %wide.load72.2 = load <8 x i8>, <8 x i8>* %74, align 8, !tbaa !7
  %75 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 80
  %76 = bitcast i8* %75 to <8 x i8>*
  %wide.load73.2 = load <8 x i8>, <8 x i8>* %76, align 16, !tbaa !7
  %77 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 88
  %78 = bitcast i8* %77 to <8 x i8>*
  %wide.load74.2 = load <8 x i8>, <8 x i8>* %78, align 8, !tbaa !7
  %79 = getelementptr inbounds i8, i8* %ct, i64 64
  %80 = bitcast i8* %79 to <8 x i8>*
  %wide.load75.2 = load <8 x i8>, <8 x i8>* %80, align 1, !tbaa !7
  %81 = getelementptr inbounds i8, i8* %ct, i64 72
  %82 = bitcast i8* %81 to <8 x i8>*
  %wide.load76.2 = load <8 x i8>, <8 x i8>* %82, align 1, !tbaa !7
  %83 = getelementptr inbounds i8, i8* %ct, i64 80
  %84 = bitcast i8* %83 to <8 x i8>*
  %wide.load77.2 = load <8 x i8>, <8 x i8>* %84, align 1, !tbaa !7
  %85 = getelementptr inbounds i8, i8* %ct, i64 88
  %86 = bitcast i8* %85 to <8 x i8>*
  %wide.load78.2 = load <8 x i8>, <8 x i8>* %86, align 1, !tbaa !7
  %87 = xor <8 x i8> %wide.load75.2, %wide.load.2
  %88 = xor <8 x i8> %wide.load76.2, %wide.load72.2
  %89 = xor <8 x i8> %wide.load77.2, %wide.load73.2
  %90 = xor <8 x i8> %wide.load78.2, %wide.load74.2
  %91 = or <8 x i8> %67, %87
  %92 = or <8 x i8> %68, %88
  %93 = or <8 x i8> %69, %89
  %94 = or <8 x i8> %70, %90
  %95 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 96
  %96 = bitcast i8* %95 to <8 x i8>*
  %wide.load.3 = load <8 x i8>, <8 x i8>* %96, align 16, !tbaa !7
  %97 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 104
  %98 = bitcast i8* %97 to <8 x i8>*
  %wide.load72.3 = load <8 x i8>, <8 x i8>* %98, align 8, !tbaa !7
  %99 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 112
  %100 = bitcast i8* %99 to <8 x i8>*
  %wide.load73.3 = load <8 x i8>, <8 x i8>* %100, align 16, !tbaa !7
  %101 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 120
  %102 = bitcast i8* %101 to <8 x i8>*
  %wide.load74.3 = load <8 x i8>, <8 x i8>* %102, align 8, !tbaa !7
  %103 = getelementptr inbounds i8, i8* %ct, i64 96
  %104 = bitcast i8* %103 to <8 x i8>*
  %wide.load75.3 = load <8 x i8>, <8 x i8>* %104, align 1, !tbaa !7
  %105 = getelementptr inbounds i8, i8* %ct, i64 104
  %106 = bitcast i8* %105 to <8 x i8>*
  %wide.load76.3 = load <8 x i8>, <8 x i8>* %106, align 1, !tbaa !7
  %107 = getelementptr inbounds i8, i8* %ct, i64 112
  %108 = bitcast i8* %107 to <8 x i8>*
  %wide.load77.3 = load <8 x i8>, <8 x i8>* %108, align 1, !tbaa !7
  %109 = getelementptr inbounds i8, i8* %ct, i64 120
  %110 = bitcast i8* %109 to <8 x i8>*
  %wide.load78.3 = load <8 x i8>, <8 x i8>* %110, align 1, !tbaa !7
  %111 = xor <8 x i8> %wide.load75.3, %wide.load.3
  %112 = xor <8 x i8> %wide.load76.3, %wide.load72.3
  %113 = xor <8 x i8> %wide.load77.3, %wide.load73.3
  %114 = xor <8 x i8> %wide.load78.3, %wide.load74.3
  %115 = or <8 x i8> %91, %111
  %116 = or <8 x i8> %92, %112
  %117 = or <8 x i8> %93, %113
  %118 = or <8 x i8> %94, %114
  %119 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 128
  %120 = bitcast i8* %119 to <8 x i8>*
  %wide.load.4 = load <8 x i8>, <8 x i8>* %120, align 16, !tbaa !7
  %121 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 136
  %122 = bitcast i8* %121 to <8 x i8>*
  %wide.load72.4 = load <8 x i8>, <8 x i8>* %122, align 8, !tbaa !7
  %123 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 144
  %124 = bitcast i8* %123 to <8 x i8>*
  %wide.load73.4 = load <8 x i8>, <8 x i8>* %124, align 16, !tbaa !7
  %125 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 152
  %126 = bitcast i8* %125 to <8 x i8>*
  %wide.load74.4 = load <8 x i8>, <8 x i8>* %126, align 8, !tbaa !7
  %127 = getelementptr inbounds i8, i8* %ct, i64 128
  %128 = bitcast i8* %127 to <8 x i8>*
  %wide.load75.4 = load <8 x i8>, <8 x i8>* %128, align 1, !tbaa !7
  %129 = getelementptr inbounds i8, i8* %ct, i64 136
  %130 = bitcast i8* %129 to <8 x i8>*
  %wide.load76.4 = load <8 x i8>, <8 x i8>* %130, align 1, !tbaa !7
  %131 = getelementptr inbounds i8, i8* %ct, i64 144
  %132 = bitcast i8* %131 to <8 x i8>*
  %wide.load77.4 = load <8 x i8>, <8 x i8>* %132, align 1, !tbaa !7
  %133 = getelementptr inbounds i8, i8* %ct, i64 152
  %134 = bitcast i8* %133 to <8 x i8>*
  %wide.load78.4 = load <8 x i8>, <8 x i8>* %134, align 1, !tbaa !7
  %135 = xor <8 x i8> %wide.load75.4, %wide.load.4
  %136 = xor <8 x i8> %wide.load76.4, %wide.load72.4
  %137 = xor <8 x i8> %wide.load77.4, %wide.load73.4
  %138 = xor <8 x i8> %wide.load78.4, %wide.load74.4
  %139 = or <8 x i8> %115, %135
  %140 = or <8 x i8> %116, %136
  %141 = or <8 x i8> %117, %137
  %142 = or <8 x i8> %118, %138
  %143 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 160
  %144 = bitcast i8* %143 to <8 x i8>*
  %wide.load.5 = load <8 x i8>, <8 x i8>* %144, align 16, !tbaa !7
  %145 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 168
  %146 = bitcast i8* %145 to <8 x i8>*
  %wide.load72.5 = load <8 x i8>, <8 x i8>* %146, align 8, !tbaa !7
  %147 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 176
  %148 = bitcast i8* %147 to <8 x i8>*
  %wide.load73.5 = load <8 x i8>, <8 x i8>* %148, align 16, !tbaa !7
  %149 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 184
  %150 = bitcast i8* %149 to <8 x i8>*
  %wide.load74.5 = load <8 x i8>, <8 x i8>* %150, align 8, !tbaa !7
  %151 = getelementptr inbounds i8, i8* %ct, i64 160
  %152 = bitcast i8* %151 to <8 x i8>*
  %wide.load75.5 = load <8 x i8>, <8 x i8>* %152, align 1, !tbaa !7
  %153 = getelementptr inbounds i8, i8* %ct, i64 168
  %154 = bitcast i8* %153 to <8 x i8>*
  %wide.load76.5 = load <8 x i8>, <8 x i8>* %154, align 1, !tbaa !7
  %155 = getelementptr inbounds i8, i8* %ct, i64 176
  %156 = bitcast i8* %155 to <8 x i8>*
  %wide.load77.5 = load <8 x i8>, <8 x i8>* %156, align 1, !tbaa !7
  %157 = getelementptr inbounds i8, i8* %ct, i64 184
  %158 = bitcast i8* %157 to <8 x i8>*
  %wide.load78.5 = load <8 x i8>, <8 x i8>* %158, align 1, !tbaa !7
  %159 = xor <8 x i8> %wide.load75.5, %wide.load.5
  %160 = xor <8 x i8> %wide.load76.5, %wide.load72.5
  %161 = xor <8 x i8> %wide.load77.5, %wide.load73.5
  %162 = xor <8 x i8> %wide.load78.5, %wide.load74.5
  %163 = or <8 x i8> %139, %159
  %164 = or <8 x i8> %140, %160
  %165 = or <8 x i8> %141, %161
  %166 = or <8 x i8> %142, %162
  %167 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 192
  %168 = bitcast i8* %167 to <8 x i8>*
  %wide.load.6 = load <8 x i8>, <8 x i8>* %168, align 16, !tbaa !7
  %169 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 200
  %170 = bitcast i8* %169 to <8 x i8>*
  %wide.load72.6 = load <8 x i8>, <8 x i8>* %170, align 8, !tbaa !7
  %171 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 208
  %172 = bitcast i8* %171 to <8 x i8>*
  %wide.load73.6 = load <8 x i8>, <8 x i8>* %172, align 16, !tbaa !7
  %173 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 216
  %174 = bitcast i8* %173 to <8 x i8>*
  %wide.load74.6 = load <8 x i8>, <8 x i8>* %174, align 8, !tbaa !7
  %175 = getelementptr inbounds i8, i8* %ct, i64 192
  %176 = bitcast i8* %175 to <8 x i8>*
  %wide.load75.6 = load <8 x i8>, <8 x i8>* %176, align 1, !tbaa !7
  %177 = getelementptr inbounds i8, i8* %ct, i64 200
  %178 = bitcast i8* %177 to <8 x i8>*
  %wide.load76.6 = load <8 x i8>, <8 x i8>* %178, align 1, !tbaa !7
  %179 = getelementptr inbounds i8, i8* %ct, i64 208
  %180 = bitcast i8* %179 to <8 x i8>*
  %wide.load77.6 = load <8 x i8>, <8 x i8>* %180, align 1, !tbaa !7
  %181 = getelementptr inbounds i8, i8* %ct, i64 216
  %182 = bitcast i8* %181 to <8 x i8>*
  %wide.load78.6 = load <8 x i8>, <8 x i8>* %182, align 1, !tbaa !7
  %183 = xor <8 x i8> %wide.load75.6, %wide.load.6
  %184 = xor <8 x i8> %wide.load76.6, %wide.load72.6
  %185 = xor <8 x i8> %wide.load77.6, %wide.load73.6
  %186 = xor <8 x i8> %wide.load78.6, %wide.load74.6
  %187 = or <8 x i8> %163, %183
  %188 = or <8 x i8> %164, %184
  %189 = or <8 x i8> %165, %185
  %190 = or <8 x i8> %166, %186
  %191 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 224
  %192 = bitcast i8* %191 to <8 x i8>*
  %wide.load.7 = load <8 x i8>, <8 x i8>* %192, align 16, !tbaa !7
  %193 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 232
  %194 = bitcast i8* %193 to <8 x i8>*
  %wide.load72.7 = load <8 x i8>, <8 x i8>* %194, align 8, !tbaa !7
  %195 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 240
  %196 = bitcast i8* %195 to <8 x i8>*
  %wide.load73.7 = load <8 x i8>, <8 x i8>* %196, align 16, !tbaa !7
  %197 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 248
  %198 = bitcast i8* %197 to <8 x i8>*
  %wide.load74.7 = load <8 x i8>, <8 x i8>* %198, align 8, !tbaa !7
  %199 = getelementptr inbounds i8, i8* %ct, i64 224
  %200 = bitcast i8* %199 to <8 x i8>*
  %wide.load75.7 = load <8 x i8>, <8 x i8>* %200, align 1, !tbaa !7
  %201 = getelementptr inbounds i8, i8* %ct, i64 232
  %202 = bitcast i8* %201 to <8 x i8>*
  %wide.load76.7 = load <8 x i8>, <8 x i8>* %202, align 1, !tbaa !7
  %203 = getelementptr inbounds i8, i8* %ct, i64 240
  %204 = bitcast i8* %203 to <8 x i8>*
  %wide.load77.7 = load <8 x i8>, <8 x i8>* %204, align 1, !tbaa !7
  %205 = getelementptr inbounds i8, i8* %ct, i64 248
  %206 = bitcast i8* %205 to <8 x i8>*
  %wide.load78.7 = load <8 x i8>, <8 x i8>* %206, align 1, !tbaa !7
  %207 = xor <8 x i8> %wide.load75.7, %wide.load.7
  %208 = xor <8 x i8> %wide.load76.7, %wide.load72.7
  %209 = xor <8 x i8> %wide.load77.7, %wide.load73.7
  %210 = xor <8 x i8> %wide.load78.7, %wide.load74.7
  %211 = or <8 x i8> %187, %207
  %212 = or <8 x i8> %188, %208
  %213 = or <8 x i8> %189, %209
  %214 = or <8 x i8> %190, %210
  %215 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 256
  %216 = bitcast i8* %215 to <8 x i8>*
  %wide.load.8 = load <8 x i8>, <8 x i8>* %216, align 16, !tbaa !7
  %217 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 264
  %218 = bitcast i8* %217 to <8 x i8>*
  %wide.load72.8 = load <8 x i8>, <8 x i8>* %218, align 8, !tbaa !7
  %219 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 272
  %220 = bitcast i8* %219 to <8 x i8>*
  %wide.load73.8 = load <8 x i8>, <8 x i8>* %220, align 16, !tbaa !7
  %221 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 280
  %222 = bitcast i8* %221 to <8 x i8>*
  %wide.load74.8 = load <8 x i8>, <8 x i8>* %222, align 8, !tbaa !7
  %223 = getelementptr inbounds i8, i8* %ct, i64 256
  %224 = bitcast i8* %223 to <8 x i8>*
  %wide.load75.8 = load <8 x i8>, <8 x i8>* %224, align 1, !tbaa !7
  %225 = getelementptr inbounds i8, i8* %ct, i64 264
  %226 = bitcast i8* %225 to <8 x i8>*
  %wide.load76.8 = load <8 x i8>, <8 x i8>* %226, align 1, !tbaa !7
  %227 = getelementptr inbounds i8, i8* %ct, i64 272
  %228 = bitcast i8* %227 to <8 x i8>*
  %wide.load77.8 = load <8 x i8>, <8 x i8>* %228, align 1, !tbaa !7
  %229 = getelementptr inbounds i8, i8* %ct, i64 280
  %230 = bitcast i8* %229 to <8 x i8>*
  %wide.load78.8 = load <8 x i8>, <8 x i8>* %230, align 1, !tbaa !7
  %231 = xor <8 x i8> %wide.load75.8, %wide.load.8
  %232 = xor <8 x i8> %wide.load76.8, %wide.load72.8
  %233 = xor <8 x i8> %wide.load77.8, %wide.load73.8
  %234 = xor <8 x i8> %wide.load78.8, %wide.load74.8
  %235 = or <8 x i8> %211, %231
  %236 = or <8 x i8> %212, %232
  %237 = or <8 x i8> %213, %233
  %238 = or <8 x i8> %214, %234
  %239 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 288
  %240 = bitcast i8* %239 to <8 x i8>*
  %wide.load.9 = load <8 x i8>, <8 x i8>* %240, align 16, !tbaa !7
  %241 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 296
  %242 = bitcast i8* %241 to <8 x i8>*
  %wide.load72.9 = load <8 x i8>, <8 x i8>* %242, align 8, !tbaa !7
  %243 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 304
  %244 = bitcast i8* %243 to <8 x i8>*
  %wide.load73.9 = load <8 x i8>, <8 x i8>* %244, align 16, !tbaa !7
  %245 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 312
  %246 = bitcast i8* %245 to <8 x i8>*
  %wide.load74.9 = load <8 x i8>, <8 x i8>* %246, align 8, !tbaa !7
  %247 = getelementptr inbounds i8, i8* %ct, i64 288
  %248 = bitcast i8* %247 to <8 x i8>*
  %wide.load75.9 = load <8 x i8>, <8 x i8>* %248, align 1, !tbaa !7
  %249 = getelementptr inbounds i8, i8* %ct, i64 296
  %250 = bitcast i8* %249 to <8 x i8>*
  %wide.load76.9 = load <8 x i8>, <8 x i8>* %250, align 1, !tbaa !7
  %251 = getelementptr inbounds i8, i8* %ct, i64 304
  %252 = bitcast i8* %251 to <8 x i8>*
  %wide.load77.9 = load <8 x i8>, <8 x i8>* %252, align 1, !tbaa !7
  %253 = getelementptr inbounds i8, i8* %ct, i64 312
  %254 = bitcast i8* %253 to <8 x i8>*
  %wide.load78.9 = load <8 x i8>, <8 x i8>* %254, align 1, !tbaa !7
  %255 = xor <8 x i8> %wide.load75.9, %wide.load.9
  %256 = xor <8 x i8> %wide.load76.9, %wide.load72.9
  %257 = xor <8 x i8> %wide.load77.9, %wide.load73.9
  %258 = xor <8 x i8> %wide.load78.9, %wide.load74.9
  %259 = or <8 x i8> %235, %255
  %260 = or <8 x i8> %236, %256
  %261 = or <8 x i8> %237, %257
  %262 = or <8 x i8> %238, %258
  %263 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 320
  %264 = bitcast i8* %263 to <8 x i8>*
  %wide.load.10 = load <8 x i8>, <8 x i8>* %264, align 16, !tbaa !7
  %265 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 328
  %266 = bitcast i8* %265 to <8 x i8>*
  %wide.load72.10 = load <8 x i8>, <8 x i8>* %266, align 8, !tbaa !7
  %267 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 336
  %268 = bitcast i8* %267 to <8 x i8>*
  %wide.load73.10 = load <8 x i8>, <8 x i8>* %268, align 16, !tbaa !7
  %269 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 344
  %270 = bitcast i8* %269 to <8 x i8>*
  %wide.load74.10 = load <8 x i8>, <8 x i8>* %270, align 8, !tbaa !7
  %271 = getelementptr inbounds i8, i8* %ct, i64 320
  %272 = bitcast i8* %271 to <8 x i8>*
  %wide.load75.10 = load <8 x i8>, <8 x i8>* %272, align 1, !tbaa !7
  %273 = getelementptr inbounds i8, i8* %ct, i64 328
  %274 = bitcast i8* %273 to <8 x i8>*
  %wide.load76.10 = load <8 x i8>, <8 x i8>* %274, align 1, !tbaa !7
  %275 = getelementptr inbounds i8, i8* %ct, i64 336
  %276 = bitcast i8* %275 to <8 x i8>*
  %wide.load77.10 = load <8 x i8>, <8 x i8>* %276, align 1, !tbaa !7
  %277 = getelementptr inbounds i8, i8* %ct, i64 344
  %278 = bitcast i8* %277 to <8 x i8>*
  %wide.load78.10 = load <8 x i8>, <8 x i8>* %278, align 1, !tbaa !7
  %279 = xor <8 x i8> %wide.load75.10, %wide.load.10
  %280 = xor <8 x i8> %wide.load76.10, %wide.load72.10
  %281 = xor <8 x i8> %wide.load77.10, %wide.load73.10
  %282 = xor <8 x i8> %wide.load78.10, %wide.load74.10
  %283 = or <8 x i8> %259, %279
  %284 = or <8 x i8> %260, %280
  %285 = or <8 x i8> %261, %281
  %286 = or <8 x i8> %262, %282
  %287 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 352
  %288 = bitcast i8* %287 to <8 x i8>*
  %wide.load.11 = load <8 x i8>, <8 x i8>* %288, align 16, !tbaa !7
  %289 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 360
  %290 = bitcast i8* %289 to <8 x i8>*
  %wide.load72.11 = load <8 x i8>, <8 x i8>* %290, align 8, !tbaa !7
  %291 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 368
  %292 = bitcast i8* %291 to <8 x i8>*
  %wide.load73.11 = load <8 x i8>, <8 x i8>* %292, align 16, !tbaa !7
  %293 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 376
  %294 = bitcast i8* %293 to <8 x i8>*
  %wide.load74.11 = load <8 x i8>, <8 x i8>* %294, align 8, !tbaa !7
  %295 = getelementptr inbounds i8, i8* %ct, i64 352
  %296 = bitcast i8* %295 to <8 x i8>*
  %wide.load75.11 = load <8 x i8>, <8 x i8>* %296, align 1, !tbaa !7
  %297 = getelementptr inbounds i8, i8* %ct, i64 360
  %298 = bitcast i8* %297 to <8 x i8>*
  %wide.load76.11 = load <8 x i8>, <8 x i8>* %298, align 1, !tbaa !7
  %299 = getelementptr inbounds i8, i8* %ct, i64 368
  %300 = bitcast i8* %299 to <8 x i8>*
  %wide.load77.11 = load <8 x i8>, <8 x i8>* %300, align 1, !tbaa !7
  %301 = getelementptr inbounds i8, i8* %ct, i64 376
  %302 = bitcast i8* %301 to <8 x i8>*
  %wide.load78.11 = load <8 x i8>, <8 x i8>* %302, align 1, !tbaa !7
  %303 = xor <8 x i8> %wide.load75.11, %wide.load.11
  %304 = xor <8 x i8> %wide.load76.11, %wide.load72.11
  %305 = xor <8 x i8> %wide.load77.11, %wide.load73.11
  %306 = xor <8 x i8> %wide.load78.11, %wide.load74.11
  %307 = or <8 x i8> %283, %303
  %308 = or <8 x i8> %284, %304
  %309 = or <8 x i8> %285, %305
  %310 = or <8 x i8> %286, %306
  %311 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 384
  %312 = bitcast i8* %311 to <8 x i8>*
  %wide.load.12 = load <8 x i8>, <8 x i8>* %312, align 16, !tbaa !7
  %313 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 392
  %314 = bitcast i8* %313 to <8 x i8>*
  %wide.load72.12 = load <8 x i8>, <8 x i8>* %314, align 8, !tbaa !7
  %315 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 400
  %316 = bitcast i8* %315 to <8 x i8>*
  %wide.load73.12 = load <8 x i8>, <8 x i8>* %316, align 16, !tbaa !7
  %317 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 408
  %318 = bitcast i8* %317 to <8 x i8>*
  %wide.load74.12 = load <8 x i8>, <8 x i8>* %318, align 8, !tbaa !7
  %319 = getelementptr inbounds i8, i8* %ct, i64 384
  %320 = bitcast i8* %319 to <8 x i8>*
  %wide.load75.12 = load <8 x i8>, <8 x i8>* %320, align 1, !tbaa !7
  %321 = getelementptr inbounds i8, i8* %ct, i64 392
  %322 = bitcast i8* %321 to <8 x i8>*
  %wide.load76.12 = load <8 x i8>, <8 x i8>* %322, align 1, !tbaa !7
  %323 = getelementptr inbounds i8, i8* %ct, i64 400
  %324 = bitcast i8* %323 to <8 x i8>*
  %wide.load77.12 = load <8 x i8>, <8 x i8>* %324, align 1, !tbaa !7
  %325 = getelementptr inbounds i8, i8* %ct, i64 408
  %326 = bitcast i8* %325 to <8 x i8>*
  %wide.load78.12 = load <8 x i8>, <8 x i8>* %326, align 1, !tbaa !7
  %327 = xor <8 x i8> %wide.load75.12, %wide.load.12
  %328 = xor <8 x i8> %wide.load76.12, %wide.load72.12
  %329 = xor <8 x i8> %wide.load77.12, %wide.load73.12
  %330 = xor <8 x i8> %wide.load78.12, %wide.load74.12
  %331 = or <8 x i8> %307, %327
  %332 = or <8 x i8> %308, %328
  %333 = or <8 x i8> %309, %329
  %334 = or <8 x i8> %310, %330
  %335 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 416
  %336 = bitcast i8* %335 to <8 x i8>*
  %wide.load.13 = load <8 x i8>, <8 x i8>* %336, align 16, !tbaa !7
  %337 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 424
  %338 = bitcast i8* %337 to <8 x i8>*
  %wide.load72.13 = load <8 x i8>, <8 x i8>* %338, align 8, !tbaa !7
  %339 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 432
  %340 = bitcast i8* %339 to <8 x i8>*
  %wide.load73.13 = load <8 x i8>, <8 x i8>* %340, align 16, !tbaa !7
  %341 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 440
  %342 = bitcast i8* %341 to <8 x i8>*
  %wide.load74.13 = load <8 x i8>, <8 x i8>* %342, align 8, !tbaa !7
  %343 = getelementptr inbounds i8, i8* %ct, i64 416
  %344 = bitcast i8* %343 to <8 x i8>*
  %wide.load75.13 = load <8 x i8>, <8 x i8>* %344, align 1, !tbaa !7
  %345 = getelementptr inbounds i8, i8* %ct, i64 424
  %346 = bitcast i8* %345 to <8 x i8>*
  %wide.load76.13 = load <8 x i8>, <8 x i8>* %346, align 1, !tbaa !7
  %347 = getelementptr inbounds i8, i8* %ct, i64 432
  %348 = bitcast i8* %347 to <8 x i8>*
  %wide.load77.13 = load <8 x i8>, <8 x i8>* %348, align 1, !tbaa !7
  %349 = getelementptr inbounds i8, i8* %ct, i64 440
  %350 = bitcast i8* %349 to <8 x i8>*
  %wide.load78.13 = load <8 x i8>, <8 x i8>* %350, align 1, !tbaa !7
  %351 = xor <8 x i8> %wide.load75.13, %wide.load.13
  %352 = xor <8 x i8> %wide.load76.13, %wide.load72.13
  %353 = xor <8 x i8> %wide.load77.13, %wide.load73.13
  %354 = xor <8 x i8> %wide.load78.13, %wide.load74.13
  %355 = or <8 x i8> %331, %351
  %356 = or <8 x i8> %332, %352
  %357 = or <8 x i8> %333, %353
  %358 = or <8 x i8> %334, %354
  %bin.rdx89 = or <8 x i8> %356, %355
  %bin.rdx7990 = or <8 x i8> %357, %bin.rdx89
  %bin.rdx8091 = or <8 x i8> %358, %bin.rdx7990
  %bin.rdx80 = zext <8 x i8> %bin.rdx8091 to <8 x i32>
  %rdx.shuf = shufflevector <8 x i32> %bin.rdx80, <8 x i32> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx81 = or <8 x i32> %rdx.shuf, %bin.rdx80
  %rdx.shuf82 = shufflevector <8 x i32> %bin.rdx81, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx83 = or <8 x i32> %bin.rdx81, %rdx.shuf82
  %rdx.shuf84 = shufflevector <8 x i32> %bin.rdx83, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %bin.rdx85 = or <8 x i32> %bin.rdx83, %rdx.shuf84
  %359 = extractelement <8 x i32> %bin.rdx85, i32 0
  %arrayidx.i = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 448
  %360 = load i8, i8* %arrayidx.i, align 16, !tbaa !7
  %arrayidx2.i = getelementptr inbounds i8, i8* %ct, i64 448
  %361 = load i8, i8* %arrayidx2.i, align 1, !tbaa !7
  %xor13.i = xor i8 %361, %360
  %xor.i = zext i8 %xor13.i to i32
  %or.i = or i32 %359, %xor.i
  %arrayidx.i.1 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 449
  %362 = load i8, i8* %arrayidx.i.1, align 1, !tbaa !7
  %arrayidx2.i.1 = getelementptr inbounds i8, i8* %ct, i64 449
  %363 = load i8, i8* %arrayidx2.i.1, align 1, !tbaa !7
  %xor13.i.1 = xor i8 %363, %362
  %xor.i.1 = zext i8 %xor13.i.1 to i32
  %or.i.1 = or i32 %or.i, %xor.i.1
  %arrayidx.i.2 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 450
  %364 = load i8, i8* %arrayidx.i.2, align 2, !tbaa !7
  %arrayidx2.i.2 = getelementptr inbounds i8, i8* %ct, i64 450
  %365 = load i8, i8* %arrayidx2.i.2, align 1, !tbaa !7
  %xor13.i.2 = xor i8 %365, %364
  %xor.i.2 = zext i8 %xor13.i.2 to i32
  %or.i.2 = or i32 %or.i.1, %xor.i.2
  %arrayidx.i.3 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 451
  %366 = load i8, i8* %arrayidx.i.3, align 1, !tbaa !7
  %arrayidx2.i.3 = getelementptr inbounds i8, i8* %ct, i64 451
  %367 = load i8, i8* %arrayidx2.i.3, align 1, !tbaa !7
  %xor13.i.3 = xor i8 %367, %366
  %xor.i.3 = zext i8 %xor13.i.3 to i32
  %or.i.3 = or i32 %or.i.2, %xor.i.3
  %arrayidx.i.4 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 452
  %368 = load i8, i8* %arrayidx.i.4, align 4, !tbaa !7
  %arrayidx2.i.4 = getelementptr inbounds i8, i8* %ct, i64 452
  %369 = load i8, i8* %arrayidx2.i.4, align 1, !tbaa !7
  %xor13.i.4 = xor i8 %369, %368
  %xor.i.4 = zext i8 %xor13.i.4 to i32
  %or.i.4 = or i32 %or.i.3, %xor.i.4
  %arrayidx.i.5 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 453
  %370 = load i8, i8* %arrayidx.i.5, align 1, !tbaa !7
  %arrayidx2.i.5 = getelementptr inbounds i8, i8* %ct, i64 453
  %371 = load i8, i8* %arrayidx2.i.5, align 1, !tbaa !7
  %xor13.i.5 = xor i8 %371, %370
  %xor.i.5 = zext i8 %xor13.i.5 to i32
  %or.i.5 = or i32 %or.i.4, %xor.i.5
  %arrayidx.i.6 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 454
  %372 = load i8, i8* %arrayidx.i.6, align 2, !tbaa !7
  %arrayidx2.i.6 = getelementptr inbounds i8, i8* %ct, i64 454
  %373 = load i8, i8* %arrayidx2.i.6, align 1, !tbaa !7
  %xor13.i.6 = xor i8 %373, %372
  %xor.i.6 = zext i8 %xor13.i.6 to i32
  %or.i.6 = or i32 %or.i.5, %xor.i.6
  %arrayidx.i.7 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 455
  %374 = load i8, i8* %arrayidx.i.7, align 1, !tbaa !7
  %arrayidx2.i.7 = getelementptr inbounds i8, i8* %ct, i64 455
  %375 = load i8, i8* %arrayidx2.i.7, align 1, !tbaa !7
  %xor13.i.7 = xor i8 %375, %374
  %xor.i.7 = zext i8 %xor13.i.7 to i32
  %or.i.7 = or i32 %or.i.6, %xor.i.7
  %arrayidx.i.8 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 456
  %376 = load i8, i8* %arrayidx.i.8, align 8, !tbaa !7
  %arrayidx2.i.8 = getelementptr inbounds i8, i8* %ct, i64 456
  %377 = load i8, i8* %arrayidx2.i.8, align 1, !tbaa !7
  %xor13.i.8 = xor i8 %377, %376
  %xor.i.8 = zext i8 %xor13.i.8 to i32
  %or.i.8 = or i32 %or.i.7, %xor.i.8
  %arrayidx.i.9 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 457
  %378 = load i8, i8* %arrayidx.i.9, align 1, !tbaa !7
  %arrayidx2.i.9 = getelementptr inbounds i8, i8* %ct, i64 457
  %379 = load i8, i8* %arrayidx2.i.9, align 1, !tbaa !7
  %xor13.i.9 = xor i8 %379, %378
  %xor.i.9 = zext i8 %xor13.i.9 to i32
  %or.i.9 = or i32 %or.i.8, %xor.i.9
  %arrayidx.i.10 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 458
  %380 = load i8, i8* %arrayidx.i.10, align 2, !tbaa !7
  %arrayidx2.i.10 = getelementptr inbounds i8, i8* %ct, i64 458
  %381 = load i8, i8* %arrayidx2.i.10, align 1, !tbaa !7
  %xor13.i.10 = xor i8 %381, %380
  %xor.i.10 = zext i8 %xor13.i.10 to i32
  %or.i.10 = or i32 %or.i.9, %xor.i.10
  %arrayidx.i.11 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 459
  %382 = load i8, i8* %arrayidx.i.11, align 1, !tbaa !7
  %arrayidx2.i.11 = getelementptr inbounds i8, i8* %ct, i64 459
  %383 = load i8, i8* %arrayidx2.i.11, align 1, !tbaa !7
  %xor13.i.11 = xor i8 %383, %382
  %xor.i.11 = zext i8 %xor13.i.11 to i32
  %or.i.11 = or i32 %or.i.10, %xor.i.11
  %arrayidx.i.12 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 460
  %384 = load i8, i8* %arrayidx.i.12, align 4, !tbaa !7
  %arrayidx2.i.12 = getelementptr inbounds i8, i8* %ct, i64 460
  %385 = load i8, i8* %arrayidx2.i.12, align 1, !tbaa !7
  %xor13.i.12 = xor i8 %385, %384
  %xor.i.12 = zext i8 %xor13.i.12 to i32
  %or.i.12 = or i32 %or.i.11, %xor.i.12
  %arrayidx.i.13 = getelementptr inbounds [462 x i8], [462 x i8]* %c0_, i64 0, i64 461
  %386 = load i8, i8* %arrayidx.i.13, align 1, !tbaa !7
  %arrayidx2.i.13 = getelementptr inbounds i8, i8* %ct, i64 461
  %387 = load i8, i8* %arrayidx2.i.13, align 1, !tbaa !7
  %xor13.i.13 = xor i8 %387, %386
  %xor.i.13 = zext i8 %xor13.i.13 to i32
  %or.i.13 = or i32 %or.i.12, %xor.i.13
  %phitmp.i = sub i32 0, %or.i.13
  %phitmp17.i = ashr i32 %phitmp.i, 31
  %phitmp18.i = trunc i32 %phitmp17.i to i8
  br label %Hashing

Hashing:                                          ; preds = %entry.Hashing_crit_edge, %if.end
  %arrayidx23.pre-phi = phi i8* [ %.pre65, %entry.Hashing_crit_edge ], [ %arrayidx10, %if.end ]
  %arrayidx3.i.23.pre-phi = phi i8* [ %.pre64, %entry.Hashing_crit_edge ], [ %arrayidx9.23, %if.end ]
  %arrayidx3.i.22.pre-phi = phi i8* [ %.pre63, %entry.Hashing_crit_edge ], [ %arrayidx9.22, %if.end ]
  %arrayidx3.i.21.pre-phi = phi i8* [ %.pre62, %entry.Hashing_crit_edge ], [ %arrayidx9.21, %if.end ]
  %arrayidx3.i.20.pre-phi = phi i8* [ %.pre61, %entry.Hashing_crit_edge ], [ %arrayidx9.20, %if.end ]
  %arrayidx3.i.19.pre-phi = phi i8* [ %.pre60, %entry.Hashing_crit_edge ], [ %arrayidx9.19, %if.end ]
  %arrayidx3.i.18.pre-phi = phi i8* [ %.pre59, %entry.Hashing_crit_edge ], [ %arrayidx9.18, %if.end ]
  %arrayidx3.i.17.pre-phi = phi i8* [ %.pre58, %entry.Hashing_crit_edge ], [ %arrayidx9.17, %if.end ]
  %arrayidx3.i.16.pre-phi = phi i8* [ %.pre57, %entry.Hashing_crit_edge ], [ %arrayidx9.16, %if.end ]
  %arrayidx3.i.15.pre-phi = phi i8* [ %.pre56, %entry.Hashing_crit_edge ], [ %arrayidx9.15, %if.end ]
  %arrayidx3.i.14.pre-phi = phi i8* [ %.pre55, %entry.Hashing_crit_edge ], [ %arrayidx9.14, %if.end ]
  %arrayidx3.i.13.pre-phi = phi i8* [ %.pre54, %entry.Hashing_crit_edge ], [ %arrayidx9.13, %if.end ]
  %arrayidx3.i.12.pre-phi = phi i8* [ %.pre53, %entry.Hashing_crit_edge ], [ %arrayidx9.12, %if.end ]
  %arrayidx3.i.11.pre-phi = phi i8* [ %.pre52, %entry.Hashing_crit_edge ], [ %arrayidx9.11, %if.end ]
  %arrayidx3.i.10.pre-phi = phi i8* [ %.pre51, %entry.Hashing_crit_edge ], [ %arrayidx9.10, %if.end ]
  %arrayidx3.i.9.pre-phi = phi i8* [ %.pre50, %entry.Hashing_crit_edge ], [ %arrayidx9.9, %if.end ]
  %arrayidx3.i.8.pre-phi = phi i8* [ %.pre49, %entry.Hashing_crit_edge ], [ %arrayidx9.8, %if.end ]
  %arrayidx3.i.7.pre-phi = phi i8* [ %.pre48, %entry.Hashing_crit_edge ], [ %arrayidx9.7, %if.end ]
  %arrayidx3.i.6.pre-phi = phi i8* [ %.pre47, %entry.Hashing_crit_edge ], [ %arrayidx9.6, %if.end ]
  %arrayidx3.i.5.pre-phi = phi i8* [ %.pre46, %entry.Hashing_crit_edge ], [ %arrayidx9.5, %if.end ]
  %arrayidx3.i.4.pre-phi = phi i8* [ %.pre45, %entry.Hashing_crit_edge ], [ %arrayidx9.4, %if.end ]
  %arrayidx3.i.3.pre-phi = phi i8* [ %.pre44, %entry.Hashing_crit_edge ], [ %arrayidx9.3, %if.end ]
  %arrayidx3.i.2.pre-phi = phi i8* [ %.pre43, %entry.Hashing_crit_edge ], [ %arrayidx9.2, %if.end ]
  %arrayidx3.i.1.pre-phi = phi i8* [ %.pre, %entry.Hashing_crit_edge ], [ %arrayidx9.1, %if.end ]
  %selector.0 = phi i8 [ -1, %entry.Hashing_crit_edge ], [ %phitmp18.i, %if.end ]
  %388 = load i8, i8* %sk, align 1, !tbaa !7
  %389 = load i8, i8* %4, align 16, !tbaa !7
  %xor16.i = xor i8 %389, %388
  %and18.i = and i8 %xor16.i, %selector.0
  %xor819.i = xor i8 %and18.i, %389
  store i8 %xor819.i, i8* %4, align 16, !tbaa !7
  %arrayidx.i37.1 = getelementptr inbounds i8, i8* %sk, i64 1
  %390 = load i8, i8* %arrayidx.i37.1, align 1, !tbaa !7
  %391 = load i8, i8* %arrayidx3.i.1.pre-phi, align 1, !tbaa !7
  %xor16.i.1 = xor i8 %391, %390
  %and18.i.1 = and i8 %xor16.i.1, %selector.0
  %xor819.i.1 = xor i8 %and18.i.1, %391
  store i8 %xor819.i.1, i8* %arrayidx3.i.1.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.2 = getelementptr inbounds i8, i8* %sk, i64 2
  %392 = load i8, i8* %arrayidx.i37.2, align 1, !tbaa !7
  %393 = load i8, i8* %arrayidx3.i.2.pre-phi, align 1, !tbaa !7
  %xor16.i.2 = xor i8 %393, %392
  %and18.i.2 = and i8 %xor16.i.2, %selector.0
  %xor819.i.2 = xor i8 %and18.i.2, %393
  store i8 %xor819.i.2, i8* %arrayidx3.i.2.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.3 = getelementptr inbounds i8, i8* %sk, i64 3
  %394 = load i8, i8* %arrayidx.i37.3, align 1, !tbaa !7
  %395 = load i8, i8* %arrayidx3.i.3.pre-phi, align 1, !tbaa !7
  %xor16.i.3 = xor i8 %395, %394
  %and18.i.3 = and i8 %xor16.i.3, %selector.0
  %xor819.i.3 = xor i8 %and18.i.3, %395
  store i8 %xor819.i.3, i8* %arrayidx3.i.3.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.4 = getelementptr inbounds i8, i8* %sk, i64 4
  %396 = load i8, i8* %arrayidx.i37.4, align 1, !tbaa !7
  %397 = load i8, i8* %arrayidx3.i.4.pre-phi, align 1, !tbaa !7
  %xor16.i.4 = xor i8 %397, %396
  %and18.i.4 = and i8 %xor16.i.4, %selector.0
  %xor819.i.4 = xor i8 %and18.i.4, %397
  store i8 %xor819.i.4, i8* %arrayidx3.i.4.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.5 = getelementptr inbounds i8, i8* %sk, i64 5
  %398 = load i8, i8* %arrayidx.i37.5, align 1, !tbaa !7
  %399 = load i8, i8* %arrayidx3.i.5.pre-phi, align 1, !tbaa !7
  %xor16.i.5 = xor i8 %399, %398
  %and18.i.5 = and i8 %xor16.i.5, %selector.0
  %xor819.i.5 = xor i8 %and18.i.5, %399
  store i8 %xor819.i.5, i8* %arrayidx3.i.5.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.6 = getelementptr inbounds i8, i8* %sk, i64 6
  %400 = load i8, i8* %arrayidx.i37.6, align 1, !tbaa !7
  %401 = load i8, i8* %arrayidx3.i.6.pre-phi, align 1, !tbaa !7
  %xor16.i.6 = xor i8 %401, %400
  %and18.i.6 = and i8 %xor16.i.6, %selector.0
  %xor819.i.6 = xor i8 %and18.i.6, %401
  store i8 %xor819.i.6, i8* %arrayidx3.i.6.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.7 = getelementptr inbounds i8, i8* %sk, i64 7
  %402 = load i8, i8* %arrayidx.i37.7, align 1, !tbaa !7
  %403 = load i8, i8* %arrayidx3.i.7.pre-phi, align 1, !tbaa !7
  %xor16.i.7 = xor i8 %403, %402
  %and18.i.7 = and i8 %xor16.i.7, %selector.0
  %xor819.i.7 = xor i8 %and18.i.7, %403
  store i8 %xor819.i.7, i8* %arrayidx3.i.7.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.8 = getelementptr inbounds i8, i8* %sk, i64 8
  %404 = load i8, i8* %arrayidx.i37.8, align 1, !tbaa !7
  %405 = load i8, i8* %arrayidx3.i.8.pre-phi, align 1, !tbaa !7
  %xor16.i.8 = xor i8 %405, %404
  %and18.i.8 = and i8 %xor16.i.8, %selector.0
  %xor819.i.8 = xor i8 %and18.i.8, %405
  store i8 %xor819.i.8, i8* %arrayidx3.i.8.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.9 = getelementptr inbounds i8, i8* %sk, i64 9
  %406 = load i8, i8* %arrayidx.i37.9, align 1, !tbaa !7
  %407 = load i8, i8* %arrayidx3.i.9.pre-phi, align 1, !tbaa !7
  %xor16.i.9 = xor i8 %407, %406
  %and18.i.9 = and i8 %xor16.i.9, %selector.0
  %xor819.i.9 = xor i8 %and18.i.9, %407
  store i8 %xor819.i.9, i8* %arrayidx3.i.9.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.10 = getelementptr inbounds i8, i8* %sk, i64 10
  %408 = load i8, i8* %arrayidx.i37.10, align 1, !tbaa !7
  %409 = load i8, i8* %arrayidx3.i.10.pre-phi, align 1, !tbaa !7
  %xor16.i.10 = xor i8 %409, %408
  %and18.i.10 = and i8 %xor16.i.10, %selector.0
  %xor819.i.10 = xor i8 %and18.i.10, %409
  store i8 %xor819.i.10, i8* %arrayidx3.i.10.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.11 = getelementptr inbounds i8, i8* %sk, i64 11
  %410 = load i8, i8* %arrayidx.i37.11, align 1, !tbaa !7
  %411 = load i8, i8* %arrayidx3.i.11.pre-phi, align 1, !tbaa !7
  %xor16.i.11 = xor i8 %411, %410
  %and18.i.11 = and i8 %xor16.i.11, %selector.0
  %xor819.i.11 = xor i8 %and18.i.11, %411
  store i8 %xor819.i.11, i8* %arrayidx3.i.11.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.12 = getelementptr inbounds i8, i8* %sk, i64 12
  %412 = load i8, i8* %arrayidx.i37.12, align 1, !tbaa !7
  %413 = load i8, i8* %arrayidx3.i.12.pre-phi, align 1, !tbaa !7
  %xor16.i.12 = xor i8 %413, %412
  %and18.i.12 = and i8 %xor16.i.12, %selector.0
  %xor819.i.12 = xor i8 %and18.i.12, %413
  store i8 %xor819.i.12, i8* %arrayidx3.i.12.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.13 = getelementptr inbounds i8, i8* %sk, i64 13
  %414 = load i8, i8* %arrayidx.i37.13, align 1, !tbaa !7
  %415 = load i8, i8* %arrayidx3.i.13.pre-phi, align 1, !tbaa !7
  %xor16.i.13 = xor i8 %415, %414
  %and18.i.13 = and i8 %xor16.i.13, %selector.0
  %xor819.i.13 = xor i8 %and18.i.13, %415
  store i8 %xor819.i.13, i8* %arrayidx3.i.13.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.14 = getelementptr inbounds i8, i8* %sk, i64 14
  %416 = load i8, i8* %arrayidx.i37.14, align 1, !tbaa !7
  %417 = load i8, i8* %arrayidx3.i.14.pre-phi, align 1, !tbaa !7
  %xor16.i.14 = xor i8 %417, %416
  %and18.i.14 = and i8 %xor16.i.14, %selector.0
  %xor819.i.14 = xor i8 %and18.i.14, %417
  store i8 %xor819.i.14, i8* %arrayidx3.i.14.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.15 = getelementptr inbounds i8, i8* %sk, i64 15
  %418 = load i8, i8* %arrayidx.i37.15, align 1, !tbaa !7
  %419 = load i8, i8* %arrayidx3.i.15.pre-phi, align 1, !tbaa !7
  %xor16.i.15 = xor i8 %419, %418
  %and18.i.15 = and i8 %xor16.i.15, %selector.0
  %xor819.i.15 = xor i8 %and18.i.15, %419
  store i8 %xor819.i.15, i8* %arrayidx3.i.15.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.16 = getelementptr inbounds i8, i8* %sk, i64 16
  %420 = load i8, i8* %arrayidx.i37.16, align 1, !tbaa !7
  %421 = load i8, i8* %arrayidx3.i.16.pre-phi, align 1, !tbaa !7
  %xor16.i.16 = xor i8 %421, %420
  %and18.i.16 = and i8 %xor16.i.16, %selector.0
  %xor819.i.16 = xor i8 %and18.i.16, %421
  store i8 %xor819.i.16, i8* %arrayidx3.i.16.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.17 = getelementptr inbounds i8, i8* %sk, i64 17
  %422 = load i8, i8* %arrayidx.i37.17, align 1, !tbaa !7
  %423 = load i8, i8* %arrayidx3.i.17.pre-phi, align 1, !tbaa !7
  %xor16.i.17 = xor i8 %423, %422
  %and18.i.17 = and i8 %xor16.i.17, %selector.0
  %xor819.i.17 = xor i8 %and18.i.17, %423
  store i8 %xor819.i.17, i8* %arrayidx3.i.17.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.18 = getelementptr inbounds i8, i8* %sk, i64 18
  %424 = load i8, i8* %arrayidx.i37.18, align 1, !tbaa !7
  %425 = load i8, i8* %arrayidx3.i.18.pre-phi, align 1, !tbaa !7
  %xor16.i.18 = xor i8 %425, %424
  %and18.i.18 = and i8 %xor16.i.18, %selector.0
  %xor819.i.18 = xor i8 %and18.i.18, %425
  store i8 %xor819.i.18, i8* %arrayidx3.i.18.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.19 = getelementptr inbounds i8, i8* %sk, i64 19
  %426 = load i8, i8* %arrayidx.i37.19, align 1, !tbaa !7
  %427 = load i8, i8* %arrayidx3.i.19.pre-phi, align 1, !tbaa !7
  %xor16.i.19 = xor i8 %427, %426
  %and18.i.19 = and i8 %xor16.i.19, %selector.0
  %xor819.i.19 = xor i8 %and18.i.19, %427
  store i8 %xor819.i.19, i8* %arrayidx3.i.19.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.20 = getelementptr inbounds i8, i8* %sk, i64 20
  %428 = load i8, i8* %arrayidx.i37.20, align 1, !tbaa !7
  %429 = load i8, i8* %arrayidx3.i.20.pre-phi, align 1, !tbaa !7
  %xor16.i.20 = xor i8 %429, %428
  %and18.i.20 = and i8 %xor16.i.20, %selector.0
  %xor819.i.20 = xor i8 %and18.i.20, %429
  store i8 %xor819.i.20, i8* %arrayidx3.i.20.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.21 = getelementptr inbounds i8, i8* %sk, i64 21
  %430 = load i8, i8* %arrayidx.i37.21, align 1, !tbaa !7
  %431 = load i8, i8* %arrayidx3.i.21.pre-phi, align 1, !tbaa !7
  %xor16.i.21 = xor i8 %431, %430
  %and18.i.21 = and i8 %xor16.i.21, %selector.0
  %xor819.i.21 = xor i8 %and18.i.21, %431
  store i8 %xor819.i.21, i8* %arrayidx3.i.21.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.22 = getelementptr inbounds i8, i8* %sk, i64 22
  %432 = load i8, i8* %arrayidx.i37.22, align 1, !tbaa !7
  %433 = load i8, i8* %arrayidx3.i.22.pre-phi, align 1, !tbaa !7
  %xor16.i.22 = xor i8 %433, %432
  %and18.i.22 = and i8 %xor16.i.22, %selector.0
  %xor819.i.22 = xor i8 %and18.i.22, %433
  store i8 %xor819.i.22, i8* %arrayidx3.i.22.pre-phi, align 1, !tbaa !7
  %arrayidx.i37.23 = getelementptr inbounds i8, i8* %sk, i64 23
  %434 = load i8, i8* %arrayidx.i37.23, align 1, !tbaa !7
  %435 = load i8, i8* %arrayidx3.i.23.pre-phi, align 1, !tbaa !7
  %xor16.i.23 = xor i8 %435, %434
  %and18.i.23 = and i8 %xor16.i.23, %selector.0
  %xor819.i.23 = xor i8 %and18.i.23, %435
  store i8 %xor819.i.23, i8* %arrayidx3.i.23.pre-phi, align 1, !tbaa !7
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %arrayidx23.pre-phi, i8* align 1 %ct, i64 486, i1 false)
  call void @shake256(i8* %ss, i64 24, i8* nonnull %4, i64 510) #10
  call void @llvm.lifetime.end.p0i8(i64 510, i8* nonnull %4) #10
  call void @llvm.lifetime.end.p0i8(i64 462, i8* nonnull %3) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %2) #10
  call void @llvm.lifetime.end.p0i8(i64 154, i8* nonnull %1) #10
  call void @llvm.lifetime.end.p0i8(i64 39, i8* nonnull %0) #10
  ret i32 0
}

declare void @mp_sub610_p2(i64*, i64*, i64*) local_unnamed_addr #5

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.umul.with.overflow.i64(i64, i64) #9

attributes #0 = { norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { norecurse nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { inlinehint norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind readonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="haswell" "target-features"="+aes,+avx,+avx2,+bmi,+bmi2,+cmov,+cx16,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt,-adx,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,-cldemote,-clflushopt,-clwb,-clzero,-fma4,-gfni,-lwp,-movdir64b,-movdiri,-mwaitx,-pconfig,-pku,-prefetchwt1,-prfchw,-ptwrite,-rdpid,-rdseed,-rtm,-sgx,-sha,-shstk,-sse4a,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,-xsavec,-xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nounwind readnone speculatable }
attributes #10 = { nounwind }

!llvm.module.flags = !{!0, !1}
!llvm.ident = !{!2}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"clang version 7.0.0 (tags/RELEASE_700/final)"}
!3 = !{!4, !4, i64 0}
!4 = !{!"long long", !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C/C++ TBAA"}
!7 = !{!5, !5, i64 0}
!8 = distinct !{!8, !9}
!9 = !{!"llvm.loop.isvectorized", i32 1}
!10 = distinct !{!10, !11, !9}
!11 = !{!"llvm.loop.unroll.runtime.disable"}
!12 = distinct !{!12, !13}
!13 = !{!"llvm.loop.unroll.disable"}
!14 = !{!15}
!15 = distinct !{!15, !16}
!16 = distinct !{!16, !"LVerDomain"}
!17 = !{!18}
!18 = distinct !{!18, !16}
!19 = distinct !{!19, !9}
!20 = distinct !{!20, !9}
!21 = !{!22}
!22 = distinct !{!22, !23}
!23 = distinct !{!23, !"LVerDomain"}
!24 = !{!25}
!25 = distinct !{!25, !23}
!26 = distinct !{!26, !9}
!27 = distinct !{!27, !13}
!28 = distinct !{!28, !13}
!29 = distinct !{!29, !9}
!30 = distinct !{!30, !13}
!31 = !{!32}
!32 = distinct !{!32, !33}
!33 = distinct !{!33, !"LVerDomain"}
!34 = !{!35}
!35 = distinct !{!35, !33}
!36 = distinct !{!36, !9}
!37 = distinct !{!37, !13}
!38 = distinct !{!38, !13}
!39 = distinct !{!39, !9}
!40 = distinct !{!40, !13}
!41 = distinct !{!41, !9}
!42 = distinct !{!42, !9}
!43 = !{!44}
!44 = distinct !{!44, !45}
!45 = distinct !{!45, !"LVerDomain"}
!46 = !{!47}
!47 = distinct !{!47, !45}
!48 = distinct !{!48, !9}
!49 = distinct !{!49, !13}
!50 = distinct !{!50, !9}
!51 = distinct !{!51, !13}
!52 = !{!53}
!53 = distinct !{!53, !54}
!54 = distinct !{!54, !"LVerDomain"}
!55 = !{!56}
!56 = distinct !{!56, !54}
!57 = distinct !{!57, !9}
!58 = distinct !{!58, !9}
!59 = !{!60, !60, i64 0}
!60 = !{!"int", !5, i64 0}
